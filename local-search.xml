<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>安装cuda驱动报错</title>
    <link href="/2023/04/11/%E5%AE%89%E8%A3%85cuda%E9%A9%B1%E5%8A%A8%E6%8A%A5%E9%94%99/"/>
    <url>/2023/04/11/%E5%AE%89%E8%A3%85cuda%E9%A9%B1%E5%8A%A8%E6%8A%A5%E9%94%99/</url>
    
    <content type="html"><![CDATA[<h1 id="当安装cuda时报错如下"><a href="#当安装cuda时报错如下" class="headerlink" title="当安装cuda时报错如下"></a>当安装cuda时报错如下</h1><p>sudo sh .&#x2F;cuda_11.7.1_515.65.01_linux.run</p><figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs vbnet">cat /var/log/nvidia-installer.log<br><span class="hljs-keyword">Using</span> built-<span class="hljs-keyword">in</span> stream user <span class="hljs-keyword">interface</span><br>-&gt; Detected <span class="hljs-number">12</span> CPUs online; setting concurrency level <span class="hljs-keyword">to</span> <span class="hljs-number">12</span>.<br><span class="hljs-symbol">ERROR:</span> An NVIDIA kernel <span class="hljs-keyword">module</span> <span class="hljs-comment">&#x27;nvidia-uvm&#x27; appears to already be loaded in your kernel.  This may be because it is in use (for example, by an X server, a CUDA program, or the NVIDIA Persistence Daemon), but this may also happen if your kernel was configured without support for module unloading.  Please be sure to exit any programs that may be using the GPU(s) before attempting to upgrade your driver.  If no GPU-based programs are running, you know that your kernel supports module unloading, and you still receive this message, then an error may have occurred that has corrupted an NVIDIA kernel module&#x27;s usage count, for which the simplest remedy is to reboot your computer.</span><br><span class="hljs-symbol">ERROR:</span> Installation has failed.  Please see the file <span class="hljs-comment">&#x27;/var/log/nvidia-installer.log&#x27; for details.  You may find suggestions on fixing installation problems in the README available on the Linux driver download page at www.nvidia.com.</span><br></code></pre></td></tr></table></figure><p>只需退出所有正在运行的cuda应用即可。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>java版本恢复</title>
    <link href="/2023/04/06/java%E7%89%88%E6%9C%AC%E6%81%A2%E5%A4%8D/"/>
    <url>/2023/04/06/java%E7%89%88%E6%9C%AC%E6%81%A2%E5%A4%8D/</url>
    
    <content type="html"><![CDATA[<h1 id="java-版本问题"><a href="#java-版本问题" class="headerlink" title="java 版本问题"></a>java 版本问题</h1><p>前提: 突然发现一台服务器因为java版本问题导致大数据服务的挂掉,恢复java版本</p><h2 id="查看现有java版本"><a href="#查看现有java版本" class="headerlink" title="查看现有java版本"></a>查看现有java版本</h2><p>java -version<br>java version “17.0.6” 2023-01-17 LTS<br>Java(TM) SE Runtime Environment (build 17.0.6+9-LTS-190)<br>Java HotSpot(TM) 64-Bit Server VM (build 17.0.6+9-LTS-190, mixed mode, sharing)</p><h2 id="查看其它大数据的java版本"><a href="#查看其它大数据的java版本" class="headerlink" title="查看其它大数据的java版本"></a>查看其它大数据的java版本</h2><p>java -version<br>java version “1.8.0_141”<br>Java(TM) SE Runtime Environment (build 1.8.0_141-b15)<br>Java HotSpot(TM) 64-Bit Server VM (build 25.141-b15, mixed mode)</p><h2 id="从官网下载对应版本"><a href="#从官网下载对应版本" class="headerlink" title="从官网下载对应版本"></a>从官网下载对应版本</h2><p><a href="https://www.oracle.com/sg/java/technologies/javase/javase8-archive-downloads.html">https://www.oracle.com/sg/java/technologies/javase/javase8-archive-downloads.html</a><br>下载的文件<br>jdk-8u141-linux-x64.tar.gz</p><h2 id="查看现有java安装路径"><a href="#查看现有java安装路径" class="headerlink" title="查看现有java安装路径"></a>查看现有java安装路径</h2><p>ls -alh &#x2F;usr&#x2F;bin&#x2F;java<br>lrwxrwxrwx 1 root root 22 Apr  6 11:56 &#x2F;usr&#x2F;bin&#x2F;java -&gt; &#x2F;etc&#x2F;alternatives&#x2F;java<br>johnson@wacserver1:~&#x2F;jvm$ ls -alh  &#x2F;etc&#x2F;alternatives&#x2F;java<br>lrwxrwxrwx 1 root root 34 Apr  6 12:06 &#x2F;etc&#x2F;alternatives&#x2F;java -&gt; &#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;jdk-17&#x2F;bin&#x2F;java</p><h2 id="解压tar包到对应目录"><a href="#解压tar包到对应目录" class="headerlink" title="解压tar包到对应目录"></a>解压tar包到对应目录</h2><p>sudo tar -xzf jdk-8u141-linux-x64.tar.gz -C &#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;<br>得到<br>&#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;jdk1.8.0_141</p><h2 id="更新默认java版本"><a href="#更新默认java版本" class="headerlink" title="更新默认java版本"></a>更新默认java版本</h2><p>sudo update-alternatives –install &#x2F;usr&#x2F;bin&#x2F;java java &#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;jdk1.8.0_141&#x2F;bin&#x2F;java 1<br>sudo update-alternatives –install &#x2F;usr&#x2F;bin&#x2F;javac javac &#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;jdk1.8.0_141&#x2F;bin&#x2F;javac 1<br>sudo update-alternatives –config java<br>sudo update-alternatives –config javac</p><h2 id="有时需要系统的环境变量文件-对所有用户生效"><a href="#有时需要系统的环境变量文件-对所有用户生效" class="headerlink" title="有时需要系统的环境变量文件,对所有用户生效"></a>有时需要系统的环境变量文件,对所有用户生效</h2><p>&#x2F;etc&#x2F;profile<br>修改<br>export JAVA_HOME&#x3D;&#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;jdk1.8.0_141<br>export PATH&#x3D;$JAVA_HOME&#x2F;bin:$PATH</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>mongo数据迁移</title>
    <link href="/2023/04/06/mongo%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB/"/>
    <url>/2023/04/06/mongo%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB/</url>
    
    <content type="html"><![CDATA[<h1 id="Mongo占用内存过大，迁移部分collection到其它机器"><a href="#Mongo占用内存过大，迁移部分collection到其它机器" class="headerlink" title="Mongo占用内存过大，迁移部分collection到其它机器"></a>Mongo占用内存过大，迁移部分collection到其它机器</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>mongo和大数据共用一个机器，当mongo中数据较多时，占用内存加到，影响到了大数据机器的稳定性，需要迁移到其它机器</p><h2 id="Mongo和内存之间的关系"><a href="#Mongo和内存之间的关系" class="headerlink" title="Mongo和内存之间的关系"></a>Mongo和内存之间的关系</h2><p>MongoDB数据库占用内存的大小主要依赖于以下几个因素:</p><p>数据量:显然,存储的文档数量越多,占用内存就越大。每个 MongoDB 文档通常占用约为 JSON 对象大小,这通常在 1KB 至 5KB 之间。</p><p>索引: MongoDB 可以在任何字段上创建索引。每个索引本身也会占用一定量的内存。所以,创建过多的索引会增加内存占用。</p><p>文档的平均大小:如果您存储的文档非常大(例如,每个文档包含大量媒体数据),那么整体内存占用将更大。</p><p>是否启用了内存索引:如果启用了内存索引,则 MongoDB 会在内存中缓存一部分的磁盘上索引,以改进查询性能。这会增加内存占用。</p><p>是否启用了内存 mapped view:与内存索引类似,如果启用了内存映射视图,则 MongoDB 也会在内存中缓存一部分数据,以提高视图的性能。这也会增加内存占用。</p><p>分片(如果适用):如果启用了 sharded 集群,每个片段又会有自己的内存占用。所以总体占用会大幅增加。</p><p>集群数(如果适用):如果您有多个互相独立的 MongoDB 集群,那么总的内存占用量将等于每个集群内存占用的总和。</p><h2 id="查看已占用内存"><a href="#查看已占用内存" class="headerlink" title="查看已占用内存"></a>查看已占用内存</h2><p>经过top名称，按内存占用大小查看，mongo占用内存大小约28.2%<br>进入mongo查看某个db占用内存, 单位是B，除以1024&#x2F;1024到MB<br>db.stats().storageSize<br>——&gt;<br>21534863360</p><h2 id="直接导出某个DB或导出某个collection"><a href="#直接导出某个DB或导出某个collection" class="headerlink" title="直接导出某个DB或导出某个collection"></a>直接导出某个DB或导出某个collection</h2><ol><li><p>直接导出某个DB<br>mongodump –db &lt;数据库名称&gt; –out &lt;输出目录&gt;<br>mongodump –db mydatabase –out .&#x2F;data<br>导入命令<br>mongorestore –host &lt;目标主机&gt; –port &lt;目标端口&gt; &lt;输入目录&gt;<br>mongorestore –db mynewdatabase –host localhost –port 27017 .&#x2F;data&#x2F;mydatabase</p></li><li><p>导出占用较大的collection<br>导出db是label,collection是brand的数据<br>mongodump –host localhost –port 27017 –db label –collection brand &gt; brand.bson<br>恢复数据一个collection数据<br>mongorestore –host otherhost –port 27017 –db label roles.bson</p></li></ol><h2 id="启动一个docker的mongo"><a href="#启动一个docker的mongo" class="headerlink" title="启动一个docker的mongo"></a>启动一个docker的mongo</h2><p>sudo docker run -d –name mongodb -v &#x2F;media&#x2F;backup&#x2F;mongo:&#x2F;data&#x2F;db   -p 27017:27017   mongo:4.4.17</p><h2 id="恢复mongo数据"><a href="#恢复mongo数据" class="headerlink" title="恢复mongo数据"></a>恢复mongo数据</h2><p>mongorestore –db label –host newnew –port 27017 .&#x2F;label</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>stable_diffusion</title>
    <link href="/2023/03/31/stable-diffusion/"/>
    <url>/2023/03/31/stable-diffusion/</url>
    
    <content type="html"><![CDATA[<h1 id="安装Stable-Diffusion，确保你已经安装了git-命令行下操作"><a href="#安装Stable-Diffusion，确保你已经安装了git-命令行下操作" class="headerlink" title="安装Stable Diffusion，确保你已经安装了git, 命令行下操作"></a>安装Stable Diffusion，确保你已经安装了git, 命令行下操作</h1><p>git clone <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui">https://github.com/AUTOMATIC1111/stable-diffusion-webui</a></p><h1 id="安装依赖环境，下载conda或miniconda-安装conda后创建虚拟环境"><a href="#安装依赖环境，下载conda或miniconda-安装conda后创建虚拟环境" class="headerlink" title="安装依赖环境，下载conda或miniconda, 安装conda后创建虚拟环境"></a>安装依赖环境，下载conda或miniconda, 安装conda后创建虚拟环境</h1><p>conda create –name webui python&#x3D;3.10<br>conda activate webui</p><h1 id="进入到stable-diffusion-webui目录，安装依赖"><a href="#进入到stable-diffusion-webui目录，安装依赖" class="headerlink" title="进入到stable-diffusion-webui目录，安装依赖"></a>进入到stable-diffusion-webui目录，安装依赖</h1><p>pip install -r requirements.txt</p><h1 id="运行webui"><a href="#运行webui" class="headerlink" title="运行webui"></a>运行webui</h1><p>python webui.py –share –listen –enable-insecure-extension-access</p><h1 id="访问"><a href="#访问" class="headerlink" title="访问"></a>访问</h1><p><a href="http://127.0.0.1:7860/">http://127.0.0.1:7860</a></p><p>#概念解释:</p><h2 id="stable-diffusion"><a href="#stable-diffusion" class="headerlink" title="stable-diffusion:"></a>stable-diffusion:</h2><p>文字生成图像，或图像生成图像,stable-diffusion是一个旨在提供高质量、稳定的人工图像合成的框架和方法<br>官网: <a href="https://stablediffusionweb.com/">https://stablediffusionweb.com</a></p><h2 id="stable-diffusion-webui"><a href="#stable-diffusion-webui" class="headerlink" title="stable-diffusion-webui:"></a>stable-diffusion-webui:</h2><p>操作stable-diffusion的一个网页界面,stable-diffusion-webui是一个基于stable-diffusion开源图像合成框架构建的交互式用户界面。</p><h2 id="下载模型地址-C站"><a href="#下载模型地址-C站" class="headerlink" title="下载模型地址: C站"></a>下载模型地址: C站</h2><p><a href="https://civitai.com/">https://civitai.com/</a></p><h2 id="什么是checkpoint"><a href="#什么是checkpoint" class="headerlink" title="什么是checkpoint"></a>什么是checkpoint</h2><p>即stable diffusion的base模型,大模型&#x2F;底模型 必备 Stable Diffusion V1.4  V1.5   V2.0  V2.1 泛化性、通用性,有的大模型自带VAE模型。不额外挂载,dreambooth可看作大模型</p><h2 id="VAE模型-必备-解码，图像效果更好"><a href="#VAE模型-必备-解码，图像效果更好" class="headerlink" title="VAE模型:必备,解码，图像效果更好"></a>VAE模型:必备,解码，图像效果更好</h2><h2 id="embedding-model"><a href="#embedding-model" class="headerlink" title="embedding model:"></a>embedding model:</h2><p>就是嵌入模型，或者叫Textual inversion，文本到向量模型,embedding: text inversion, 这里<br>是文本反嵌入，就是用一个词代表很多词的意思，就是某个提示词代表了很多提示词的意思，类似别名词, C站可以&gt;下载embedding模型, embedding模型不大</p><h2 id="Lora"><a href="#Lora" class="headerlink" title="Lora"></a>Lora</h2><p>一种训练模型的方法，很小的插件模型,微调模型</p><h2 id="Tag"><a href="#Tag" class="headerlink" title="Tag"></a>Tag</h2><p>提示词，即描述如何生成图像</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>cuda_amp</title>
    <link href="/2023/03/30/cuda-amp/"/>
    <url>/2023/03/30/cuda-amp/</url>
    
    <content type="html"><![CDATA[<h1 id="torch-cuda-amp-cuda的混合精度"><a href="#torch-cuda-amp-cuda的混合精度" class="headerlink" title="torch cuda amp  cuda的混合精度"></a>torch cuda amp  cuda的混合精度</h1><p>torch.cuda.amp.autocast函数：自动将上下文中的计算步骤转换为 FP16 格式，并在计算完成后将结果转换回 FP32 格式，以保证数值精度。需要注意的是，autocast() 只会自动转换支持 FP16 格式的计算步骤，对于不支持 FP16 格式的计算步骤，仍然会使用 FP32 格式进行计算。另外，autocast() 需要与支持 FP16 的硬件和软件环境一起使用，否则可能会导致计算结果的不准确性。</p><p>contextlib.nullcontext(): 用于在不需要执行任何操作的情况下创建上下文。它可以作为一个占位符上下文管理器使用，以便在某些情况下避免代码重复或错误。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">maybe_autocast</span>(<span class="hljs-params">self, dtype=torch.float16</span>):<br>    <span class="hljs-comment"># if on cpu, don&#x27;t use autocast</span><br>    <span class="hljs-comment"># if on gpu, use autocast with dtype if provided, otherwise use torch.float16</span><br>    enable_autocast = self.device != torch.device(<span class="hljs-string">&quot;cpu&quot;</span>)<br><br>    <span class="hljs-keyword">if</span> enable_autocast:<br>        <span class="hljs-keyword">return</span> torch.cuda.amp.autocast(dtype=dtype)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> contextlib.nullcontext()<br><span class="hljs-keyword">with</span> self.maybe_autocast():  <br>    image_embeds = self.ln_vision(self.visual_encoder(image)) <br></code></pre></td></tr></table></figure><p>这里的self.maybe_autocast() 是一个上下文管理器，用于控制模型是否启用自动混合精度（Automatic Mixed Precision，简称 AMP）加速。当启用 AMP 加速时，模型的参数和梯度会以 FP16 格式存储和计算，从而减少计算量和内存占用。但是，由于 FP16 格式的数值精度较低，可能会对模型的精度造成一定影响。<br>self.maybe_autocast() 的作用是判断当前环境是否支持使用 AMP 加速。如果支持，则启用 AMP 加速，否则不启用。这样可以在不同的环境下保持代码的兼容性，并且可以轻松地在支持 AMP 的环境中实现加速。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>webui报错</title>
    <link href="/2023/03/29/webui%E6%8A%A5%E9%94%99/"/>
    <url>/2023/03/29/webui%E6%8A%A5%E9%94%99/</url>
    
    <content type="html"><![CDATA[<h1 id="升级Webui时报错如下时"><a href="#升级Webui时报错如下时" class="headerlink" title="升级Webui时报错如下时"></a>升级Webui时报错如下时</h1><p>升级下gradio即可，pip install -U gradio</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">Traceback (most recent call last):<br>  File <span class="hljs-string">&quot;/user/stable-diffusion-webui/webui.py&quot;</span>, line <span class="hljs-number">340</span>, <span class="hljs-keyword">in</span> &lt;<span class="hljs-keyword">module</span>&gt;<br>    webui<span class="hljs-literal">()</span><br>  File <span class="hljs-string">&quot;/user/stable-diffusion-webui/webui.py&quot;</span>, line <span class="hljs-number">243</span>, <span class="hljs-keyword">in</span> webui<br>    shared.demo = modules.ui.create<span class="hljs-constructor">_ui()</span><br>  File <span class="hljs-string">&quot;/user/stable-diffusion-webui/modules/ui.py&quot;</span>, line <span class="hljs-number">448</span>, <span class="hljs-keyword">in</span> create_ui<br>    <span class="hljs-keyword">with</span> gr.<span class="hljs-constructor">Blocks(<span class="hljs-params">analytics_enabled</span>=False)</span> <span class="hljs-keyword">as</span> txt2img_interface:<br>  File <span class="hljs-string">&quot;/user/anaconda3/envs/webui/lib/python3.10/site-packages/gradio/blocks.py&quot;</span>, line <span class="hljs-number">486</span>, <span class="hljs-keyword">in</span> __init__<br>    super<span class="hljs-literal">()</span>.<span class="hljs-constructor">__init__(<span class="hljs-params">render</span>=False, <span class="hljs-operator">**</span><span class="hljs-params">kwargs</span>)</span><br>  File <span class="hljs-string">&quot;/user/stable-diffusion-webui/modules/scripts.py&quot;</span>, line <span class="hljs-number">561</span>, <span class="hljs-keyword">in</span> BlockContext_init<br>    add<span class="hljs-constructor">_classes_to_gradio_component(<span class="hljs-params">self</span>)</span><br>  File <span class="hljs-string">&quot;/user/stable-diffusion-webui/modules/scripts.py&quot;</span>, line <span class="hljs-number">529</span>, <span class="hljs-keyword">in</span> add_classes_to_gradio_component<br>    comp.elem_classes = <span class="hljs-literal">[&quot;<span class="hljs-identifier">gradio</span>-&quot; + <span class="hljs-identifier">comp</span>.<span class="hljs-identifier">get_block_name</span>(), <span class="hljs-operator">*</span>(<span class="hljs-identifier">comp</span>.<span class="hljs-identifier">elem_classes</span> <span class="hljs-identifier">or</span> []</span>)]<br>AttributeError: &#x27;Blocks&#x27; <span class="hljs-keyword">object</span> has no attribute &#x27;elem_classes<br><br><br>Traceback (most recent call last):<br>  File <span class="hljs-string">&quot;/user/stable-diffusion-webui/modules/ui.py&quot;</span>, line <span class="hljs-number">460</span>, <span class="hljs-keyword">in</span> create_ui<br>    txt2img_prompt, txt2img_prompt_styles, txt2img_negative_prompt, submit, _, _, txt2img_prompt_style_apply, txt2img_save_style, txt2img_paste, extra_networks_button, token_counter, token_button, negative_token_counter, negative_token_button = create<span class="hljs-constructor">_toprow(<span class="hljs-params">is_img2img</span>=False)</span><br>  File <span class="hljs-string">&quot;/user/stable-diffusion-webui/modules/ui.py&quot;</span>, line <span class="hljs-number">288</span>, <span class="hljs-keyword">in</span> create_toprow<br>    prompt = gr.<span class="hljs-constructor">Textbox(<span class="hljs-params">label</span>=<span class="hljs-string">&quot;Prompt&quot;</span>, <span class="hljs-params">elem_id</span>=<span class="hljs-params">f</span><span class="hljs-string">&quot;&#123;id_part&#125;_prompt&quot;</span>, <span class="hljs-params">show_label</span>=False, <span class="hljs-params">lines</span>=3, <span class="hljs-params">placeholder</span>=<span class="hljs-string">&quot;Prompt (press Ctrl+Enter or Alt+Enter to generate)&quot;</span>)</span><br>  File <span class="hljs-string">&quot;/user/anaconda3/envs/webui/lib/python3.10/site-packages/gradio/components.py&quot;</span>, line <span class="hljs-number">300</span>, <span class="hljs-keyword">in</span> __init__<br>    <span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">IOComponent</span>.</span><span class="hljs-module"><span class="hljs-identifier">__init__</span>(</span></span><br>  File <span class="hljs-string">&quot;/user/stable-diffusion-webui/modules/scripts.py&quot;</span>, line <span class="hljs-number">536</span>, <span class="hljs-keyword">in</span> IOComponent_init<br>    add<span class="hljs-constructor">_classes_to_gradio_component(<span class="hljs-params">self</span>)</span><br>  File <span class="hljs-string">&quot;/user/stable-diffusion-webui/modules/scripts.py&quot;</span>, line <span class="hljs-number">521</span>, <span class="hljs-keyword">in</span> add_classes_to_gradio_component<br>    comp.elem_classes = <span class="hljs-literal">[&quot;<span class="hljs-identifier">gradio</span>-&quot; + <span class="hljs-identifier">comp</span>.<span class="hljs-identifier">get_block_name</span>(), <span class="hljs-operator">*</span>(<span class="hljs-identifier">comp</span>.<span class="hljs-identifier">elem_classes</span> <span class="hljs-identifier">or</span> []</span>)]<br>AttributeError: &#x27;Textbox&#x27; <span class="hljs-keyword">object</span> has no attribute &#x27;elem_classes&#x27;<br><br>During handling <span class="hljs-keyword">of</span> the above <span class="hljs-keyword">exception</span>, another <span class="hljs-keyword">exception</span> occurred:<br><br>Traceback (most recent call last):<br>  File <span class="hljs-string">&quot;/user/stable-diffusion-webui/webui.py&quot;</span>, line <span class="hljs-number">337</span>, <span class="hljs-keyword">in</span> &lt;<span class="hljs-keyword">module</span>&gt;<br>    webui<span class="hljs-literal">()</span><br>  File <span class="hljs-string">&quot;/user/stable-diffusion-webui/webui.py&quot;</span>, line <span class="hljs-number">240</span>, <span class="hljs-keyword">in</span> webui<br>    shared.demo = modules.ui.create<span class="hljs-constructor">_ui()</span><br>  File <span class="hljs-string">&quot;/user/stable-diffusion-webui/modules/ui.py&quot;</span>, line <span class="hljs-number">459</span>, <span class="hljs-keyword">in</span> create_ui<br>    <span class="hljs-keyword">with</span> gr.<span class="hljs-constructor">Blocks(<span class="hljs-params">analytics_enabled</span>=False)</span> <span class="hljs-keyword">as</span> txt2img_interface:<br>  File <span class="hljs-string">&quot;/user/anaconda3/envs/webui/lib/python3.10/site-packages/gradio/blocks.py&quot;</span>, line <span class="hljs-number">1097</span>, <span class="hljs-keyword">in</span> __exit__<br>    self.config = self.get<span class="hljs-constructor">_config_file()</span><br>  File <span class="hljs-string">&quot;/user/anaconda3/envs/webui/lib/python3.10/site-packages/gradio/blocks.py&quot;</span>, line <span class="hljs-number">1073</span>, <span class="hljs-keyword">in</span> get_config_file<br>    <span class="hljs-string">&quot;props&quot;</span>: utils.delete<span class="hljs-constructor">_none(<span class="hljs-params">block</span>.<span class="hljs-params">get_config</span>()</span>)<br>  File <span class="hljs-string">&quot;/user/anaconda3/envs/webui/lib/python3.10/site-packages/gradio/components.py&quot;</span>, line <span class="hljs-number">322</span>, <span class="hljs-keyword">in</span> get_config<br>    <span class="hljs-string">&quot;type&quot;</span>: self.<span class="hljs-keyword">type</span>,<br>AttributeError: &#x27;Textbox&#x27; <span class="hljs-keyword">object</span> has no attribute &#x27;<span class="hljs-keyword">type</span>&#x27;. Did you mean: &#x27;style&#x27;?<br></code></pre></td></tr></table></figure>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>lavis和transformers的冲突</title>
    <link href="/2023/03/27/lavis%E5%92%8Ctransformers%E7%9A%84%E5%86%B2%E7%AA%81/"/>
    <url>/2023/03/27/lavis%E5%92%8Ctransformers%E7%9A%84%E5%86%B2%E7%AA%81/</url>
    
    <content type="html"><![CDATA[<p>salesforce的LAVIS包，<a href="https://github.com/salesforce/LAVIS%E6%98%AF%E4%B8%80%E4%B8%AA%E5%A4%9A%E6%A8%A1%E6%80%81%E7%9A%84%E5%BA%93%EF%BC%8C%E5%85%B6%E4%B8%AD%E7%9A%84BLIP2%E6%A8%A1%E5%9D%97%E9%83%A8%E5%88%86%E5%92%8Chuggingface%E7%9A%84trasformers==4.27.1%E4%B8%8D%E5%85%BC%E5%AE%B9,%E4%B8%8D%E5%85%BC%E5%AE%B9%E9%83%A8%E5%88%86%E6%98%AF,%E5%8E%9F%E5%9B%A0%E6%98%AFquery_embeds%E8%A2%ABrepeat%E4%BA%86%E7%BB%B4%E5%BA%A60%E4%B8%A4%E6%AC%A1%EF%BC%8C%E6%89%80%E4%BB%A5%E9%80%A0%E6%88%90torch.cat%E6%8B%BC%E6%8E%A5%E6%97%B6%E5%86%B2%E7%AA%81%E3%80%82">https://github.com/salesforce/LAVIS是一个多模态的库，其中的BLIP2模块部分和huggingface的trasformers==4.27.1不兼容,不兼容部分是,原因是query_embeds被repeat了维度0两次，所以造成torch.cat拼接时冲突。</a></p><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs maxima">lavis/models/blip2_models/blip2_opt.py<br>的第<span class="hljs-number">217</span>和<span class="hljs-number">218</span>行<br>            # <span class="hljs-keyword">else</span>:<br>            #     query_embeds = inputs_opt.repeat_interleave(num_beams, <span class="hljs-built_in">dim</span>=<span class="hljs-number">0</span>)<br>和trasformers==<span class="hljs-number">4.27</span><span class="hljs-number">.1</span>的<span class="hljs-number">679</span>到<span class="hljs-number">683</span>冲突<br>        def _expand_dict_for_generation(dict_to_expand):<br>            <span class="hljs-keyword">for</span> <span class="hljs-built_in">key</span> <span class="hljs-keyword">in</span> dict_to_expand:<br>                <span class="hljs-keyword">if</span> dict_to_expand[<span class="hljs-built_in">key</span>] <span class="hljs-built_in">is</span> <span class="hljs-keyword">not</span> None <span class="hljs-keyword">and</span> isinstance(dict_to_expand[<span class="hljs-built_in">key</span>], torch.Tensor):<br>                    dict_to_expand[<span class="hljs-built_in">key</span>] = dict_to_expand[<span class="hljs-built_in">key</span>].repeat_interleave(expand_size, <span class="hljs-built_in">dim</span>=<span class="hljs-number">0</span>)<br>            <span class="hljs-built_in">return</span> dict_to_expand<br><br>造成 lavis/models/blip2_models/modeling_opt.py 的<span class="hljs-number">703</span>到<span class="hljs-number">705</span>行 cat拼接时维度不一致<br>        <span class="hljs-keyword">if</span> query_embeds <span class="hljs-built_in">is</span> <span class="hljs-keyword">not</span> None:<br>            inputs_embeds = torch.cat([query_embeds, inputs_embeds], <span class="hljs-built_in">dim</span>=<span class="hljs-number">1</span>)<br>            input_shape = inputs_embeds.size()[:-<span class="hljs-number">1</span>]<br></code></pre></td></tr></table></figure><p>repeat_interleave()是PyTorch中的一个函数，用于将张量中的元素沿某一维度复制n次，即复制后的张量沿该维度.<br>这个函数有两个参数，第一个参数是重复的次数，第二个参数是重复的维度 (pytorch.org).<br>例如，如果你有一个形状为(3, 4)的张量，你可以使用repeat_interleave()函数将其中的每个元素沿着第0维重复2次，如下所示：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs stylus">import torch<br><br>x = torch<span class="hljs-selector-class">.tensor</span>(<span class="hljs-selector-attr">[[1, 2, 3, 4]</span>,<br><span class="hljs-selector-attr">[5, 6, 7, 8]</span>,<br><span class="hljs-selector-attr">[9, 10, 11, 12]</span>])<br><br>y = torch<span class="hljs-selector-class">.repeat_interleave</span>(x, repeats=<span class="hljs-number">2</span>, dim=<span class="hljs-number">0</span>)<br><br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(y)</span></span><br></code></pre></td></tr></table></figure><p>输出结果为：</p><p>tensor([[ 1,  2,  3,  4],<br>[ 1,  2,  3,  4],<br>[ 5,  6,  7,  8],<br>[ 5,  6,  7,  8],<br>[ 9, 10, 11, 12],<br>[ 9, 10, 11, 12]])<br>在这个例子中，我们将x沿着第0维重复了2次，因此输出结果中每个元素都被重复了2次</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>知识点总结</title>
    <link href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/"/>
    <url>/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/</url>
    
    <content type="html"><![CDATA[<h1 id="NLP方向总结-其它"><a href="#NLP方向总结-其它" class="headerlink" title="NLP方向总结-其它"></a>NLP方向总结-其它</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E5%85%B6%E5%AE%83.pdf" title="[NLP方向总结-其它.pdf]">[NLP方向总结-其它.pdf]</a><h1 id="NLP方向总结-对比学习"><a href="#NLP方向总结-对比学习" class="headerlink" title="NLP方向总结-对比学习"></a>NLP方向总结-对比学习</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0.pdf" title="[NLP方向总结-对比学习.pdf]">[NLP方向总结-对比学习.pdf]</a><h1 id="NLP方向总结-翻译"><a href="#NLP方向总结-翻译" class="headerlink" title="NLP方向总结-翻译"></a>NLP方向总结-翻译</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E7%BF%BB%E8%AF%91.pdf" title="[NLP方向总结-翻译.pdf]">[NLP方向总结-翻译.pdf]</a><h1 id="NLP方向总结-多模态"><a href="#NLP方向总结-多模态" class="headerlink" title="NLP方向总结-多模态"></a>NLP方向总结-多模态</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E5%A4%9A%E6%A8%A1%E6%80%81.pdf" title="[NLP方向总结-多模态.pdf]">[NLP方向总结-多模态.pdf]</a><h1 id="NLP方向总结-显存优化"><a href="#NLP方向总结-显存优化" class="headerlink" title="NLP方向总结-显存优化"></a>NLP方向总结-显存优化</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E6%98%BE%E5%AD%98%E4%BC%98%E5%8C%96.pdf" title="[NLP方向总结-显存优化.pdf]">[NLP方向总结-显存优化.pdf]</a><h1 id="NLP方向总结-数据结构"><a href="#NLP方向总结-数据结构" class="headerlink" title="NLP方向总结-数据结构"></a>NLP方向总结-数据结构</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.pdf" title="[NLP方向总结-数据结构.pdf]">[NLP方向总结-数据结构.pdf]</a><h1 id="NLP方向总结-文本摘要"><a href="#NLP方向总结-文本摘要" class="headerlink" title="NLP方向总结-文本摘要"></a>NLP方向总结-文本摘要</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E6%96%87%E6%9C%AC%E6%91%98%E8%A6%81.pdf" title="[NLP方向总结-文本摘要.pdf]">[NLP方向总结-文本摘要.pdf]</a><h1 id="NLP方向总结-注意力机制"><a href="#NLP方向总结-注意力机制" class="headerlink" title="NLP方向总结-注意力机制"></a>NLP方向总结-注意力机制</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6.pdf" title="[NLP方向总结-注意力机制.pdf]">[NLP方向总结-注意力机制.pdf]</a><h1 id="量化金融总结"><a href="#量化金融总结" class="headerlink" title="量化金融总结"></a>量化金融总结</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/%E9%87%8F%E5%8C%96%E9%87%91%E8%9E%8D%E6%80%BB%E7%BB%93.pdf" title="[量化金融总结.pdf]">[量化金融总结.pdf]</a><h1 id="NLP方向总结-新词发现"><a href="#NLP方向总结-新词发现" class="headerlink" title="NLP方向总结-新词发现"></a>NLP方向总结-新词发现</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E6%96%B0%E8%AF%8D%E5%8F%91%E7%8E%B0.pdf" title="[NLP方向总结-新词发现.pdf]">[NLP方向总结-新词发现.pdf]</a><h1 id="NLP方向总结-损失函数"><a href="#NLP方向总结-损失函数" class="headerlink" title="NLP方向总结-损失函数"></a>NLP方向总结-损失函数</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0.pdf" title="[NLP方向总结-损失函数.pdf]">[NLP方向总结-损失函数.pdf]</a><h1 id="NLP方向总结-模型蒸馏"><a href="#NLP方向总结-模型蒸馏" class="headerlink" title="NLP方向总结-模型蒸馏"></a>NLP方向总结-模型蒸馏</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F.pdf" title="[NLP方向总结-模型蒸馏.pdf]">[NLP方向总结-模型蒸馏.pdf]</a><h1 id="NLP方向总结-主体"><a href="#NLP方向总结-主体" class="headerlink" title="NLP方向总结-主体"></a>NLP方向总结-主体</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E4%B8%BB%E4%BD%93.pdf" title="[NLP方向总结-主体.pdf]">[NLP方向总结-主体.pdf]</a><h1 id="NLP方向总结-对抗学习"><a href="#NLP方向总结-对抗学习" class="headerlink" title="NLP方向总结-对抗学习"></a>NLP方向总结-对抗学习</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E5%AF%B9%E6%8A%97%E5%AD%A6%E4%B9%A0.pdf" title="[NLP方向总结-对抗学习.pdf]">[NLP方向总结-对抗学习.pdf]</a><h1 id="NLP方向总结-数据增强"><a href="#NLP方向总结-数据增强" class="headerlink" title="NLP方向总结-数据增强"></a>NLP方向总结-数据增强</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA.pdf" title="[NLP方向总结-数据增强.pdf]">[NLP方向总结-数据增强.pdf]</a><h1 id="NLP方向总结-问答"><a href="#NLP方向总结-问答" class="headerlink" title="NLP方向总结-问答"></a>NLP方向总结-问答</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E9%97%AE%E7%AD%94.pdf" title="[NLP方向总结-问答.pdf]">[NLP方向总结-问答.pdf]</a><h1 id="3D领域总结"><a href="#3D领域总结" class="headerlink" title="3D领域总结"></a>3D领域总结</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/3D%E9%A2%86%E5%9F%9F%E6%80%BB%E7%BB%93.pdf" title="[3D领域总结.pdf]">[3D领域总结.pdf]</a><h1 id="NLP方向总结-分词"><a href="#NLP方向总结-分词" class="headerlink" title="NLP方向总结-分词"></a>NLP方向总结-分词</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E5%88%86%E8%AF%8D.pdf" title="[NLP方向总结-分词.pdf]">[NLP方向总结-分词.pdf]</a><h1 id="强化学习总结"><a href="#强化学习总结" class="headerlink" title="强化学习总结"></a>强化学习总结</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93.pdf" title="[强化学习总结.pdf]">[强化学习总结.pdf]</a><h1 id="NLP方向总结-检索"><a href="#NLP方向总结-检索" class="headerlink" title="NLP方向总结-检索"></a>NLP方向总结-检索</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E6%A3%80%E7%B4%A2.pdf" title="[NLP方向总结-检索.pdf]">[NLP方向总结-检索.pdf]</a><h1 id="NLP方向总结-数据标注"><a href="#NLP方向总结-数据标注" class="headerlink" title="NLP方向总结-数据标注"></a>NLP方向总结-数据标注</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E6%95%B0%E6%8D%AE%E6%A0%87%E6%B3%A8.pdf" title="[NLP方向总结-数据标注.pdf]">[NLP方向总结-数据标注.pdf]</a><h1 id="NLP方向总结-优化器"><a href="#NLP方向总结-优化器" class="headerlink" title="NLP方向总结-优化器"></a>NLP方向总结-优化器</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E4%BC%98%E5%8C%96%E5%99%A8.pdf" title="[NLP方向总结-优化器.pdf]">[NLP方向总结-优化器.pdf]</a><h1 id="NLP方向总结-矩阵"><a href="#NLP方向总结-矩阵" class="headerlink" title="NLP方向总结-矩阵"></a>NLP方向总结-矩阵</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E7%9F%A9%E9%98%B5.pdf" title="[NLP方向总结-矩阵.pdf]">[NLP方向总结-矩阵.pdf]</a><h1 id="NLP方向总结-transformer"><a href="#NLP方向总结-transformer" class="headerlink" title="NLP方向总结-transformer"></a>NLP方向总结-transformer</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-transformer.pdf" title="[NLP方向总结-transformer.pdf]">[NLP方向总结-transformer.pdf]</a><h1 id="NLP方向总结-机器学习"><a href="#NLP方向总结-机器学习" class="headerlink" title="NLP方向总结-机器学习"></a>NLP方向总结-机器学习</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.pdf" title="[NLP方向总结-机器学习.pdf]">[NLP方向总结-机器学习.pdf]</a><h1 id="NLP方向总结-情感分析"><a href="#NLP方向总结-情感分析" class="headerlink" title="NLP方向总结-情感分析"></a>NLP方向总结-情感分析</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90.pdf" title="[NLP方向总结-情感分析.pdf]">[NLP方向总结-情感分析.pdf]</a><h1 id="NLP方向总结-CNN"><a href="#NLP方向总结-CNN" class="headerlink" title="NLP方向总结-CNN"></a>NLP方向总结-CNN</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-CNN.pdf" title="[NLP方向总结-CNN.pdf]">[NLP方向总结-CNN.pdf]</a><h1 id="NLP方向总结-提示学习"><a href="#NLP方向总结-提示学习" class="headerlink" title="NLP方向总结-提示学习"></a>NLP方向总结-提示学习</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0.pdf" title="[NLP方向总结-提示学习.pdf]">[NLP方向总结-提示学习.pdf]</a><h1 id="NLP方向总结-知识图谱"><a href="#NLP方向总结-知识图谱" class="headerlink" title="NLP方向总结-知识图谱"></a>NLP方向总结-知识图谱</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1.pdf" title="[NLP方向总结-知识图谱.pdf]">[NLP方向总结-知识图谱.pdf]</a><h1 id="NLP方向总结-激活函数"><a href="#NLP方向总结-激活函数" class="headerlink" title="NLP方向总结-激活函数"></a>NLP方向总结-激活函数</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0.pdf" title="[NLP方向总结-激活函数.pdf]">[NLP方向总结-激活函数.pdf]</a><h1 id="计算机视觉总结"><a href="#计算机视觉总结" class="headerlink" title="计算机视觉总结"></a>计算机视觉总结</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%80%BB%E7%BB%93.pdf" title="[计算机视觉总结.pdf]">[计算机视觉总结.pdf]</a><h1 id="NLP方向总结-训练"><a href="#NLP方向总结-训练" class="headerlink" title="NLP方向总结-训练"></a>NLP方向总结-训练</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E8%AE%AD%E7%BB%83.pdf" title="[NLP方向总结-训练.pdf]">[NLP方向总结-训练.pdf]</a><h1 id="NLP方向总结-实体链接"><a href="#NLP方向总结-实体链接" class="headerlink" title="NLP方向总结-实体链接"></a>NLP方向总结-实体链接</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E5%AE%9E%E4%BD%93%E9%93%BE%E6%8E%A5.pdf" title="[NLP方向总结-实体链接.pdf]">[NLP方向总结-实体链接.pdf]</a><h1 id="NLP方向总结-文本生成"><a href="#NLP方向总结-文本生成" class="headerlink" title="NLP方向总结-文本生成"></a>NLP方向总结-文本生成</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90.pdf" title="[NLP方向总结-文本生成.pdf]">[NLP方向总结-文本生成.pdf]</a><h1 id="NLP方向总结-Metric"><a href="#NLP方向总结-Metric" class="headerlink" title="NLP方向总结-Metric"></a>NLP方向总结-Metric</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-Metric.pdf" title="[NLP方向总结-Metric.pdf]">[NLP方向总结-Metric.pdf]</a><h1 id="NLP方向总结-信息抽取"><a href="#NLP方向总结-信息抽取" class="headerlink" title="NLP方向总结-信息抽取"></a>NLP方向总结-信息抽取</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96.pdf" title="[NLP方向总结-信息抽取.pdf]">[NLP方向总结-信息抽取.pdf]</a>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>NLP项目和论文搜索</title>
    <link href="/2023/03/21/NLP%E9%A1%B9%E7%9B%AE%E5%92%8C%E8%AE%BA%E6%96%87%E6%90%9C%E7%B4%A2/"/>
    <url>/2023/03/21/NLP%E9%A1%B9%E7%9B%AE%E5%92%8C%E8%AE%BA%E6%96%87%E6%90%9C%E7%B4%A2/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
    <tags>
      
      <tag>summary</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>chatgpt</title>
    <link href="/2023/03/02/chatgpt/"/>
    <url>/2023/03/02/chatgpt/</url>
    
    <content type="html"><![CDATA[<hr><h1 id="一、ChatGPT介绍"><a href="#一、ChatGPT介绍" class="headerlink" title="一、ChatGPT介绍"></a>一、ChatGPT介绍</h1><h2 id="1-什么是ChatGPT"><a href="#1-什么是ChatGPT" class="headerlink" title="1. 什么是ChatGPT?"></a>1. 什么是ChatGPT?</h2><p><a href="https://openai.com/blog/chatgpt/">https://openai.com/blog/chatgpt/</a></p><ol><li>来自官网介绍：<br> 我们已经训练了一个叫做ChatGPT的模型，它以对话的方式进行互动。对话的形式使ChatGPT有可能回答后续问题，承认自己的错误，挑战不正确的前提，并拒绝不适当的请求。ChatGPT是InstructGPT的兄弟姐妹模型，InstructGPT被训练成能够遵循提示中的指令并提供详细的回应。</li><li>ChatGPT自己介绍自己：<br> ChatGPT是一种基于自然语言处理（NLP）的人工智能模型，它是基于GPT模型（Generative Pre-trained Transformer）和聊天机器人技术的结合而产生的。ChatGPT模型使用大规模的文本数据进行预训练，然后可以生成具有连贯性和逻辑性的自然语言响应，以进行人机交互和对话。</li><li>更智能的全面知识面的个人助手， 本文80%以上内容来自ChatGPT的回答。</li></ol><h2 id="2-ChatGPT示例"><a href="#2-ChatGPT示例" class="headerlink" title="2. ChatGPT示例"></a>2. ChatGPT示例</h2><p>【（真·人工智能）】<a href="https://b23.tv/As9Tqm5">https://b23.tv/As9Tqm5</a><br>【试用了集合ChatGPT的Bing搜索后，感觉潘多拉魔盒已经打开了】 <a href="https://b23.tv/aDMiJ4p">https://b23.tv/aDMiJ4p</a></p><img src="/2023/03/02/chatgpt/chatgpt10.png" class=""><img src="/2023/03/02/chatgpt/chatgpt9.png" class=""><p>NLP任务处理</p><img src="/2023/03/02/chatgpt/chatgpt8.png" class=""><img src="/2023/03/02/chatgpt/chatgpt7.png" class=""><img src="/2023/03/02/chatgpt/chatgpt3.png" class=""><p>计算器</p><img src="/2023/03/02/chatgpt/image-20230215150045240.png" class=""><h2 id="3-ChatGPT注册"><a href="#3-ChatGPT注册" class="headerlink" title="3. ChatGPT注册"></a>3. ChatGPT注册</h2><p>由于ChatGPT暂不支持国内用户，需要使用国外代理，然后注册ChatGPT账号，还需使用国外手机验证一下，然后就可以直接使用了。</p><p>附件： [OpenAI Chatgpt注册及使用教程.pdf](..&#x2F;..&#x2F;..&#x2F;Users&#x2F;admin&#x2F;Downloads&#x2F;ChatGPT&#x2F;OpenAI Chatgpt注册及使用教程.pdf) </p><h2 id="4-专有名词"><a href="#4-专有名词" class="headerlink" title="4. 专有名词"></a>4. 专有名词</h2><p><strong>AIGC</strong>即AI Generated Content，是指利用人工智能技术来生成内容，AIGC也被认为是继UGC、PGC之后的新型内容生产方式，AI绘画(<strong>Stable Diffusion，根据用户文字生成图片</strong>)、AI写作等都属于AIGC的分支。 对AIGC来说，2022年被认为是其发展速度惊人的一年。</p><p><strong>Few-shot，one-shot，zero-shot Learning</strong><br>Few-shot learning（少样本学习）是指通过少量的样本（通常是几十个到几百个）来训练一个模型，使其能够在新任务上进行准确的预测。这通常涉及到对预训练模型进行微调，以适应新任务的要求。<br>One-shot learning（单样本学习）是指通过仅一个样本来学习一个新类别。这对于那些数据量有限、样本获取困难的任务尤为有用，但是由于训练样本极少，因此需要具有较强的泛化能力的模型。<strong>（就是我们常说的举个例子看看）</strong><br>Zero-shot learning（零样本学习）是指通过学习没有样本的新任务或新类别。在这种情况下，模型需要利用先前学习到的知识和先验信息来推断新任务或新类别的属性和特征。</p><p><strong>提示学习</strong>（Prompt Learning）是指一种基于自然语言提示（即提示语或样例）来指导神经网络进行生成或分类任务的学习方法。它是自然语言处理领域中的一种新兴研究方向，旨在缓解深度学习模型的数据需求和泛化能力问题，同时可以提高模型的可解释性和人机交互性。</p><hr><h1 id="二、ChatGPT基础"><a href="#二、ChatGPT基础" class="headerlink" title="二、ChatGPT基础"></a>二、ChatGPT基础</h1><h2 id="1-OpenAI介绍"><a href="#1-OpenAI介绍" class="headerlink" title="1. OpenAI介绍"></a>1. OpenAI介绍</h2><p>OpenAI是一个非营利性研究组织，致力于研究人工智能（AI）的安全性和可控性，并推动AI技术的全面发展。该组织成立于2015年，总部位于美国旧金山。OpenAI由众多顶尖的科学家和工程师组成，包括<strong>Elon Musk</strong>、Sam Altman、Greg Brockman等知名人士，同时获得了多个知名公司的资助，如<strong>微软</strong>、亚马逊等。该组织致力于开发人工智能系统，使之更加智能、<strong>安全、透明和可控</strong>。</p><p>其它产品： <a href="https://openai.com/dall-e-2/%EF%BC%8C">https://openai.com/dall-e-2/，</a> <a href="https://openai.com/blog/openai-codex/">https://openai.com/blog/openai-codex/</a></p><p><a href="https://fortune.com/2023/02/17/chatgpt-elon-musk-openai-microsoft-company-regulator-oversight/">Elon Musk just disowned ChatGPT parent company OpenAI | Fortune</a></p><p>不再像他曾经在2015年12月共同创立的那样。据马斯克说，它被设计成一个开源的非营利组织，这正是它被称为OpenAI的原因。<br>“现在，它已经成为一个由微软有效控制的闭源、最高利润的公司，”他在Twitter上发帖。”完全不是我的初衷。”—OpenAI失去初心。</p><p>Google 投资 <a href="https://www.anthropic.com/">Anthropic</a></p><h2 id="2-ChatGPT的起源"><a href="#2-ChatGPT的起源" class="headerlink" title="2. ChatGPT的起源"></a>2. ChatGPT的起源</h2><ol><li><p>2018年6月：OpenAI发布了第一代GPT模型（Generative Pre-trained Transformer），可以用于自然语言处理任务，如文本分类、语言翻译等。</p></li><li><p>2019年2月：OpenAI发布了GPT-2模型，拥有超过15亿个参数，可以生成高质量的自然语言文本，引起了广泛的关注和讨论。</p></li><li><p>2019年11月：OpenAI发布了GPT-2的一部分模型，用于构建生成式聊天机器人，该模型名为DialoGPT。</p></li><li><p>2020年2月：OpenAI发布了DialoGPT的改进版本，即DialoGPT-2，引入了多个新的技术和策略，可以更好地生成连贯和有意义的对话。</p></li><li><p>2020年5月：OpenAI推出了GPT-3模型，它是迄今为止最大的模型，拥有1750亿个参数，可以生成更加逼真和多样化的自然语言文本，同时也可以用于构建聊天机器人。</p></li><li><p>2021年1月：OpenAI发布了DialoGPT-3模型，它是基于GPT-3的改进版本，可以生成更加准确和多样化的自然语言响应，被广泛应用于人机交互和智能客服等场景。</p></li></ol><table><thead><tr><th>模型</th><th>发布时间</th><th>参数量</th><th>预训练数据量</th></tr></thead><tbody><tr><td>GPT</td><td>2018 年 6 月</td><td>1.17 亿</td><td>约 5GB</td></tr><tr><td>GPT-2</td><td>2019 年 2 月</td><td>15 亿</td><td>40GB</td></tr><tr><td>GPT-3</td><td>2020 年 5 月</td><td>1,750 亿</td><td>45TB</td></tr></tbody></table><h2 id="3-GPT原理"><a href="#3-GPT原理" class="headerlink" title="3. GPT原理"></a>3. GPT原理</h2><ol><li><p>什么是GPT</p><p>GPT（Generative Pre-trained Transformer）是一种基于Transformer结构的自然语言处理模型，其原理主要包括两个部分：预训练和微调。</p><p>预训练部分是指使用大规模的文本数据对模型进行无监督的预训练。具体来说，GPT使用了一种被称为“掩码语言建模”（Masked Language Modeling，MLM）的技术，即在输入的文本序列中随机掩盖一些词汇，并让模型预测这些被掩盖的词汇。通过这种方式，模型可以学习到词汇之间的上下文信息和语言规律。</p><p>微调部分是指在完成预训练后，将模型用于特定的自然语言处理任务，如文本分类、命名实体识别、情感分析等，通过反向传播算法对模型参数进行微调，使其适应具体任务的要求。</p></li><li><p>什么是Bert</p><p>BERT（Bidirectional Encoder Representations from Transformers）是一种基于Transformer结构的预训练语言模型，由Google研究团队在2018年提出。BERT可以用于多种自然语言处理任务，如文本分类、问答系统、语言翻译等，取得了很好的效果，并在自然语言处理领域引起了广泛关注。</p><p>与之前的自然语言处理模型不同，BERT使用了一种双向预训练的方式，即通过联合训练两个方向的语言模型（从左到右和从右到左），来学习词汇之间的上下文信息。这种方法可以更好地捕捉文本序列中的语言规律和语义信息，并在下游任务中提高模型的泛化能力。</p><p>BERT模型由多个Transformer编码器组成，其中每个编码器由多个自注意力层和前馈神经网络层组成。自注意力层用于学习输入序列中不同位置之间的交互关系，前馈神经网络层用于对特征进行非线性变换。BERT使用了大规模的文本数据进行预训练，并使用了多种技术和策略来优化模型的预训练和微调过程，如掩码语言模型（Masked Language Model，MLM）、下一句预测（Next Sentence Prediction，NSP）等。</p><p>由于BERT具有较强的语义理解和泛化能力，可以对多种自然语言处理任务进行有效处理，因此在自然语言处理领域得到了广泛应用，并成为了自然语言处理领域的重要里程碑。</p></li><li><p>Transformer结构<br>Transformer是一种基于自注意力机制（self-attention）的神经网络模型，主要用于自然语言处理（NLP）任务中的序列建模和序列到序列学习。它于2017年由Google提出，是一种与循环神经网络（RNN）和卷积神经网络（CNN）不同的新型序列建模方法。Transformer模型通过自注意力机制可以在不依赖顺序的情况下对输入序列中的任意位置进行建模，使其具有更好的并行性和效率。同时，它还采用了残差连接和层归一化等技术来缓解梯度消失和梯度爆炸等训练中的常见问题，使得模型训练更加稳定和快速。</p><p>完型填空(BERT已经上下文);根据前文预测后文(GPT预测以后的事)</p></li></ol><img src="/2023/03/02/chatgpt/image-20230215095051761.png" class=""><hr><h1 id="三、ChatGPT原理"><a href="#三、ChatGPT原理" class="headerlink" title="三、ChatGPT原理"></a>三、ChatGPT原理</h1><h2 id="1-RLHF，ChatGPT更懂交流"><a href="#1-RLHF，ChatGPT更懂交流" class="headerlink" title="1. RLHF，ChatGPT更懂交流"></a>1. RLHF，ChatGPT更懂交流</h2><p>reinforcement learning from human feedback，人类反馈的强化学习, 对齐AI系统和人类，即AI系统更懂人类，因为人类很难直接评估。<br>为什么要用RLHF<br>语言模型生成文字的的好坏，很难定义的，因为它是主观的，而且取决于上下文，如写故事，你希望有创意，信息性的文本应该是真实的，或者我们希望代码片段是可执行的。<br>编写一个损失函数来捕捉这些好的属性很难，例如交叉熵损失，评价指标如BLEU或ROUGE，这些指标只是将生成的文本与具有简单规则的参考进行比较，所以提出将这种反馈作为损失来优化模型，使语言模型的答案与复杂的人类价值相一致</p><h2 id="2-ChatGPT的训练过程"><a href="#2-ChatGPT的训练过程" class="headerlink" title="2. ChatGPT的训练过程"></a>2. ChatGPT的训练过程</h2><img src="/2023/03/02/chatgpt/image-20230215102827587.png" class=""><p>Step1: 训练一个supervised fine-tuning监督微调模型，主要目的是学习基本的人类问答知识。使用监督学习在人工标注的数据上微调预训练的GPT-3 1750亿参数模型，大约13000个训练提示，即用户的提出的问题，问题的多样性，生成性问题，开放式问答，头脑风暴，闲聊，重写，总结摘要，分类，封闭式问答，信息提取，99%的问题是英语，其它语种比较少，问题的长度最小是1，最大长度是2039个字，不同的任务长度都有所不同。<br>Step2: 训练一个奖励模型或者叫做偏好模型，主要目的是对模型的回答进行打分，为最后一步强化学习训练提供评判标准。标注者指出他们对一个给定的输入更喜欢哪一个模型的输出。然后我们训练一个奖励模型来预测人类喜欢的输出。用排序的方式代替评分，解决不同人对同一问题的评分不同的而产生的噪声。人工根据模型的不同回答打分，然后对回答得分进行排序,然后训练奖励模型（gpt-3，60亿参数），大约数据集需要33000个训练提示。<br>Step3：训练最终的ChatGPT模型，即RLHF模型，用强化学习对模型进行微调，使用RM的输出作为一个标量奖励,使用PPO算法微调SFT模型。</p><p>整个强化学习系统由智能体（Agent）、状态（State）、奖赏（Reward）、动作（Action）和环境（Environment）五部分组成。</p><h2 id="3-ChatGPT的测试过程"><a href="#3-ChatGPT的测试过程" class="headerlink" title="3.ChatGPT的测试过程"></a>3.ChatGPT的测试过程</h2><p>模型测试<br>    毒性测试：有害的回答，消极的回答，诋毁，暴力内容等<br>    隐私测试：泄露隐私数据<br>    偏见测试：例如性别种族歧视等<br>    真实性测试：不编造事实，以事实为依据的回答，使用封闭领域任务中进行测试，例如TruthfulQA数据集<br>    对齐测试： 不是答非所问，正确的废话，就是回答符合用户意图<br>    其它问题<br>    模型有时会错误地假定前提是真的，例如马斯克出生在中国哪个地区？<br>        Elon Musk was not born in China. He was born on June 28, 1971 in Pretoria, South Africa.<br>    对语言模型使用约束条件，例如，用指定的句子数量写一个摘要，模型的性能就会下降。<br>    人们不可能一下子就训练出一个符合每个人偏好的系统<br>    ChatGPT有时会写出听起来很有道理但不正确或无意义的答案<br>        1）RL训练期间，加上答案的参考来源<br>        2）模型回答的置信度调整，这可能导致它拒绝它可以正确回答的问题<br>        3）监督训练的误差，模型的答案类型取决于标注者<br>    对用户的模糊问题，会猜测一个意图，而不是让用户澄清更具体的问题</p><h2 id="4-ChatGPT模型的优点和局限性"><a href="#4-ChatGPT模型的优点和局限性" class="headerlink" title="4. ChatGPT模型的优点和局限性"></a>4. ChatGPT模型的优点和局限性</h2><p>优点：智能，全面的聊天机器人<br>缺点：ChatGPT有时答案没有依据或随意幻想答案。</p><p>其它疑问： ChatGPT是如何学会承认错误的。</p><hr><h1 id="四、使用ChatGPT模型"><a href="#四、使用ChatGPT模型" class="headerlink" title="四、使用ChatGPT模型"></a>四、使用ChatGPT模型</h1><h2 id="1-体验账号"><a href="#1-体验账号" class="headerlink" title="1. 体验账号"></a>1. 体验账号</h2><p><a href="https://chat.openai.com/">https://chat.openai.com</a></p><h2 id="2-其它使用案例"><a href="#2-其它使用案例" class="headerlink" title="2. 其它使用案例"></a>2. 其它使用案例</h2><p>难记的正则表达式</p><img src="/2023/03/02/chatgpt/image-20230215104822863.png" class=""><p>创作一首歌曲。它应该以一个纺织机操作员和一个落后的手工编织者之间的竞争为特色。它应该包含押韵的诙谐笑话。包括与之相配的钢琴和弦。</p><p>教毕达哥拉斯定理，包括最后的测验，但不要给我答案，然后在我回答时告诉我|是否答对了答案。<br>ChatGPT当导游，各学科老师，写作，写诗，写邮件，改写邮件更正式，写markdown，写sql，角色扮演游戏（当只猫，或Siri），让它有幽默感的段子手。</p><p>工具类使用：Toolformer</p><hr><h1 id="五、ChatGPT模型的发展和未来"><a href="#五、ChatGPT模型的发展和未来" class="headerlink" title="五、ChatGPT模型的发展和未来"></a>五、ChatGPT模型的发展和未来</h1><h2 id="1-国内外进展新闻"><a href="#1-国内外进展新闻" class="headerlink" title="1. 国内外进展新闻"></a>1. 国内外进展新闻</h2><ul><li>百度将发布“中国版ChatGPT”，三月完成内测，定名为“文心一言”</li><li>挑战ChatGPT，谷歌正式发布Bard</li><li>首个中文版ChatGPT来了：大模型的中国元“Yuan”</li><li>京东将发布ChatJD</li><li>阿里内测版本ChatGPT</li><li>正式发布！北京：支持头部企业打造对标ChatGPT的大模型</li></ul><h2 id="2-New-Bing（ChatGPT-4-0"><a href="#2-New-Bing（ChatGPT-4-0" class="headerlink" title="2. New Bing（ChatGPT 4.0)"></a>2. New Bing（ChatGPT 4.0)</h2><ul><li>全语言支持（如英语，中文，日本语，西班牙语，法语或德语），ChatGPT也可以</li><li>Bing chat可以为你搜索网络结果，并提供网站的引用和来源。</li><li>你可以给Bing chat发送一个链接，它会给你一个简短的摘要</li><li>Bing chat可以帮助你进行更自然和流畅的对话，它可以理解你的意图和(情感)，具有人类的同理心。</li><li>加入NewBing的体验,  <a href="https://www.bing.com/new">https://www.bing.com/new</a></li></ul><h2 id="3-未来发展"><a href="#3-未来发展" class="headerlink" title="3. 未来发展"></a>3. 未来发展</h2><p>Step1: (加上答案的来源依据，实施联网获取最新知识)，个人化，例如钢铁侠中的贾维斯（符合你的幽默感，知道你的问答风格， VR虚拟助手）<br>Step2: 结合多模态知识，图片，声音，视频，进行学习，也可以产出图片，声音，视频，成为一个全能的聊天机器人。<br>Step3: 结合波士顿动力的机器人动作，加上全能的ChatGPT进化版，成为会带来AI的革命。<br>Step4: 自我进化，目前的AI模型都是固定好的神经参数，人工来提供训练语料，然后进行训练，当模型会自我获取数据自我训练时，科技将指数级发展，AI的危险也随之到来。</p><hr><h1 id="六、参考"><a href="#六、参考" class="headerlink" title="六、参考"></a>六、参考</h1><p>Training language models to follow instructions with human feedback<br>Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback<br>Learning to summarize from human feedback<br><a href="https://openai.com/blog/chatgpt/">https://openai.com/blog/chatgpt/</a></p><hr>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>多模态项目记录</title>
    <link href="/2022/10/13/%E5%A4%9A%E6%A8%A1%E6%80%81%E9%A1%B9%E7%9B%AE%E8%AE%B0%E5%BD%95/"/>
    <url>/2022/10/13/%E5%A4%9A%E6%A8%A1%E6%80%81%E9%A1%B9%E7%9B%AE%E8%AE%B0%E5%BD%95/</url>
    
    <content type="html"><![CDATA[<h1 id="项目目的，根据给定的图片和标题，判断所属的商品是库中的哪个商品"><a href="#项目目的，根据给定的图片和标题，判断所属的商品是库中的哪个商品" class="headerlink" title="项目目的，根据给定的图片和标题，判断所属的商品是库中的哪个商品"></a>项目目的，根据给定的图片和标题，判断所属的商品是库中的哪个商品</h1><h1 id="数据标注"><a href="#数据标注" class="headerlink" title="数据标注"></a>数据标注</h1><p>开发一个前后端，前端标注人员可以根据提供的关键字进行搜索，搜索通过后端调取爬虫平台，实时获取爬取结果，因为爬取不稳定，添加额外缓存系统，当爬取过一次后，可以直接读取缓存，用户也可以不读取缓存，用户标注的结果提交到后台的mongo中保存<br>标注工具示例:</p><img src="/2022/10/13/%E5%A4%9A%E6%A8%A1%E6%80%81%E9%A1%B9%E7%9B%AE%E8%AE%B0%E5%BD%95/labeltool.png" class=""><p>优化:<br>    0. 提交按钮是浮动状态，方便用户下拉选中后也可以提交<br>    1. 图标加上tmall官方链接，方便标注人员点击查看<br>    2. 标注人员提交标注结果后，给与成功提示，否则给与失败提示，然后清空搜索框<br>    3.Flask接口失败时，也会给与友好提示<br>    4. 当用户搜索关键字为空时，默认给一个搜搜关键字示例<br>    5. 给列表中每个搜索结果的a标签图片都加上点击事件，当是非checked状态时，点击后，变成checked状态，当是checked状态时，点击后变成非checked状态<br>    6. 如果给的关键字在天猫中没有搜索到，返回也是空的，那么给出友好提示<br>    7.判断用户提交的关联商品的名称是否为空，如果为空，提示一下<br>    8. 追加原始的天猫的店铺的url链接，方便标注后一同导入到数据库中<br>    9. 翻页后标签图片的点击事件失效问题修复<br>    10. 增加强制爬取按钮：爬虫搜索（表示不使用缓存直接爬取）<br>        1. 因为缓存的结果可能不存在，那么直接使用强制爬取<br>        html中增加一个div，里面有一个button按钮<br>        css中对这个div浮动，对button更改大小<br>        js中添加事件，点击这个button后，传入的url多加一个spider&#x3D;ture的参数<br>        js通过DOM的location.search解析url参数，获取spider关键字状态，发送请求时根据spdier状态判断请求的force_update参数</p><h1 id="使用模型"><a href="#使用模型" class="headerlink" title="使用模型"></a>使用模型</h1><ol><li>使用的Vilt模型，对比了单流架构和双流架构，单流架构更符合本项目，因为单流架构是汇总了一个文本和图片的高阶特征，而不是2个特征</li><li>首先使用模型继续预训练，我们下载了约70G数据，然后按照Vilt论文中所述，继续预训练，使其适应我们自己的数据集。</li><li>微调模型训练，自定义2个损失，品牌分类损失+商品分类损失，如果只是商品分类损失，模型没有学到品牌的信息点，很容易在品牌上就预测错了，那么商品上更预测错误了，结果能够比单纯的预测商品分类损失准确率提高10%左右</li><li>损失的权重，商品分类损失权重更大一些，因为品牌分类损失更简单，模型很容易就拟合了，结果证明商品分类损失权重大一些的话，准确率提高2%左右。</li><li>损失和训练step的对比图, 使用Visdom绘图, 明显损失相同的情况下，更难的任务拟合更慢<br>图0：预训练模型的MLM和ITM损失<img src="/2022/10/13/%E5%A4%9A%E6%A8%A1%E6%80%81%E9%A1%B9%E7%9B%AE%E8%AE%B0%E5%BD%95/pretrain_loss.png" class=""></li></ol><p>图1：损失权重相同的情况</p><img src="/2022/10/13/%E5%A4%9A%E6%A8%A1%E6%80%81%E9%A1%B9%E7%9B%AE%E8%AE%B0%E5%BD%95/loss1.png" class=""><p>图2：损失权重不同的情况</p><img src="/2022/10/13/%E5%A4%9A%E6%A8%A1%E6%80%81%E9%A1%B9%E7%9B%AE%E8%AE%B0%E5%BD%95/loss.png" class=""><p>Vilt总结:<br>ViLT：没有卷积或区域监督的视觉和语言transformer<br>    定义<br>        视觉和语言预训练（VLP），Vision-and-Language Pre-training<br>        Vision-and-Language Transformer (ViLT)<br>            以一种统一的方式处理两种模态<br>            与以前的VLP模型的主要区别在于它对像素级输入的浅层无卷积嵌入。去除仅用于视觉输入的深层嵌入，通过设计大大减少了模型的大小和运行时间<br>            图2d类型，原始像素的嵌入层很浅，计算量也很小，与文本token一样，将大部分的计算集中在模态交互的建模上<br>        VSE：visual semantic embedding，视觉语义嵌入<br>        MI：modality interaction 模态交互<br>            单流方法: Single-Stream<br>                各层操作图像和文本输入的拼接，例如UNITER<br>            双流方法: Dual-stream<br>                两种模态在输入层面没有拼接起来,类似ViLBERT，LXMERT<br>        TE: textual embedder 文本嵌入器<br>        VE: visual embedder 视觉嵌入器<br>            使用碎片投影减小开销，使用一个32×32的补丁投影，只需要2.4M的参数<br>            传统的区域特征需要步骤（参数量大）：<br>                一个区域建议网络（RPN）根据从CNN主干网汇集的网格特征提出感兴趣的区域（RoI）<br>                非最大限度的抑制（NMS）将RoI的数量减少到几千个<br>                RoI经过RoI头，成为区域特征<br>                NMS再次应用于每个类别，最终将特征的数量减少到一百个以下<br>        MSA: multiheaded self-attention 多头自注意力<br>        ITM: Image Text Match: 图像文本匹配<br>        ViT-B&#x2F;32：代表Patch大小为32，即图片的每个碎片的大小，即32*32像素的，使用Conv2d即可<br>    模型（图3）<br>        模型结构<br>            文本嵌入：词嵌入+位置嵌入+模态类型嵌入<br>            视觉嵌入：图片切成块，线性投影嵌入+位置嵌入+模态类型嵌入<br>            被串联成一个组合序列z0<br>            transformer层<br>                由多个块组成，每个块包含一个多头self-attention(MSA)和一个多层感知器(MLP)<br>                层归一化（LN）在MSA和MLP之前<br>                输出上下文序列zD<br>        预训练目标<br>            图像文本匹配（ITM）<br>                以0.5的概率随机地用不同的图像来替换对齐的图像。一个单一的线性层ITM头将汇集的输出特征p投射到二分类的logits上，我们计算出负logits可能性损失作为我们的ITM损失<br>                word patch alignment 词块对齐（WPA）损失<br>                    计算文本子集和视觉子集两个子集之间的对齐分数，使用非精确近似点法进行最优转译optimal transports（IPOT），并将近似的Wasserstein距离乘以0.1加到ITM损失中<br>                    可视化对齐结果见图4，图像部分和词进行了对齐<br>            mask语言模型（MLM）<br>                0.15的概率随机mask，预测被masked的文本ground truth标签<br>                全词mask，而不是仅仅是词片wordpiecemask<br>        使用RandAugment进行图像增强<br>    数据集<br>        预训练<br>            微软COCO（MSCOCO），视觉基因组（VG），SBU字幕（SBU），以及谷歌概念字幕（GCC）<br>        微调测试任务：<br>            分类任务：VQAv2，NLVR2<br>            检索任务: MSCOCO, Flickr30K</p><h1 id="开发多模态模型评估系统"><a href="#开发多模态模型评估系统" class="headerlink" title="开发多模态模型评估系统"></a>开发多模态模型评估系统</h1><ol start="3"><li>开发2个Tab标签，一个是测试预测，一个是统计<ol><li>测试预测逻辑<br> 用户提交关键词<br> 调用&#x2F;api&#x2F;goodslist获取爬取结果<br> 对爬取结果的图片进行本地缓存<br> 对结果处理后提交多模态模型预测品牌和所属商品<br> 对预测结果进行展示<br> 展示预测结果<br> 展示图片，title，价格，店铺<br> 用户判断预测结果是否正确<br> 如果错误，给出正确的预测商品<br> 提交用户判断结果到后台<br> 统计逻辑<br> 从mongo中读取用户人工判断的结果<br> 展示所有数据的表格形式<br> 统计模型判断正确和错误的结果，显示准确率<img src="/2022/10/13/%E5%A4%9A%E6%A8%A1%E6%80%81%E9%A1%B9%E7%9B%AE%E8%AE%B0%E5%BD%95/eval1.png" class=""><img src="/2022/10/13/%E5%A4%9A%E6%A8%A1%E6%80%81%E9%A1%B9%E7%9B%AE%E8%AE%B0%E5%BD%95/eval2.png" class=""></li></ol></li></ol>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>一个transformers报错</title>
    <link href="/2022/07/04/%E4%B8%80%E4%B8%AAtransformers%E6%8A%A5%E9%94%99/"/>
    <url>/2022/07/04/%E4%B8%80%E4%B8%AAtransformers%E6%8A%A5%E9%94%99/</url>
    
    <content type="html"><![CDATA[<h1 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h1><p>我们在使用huggiface transformers时, 有时会报错<br>transformers报错如下：</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">    <span class="hljs-keyword">raise</span> ValueError(&quot;got_ver is None&quot;)<br>ValueError: got_ver <span class="hljs-keyword">is</span> <span class="hljs-keyword">None</span><br></code></pre></td></tr></table></figure><h1 id="错误分析"><a href="#错误分析" class="headerlink" title="错误分析"></a>错误分析</h1><p>这是由于transformers使用时，会检查需要依赖的依赖包版本是否满足要求，使用的是importlib_metadata库，<br>没有获取到给定的包的名字的版本号，例如pkg是numpy，而numpy安装不正确，或者importlib_metadata有问题，获取numpy的版本为None，那么就报错如上，got_ver &#x3D; importlib_metadata.version(pkg)</p><h1 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h1><p>请查看是否混用了conda和pip，混用是没有问题的，但是有时它们还是会有部分兼容性问题，我报错的原因是importlib_metadata无法检查到conda安装的numpy的版本，改成使用pip重新安装numpy，然后手动测试是否能成功检查版本</p><figure class="highlight python-repl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python-repl">python<br><span class="hljs-meta">&gt;&gt;&gt;</span> <span class="language-python"><span class="hljs-keyword">import</span> importlib_metadata</span><br><span class="hljs-meta">&gt;&gt;&gt;</span> <span class="language-python">importlib_metadata.version(<span class="hljs-string">&#x27;numpy&#x27;</span>)</span><br>&#x27;1.23.0&#x27;<br><span class="hljs-meta">&gt;&gt;&gt;</span><br></code></pre></td></tr></table></figure><p>如果能够检查到，说明问题解决</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>满意度预测模型</title>
    <link href="/2022/07/04/%E6%BB%A1%E6%84%8F%E5%BA%A6%E9%A2%84%E6%B5%8B%E6%A8%A1%E5%9E%8B/"/>
    <url>/2022/07/04/%E6%BB%A1%E6%84%8F%E5%BA%A6%E9%A2%84%E6%B5%8B%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="更多信息参见公众号原文"><a href="#更多信息参见公众号原文" class="headerlink" title="更多信息参见公众号原文"></a>更多信息参见公众号原文</h1><p><a href="https://mp.weixin.qq.com/s/IHcioj1-i0HzloSQ3gu7tw">https://mp.weixin.qq.com/s/IHcioj1-i0HzloSQ3gu7tw</a></p><h1 id="实现意义"><a href="#实现意义" class="headerlink" title="实现意义"></a>实现意义</h1><p>结果： 应该把提升用户满意度的钱花在哪个方面，即产品的哪个属性上，然后再哪个属性上应该提升多少，为提升客户对某产品的整体满意度，对用户评论进行分析，判断出用户对产品的哪些属性的满意度较差，提升哪些属性的产品满意度，能显著影响产品的整体满意度。</p><h1 id="实现思路"><a href="#实现思路" class="headerlink" title="实现思路"></a>实现思路</h1><p>主要分为4个模型</p><h2 id="Aspect情感模型"><a href="#Aspect情感模型" class="headerlink" title="Aspect情感模型"></a>Aspect情感模型</h2><p>预测属性词在句子中的情感, 标签:积极，消极，中性</p><h2 id="整体情感模型"><a href="#整体情感模型" class="headerlink" title="整体情感模型"></a>整体情感模型</h2><p>表达对这个产品的整体情感， 标签:整体积极，整体消极，整体中性，无整体情感<br>   eg: 东西还不错，就是洗了脸有点干干的，也洗的很干净</p><h2 id="贡献度模型"><a href="#贡献度模型" class="headerlink" title="贡献度模型"></a>贡献度模型</h2><p>预测每个aspect对整体情感的贡献度,使用普通线性回归模型，决策树和集成学习模型，深度学习模型分别进行实验<br>线性回归模型<br>    普通线性回归模型<br>    LASSO回归<br>    Ridge回归<br>    ElasticNet<br>    多项式回归<br>    Bayesian回归<br>    Bayesian ARD回归<br>    主成分回归<br>    偏最小二乘回归</p><p>决策树和集成学习模型： 使用特征重要性作为系数, feature_importance_<br>        Decision Tree<br>        Random Forest<br>        GradientBoosting<br>        AdaBoost<br>        XGBRegressor<br>        LightGBM<br>深度学习</p><h2 id="模型的可解释性"><a href="#模型的可解释性" class="headerlink" title="模型的可解释性"></a>模型的可解释性</h2><p>基于shapley值的可解释性，探讨属性的重要程度<br>特征重要性<br>    SHAP的特征重要性是shapley值的大小，或这说绝对值的大小，0表示这个特征可有可无，因为是加性归因，shapley值的特征重要性是累加思想，即每个特征的重要性是可以累加的。<br>        Shapley值是从整体考虑的特征重要性<br>    而原始的XGBoost树模型的特征重要性，是来自该特征在所有树的节点分割中使用的平均增益, 平均增益越大，那么就越重要<br>        表明每个特征在模型内构建提升决策树时的有用性或价值。一个属性特征越是用于决策树的关键决策，其相对重要性就越高<br>        重要性是通过每个属性分割点提高性能指标的量来计算的，性能指标衡量分割点“纯度”，例如信息增益<br>        集成树模型是从局部考虑特征重要性，然后做的加权平均</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>PCA和xlstat</title>
    <link href="/2022/06/24/PCA%E5%92%8Cxlstat/"/>
    <url>/2022/06/24/PCA%E5%92%8Cxlstat/</url>
    
    <content type="html"><![CDATA[<h1 id="PCA和xlsxstat分析"><a href="#PCA和xlsxstat分析" class="headerlink" title="PCA和xlsxstat分析"></a>PCA和xlsxstat分析</h1><img src="/2022/06/24/PCA%E5%92%8Cxlstat/PCA%E5%92%8Cxlstat.png" class="">]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>torch版本和随机数</title>
    <link href="/2022/04/14/torch%E7%89%88%E6%9C%AC%E5%92%8C%E9%9A%8F%E6%9C%BA%E6%95%B0/"/>
    <url>/2022/04/14/torch%E7%89%88%E6%9C%AC%E5%92%8C%E9%9A%8F%E6%9C%BA%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="在不同的PyTorch版本或不同的平台上，不保证完全可重复的结果。此外，即使使用相同的种子，在CPU和GPU的执行中，结果也可能无法重现。"><a href="#在不同的PyTorch版本或不同的平台上，不保证完全可重复的结果。此外，即使使用相同的种子，在CPU和GPU的执行中，结果也可能无法重现。" class="headerlink" title="在不同的PyTorch版本或不同的平台上，不保证完全可重复的结果。此外，即使使用相同的种子，在CPU和GPU的执行中，结果也可能无法重现。"></a>在不同的PyTorch版本或不同的平台上，不保证完全可重复的结果。此外，即使使用相同的种子，在CPU和GPU的执行中，结果也可能无法重现。</h1><p>以下在6台机器上实验，不设置随机数种子, 有的机器是torch相同的版本，有的不是,对比预测的logits分数和最终的预测结果。测试的是情感模型的预测结果.<br>不同的torch版本，也会导致预测有一些差异，但是差异很小，预测的分数有14%的差异，但是数千条数据，预测的结果只有一条有差异</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">w69</span> | CHANGED | rc=<span class="hljs-number">0</span> &gt;&gt;<br><span class="hljs-attribute">torch</span>==<span class="hljs-number">1</span>.<span class="hljs-number">8</span>.<span class="hljs-number">1</span><br><br><span class="hljs-attribute">w79</span> | CHANGED | rc=<span class="hljs-number">0</span> &gt;&gt;<br><span class="hljs-attribute">torch</span>==<span class="hljs-number">1</span>.<span class="hljs-number">8</span>.<span class="hljs-number">1</span><br><br><span class="hljs-attribute">w19</span> | CHANGED | rc=<span class="hljs-number">0</span> &gt;&gt;<br><span class="hljs-attribute">torch</span>==<span class="hljs-number">1</span>.<span class="hljs-number">8</span>.<span class="hljs-number">1</span><br><br><span class="hljs-attribute">w39</span> | CHANGED | rc=<span class="hljs-number">0</span> &gt;&gt;<br><span class="hljs-attribute">torch</span>==<span class="hljs-number">1</span>.<span class="hljs-number">7</span>.<span class="hljs-number">0</span>+cu110<br><br><span class="hljs-attribute">w09</span> | CHANGED | rc=<span class="hljs-number">0</span> &gt;&gt;<br><span class="hljs-attribute">torch</span>==<span class="hljs-number">1</span>.<span class="hljs-number">9</span>.<span class="hljs-number">0</span>+cu111<br><br><span class="hljs-attribute">w89</span> | CHANGED | rc=<span class="hljs-number">0</span> &gt;&gt;<br><span class="hljs-attribute">torch</span>==<span class="hljs-number">1</span>.<span class="hljs-number">9</span>.<span class="hljs-number">0</span>+cu111<br><br><span class="hljs-attribute">w99</span> | CHANGED | rc=<span class="hljs-number">0</span> &gt;&gt;<br><span class="hljs-attribute">torch</span>==<span class="hljs-number">1</span>.<span class="hljs-number">9</span>.<span class="hljs-number">0</span><br></code></pre></td></tr></table></figure><p>预测结果如下：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs stylus">主机<span class="hljs-number">19</span>的结果保存到: <span class="hljs-number">19</span>_result<span class="hljs-selector-class">.xlsx</span>, 标签占比是<span class="hljs-built_in">Counter</span>(&#123;<span class="hljs-string">&#x27;积极&#x27;</span>: <span class="hljs-number">351</span>, <span class="hljs-string">&#x27;中性&#x27;</span>: <span class="hljs-number">109</span>, <span class="hljs-string">&#x27;消极&#x27;</span>: <span class="hljs-number">40</span>&#125;)<br>主机<span class="hljs-number">39</span>的结果保存到: <span class="hljs-number">39</span>_result<span class="hljs-selector-class">.xlsx</span>, 标签占比是<span class="hljs-built_in">Counter</span>(&#123;<span class="hljs-string">&#x27;积极&#x27;</span>: <span class="hljs-number">351</span>, <span class="hljs-string">&#x27;中性&#x27;</span>: <span class="hljs-number">109</span>, <span class="hljs-string">&#x27;消极&#x27;</span>: <span class="hljs-number">40</span>&#125;)<br>主机<span class="hljs-number">69</span>的结果保存到: <span class="hljs-number">69</span>_result<span class="hljs-selector-class">.xlsx</span>, 标签占比是<span class="hljs-built_in">Counter</span>(&#123;<span class="hljs-string">&#x27;积极&#x27;</span>: <span class="hljs-number">351</span>, <span class="hljs-string">&#x27;中性&#x27;</span>: <span class="hljs-number">109</span>, <span class="hljs-string">&#x27;消极&#x27;</span>: <span class="hljs-number">40</span>&#125;)<br>主机<span class="hljs-number">79</span>的结果保存到: <span class="hljs-number">79</span>_result<span class="hljs-selector-class">.xlsx</span>, 标签占比是<span class="hljs-built_in">Counter</span>(&#123;<span class="hljs-string">&#x27;积极&#x27;</span>: <span class="hljs-number">351</span>, <span class="hljs-string">&#x27;中性&#x27;</span>: <span class="hljs-number">109</span>, <span class="hljs-string">&#x27;消极&#x27;</span>: <span class="hljs-number">40</span>&#125;)<br>主机<span class="hljs-number">89</span>的结果保存到: <span class="hljs-number">89</span>_result<span class="hljs-selector-class">.xlsx</span>, 标签占比是<span class="hljs-built_in">Counter</span>(&#123;<span class="hljs-string">&#x27;积极&#x27;</span>: <span class="hljs-number">352</span>, <span class="hljs-string">&#x27;中性&#x27;</span>: <span class="hljs-number">109</span>, <span class="hljs-string">&#x27;消极&#x27;</span>: <span class="hljs-number">39</span>&#125;)<br>主机<span class="hljs-number">09</span>的结果保存到: <span class="hljs-number">09</span>_result<span class="hljs-selector-class">.xlsx</span>, 标签占比是<span class="hljs-built_in">Counter</span>(&#123;<span class="hljs-string">&#x27;积极&#x27;</span>: <span class="hljs-number">352</span>, <span class="hljs-string">&#x27;中性&#x27;</span>: <span class="hljs-number">109</span>, <span class="hljs-string">&#x27;消极&#x27;</span>: <span class="hljs-number">39</span>&#125;)<br></code></pre></td></tr></table></figure><h1 id="对比预测结果和logits"><a href="#对比预测结果和logits" class="headerlink" title="对比预测结果和logits"></a>对比预测结果和logits</h1><p>相同的torch版本，预测结果相同</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">diff <span class="hljs-number">09</span>_result<span class="hljs-selector-class">.xlsx</span><span class="hljs-selector-class">.json</span> <span class="hljs-number">89</span>_result<span class="hljs-selector-class">.xlsx</span>.json<br></code></pre></td></tr></table></figure><p>不同的torch版本，预测结果不同</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">diff -<span class="hljs-selector-tag">q</span> <span class="hljs-number">09</span>_result<span class="hljs-selector-class">.xlsx</span><span class="hljs-selector-class">.json</span> <span class="hljs-number">19</span>_result<span class="hljs-selector-class">.xlsx</span><span class="hljs-selector-class">.json</span><br>Files <span class="hljs-number">09</span>_result<span class="hljs-selector-class">.xlsx</span><span class="hljs-selector-class">.json</span> and <span class="hljs-number">19</span>_result<span class="hljs-selector-class">.xlsx</span><span class="hljs-selector-class">.json</span> differ<br></code></pre></td></tr></table></figure><h1 id="所以我们在复现实验的时候，最好设定随机数种子-例如"><a href="#所以我们在复现实验的时候，最好设定随机数种子-例如" class="headerlink" title="所以我们在复现实验的时候，最好设定随机数种子, 例如"></a>所以我们在复现实验的时候，最好设定随机数种子, 例如</h1><p>设置random_seed</p><figure class="highlight monkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs monkey"><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> numpy as np<br><span class="hljs-built_in">seed</span>=<span class="hljs-number">100</span><span class="hljs-meta"></span><br><span class="hljs-meta"># torch的随机数种子固定，torch.manual_seed已经是支持CPU和GPU了，不需要设置这个torch.cuda.manual_seed_all了</span><br>torch.manual_seed(<span class="hljs-built_in">seed</span>)<span class="hljs-meta"></span><br><span class="hljs-meta"># numpy的随机数种子</span><br>np.random.<span class="hljs-built_in">seed</span>(<span class="hljs-built_in">seed</span>)<span class="hljs-meta"></span><br><span class="hljs-meta"># python的随机数种子</span><br>random.<span class="hljs-built_in">seed</span>(<span class="hljs-built_in">seed</span>)<span class="hljs-meta"></span><br><span class="hljs-meta"># cuDNN的保证每次实验使用相同的算法</span><br>torch.backends.cudnn.benchmark = <span class="hljs-literal">False</span><span class="hljs-meta">   # 如果改为True，表示速度提升，但是不是同一算法</span><span class="hljs-meta"></span><br><span class="hljs-meta"># 保证每个算法的确定性</span><br>torch.backends.cudnn.deterministic = <span class="hljs-literal">True</span> 或torch.use_deterministic_algorithms(<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>torch</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>apex报错</title>
    <link href="/2022/04/12/apex%E6%8A%A5%E9%94%99/"/>
    <url>/2022/04/12/apex%E6%8A%A5%E9%94%99/</url>
    
    <content type="html"><![CDATA[<h1 id="apex-报错"><a href="#apex-报错" class="headerlink" title="apex 报错"></a>apex 报错</h1><p>当使用pytorch_transformers时，遇到报错如下<br>ModuleNotFoundError: No module named ‘fused_layer_norm_cuda’</p><h1 id="解决方式"><a href="#解决方式" class="headerlink" title="解决方式"></a>解决方式</h1><p>手动编译安装apex</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli">git clone https:<span class="hljs-string">//github.com/NVIDIA/apex</span><br><span class="hljs-keyword">cd</span> apex<br>CUDA_HOME=<span class="hljs-string">/usr/local/cuda-11.2</span> pip install -v <span class="hljs-params">--no-cache-dir</span> <span class="hljs-params">--global-option=</span><span class="hljs-string">&quot;--cpp_ext&quot;</span> <span class="hljs-params">--global-option=</span><span class="hljs-string">&quot;--cuda_ext&quot;</span> <span class="hljs-string">./</span><br></code></pre></td></tr></table></figure><h1 id="安装时对不同的cuda版本的需求会导致apex报错"><a href="#安装时对不同的cuda版本的需求会导致apex报错" class="headerlink" title="安装时对不同的cuda版本的需求会导致apex报错"></a>安装时对不同的cuda版本的需求会导致apex报错</h1><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs awk">    Traceback (most recent call last):<br>      File <span class="hljs-string">&quot;&lt;string&gt;&quot;</span>, line <span class="hljs-number">1</span>, <span class="hljs-keyword">in</span> &lt;module&gt;<br>      File <span class="hljs-string">&quot;/media/backup/john/project/apex/setup.py&quot;</span>, line <span class="hljs-number">177</span>, <span class="hljs-keyword">in</span> &lt;module&gt;<br>        check_cuda_torch_binary_vs_bare_metal(CUDA_HOME)<br>      File <span class="hljs-string">&quot;/media/backup/john/project/apex/setup.py&quot;</span>, line <span class="hljs-number">34</span>, <span class="hljs-keyword">in</span> check_cuda_torch_binary_vs_bare_metal<br>        raise RuntimeError(<br>    RuntimeError: Cuda extensions are being compiled with a version of Cuda that does not match the version used to compile Pytorch binaries.  Pytorch binaries were compiled with Cuda <span class="hljs-number">11.3</span>.<br>    In some cases, a minor-version mismatch will not cause later errors:  https:<span class="hljs-regexp">//gi</span>thub.com<span class="hljs-regexp">/NVIDIA/</span>apex<span class="hljs-regexp">/pull/</span><span class="hljs-number">323</span><span class="hljs-comment">#discussion_r287021798.  You can try commenting out this check (at your own risk).</span><br>ERROR: Command errored out with <span class="hljs-keyword">exit</span> status <span class="hljs-number">1</span>: <span class="hljs-regexp">/home/</span>anaconda3<span class="hljs-regexp">/envs/</span>py38<span class="hljs-regexp">/bin/</span>python -u -c <span class="hljs-string">&#x27;import io, os, sys, setuptools, tokenize; sys.argv[0] = &#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;/media//john/project/apex/setup.py&#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;; __file__=&#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;/media//john/project/apex/setup.py&#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;;f = getattr(tokenize, &#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;open&#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;, open)(__file__) if os.path.exists(__file__) else io.StringIO(&#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;from setuptools import setup; setup()&#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;);code = f.read().replace(&#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;\r\n&#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;, &#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;\n&#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;);f.close();exec(compile(code, __file__, &#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;exec&#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;))&#x27;</span> --cpp_ext --cuda_ext install --record <span class="hljs-regexp">/tmp/</span>pip-record-rw1s_hs_<span class="hljs-regexp">/install-record.txt --single-version-externally-managed --compile --install-headers /</span>home<span class="hljs-regexp">//</span>anaconda3<span class="hljs-regexp">/envs/</span>py38<span class="hljs-regexp">/include/</span>python3.<span class="hljs-number">8</span>/apex Check the logs <span class="hljs-keyword">for</span> full command output.<br></code></pre></td></tr></table></figure><p>解决方式，注销掉检查cuda版本的语句即可，例如根据提示，注销掉setup.py的177行，检查cuda版本的句子, 重新编译安装即可</p>]]></content>
    
    
    <categories>
      
      <category>apex</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>neo4j的构建的知识图谱的语法示例</title>
    <link href="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/"/>
    <url>/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="查询包含甘油的产品"><a href="#查询包含甘油的产品" class="headerlink" title="查询包含甘油的产品"></a>查询包含甘油的产品</h1><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">MATCH p=()-[r:PRODUCT_COMPONENT_IS] -&gt;(n:Component &#123;<span class="hljs-type">name</span>:&quot;甘油&quot;&#125;) <span class="hljs-keyword">return</span> p <span class="hljs-keyword">limit</span> <span class="hljs-number">50</span><br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/gan.png" class=""><p>#查看2个品牌之间有什么共同点</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs stylus">MATCH<br>(n:Brand &#123;name:<span class="hljs-string">&quot;希思黎&quot;</span>&#125;), (<span class="hljs-selector-tag">b</span>:Brand &#123;name:<span class="hljs-string">&#x27;欧莱雅&#x27;</span>&#125;), <span class="hljs-selector-tag">p</span> = <span class="hljs-built_in">allShortestPaths</span>((n)-<span class="hljs-selector-attr">[*]</span><span class="hljs-built_in">-</span>(b))<br>RETURN <span class="hljs-selector-tag">p</span> <br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/pin.png" class=""><h1 id="法国品牌"><a href="#法国品牌" class="headerlink" title="法国品牌"></a>法国品牌</h1><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">MATCH p=()-[r:BRAND_COUNTRY_IS]-&gt;(c:Country &#123;<span class="hljs-type">name</span>:&quot;法国&quot;&#125;) <span class="hljs-keyword">RETURN</span> p <span class="hljs-keyword">LIMIT</span> <span class="hljs-number">25</span><br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/fa.png" class=""><h1 id="collect-统计-各个品牌关于手部护理的产品的价格统计"><a href="#collect-统计-各个品牌关于手部护理的产品的价格统计" class="headerlink" title="collect 统计, 各个品牌关于手部护理的产品的价格统计"></a>collect 统计, 各个品牌关于手部护理的产品的价格统计</h1><figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs livescript">MATCH <span class="hljs-function"><span class="hljs-params">(:ProductCategory &#123;name:<span class="hljs-string">&quot;手部护理&quot;</span>&#125;)</span>--&gt;</span><span class="hljs-function"><span class="hljs-params">(:ProductCategory)</span>&lt;--<span class="hljs-params">(p:Product)</span>--&gt;</span>(b:Brand)<br>RETURN b.name <span class="hljs-keyword">as</span> Brand, collect(distinct p.price) <span class="hljs-keyword">as</span> Price<br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/price.png" class=""><h1 id="价格在200-300之间"><a href="#价格在200-300之间" class="headerlink" title="价格在200-300之间"></a>价格在200-300之间</h1><figure class="highlight fortran"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs fortran">MATCH (n:<span class="hljs-built_in">Product</span>) <span class="hljs-keyword">WHERE</span> n.price &gt;= <span class="hljs-number">200</span> AND n.price &lt; <span class="hljs-number">300</span> <span class="hljs-keyword">RETURN</span> n<br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/pris.png" class=""><h1 id="欧莱雅商品"><a href="#欧莱雅商品" class="headerlink" title="欧莱雅商品"></a>欧莱雅商品</h1><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs css">MATCH (n:Brand &#123;name:<span class="hljs-string">&quot;欧莱雅&quot;</span>&#125;) &lt;-<span class="hljs-selector-attr">[:PRODUCT_BRAND_IS]</span>-(<span class="hljs-selector-tag">p</span>) RETURN n,<span class="hljs-selector-tag">p</span> LIMIT <span class="hljs-number">25</span><br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/ou.png" class=""><h1 id="同样功效的产品"><a href="#同样功效的产品" class="headerlink" title="同样功效的产品"></a>同样功效的产品</h1><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs css">MATCH (n:Product &#123;name:<span class="hljs-string">&quot;欧莱雅强韧柔顺洗发露&quot;</span>&#125;)-<span class="hljs-selector-attr">[:PRODUCT_EFFECT_IS]</span>-&gt;(m)&lt;-<span class="hljs-selector-attr">[:PRODUCT_EFFECT_IS]</span>-(<span class="hljs-selector-tag">p</span>) RETURN n,<span class="hljs-selector-tag">p</span><br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/same.png" class=""><h1 id="同样功效，价格便宜"><a href="#同样功效，价格便宜" class="headerlink" title="同样功效，价格便宜"></a>同样功效，价格便宜</h1><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs css">MATCH (n:Product &#123;name:<span class="hljs-string">&quot;倩碧水嫩保湿水精萃&quot;</span>&#125;)-<span class="hljs-selector-attr">[:PRODUCT_EFFECT_IS]</span>-&gt;(m)&lt;-<span class="hljs-selector-attr">[:PRODUCT_EFFECT_IS]</span>-(<span class="hljs-selector-tag">p</span>) WHERE <span class="hljs-selector-tag">p</span><span class="hljs-selector-class">.price</span> &lt;n<span class="hljs-selector-class">.price</span> RETURN n,<span class="hljs-selector-tag">p</span> Limit <span class="hljs-number">10</span><br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/smae.png" class=""><h1 id="希思黎生产过哪些类型产品"><a href="#希思黎生产过哪些类型产品" class="headerlink" title="希思黎生产过哪些类型产品"></a>希思黎生产过哪些类型产品</h1><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs lisp">MATCH (<span class="hljs-name">c</span><span class="hljs-symbol">:Brand</span> &#123;name:<span class="hljs-string">&quot;希思黎&quot;</span>&#125;)&lt;--(<span class="hljs-symbol">:Product</span>)--&gt;(<span class="hljs-name">s</span><span class="hljs-symbol">:ProductCategory</span>)<br>RETURN DISTINCT s<br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/xisi.png" class=""><h1 id="小众品牌"><a href="#小众品牌" class="headerlink" title="小众品牌"></a>小众品牌</h1><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">MATCH p=()-[r:BRAND_POPULARITY_IS]-&gt;(b:BrandPopularity &#123;<span class="hljs-type">name</span>:&quot;小众&quot;&#125;) <span class="hljs-keyword">RETURN</span> p <span class="hljs-keyword">LIMIT</span> <span class="hljs-number">25</span><br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/xiaozhong.png" class=""><h1 id="找2个产品2跳以内的共同点"><a href="#找2个产品2跳以内的共同点" class="headerlink" title="找2个产品2跳以内的共同点"></a>找2个产品2跳以内的共同点</h1><figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs excel"><span class="hljs-built_in">MATCH</span> p=(<br>(<span class="hljs-symbol">n:Pr</span>oduct &#123;<span class="hljs-built_in">na</span><span class="hljs-symbol">me:</span><span class="hljs-string">&quot;倩碧水嫩保湿水精萃&quot;</span>&#125;)-[*<span class="hljs-number">1</span>..<span class="hljs-number">2</span>]-(<span class="hljs-symbol">m:Pr</span>oduct &#123;<span class="hljs-built_in">na</span><span class="hljs-symbol">me:</span><span class="hljs-string">&quot;蒂迩肌男士水油平衡洁面泡沫&quot;</span>&#125;)<br>)<br>RETURN p<br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/liangtiao.png" class=""><h1 id="找2个产品的一个共同点"><a href="#找2个产品的一个共同点" class="headerlink" title="找2个产品的一个共同点"></a>找2个产品的一个共同点</h1><figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs excel"><span class="hljs-built_in">MATCH</span> p=shortestPath(<br>(<span class="hljs-symbol">n:Pr</span>oduct &#123;<span class="hljs-built_in">na</span><span class="hljs-symbol">me:</span><span class="hljs-string">&quot;倩碧水嫩保湿水精萃&quot;</span>&#125;)-[*]-(<span class="hljs-symbol">m:Pr</span>oduct &#123;<span class="hljs-built_in">na</span><span class="hljs-symbol">me:</span><span class="hljs-string">&quot;蒂迩肌男士水油平衡洁面泡沫&quot;</span>&#125;)<br>)<br>RETURN p<br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/yige.png" class=""><h1 id="总产品数"><a href="#总产品数" class="headerlink" title="总产品数"></a>总产品数</h1><figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs excel"><span class="hljs-built_in">MATCH</span> (<span class="hljs-symbol">n:Pr</span>oduct)<br>RETURN <span class="hljs-built_in">count</span>(<span class="hljs-built_in">n</span>)<br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/az.png" class=""><h1 id="总成分数"><a href="#总成分数" class="headerlink" title="总成分数"></a>总成分数</h1><figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs excel"><span class="hljs-built_in">MATCH</span> (<span class="hljs-symbol">n:Co</span>mponent)<br>RETURN <span class="hljs-built_in">count</span>(<span class="hljs-built_in">n</span>)<br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/chf.png" class=""><h1 id="meta-graph，元图"><a href="#meta-graph，元图" class="headerlink" title="meta-graph，元图"></a>meta-graph，元图</h1><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">CALL</span> db.<span class="hljs-keyword">schema</span>.visualization()<br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/zitu.png" class="">]]></content>
    
    
    <categories>
      
      <category>知识图谱</category>
      
    </categories>
    
    
    <tags>
      
      <tag>cql语法</tag>
      
      <tag>neo4j</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ubuntu20.04的Realtek网卡驱动安装</title>
    <link href="/2022/03/14/ubuntu20-04%E7%9A%84Realtek%E7%BD%91%E5%8D%A1%E9%A9%B1%E5%8A%A8%E5%AE%89%E8%A3%85/"/>
    <url>/2022/03/14/ubuntu20-04%E7%9A%84Realtek%E7%BD%91%E5%8D%A1%E9%A9%B1%E5%8A%A8%E5%AE%89%E8%A3%85/</url>
    
    <content type="html"><![CDATA[<h1 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h1><p>ubuntu的20.04版本对部分网卡的驱动没有默认集成，需要手动安装, 记录下安装流程</p><h2 id="查看网卡型号"><a href="#查看网卡型号" class="headerlink" title="查看网卡型号"></a>查看网卡型号</h2><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs dts">sudo lshw -C network<br>  *-network                 <br><span class="hljs-symbol">       description:</span> Ethernet interface<br><span class="hljs-symbol">       product:</span> RTL8125 <span class="hljs-number">2.5</span>GbE Controller<br><span class="hljs-symbol">       vendor:</span> Realtek Semiconductor Co., Ltd.<br></code></pre></td></tr></table></figure><h2 id="得知型号是RTL8125-2-5G，然后去官方网站下载对应的驱动"><a href="#得知型号是RTL8125-2-5G，然后去官方网站下载对应的驱动" class="headerlink" title="得知型号是RTL8125 2.5G，然后去官方网站下载对应的驱动"></a>得知型号是RTL8125 2.5G，然后去官方网站下载对应的驱动</h2><p><a href="https://www.realtek.com/en/component/zoo/category/network-interface-controllers-10-100-1000m-gigabit-ethernet-pci-express-software">https://www.realtek.com/en/component/zoo/category/network-interface-controllers-10-100-1000m-gigabit-ethernet-pci-express-software</a></p><h2 id="在你的机器上首先确保有make相关组件-新安装系统时需要安装好一些编译的包，也可以按下列方式重新安装"><a href="#在你的机器上首先确保有make相关组件-新安装系统时需要安装好一些编译的包，也可以按下列方式重新安装" class="headerlink" title="在你的机器上首先确保有make相关组件,新安装系统时需要安装好一些编译的包，也可以按下列方式重新安装"></a>在你的机器上首先确保有make相关组件,新安装系统时需要安装好一些编译的包，也可以按下列方式重新安装</h2><h3 id="首先，你网卡没法联网，只能使用本地镜像，本地镜像的构建方式如下"><a href="#首先，你网卡没法联网，只能使用本地镜像，本地镜像的构建方式如下" class="headerlink" title="首先，你网卡没法联网，只能使用本地镜像，本地镜像的构建方式如下:"></a>首先，你网卡没法联网，只能使用本地镜像，本地镜像的构建方式如下:</h3><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment">#挂载镜像</span><br>mkdir <span class="hljs-regexp">/media/i</span>so<br>sudo mount  ~<span class="hljs-regexp">/Desktop/u</span>buntu-<span class="hljs-number">20.04</span>.<span class="hljs-number">2.0</span>-desktop-amd64.iso <span class="hljs-regexp">/media/i</span>so<br></code></pre></td></tr></table></figure><p>#focal是ubtunu20.04的版本的名称<br>sudo vim &#x2F;etc&#x2F;apt&#x2F;sources.list<br>deb file:&#x2F;media&#x2F;iso&#x2F; focal main contrib</p><p>#更新下包的缓存<br>sudo apt update</p><p>#安装make命令, build-essential是编译代码所需的包，iso镜像中自带了，其实可以在安装系统时安装上<br>sudo apt install build-essential 或者make</p><h2 id="然把你下载的驱动拷贝到服务器，我的对应驱动是r8125-9-005-06-tar-bz2"><a href="#然把你下载的驱动拷贝到服务器，我的对应驱动是r8125-9-005-06-tar-bz2" class="headerlink" title="然把你下载的驱动拷贝到服务器，我的对应驱动是r8125-9.005.06.tar.bz2"></a>然把你下载的驱动拷贝到服务器，我的对应驱动是r8125-9.005.06.tar.bz2</h2><p>解压<br>tar jxvf r8125-9.005.06.tar.bz2</p><h2 id="编译和安装"><a href="#编译和安装" class="headerlink" title="编译和安装"></a>编译和安装</h2><p>cd r8125-9.005.06<br>sudo make<br>sudo .&#x2F;autorun.sh</p><h2 id="正常查看网络，或者手动配置ip"><a href="#正常查看网络，或者手动配置ip" class="headerlink" title="正常查看网络，或者手动配置ip"></a>正常查看网络，或者手动配置ip</h2><p>ip a</p>]]></content>
    
    
    <categories>
      
      <category>linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ubuntu</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ubuntu远程桌面的三种实现方式</title>
    <link href="/2022/03/14/ubuntu%E8%BF%9C%E7%A8%8B%E6%A1%8C%E9%9D%A2/"/>
    <url>/2022/03/14/ubuntu%E8%BF%9C%E7%A8%8B%E6%A1%8C%E9%9D%A2/</url>
    
    <content type="html"><![CDATA[<h1 id="方式1：-ubuntu-自带的vino的版本的vnc"><a href="#方式1：-ubuntu-自带的vino的版本的vnc" class="headerlink" title="方式1： ubuntu 自带的vino的版本的vnc"></a>方式1： ubuntu 自带的vino的版本的vnc</h1><h2 id="步骤1，需要登录到ubuntu的桌面环境，找到设置-然后找到Sharing选项"><a href="#步骤1，需要登录到ubuntu的桌面环境，找到设置-然后找到Sharing选项" class="headerlink" title="步骤1，需要登录到ubuntu的桌面环境，找到设置, 然后找到Sharing选项"></a>步骤1，需要登录到ubuntu的桌面环境，找到设置, 然后找到Sharing选项</h2><p>点击Screen Sharing，设置一个密码，注意Network选项是开启的</p><h2 id="步骤2-取消加密协议"><a href="#步骤2-取消加密协议" class="headerlink" title="步骤2,取消加密协议"></a>步骤2,取消加密协议</h2><p>不用root用户运行，取消加密</p><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs lasso">gsettings <span class="hljs-built_in">set</span> org.gnome.Vino <span class="hljs-keyword">require</span><span class="hljs-params">-encryption</span> <span class="hljs-literal">false</span><br></code></pre></td></tr></table></figure><h2 id="步骤3，使用苹果的屏幕共享货vnc-viewer连接即可-端口5900"><a href="#步骤3，使用苹果的屏幕共享货vnc-viewer连接即可-端口5900" class="headerlink" title="步骤3，使用苹果的屏幕共享货vnc viewer连接即可, 端口5900"></a>步骤3，使用苹果的屏幕共享货vnc viewer连接即可, 端口5900</h2><h1 id="方式2：-使用tigervnc"><a href="#方式2：-使用tigervnc" class="headerlink" title="方式2： 使用tigervnc"></a>方式2： 使用tigervnc</h1><h2 id="安装tigervnc-vncserver和vncconfig命令安装成功"><a href="#安装tigervnc-vncserver和vncconfig命令安装成功" class="headerlink" title="安装tigervnc, vncserver和vncconfig命令安装成功"></a>安装tigervnc, vncserver和vncconfig命令安装成功</h2><figure class="highlight axapta"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs axapta">apt install tigervnc-standalone-<span class="hljs-keyword">server</span><br></code></pre></td></tr></table></figure><p>其它机器可以安装 客户端，如果需要连接vncserver</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake">apt <span class="hljs-keyword">install</span> tigervnc-viewer<br></code></pre></td></tr></table></figure><p>默认使用当前用户连接VNC，如果需要使用其它用户连接VNC server，那么需要建立新的用户<br>设置VNC的连接密码</p><figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs vbnet">vncpasswd<br><span class="hljs-symbol">Password:</span><br><span class="hljs-symbol">Verify:</span><br>Would you <span class="hljs-built_in">like</span> <span class="hljs-keyword">to</span> enter a view-only password (y/n)? n  #不设置只能查看的vnc密码<br></code></pre></td></tr></table></figure><h2 id="编辑用户下的配置文件"><a href="#编辑用户下的配置文件" class="headerlink" title="编辑用户下的配置文件"></a>编辑用户下的配置文件</h2><p>.vnc&#x2F;xstartup<br>内容如下，这是专为Gnome准备的</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment">#!/bin/sh</span><br><span class="hljs-comment"># Start Gnome 3 Desktop </span><br>[ -x <span class="hljs-regexp">/etc/</span>vnc<span class="hljs-regexp">/xstartup ] &amp;&amp; exec /</span>etc<span class="hljs-regexp">/vnc/</span>xstartup<br>[ -r <span class="hljs-variable">$HOME</span><span class="hljs-regexp">/.Xresources ] &amp;&amp; xrdb $HOME/</span>.Xresources<br>vncconfig -iconic &amp;<br>dbus-launch --<span class="hljs-keyword">exit</span>-with-session gnome-session &amp;<br></code></pre></td></tr></table></figure><p>可执行权限<br>chmod a+x .vnc&#x2F;xstartup</p><h2 id="启动vncserver"><a href="#启动vncserver" class="headerlink" title="启动vncserver"></a>启动vncserver</h2><p>vncserver -localhost no  #不是只监听localhost的端口</p><p>#查看启动的VNCserver<br>vncserver -list</p><p>#如果不使用VNC，可以选择kill掉, :1代表kill 5901端口<br>vncserver -kill :1</p><p>#vncserver的自启动服务<br>mkdir -p .local&#x2F;share&#x2F;systemd&#x2F;user&#x2F;</p><h2 id="步骤4-作为服务启动"><a href="#步骤4-作为服务启动" class="headerlink" title="步骤4: 作为服务启动"></a>步骤4: 作为服务启动</h2><p>#编辑用户的service<br>#cat .local&#x2F;share&#x2F;systemd&#x2F;user&#x2F;vncserver@.service</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-section">[Unit]</span><br><span class="hljs-attr">Description</span>=TigerVNC Service<br><br><span class="hljs-section">[Service]</span><br><span class="hljs-attr">Type</span>=forking<br><span class="hljs-attr">ExecStartPre</span>=-/usr/bin/vncserver -kill :%i &gt; /dev/null <span class="hljs-number">2</span>&gt;&amp;<span class="hljs-number">1</span><br><span class="hljs-attr">ExecStart</span>=/usr/bin/vncserver :%i -localhost <span class="hljs-literal">no</span><br><span class="hljs-attr">ExecStop</span>=/usr/bin/vncserver -kill :%i<br><br><span class="hljs-section">[Install]</span><br><span class="hljs-attr">WantedBy</span>=default.target<br></code></pre></td></tr></table></figure><p>#vim ~&#x2F;.xinitrc   #启动VNC的时候使用x11的session<br>export XDG_SESSION_TYPE&#x3D;x11</p><p>#创建服务的xtartup脚本, 这个是用于服务的<br>sudo mkdir &#x2F;etc&#x2F;vnc<br>sudo cat &#x2F;etc&#x2F;vnc&#x2F;xstartup</p><figure class="highlight d"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs d"><span class="hljs-meta">#!/bin/sh</span><br>test x<span class="hljs-string">&quot;$SHELL&quot;</span> = <span class="hljs-string">x&quot;&quot;</span> &amp;&amp; SHELL=/bin/bash<br>test x<span class="hljs-string">&quot;$1&quot;</span>     = <span class="hljs-string">x&quot;&quot;</span> &amp;&amp; set -- <span class="hljs-keyword">default</span><br><br>vncconfig -iconic &amp;<br><span class="hljs-string">&quot;$SHELL&quot;</span> -l &lt;&lt; EOF<br><span class="hljs-keyword">export</span> XDG_SESSION_TYPE=x11<br><span class="hljs-keyword">export</span> GNOME_SHELL_SESSION_MODE=ubuntu<br>dbus-launch --exit-<span class="hljs-keyword">with</span>-session gnome-session --session=ubuntu<br>EOF<br>vncserver -kill $DISPLAY<br></code></pre></td></tr></table></figure><p>#设置可执行<br>sudo chmod a+x  &#x2F;etc&#x2F;vnc&#x2F;xstartup</p><p>#用户的服务reload, 只能这个用户启动<br>systemctl daemon-reload –user<br>systemctl restart <a href="mailto:&#x76;&#x6e;&#99;&#x73;&#101;&#114;&#x76;&#x65;&#x72;&#x40;&#x31;&#46;&#x73;&#101;&#x72;&#x76;&#x69;&#99;&#101;">&#x76;&#x6e;&#99;&#x73;&#101;&#114;&#x76;&#x65;&#x72;&#x40;&#x31;&#46;&#x73;&#101;&#x72;&#x76;&#x69;&#99;&#101;</a> –user<br>systemctl status <a href="mailto:&#118;&#110;&#x63;&#115;&#101;&#114;&#x76;&#x65;&#x72;&#64;&#x31;&#46;&#x73;&#101;&#x72;&#118;&#x69;&#x63;&#x65;">&#118;&#110;&#x63;&#115;&#101;&#114;&#x76;&#x65;&#x72;&#64;&#x31;&#46;&#x73;&#101;&#x72;&#118;&#x69;&#x63;&#x65;</a> –user<br>#加到开机启动<br>systemctl enable <a href="mailto:&#118;&#110;&#99;&#x73;&#101;&#114;&#x76;&#101;&#114;&#64;&#x31;&#46;&#115;&#x65;&#114;&#118;&#105;&#99;&#x65;">&#118;&#110;&#99;&#x73;&#101;&#114;&#x76;&#101;&#114;&#64;&#x31;&#46;&#115;&#x65;&#114;&#118;&#105;&#99;&#x65;</a> –user</p><h1 id="方法3：Ubuntu-xrdp的安装方法-xrdp等同于vnc-server，只是需要用微软的remote-desktop工具连接"><a href="#方法3：Ubuntu-xrdp的安装方法-xrdp等同于vnc-server，只是需要用微软的remote-desktop工具连接" class="headerlink" title="方法3：Ubuntu xrdp的安装方法, xrdp等同于vnc server，只是需要用微软的remote desktop工具连接"></a>方法3：Ubuntu xrdp的安装方法, xrdp等同于vnc server，只是需要用微软的remote desktop工具连接</h1><h2 id="如果没安装Desktop环境，需要安装"><a href="#如果没安装Desktop环境，需要安装" class="headerlink" title="如果没安装Desktop环境，需要安装"></a>如果没安装Desktop环境，需要安装</h2><p>sudo apt install tasksel -y<br>tasksel   #选中Ubuntu desktop，然后开始安装<br>systemctl set-default graphical.target #  启动图像界面作为默认</p><h2 id="安装xrdp"><a href="#安装xrdp" class="headerlink" title="安装xrdp"></a>安装xrdp</h2><p>sudo apt install xrdp -y<br>sudo systemctl status xrdp<br>sudo systemctl enable xrdp<br>sudo usermod -a -G ssl-cert xxx   #把你的当前用户xxx用户加入到ssl用户组，例如johnson<br>sudo vim &#x2F;etc&#x2F;xrdp&#x2F;startwm.sh<br>#在前2行加入如下配置<br>Unset DBUS_SESSION_ADDRESS<br>Unset XDG_RUNTIME_DIR</p><p>sudo systemctl restart xrdp</p><h2 id="如果启用了防火墙，需要配置3389可以访问"><a href="#如果启用了防火墙，需要配置3389可以访问" class="headerlink" title="如果启用了防火墙，需要配置3389可以访问"></a>如果启用了防火墙，需要配置3389可以访问</h2><p>sudo ufw allow from 192.168.1.0&#x2F;24 to any port 3389<br>sudo ufw reload</p><h2 id="完成，可以用微软的远程桌面客户端工具开始连接-也可以通过NAT映射出去一个端口，那么连接的时候直接用IP-PORT的"><a href="#完成，可以用微软的远程桌面客户端工具开始连接-也可以通过NAT映射出去一个端口，那么连接的时候直接用IP-PORT的" class="headerlink" title="完成，可以用微软的远程桌面客户端工具开始连接, 也可以通过NAT映射出去一个端口，那么连接的时候直接用IP:PORT的"></a>完成，可以用微软的远程桌面客户端工具开始连接, 也可以通过NAT映射出去一个端口，那么连接的时候直接用IP:PORT的</h2><p>方式连接就可以</p><p>#日志位置<br>sudo tail -f &#x2F;var&#x2F;log&#x2F;xrdp.log</p><p>#如果连接进行是黑屏，处理方法<br>echo “gnome-session -–session&#x3D;gnome-fallback” &gt; ~&#x2F;.xsession<br>sudo &#x2F;etc&#x2F;init.d&#x2F;xrdp restart</p><h1 id="然后再删掉-xsession-重启后就恢复了"><a href="#然后再删掉-xsession-重启后就恢复了" class="headerlink" title="然后再删掉.xsession, 重启后就恢复了"></a>然后再删掉.xsession, 重启后就恢复了</h1>]]></content>
    
    
    <categories>
      
      <category>linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ubuntu</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>知乎博客检索</title>
    <link href="/2022/03/11/%E7%9F%A5%E4%B9%8E%E5%8D%9A%E5%AE%A2%E6%A3%80%E7%B4%A2/"/>
    <url>/2022/03/11/%E7%9F%A5%E4%B9%8E%E5%8D%9A%E5%AE%A2%E6%A3%80%E7%B4%A2/</url>
    
    <content type="html"><![CDATA[<p>具有交叉注意力控制功能的提示-提示图像编辑<br><a href="https://zhuanlan.zhihu.com/p/577527077">https://zhuanlan.zhihu.com/p/577527077</a><br>PROMPT-TO-PROMPT IMAGE EDITING WITH CROSS-ATTENTION CONTROL</p><p>知识图谱在食品科学与工业中的应用<br><a href="https://zhuanlan.zhihu.com/p/591966904">https://zhuanlan.zhihu.com/p/591966904</a><br>APPLICATIONS OF KNOWLEDGE GRAPHS FOR THE FOOD SCIENCE AND INDUSTRY</p><p>AltCLIP：改变CLIP中的语言编码器以扩展语言能力<br><a href="https://zhuanlan.zhihu.com/p/589700046">https://zhuanlan.zhihu.com/p/589700046</a><br>AltCLIP：Altering the Language Encoder in CLIP for Extended Language Capabilities</p><p>使用Attention-RPN和多关系检测器进行few-shot目标检测<br><a href="https://zhuanlan.zhihu.com/p/588230585">https://zhuanlan.zhihu.com/p/588230585</a><br>Few-Shot Object Detection with Attention-RPN and Multi-Relation Detector</p><p>FSCE: 通过对比性建议编码进行的few-shot目标检测<br><a href="https://zhuanlan.zhihu.com/p/588231035">https://zhuanlan.zhihu.com/p/588231035</a><br>FSCE： Few-Shot Object Detection via Contrastive Proposal Encoding</p><p>AliMe Assist：打造创新电商体验的智能助手<br><a href="https://zhuanlan.zhihu.com/p/587596523">https://zhuanlan.zhihu.com/p/587596523</a><br>AliMe Assist： An Intelligent Assistant for Creating an Innovative E-commerce Experience</p><p>社交聊天机器人小冰的设计与实现<br><a href="https://zhuanlan.zhihu.com/p/587595835">https://zhuanlan.zhihu.com/p/587595835</a><br>The Design and Implementation of XiaoIce, an Empathetic Social Chatbot</p><p>用于多目标跟踪的准密集相似性学习<br><a href="https://zhuanlan.zhihu.com/p/586082025">https://zhuanlan.zhihu.com/p/586082025</a><br>Quasi-Dense Similarity Learning for Multiple Object Tracking</p><p>深度感知的生成对抗网络用于口播视频的生成<br><a href="https://zhuanlan.zhihu.com/p/569320116">https://zhuanlan.zhihu.com/p/569320116</a><br>Depth-Aware Generative Adversarial Network for Talking Head Video Generation</p><p>使用 Vision Transformers 进行简单的开放式单词表目标检测<br><a href="https://zhuanlan.zhihu.com/p/586087658">https://zhuanlan.zhihu.com/p/586087658</a><br>Simple Open-Vocabulary Object Detection with Vision Transformers</p><p>用于one-shot目标检测的平衡和层次关系学习<br><a href="https://zhuanlan.zhihu.com/p/586094468">https://zhuanlan.zhihu.com/p/586094468</a><br>Balanced and Hierarchical Relation Learning for One-shot Object Detection</p><p>用于one-shot目标检测的自适应图像transformer<br><a href="https://zhuanlan.zhihu.com/p/585327946">https://zhuanlan.zhihu.com/p/585327946</a><br>Adaptive Image Transformer for One-Shot Object Detection</p><p>roformer：带有旋转位置嵌入的增强型transformer<br><a href="https://zhuanlan.zhihu.com/p/574478161">https://zhuanlan.zhihu.com/p/574478161</a><br>ROFORMER： ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING</p><p>用于One-shot目标检测的语义对齐融合transformer<br><a href="https://zhuanlan.zhihu.com/p/585256263">https://zhuanlan.zhihu.com/p/585256263</a><br>Semantic-aligned Fusion Transformer for One-shot Object Detection</p><p>PIFuHD：用于高分辨率三维人体数字化的多级像素对齐隐式函数<br><a href="https://zhuanlan.zhihu.com/p/566093991">https://zhuanlan.zhihu.com/p/566093991</a><br>PIFuHD： Multi-Level Pixel-Aligned Implicit Function for High-Resolution 3D Human Digitization</p><p>Imagic: 基于文本的真实图像编辑与扩散模型<br><a href="https://zhuanlan.zhihu.com/p/576710237">https://zhuanlan.zhihu.com/p/576710237</a><br>Imagic: Text-Based Real Image Editing with Diffusion Models</p><p>多模态对比学习LIMoE: 图像-语言的混合专家<br><a href="https://zhuanlan.zhihu.com/p/583728857">https://zhuanlan.zhihu.com/p/583728857</a><br>Multimodal Contrastive Learning with LIMoE：the Language-Image Mixture of Experts</p><p>统一的多选视角实现自然语言理解的zero-shot学习<br><a href="https://zhuanlan.zhihu.com/p/577097077">https://zhuanlan.zhihu.com/p/577097077</a><br>Zero-Shot Learners for Natural Language Understanding via a Uniﬁed Multiple Choice Perspective</p><p>用于通用信息提取的统一结构生成<br><a href="https://zhuanlan.zhihu.com/p/569268582">https://zhuanlan.zhihu.com/p/569268582</a><br>Uniﬁed Structure Generation for Universal Information Extraction</p><p>Copilot: 评估在代码上训练的大型语言模型<br><a href="https://zhuanlan.zhihu.com/p/571373422">https://zhuanlan.zhihu.com/p/571373422</a><br>Evaluating Large Language Models Trained on Code</p><p>视觉表示学习的多模态对比性训练<br><a href="https://zhuanlan.zhihu.com/p/544355035">https://zhuanlan.zhihu.com/p/544355035</a><br>Multimodal Contrastive Training for Visual Representation Learning</p><p>KenLM：更快、更小的语言模型查询<br><a href="https://zhuanlan.zhihu.com/p/564731709">https://zhuanlan.zhihu.com/p/564731709</a><br>KenLM： Faster and Smaller Language Model Queries</p><p>GenIE: 生成式信息提取<br><a href="https://zhuanlan.zhihu.com/p/562155662">https://zhuanlan.zhihu.com/p/562155662</a><br>GenIE： Generative Information Extraction</p><p>通过路由不确定性意识的交易专家进行量化股票投资的多任务学习方法<br><a href="https://zhuanlan.zhihu.com/p/543453690">https://zhuanlan.zhihu.com/p/543453690</a><br>Quantitative Stock Investment by Routing Uncertainty-Aware Trading Experts： A Multi-Task Learning Approach</p><p>ViLBERT: 视觉和语言任务的预训练任务无关的视觉语言学表示<br><a href="https://zhuanlan.zhihu.com/p/545869261">https://zhuanlan.zhihu.com/p/545869261</a><br>ViLBERT： Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks</p><p>用于手写2202数学表达式识别的计数感知网络<br><a href="https://zhuanlan.zhihu.com/p/546590327">https://zhuanlan.zhihu.com/p/546590327</a><br>When Counting Meets HMER：Counting-Aware Network for Handwritten 2202 Mathematical Expression Recognition</p><p>OpenPose: 使用部分亲和域的实时多人二维姿势估计<br><a href="https://zhuanlan.zhihu.com/p/561804021">https://zhuanlan.zhihu.com/p/561804021</a><br>OpenPose： Realtime Multi-Person 2D Pose Estimation using Part Afﬁnity Fields</p><p>使用二维动漫人物表的协作式神经渲染模型<br><a href="https://zhuanlan.zhihu.com/p/560585021">https://zhuanlan.zhihu.com/p/560585021</a><br>Collaborative Neural Rendering using 2D Anime Character Sheets</p><p>GLM: 自回归空白填充的通用语言模型预训练<br><a href="https://zhuanlan.zhihu.com/p/560559133">https://zhuanlan.zhihu.com/p/560559133</a><br>GLM： General Language Model Pretraining with Autoregressive Blank Inﬁlling</p><p>图像作为一种外语: 所有视觉和视觉语言任务的BEIT预训练<br><a href="https://zhuanlan.zhihu.com/p/559116135">https://zhuanlan.zhihu.com/p/559116135</a><br>Image as a Foreign Language： BEIT Pretraining for All Vision and Vision-Language Tasks</p><p>多粒度视觉语言预训练：将文本与视觉概念联系起来<br><a href="https://zhuanlan.zhihu.com/p/554130166">https://zhuanlan.zhihu.com/p/554130166</a><br>Multi-Grained Vision Language Pre-Training：Aligning Texts with Visual Concepts</p><p>ERNIE-ViL：通过场景图的知识强化视觉语言表述<br><a href="https://zhuanlan.zhihu.com/p/554100902">https://zhuanlan.zhihu.com/p/554100902</a><br>ERNIE-ViL： Knowledge Enhanced Vision-Language Representations through Scene Graphs</p><p>OFA：通过一个简单的seq2seq的学习框架来统一架构、任务和模态<br><a href="https://zhuanlan.zhihu.com/p/548392602">https://zhuanlan.zhihu.com/p/548392602</a><br>OFA： UNIFYING ARCHITECTURES, TASKS, AND MODALITIES THROUGH A SIMPLE SEQUENCE-TO-SEQUENCE LEARNING FRAMEWORK</p><p>Wukong：一亿规模的中文跨模态预训练基准<br><a href="https://zhuanlan.zhihu.com/p/551622338">https://zhuanlan.zhihu.com/p/551622338</a><br>Wukong：A 100 Million Large-scale Chinese Cross-modal Pre-training Benchmark</p><p>YOLOv7：可训练的bag-of-freebies为实时目标检测器树立了新的榜样<br><a href="https://zhuanlan.zhihu.com/p/546609857">https://zhuanlan.zhihu.com/p/546609857</a><br>YOLOv7： Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors</p><p>ReFNet:多模态融合精炼网络<br><a href="https://zhuanlan.zhihu.com/p/545135269">https://zhuanlan.zhihu.com/p/545135269</a><br>Multimodal Fusion Refiner Networks</p><p>SimCLR:视觉表示对比学习的简单框架<br><a href="https://zhuanlan.zhihu.com/p/544005001">https://zhuanlan.zhihu.com/p/544005001</a><br>A Simple Framework for Contrastive Learning of Visual Representations</p><p>有监督的对比学习<br><a href="https://zhuanlan.zhihu.com/p/543961298">https://zhuanlan.zhihu.com/p/543961298</a><br>Supervised Contrastive Learning</p><p>仅从字幕中训练视觉语言transformer模型<br><a href="https://zhuanlan.zhihu.com/p/540718732">https://zhuanlan.zhihu.com/p/540718732</a><br>Training Vision-Language Transformers from Captions Alone</p><p>MS-COCO的扩展模态内和模态间语义相似性判断<br><a href="https://zhuanlan.zhihu.com/p/540954741">https://zhuanlan.zhihu.com/p/540954741</a><br>Crisscrossed Captions：Extended Intramodal and Intermodal Semantic Similarity Judgments for MS-COCO</p><p>利用表示编码簿进行多模态对齐<br><a href="https://zhuanlan.zhihu.com/p/540703003">https://zhuanlan.zhihu.com/p/540703003</a><br>Multi-modal Alignment using Representation Codebook</p><p>M6: 一个中文的多模态预训练模型<br><a href="https://zhuanlan.zhihu.com/p/541143888">https://zhuanlan.zhihu.com/p/541143888</a><br>M6： A Chinese Multimodal Pretrainer</p><p>通过文本生成将视觉和语言任务统一起来<br><a href="https://zhuanlan.zhihu.com/p/540679125">https://zhuanlan.zhihu.com/p/540679125</a><br>Unifying Vision-and-Language Tasks via Text Generation</p><p>利用噪声文本监督扩大视觉和视觉语言表示学习的规模<br><a href="https://zhuanlan.zhihu.com/p/540570838">https://zhuanlan.zhihu.com/p/540570838</a><br>Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision</p><p>Pixel-BERT:通过深度多模态变换将图像像素与文本对齐<br><a href="https://zhuanlan.zhihu.com/p/539102716">https://zhuanlan.zhihu.com/p/539102716</a><br>Pixel-BERT: Aligning Image Pixels with Text by Deep Multi-Modal Transformers</p><p>通过模型不确定性融合的多任务密集检索用于开放领域的问答<br><a href="https://zhuanlan.zhihu.com/p/538610416">https://zhuanlan.zhihu.com/p/538610416</a><br>Multi-Task Dense Retrieval via Model Uncertainty Fusion for Open-Domain Question Answering</p><p>使用CLIP Latent的分层文本条件的图像生成<br><a href="https://zhuanlan.zhihu.com/p/538403355">https://zhuanlan.zhihu.com/p/538403355</a><br>Hierarchical Text-Conditional Image Generation with CLIP Latents</p><p>RNG-KBQA: 用于知识库问答的生成增强型迭代排名<br><a href="https://zhuanlan.zhihu.com/p/535420059">https://zhuanlan.zhihu.com/p/535420059</a><br>RNG-KBQA: Generation Augmented Iterative Ranking for Knowledge Base Question Answering</p><p>ViLT：没有卷积或区域监督的视觉和语言transformer<br><a href="https://zhuanlan.zhihu.com/p/537416032">https://zhuanlan.zhihu.com/p/537416032</a><br>ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision</p><p>图像-文本匹配的相似性推理和过滤<br><a href="https://zhuanlan.zhihu.com/p/537392389">https://zhuanlan.zhihu.com/p/537392389</a><br>Similarity Reasoning and Filtration for Image-Text Matching</p><p>关于图像-文本检索的可复现性问题<br><a href="https://zhuanlan.zhihu.com/p/535969785">https://zhuanlan.zhihu.com/p/535969785</a><br>Where Does the Performance Improvement Come From? - A Reproducibility Concern about Image-Text Retrieval</p><p>多模态检索的跨语言跨模态预训练<br><a href="https://zhuanlan.zhihu.com/p/535949214">https://zhuanlan.zhihu.com/p/535949214</a><br>Cross-lingual Cross-modal Pretraining for Multimodal Retrieval</p><p>检索和阅读：关于开放域问答的综合调查<br><a href="https://zhuanlan.zhihu.com/p/535315271">https://zhuanlan.zhihu.com/p/535315271</a><br>Retrieving and Reading ： A Comprehensive Survey on Open-domain Question Answering</p><p>扩散-LM改善可控文本的生成<br><a href="https://zhuanlan.zhihu.com/p/532644454">https://zhuanlan.zhihu.com/p/532644454</a><br>Diffusion-LM Improves Controllable Text Generation</p><p>通过随机过程建立的语言模型<br><a href="https://zhuanlan.zhihu.com/p/507834523">https://zhuanlan.zhihu.com/p/507834523</a><br>LANGUAGE MODELING VIA STOCHASTIC PROCESSES</p><p>UNITER: 通用图像-文本表示法学习<br><a href="https://zhuanlan.zhihu.com/p/510622677">https://zhuanlan.zhihu.com/p/510622677</a><br>UNITER： UNiversal Image-TExt Representation Learning</p><p>重新审视无监督的关系抽取<br><a href="https://zhuanlan.zhihu.com/p/527512757">https://zhuanlan.zhihu.com/p/527512757</a><br>Revisiting Unsupervised Relation Extraction</p><p>Hateful Memes 多模态数据集<br><a href="https://zhuanlan.zhihu.com/p/509654285">https://zhuanlan.zhihu.com/p/509654285</a><br>The Hateful Memes Challenge: Detecting Hate Speech in Multimodal Memes</p><p>OCR-VQA: 通过阅读图像中的文字进行可视化答题<br><a href="https://zhuanlan.zhihu.com/p/506453197">https://zhuanlan.zhihu.com/p/506453197</a><br>OCR-VQA： Visual Question Answering by Reading Text in Images</p><p>PaLM：大模型的规模探索<br><a href="https://zhuanlan.zhihu.com/p/503968575">https://zhuanlan.zhihu.com/p/503968575</a><br>PaLM： Scaling Language Modeling with Pathways</p><p>PICARD: 文本到SQL的自回归解码语言模型<br><a href="https://zhuanlan.zhihu.com/p/504133233">https://zhuanlan.zhihu.com/p/504133233</a><br>PICARD:Parsing Incrementally for Constrained Auto-Regressive Decoding from Language Models</p><p>Survey：复杂知识库问答<br><a href="https://zhuanlan.zhihu.com/p/503965660">https://zhuanlan.zhihu.com/p/503965660</a><br>A Survey on Complex Knowledge Base Question Answering： Methods, Challenges and Solutions</p><p>Tweets的多模态实体链接<br><a href="https://zhuanlan.zhihu.com/p/502269546">https://zhuanlan.zhihu.com/p/502269546</a><br>Multimodal Entity Linking for Tweets</p><p>ELQ: 高效的一次性端到端实体链接的问题<br><a href="https://zhuanlan.zhihu.com/p/497708749">https://zhuanlan.zhihu.com/p/497708749</a><br>Efﬁcient One-Pass End-to-End Entity Linking for Questions</p><p>可扩展的zero-shot实体链接与密集实体检索<br><a href="https://zhuanlan.zhihu.com/p/495291925">https://zhuanlan.zhihu.com/p/495291925</a><br>Scalable Zero-shot Entity Linking with Dense Entity Retrieval</p><p>实体链接技术和解决方案<br><a href="https://zhuanlan.zhihu.com/p/495278919">https://zhuanlan.zhihu.com/p/495278919</a><br>Entity Linking Meets Deep Learning： Techniques and Solutions</p><p>多模态实体链接: 一个新的数据集和一个基线<br><a href="https://zhuanlan.zhihu.com/p/494415154">https://zhuanlan.zhihu.com/p/494415154</a><br>Multimodal Entity Linking：A New Dataset and A Baseline</p><p>Zeroshot多模态命名实体歧义的社交媒体帖子<br><a href="https://zhuanlan.zhihu.com/p/494350411">https://zhuanlan.zhihu.com/p/494350411</a><br>Zeroshot Multimodal Named Entity Disambiguation for Noisy Social Media Posts</p><p>Survey:多模态知识图谱的构建和应用<br><a href="https://zhuanlan.zhihu.com/p/491610188">https://zhuanlan.zhihu.com/p/491610188</a><br>Multi-Modal Knowledge Graph Construction and Application： A Survey</p><p>多模态知识图谱完成<br><a href="https://zhuanlan.zhihu.com/p/490909554">https://zhuanlan.zhihu.com/p/490909554</a><br>Embedding Multimodal Relational Data for Knowledge Base Completion</p><p>从Tweets中建立一个多模态实体链接数据集<br><a href="https://zhuanlan.zhihu.com/p/490888754">https://zhuanlan.zhihu.com/p/490888754</a><br>Building a Multimodal Entity Linking Dataset From Tweets</p><p>ConVSE：视觉-语义嵌入的对比性学习<br><a href="https://zhuanlan.zhihu.com/p/490315692">https://zhuanlan.zhihu.com/p/490315692</a><br>Contrastive Learning of Visual-Semantic Embeddings</p><p>用于图像-文本匹配的视觉语义推理<br><a href="https://zhuanlan.zhihu.com/p/490302244">https://zhuanlan.zhihu.com/p/490302244</a><br>Visual Semantic Reasoning for Image-Text Matching</p><p>CLIP:从自然语言监督中学习可迁移的视觉模型<br><a href="https://zhuanlan.zhihu.com/p/478889210">https://zhuanlan.zhihu.com/p/478889210</a><br>Learning Transferable Visual Models From Natural Language Supervision</p><p>VisualSem: 用于视觉和语言的高质量知识图谱<br><a href="https://zhuanlan.zhihu.com/p/478679587">https://zhuanlan.zhihu.com/p/478679587</a><br>VisualSem： A High-quality Knowledge Graph for Vision &amp; Language</p><p>MET:用多模态知识库进行多模态实体标注<br><a href="https://zhuanlan.zhihu.com/p/478627581">https://zhuanlan.zhihu.com/p/478627581</a><br>Multimodal Entity Tagging with Multimodal Knowledge Base</p><p>M4C多模态transformer对TextVQA进行迭代式答案预测<br><a href="https://zhuanlan.zhihu.com/p/477062474">https://zhuanlan.zhihu.com/p/477062474</a><br>Iterative Answer Prediction with Pointer-Augmented Multimodal Transformers for TextVQA</p><p>TPLinker: 通过token对链接的单阶段联合提取实体和关系<br><a href="https://zhuanlan.zhihu.com/p/471975897">https://zhuanlan.zhihu.com/p/471975897</a><br>TPLinker：Single-stage Joint Extraction of Entities and Relations Through Token Pair Linking</p><p>UNIRE：实体关系抽取的统一标签空间<br><a href="https://zhuanlan.zhihu.com/p/454398188">https://zhuanlan.zhihu.com/p/454398188</a><br>UNIRE： A Uniﬁed Label Space for Entity Relation Extraction</p><p>SCIERC实体识别和关系抽取的英文数据集<br><a href="https://zhuanlan.zhihu.com/p/462638191">https://zhuanlan.zhihu.com/p/462638191</a><br>Multi-Task Identiﬁcation of Entities, Relations, and Coreference for Scientiﬁc Knowledge Graph Construction</p><p>SHAP解释树模型<br><a href="https://zhuanlan.zhihu.com/p/459470781">https://zhuanlan.zhihu.com/p/459470781</a><br>A Unified Approach to Interpreting Model Predictions</p><p>HySPA：用于可扩展的文本到图提取的混合跨度生成<br><a href="https://zhuanlan.zhihu.com/p/454339907">https://zhuanlan.zhihu.com/p/454339907</a><br>HySPA： Hybrid Span Generation for Scalable Text-to-Graph Extraction</p><p>对树模型进行局部解释<br><a href="https://zhuanlan.zhihu.com/p/458958125">https://zhuanlan.zhihu.com/p/458958125</a><br>From local explanations to global understanding with explainable AI for trees</p><p>XGBoost 一个可扩展的tree boosting系统<br><a href="https://zhuanlan.zhihu.com/p/459470547">https://zhuanlan.zhihu.com/p/459470547</a><br>XGBoost： A Scalable Tree Boosting System</p><p>用图卷积网络进行联合信息提取<br><a href="https://zhuanlan.zhihu.com/p/454304430">https://zhuanlan.zhihu.com/p/454304430</a><br>Cross-Task Instance Representation Interactions and Label Dependencies for Joint Information Extraction with Graph Convolutional Networks</p><p>用全局特征进行信息提取的联合神经模型<br><a href="https://zhuanlan.zhihu.com/p/454108143">https://zhuanlan.zhihu.com/p/454108143</a><br>A Joint Neural Model for Information Extraction with Global Features</p><p>利用打包浮动标记进行实体和关系抽取<br><a href="https://zhuanlan.zhihu.com/p/454398356">https://zhuanlan.zhihu.com/p/454398356</a><br>Pack Together： Entity and Relation Extraction with Levitated Marker</p><p>社媒的热点主题预测<br><a href="https://zhuanlan.zhihu.com/p/453417760">https://zhuanlan.zhihu.com/p/453417760</a><br>Hot topic prediction considering influence and expertise in social media</p><p>社交媒体大数据分析<br><a href="https://zhuanlan.zhihu.com/p/453838204">https://zhuanlan.zhihu.com/p/453838204</a><br>Big Social Media Data Analytics</p><p>PRCA和IGA联合建模分析顾客满意度<br><a href="https://zhuanlan.zhihu.com/p/449441801">https://zhuanlan.zhihu.com/p/449441801</a><br>Integrating methods for the prioritization of innovations and improvements in services</p><p>基于实体相对位置表示的多头选择的联合实体和关系抽取<br><a href="https://zhuanlan.zhihu.com/p/448112834">https://zhuanlan.zhihu.com/p/448112834</a><br>Entity Relative Position Representation based Multi-head Selection for Joint Entity and Relation Extraction</p><p>Kano加诺模型与数据挖掘的整合来预测客户满意度<br><a href="https://zhuanlan.zhihu.com/p/448486378">https://zhuanlan.zhihu.com/p/448486378</a><br>Concept Paper Kano Model Integration with Data Mining to Predict Customer Satisfaction</p><p>PRCA惩罚-奖励-对比分析：在顾客满意度研究中的应用<br><a href="https://zhuanlan.zhihu.com/p/449242532">https://zhuanlan.zhihu.com/p/449242532</a><br>Penalty–Reward-Contrast Analysis： a review of its application in customer satisfaction research</p><p>极端多标签文本分类的快速多分辨率transformer微调技术<br><a href="https://zhuanlan.zhihu.com/p/445661903">https://zhuanlan.zhihu.com/p/445661903</a><br>Fast Multi-Resolution Transformer Fine-tuning for Extreme Multi-label Text Classiﬁcation</p><p>多任务学习加强多标签文本分类<br><a href="https://zhuanlan.zhihu.com/p/445661700">https://zhuanlan.zhihu.com/p/445661700</a><br>Enhancing Label Correlation Feedback in Multi-Label Text Classiﬁcation via Multi-Task Learning</p><p>基于TFIDF和GloVe的多标签文本分类<br><a href="https://zhuanlan.zhihu.com/p/445587449">https://zhuanlan.zhihu.com/p/445587449</a><br>Deep Learning Based Multi-Label Text Classification of UNGA Resolutions</p><p>动态语义表示和深度神经网络结合的多标签文本分类方法<br><a href="https://zhuanlan.zhihu.com/p/445517482">https://zhuanlan.zhihu.com/p/445517482</a><br>A multi-label text classification method via dynamic semantic representation model and deep neural network</p><p>表-序列编码器联合提取实体和关系<br><a href="https://zhuanlan.zhihu.com/p/440722315">https://zhuanlan.zhihu.com/p/440722315</a><br>Two are Better than One：Joint Entity and Relation Extraction with Table-Sequence Encoders</p><p>用上下文跨度表示的实体、关系和事件提取<br><a href="https://zhuanlan.zhihu.com/p/443573825">https://zhuanlan.zhihu.com/p/443573825</a><br>Entity, Relation, and Event Extraction with Contextualized Span Representations</p><p>多头选择框架的BERT联合实体关系抽取<br><a href="https://zhuanlan.zhihu.com/p/443577609">https://zhuanlan.zhihu.com/p/443577609</a><br>BERT-Based Multi-Head Selection for Joint Entity-Relation Extraction</p><p>实体和关系抽取的简单方法<br><a href="https://zhuanlan.zhihu.com/p/440704543">https://zhuanlan.zhihu.com/p/440704543</a><br>A Frustratingly Easy Approach for Entity and Relation Extraction</p><p>BenchIE：基于事实而非token的开放式信息提取评估<br><a href="https://zhuanlan.zhihu.com/p/438437407">https://zhuanlan.zhihu.com/p/438437407</a><br>BenchIE： Open Information Extraction Evaluation Based on Facts, Not Tokens</p><p>OpenIE6：用于开放信息提取的迭代网格标签和协调分析<br><a href="https://zhuanlan.zhihu.com/p/438007291">https://zhuanlan.zhihu.com/p/438007291</a><br>OpenIE6: Iterative Grid Labeling and Coordination Analysis for Open Information Extraction</p><p>医学放射科报告生成与知识图谱<br><a href="https://zhuanlan.zhihu.com/p/436319124">https://zhuanlan.zhihu.com/p/436319124</a><br>When Radiology Report Generation Meets Knowledge Graph</p><p>BUTD：自下而上和自上而下的注意力多模态模型<br><a href="https://zhuanlan.zhihu.com/p/435174845">https://zhuanlan.zhihu.com/p/435174845</a><br>Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering</p><p>UniT：多模态多任务模型<br><a href="https://zhuanlan.zhihu.com/p/434243735">https://zhuanlan.zhihu.com/p/434243735</a><br>UniT: Multimodal Multitask Learning with a Uniﬁed Transformer</p><p>ACT: 自适应聚类transformer端到端目标检测<br><a href="https://zhuanlan.zhihu.com/p/435175009">https://zhuanlan.zhihu.com/p/435175009</a><br>End-to-End Object Detection with Adaptive Clustering Transformer</p><p>VisualBert: 经过预训练的多模态模型<br><a href="https://zhuanlan.zhihu.com/p/434272329">https://zhuanlan.zhihu.com/p/434272329</a><br>VISUALBERT: A SIMPLE AND PERFORMANT BASELINE FOR VISION AND LANGUAGE</p><p>双线性注意力网络（多模态）<br><a href="https://zhuanlan.zhihu.com/p/432970660">https://zhuanlan.zhihu.com/p/432970660</a><br>Bilinear Attention Networks</p><p>OpenUE：从文本中提取通用信息的开放工具箱<br><a href="https://zhuanlan.zhihu.com/p/431805279">https://zhuanlan.zhihu.com/p/431805279</a><br>OpenUE: An Open Toolkit of Universal Extraction from Text</p><p>多模态分类的跨模态检索增强功能<br><a href="https://zhuanlan.zhihu.com/p/432389016">https://zhuanlan.zhihu.com/p/432389016</a><br>Cross-Modal Retrieval Augmentation for Multi-Modal Classiﬁcation</p><p>艺术品类图像的双流多模态模型情感分析<br><a href="https://zhuanlan.zhihu.com/p/432373663">https://zhuanlan.zhihu.com/p/432373663</a><br>Understanding of Emotion Perception from Art</p><p>基于远端监督的开放领域数据的命名实体识别<br><a href="https://zhuanlan.zhihu.com/p/428925959">https://zhuanlan.zhihu.com/p/428925959</a><br>Named Entity Recognition for Open Domain Data Based on Distant Supervision</p><p>MISA: 多模态情感分析的模态不变和模态特定表示<br><a href="https://zhuanlan.zhihu.com/p/430407430">https://zhuanlan.zhihu.com/p/430407430</a><br>MISA: Modality-Invariant and -Specific Representations for Multimodal Sentiment Analysis</p><p>利用网络资源发现新的实体<br><a href="https://zhuanlan.zhihu.com/p/428861588">https://zhuanlan.zhihu.com/p/428861588</a><br>Emerging Entity Discovery Using Web Sources</p><p>知识图谱完成方法的重新评估<br><a href="https://zhuanlan.zhihu.com/p/428088532">https://zhuanlan.zhihu.com/p/428088532</a><br>A Re-evaluation of Knowledge Graph Completion Methods</p><p>Info-HCVAE问答对生成<br><a href="https://zhuanlan.zhihu.com/p/421265798">https://zhuanlan.zhihu.com/p/421265798</a><br>Generating Diverse and Consistent QA pairs from Contexts with Information-Maximizing Hierarchical Conditional VAEs</p><p>多任务学习框架下的观点三元组提取<br><a href="https://zhuanlan.zhihu.com/p/426376153">https://zhuanlan.zhihu.com/p/426376153</a><br>A Multi-task Learning Framework for Opinion Triplet Extraction</p><p>ASAP: 中文评论数据集：aspect的情感分析<br><a href="https://zhuanlan.zhihu.com/p/425981216">https://zhuanlan.zhihu.com/p/425981216</a><br>ASAP: A Chinese Review Dataset Towards Aspect Category Sentiment Analysis and Rating Prediction</p><p>DiaKG：用于构建医学知识图谱的糖尿病标注数据集<br><a href="https://zhuanlan.zhihu.com/p/424733768">https://zhuanlan.zhihu.com/p/424733768</a><br>DiaKG: an Annotated Diabetes Dataset for Medical Knowledge Graph Construction</p><p>P-Tuning v2: 与微调性能相等的提示性优化<br><a href="https://zhuanlan.zhihu.com/p/423902902">https://zhuanlan.zhihu.com/p/423902902</a><br>P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks</p><p>TechKG：一个大规模的中文技术导向的知识图谱<br><a href="https://zhuanlan.zhihu.com/p/420557472">https://zhuanlan.zhihu.com/p/420557472</a><br>TechKG: A Large-Scale Chinese Technology-Oriented Knowledge Graph</p><p>知识图谱增强的aspect情感分析<br><a href="https://zhuanlan.zhihu.com/p/414252384">https://zhuanlan.zhihu.com/p/414252384</a><br>Scalable End-to-End Training of Knowledge Graph-Enhanced Aspect Embedding for Aspect Level Sentiment Analysis</p><p>Pre-train, Prompt, and Predict: 自然语言处理中prompting方法总结<br><a href="https://zhuanlan.zhihu.com/p/411341801">https://zhuanlan.zhihu.com/p/411341801</a><br>Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing</p><p>用常识性知识图谱进行zero-shot学习<br><a href="https://zhuanlan.zhihu.com/p/410561852">https://zhuanlan.zhihu.com/p/410561852</a><br>Zero-Shot Learning with Common Sense Knowledge Graphs</p><p>用于自然语言推理的随机答案网络<br><a href="https://zhuanlan.zhihu.com/p/409085184">https://zhuanlan.zhihu.com/p/409085184</a><br>Stochastic Answer Networks for Natural Language Inference</p><p>用于自然语言理解的微软多任务深度神经网络工具包<br><a href="https://zhuanlan.zhihu.com/p/408851910">https://zhuanlan.zhihu.com/p/408851910</a><br>The Microsoft Toolkit of Multi-Task Deep Neural Networks for Natural Language Understanding</p><p>大型神经语言模型的对抗性训练<br><a href="https://zhuanlan.zhihu.com/p/408582923">https://zhuanlan.zhihu.com/p/408582923</a><br>Adversarial Training for Large Neural Language Models</p><p>行为克隆强化学习玩CS反恐精英<br><a href="https://zhuanlan.zhihu.com/p/403123868">https://zhuanlan.zhihu.com/p/403123868</a><br>Counter-Strike Deathmatch with Large-Scale Behavioural Cloning</p><p>HyperTools: 可视化和操作高维度据的Python工具箱<br><a href="https://zhuanlan.zhihu.com/p/407691325">https://zhuanlan.zhihu.com/p/407691325</a><br>HyperTools: A Python toolbox for visualizing and manipulating high-dimensional data</p><p>显存优化<br><a href="https://zhuanlan.zhihu.com/p/407429742">https://zhuanlan.zhihu.com/p/407429742</a><br>Training Deep Nets with Sublinear Memory Cost</p><p>自然语言查询问答模型<br><a href="https://zhuanlan.zhihu.com/p/406453009">https://zhuanlan.zhihu.com/p/406453009</a><br>Database Reasoning Over Text</p><p>Transformer Survey<br><a href="https://zhuanlan.zhihu.com/p/405623198">https://zhuanlan.zhihu.com/p/405623198</a><br>A Survey of Transformers</p><p>X-modaler: 用于跨模态分析的多功能和高性能的代码库<br><a href="https://zhuanlan.zhihu.com/p/402620759">https://zhuanlan.zhihu.com/p/402620759</a><br>X-modaler: A Versatile and High-performance Codebase for Cross-modal Analytics</p><p>PonderNet：适应性模型，提高模型计算效率<br><a href="https://zhuanlan.zhihu.com/p/401874414">https://zhuanlan.zhihu.com/p/401874414</a><br>PonderNet: Learning to Ponder</p><p>模式引导下的多领域对话数据集<br><a href="https://zhuanlan.zhihu.com/p/401779764">https://zhuanlan.zhihu.com/p/401779764</a><br>Towards Scalable Multi-Domain Conversational Agents: The Schema-Guided Dialogue Dataset</p><p>新冠COVID-19文献知识图谱构建<br><a href="https://zhuanlan.zhihu.com/p/400944819">https://zhuanlan.zhihu.com/p/400944819</a><br>COVID-19 Literature Knowledge Graph Construction and Drug Repurposing Report Generation</p><p>AutoKnow: 上千种产品的自动知识收集<br><a href="https://zhuanlan.zhihu.com/p/399419662">https://zhuanlan.zhihu.com/p/399419662</a><br>AutoKnow: Self-Driving Knowledge Collection for Products of Thousands of Types</p><p>用于联合意向分类和槽位填充的BERT<br><a href="https://zhuanlan.zhihu.com/p/399103189">https://zhuanlan.zhihu.com/p/399103189</a><br>BERT for Joint Intent Classiﬁcation and Slot Filling</p><p>数据标注的质量控制案例:TDT语料<br><a href="https://zhuanlan.zhihu.com/p/398515851">https://zhuanlan.zhihu.com/p/398515851</a><br>Quality Control in Large Annotation Projects Involving Multiple Judges: The Case of the TDT Corpora</p><p>DeiT: 蒸馏的图像transformer模型<br><a href="https://zhuanlan.zhihu.com/p/394627382">https://zhuanlan.zhihu.com/p/394627382</a><br>Training data-efﬁcient image transformers &amp; distillation through attention</p><p>ViT: transformer用于图像识别<br><a href="https://zhuanlan.zhihu.com/p/394288661">https://zhuanlan.zhihu.com/p/394288661</a><br>AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE</p><p>YOLOX<br><a href="https://zhuanlan.zhihu.com/p/393955749">https://zhuanlan.zhihu.com/p/393955749</a><br>YOLOX: Exceeding YOLO Series in 2021</p><p>完善知识图谱总结<br><a href="https://zhuanlan.zhihu.com/p/393885109">https://zhuanlan.zhihu.com/p/393885109</a><br>Knowledge Graph Refinement: A Survey of Approaches and Evaluation Methods</p><p>AdaShare: 高效的深度多任务学习<br><a href="https://zhuanlan.zhihu.com/p/393243186">https://zhuanlan.zhihu.com/p/393243186</a><br>AdaShare: Learning What To Share For Efﬁcient Deep Multi-Task Learning</p><p>知识图谱总结： 表示、获取和应用<br><a href="https://zhuanlan.zhihu.com/p/392429070">https://zhuanlan.zhihu.com/p/392429070</a><br>A Survey on Knowledge Graphs: Representation, Acquisition and Applications</p><p>REPAINT：深度强化学习中的知识迁移<br><a href="https://zhuanlan.zhihu.com/p/391824772">https://zhuanlan.zhihu.com/p/391824772</a><br>REPAINT: Knowledge Transfer in Deep Reinforcement Learning</p><p>重新审视Rainbow<br><a href="https://zhuanlan.zhihu.com/p/391126427">https://zhuanlan.zhihu.com/p/391126427</a><br>Revisiting Rainbow: Promoting more Insightful and Inclusive Deep Reinforcement Learning Research</p><p>遗传进化强化学习算法<br><a href="https://zhuanlan.zhihu.com/p/389895408">https://zhuanlan.zhihu.com/p/389895408</a><br>EVOLVING REINFORCEMENT LEARNING ALGORITHMS</p><p>强化学习环境：Google足球游戏<br><a href="https://zhuanlan.zhihu.com/p/389567798">https://zhuanlan.zhihu.com/p/389567798</a><br>Google Research Football: A Novel Reinforcement Learning Environment</p><p>无监督文本摘要<br><a href="https://zhuanlan.zhihu.com/p/388911963">https://zhuanlan.zhihu.com/p/388911963</a><br>Learning to Encode Text as Human-Readable Summaries using Generative Adversarial Networks</p><p>ERNIE 3.0: 用于语言理解和生成的大规模知识强化预训练<br><a href="https://zhuanlan.zhihu.com/p/388172601">https://zhuanlan.zhihu.com/p/388172601</a><br>ERNIE 3.0: LARGE-SCALE KNOWLEDGE ENHANCED PRE-TRAINING FOR LANGUAGE UNDERSTANDING AND GENERATION</p><p>COMET：自动构建知识图谱的常识transformer<br><a href="https://zhuanlan.zhihu.com/p/388106049">https://zhuanlan.zhihu.com/p/388106049</a><br>COMET : Commonsense Transformers for Automatic Knowledge Graph Construction</p><p>D2S: 通过基于查询的文本总结进行文档到幻灯片的生成<br><a href="https://zhuanlan.zhihu.com/p/387544973">https://zhuanlan.zhihu.com/p/387544973</a><br>D2S: Document-to-Slide Generation Via Query-Based Text Summarization</p><p>斗地主强化学习<br><a href="https://zhuanlan.zhihu.com/p/385496621">https://zhuanlan.zhihu.com/p/385496621</a><br>DouZero: Mastering DouDizhu with Self-Play Deep Reinforcement Learning</p><p>通过知识蒸馏改进多任务深度神经网络以促进自然语言理解<br><a href="https://zhuanlan.zhihu.com/p/384120253">https://zhuanlan.zhihu.com/p/384120253</a><br>Improving Multi-Task Deep Neural Networks via Knowledge Distillation for Natural Language Understanding</p><p>使用深度强化学习玩MOBA游戏<br><a href="https://zhuanlan.zhihu.com/p/378789632">https://zhuanlan.zhihu.com/p/378789632</a><br>Towards Playing Full MOBA Games with Deep Reinforcement Learning</p><p>MOBA游戏的复杂控制与深度强化学习<br><a href="https://zhuanlan.zhihu.com/p/379091485">https://zhuanlan.zhihu.com/p/379091485</a><br>Mastering Complex Control in MOBA Games with Deep Reinforcement Learning</p><p>用强化学习玩英雄联盟<br><a href="https://zhuanlan.zhihu.com/p/363495437">https://zhuanlan.zhihu.com/p/363495437</a><br>Deep Learning Bot for League of Legends</p><p>ATARI游戏的Model based的强化学习<br><a href="https://zhuanlan.zhihu.com/p/363279136">https://zhuanlan.zhihu.com/p/363279136</a><br>MODEL BASED REINFORCEMENT LEARNING FOR ATARI</p><p>关于视频游戏的深度强化学习算法<br><a href="https://zhuanlan.zhihu.com/p/363115461">https://zhuanlan.zhihu.com/p/363115461</a><br>A Survey of Deep Reinforcement Learning in Video Games</p><p>用于自然语言理解的多任务深度神经网络<br><a href="https://zhuanlan.zhihu.com/p/383137481">https://zhuanlan.zhihu.com/p/383137481</a><br>Multi-Task Deep Neural Networks for Natural Language Understanding</p><p>模仿学习: 自动排序的演示学习<br><a href="https://zhuanlan.zhihu.com/p/382272429">https://zhuanlan.zhihu.com/p/382272429</a><br>Better-than-Demonstrator Imitation Learning via Automatically-Ranked Demonstrations</p><p>预训练编码器文本摘要<br><a href="https://zhuanlan.zhihu.com/p/381490918">https://zhuanlan.zhihu.com/p/381490918</a><br>Text Summarization with Pretrained Encoders</p><p>Survey: 多任务学习<br><a href="https://zhuanlan.zhihu.com/p/381229374">https://zhuanlan.zhihu.com/p/381229374</a><br>A Survey on Multi-Task Learning</p><p>DDPG论文: 深强化学习连续控制<br><a href="https://zhuanlan.zhihu.com/p/371451813">https://zhuanlan.zhihu.com/p/371451813</a><br>CONTINUOUS CONTROL WITH DEEP REINFORCEMENT LEARNING</p><p>使用图像做无地图导航的强化学习<br><a href="https://zhuanlan.zhihu.com/p/379270657">https://zhuanlan.zhihu.com/p/379270657</a><br>Using RGB Image as Visual Input for Mapless Robot Navigation</p><p>Pettingzoo：类似gym的多Agent强化学习的环境<br><a href="https://zhuanlan.zhihu.com/p/375049925">https://zhuanlan.zhihu.com/p/375049925</a><br>PettingZoo: Gym for Multi-Agent Reinforcement Learning</p><p>RIIT: 最新的多Agent合作控制强化学习算法<br><a href="https://zhuanlan.zhihu.com/p/368284926">https://zhuanlan.zhihu.com/p/368284926</a><br>RIIT: Rethinking the Importance of Implementation Tricks in Multi-Agent Reinforcement Learning</p><p>复现深度强化学习算法效果的因素<br><a href="https://zhuanlan.zhihu.com/p/377369590">https://zhuanlan.zhihu.com/p/377369590</a><br>Deep Reinforcement Learning that Matters</p><p>PPO算法<br><a href="https://zhuanlan.zhihu.com/p/376978985">https://zhuanlan.zhihu.com/p/376978985</a><br>Proximal Policy Optimization Algorithms</p><p>交互式的强化学习<br><a href="https://zhuanlan.zhihu.com/p/379871647">https://zhuanlan.zhihu.com/p/379871647</a><br>REINFORCEMENT LEARNING WITH HUMAN ADVICE: A SURVEY</p><p>半监督机器翻译的简单基准<br><a href="https://zhuanlan.zhihu.com/p/378838885">https://zhuanlan.zhihu.com/p/378838885</a><br>A Simple Baseline to Semi-Supervised Domain Adaptation for Machine Translation</p><p>Survey: 深度神经网络翻译<br><a href="https://zhuanlan.zhihu.com/p/378524968">https://zhuanlan.zhihu.com/p/378524968</a><br>A Survey of Deep Learning Techniques for Neural Machine Translation</p><p>MMBT: 用于图像和文本分类的有监督多模态双向Transformer<br><a href="https://zhuanlan.zhihu.com/p/373581881">https://zhuanlan.zhihu.com/p/373581881</a><br>Supervised Multimodal Bitransformers for Classifying Images and Text</p><p>XLM-R: 大规模无监督跨语言表示模型<br><a href="https://zhuanlan.zhihu.com/p/372978148">https://zhuanlan.zhihu.com/p/372978148</a><br>Unsupervised Cross-lingual Representation Learning at Scale</p><p>跨语言的语言模型预训练<br><a href="https://zhuanlan.zhihu.com/p/372001934">https://zhuanlan.zhihu.com/p/372001934</a><br>Cross-lingual Language Model Pretraining</p><p>神经机器翻译的无监督领域适应<br><a href="https://zhuanlan.zhihu.com/p/371626610">https://zhuanlan.zhihu.com/p/371626610</a><br>Unsupervised Domain Adaptation for Neural Machine Translation with Domain-Aware Feature Embeddings</p><p>域适应翻译中的单词表适应方法<br><a href="https://zhuanlan.zhihu.com/p/371392857">https://zhuanlan.zhihu.com/p/371392857</a><br>Vocabulary Adaptation for Domain Adaptation in Neural Machine Translation</p><p>使用术语限制的神经网络翻译<br><a href="https://zhuanlan.zhihu.com/p/370661928">https://zhuanlan.zhihu.com/p/370661928</a><br>Training Neural Machine Translation To Apply Terminology Constraints</p><p>Survey: 机器翻译的领域适应和多领域适应<br><a href="https://zhuanlan.zhihu.com/p/370390321">https://zhuanlan.zhihu.com/p/370390321</a><br>Domain Adaptation and Multi-Domain Adaptation for Neural Machine Translation: A Survey</p><p>M2M-100: 多语言翻译模型<br><a href="https://zhuanlan.zhihu.com/p/368226087">https://zhuanlan.zhihu.com/p/368226087</a><br>Beyond English-Centric Multilingual Machine Translation</p><p>FAIRSEQ 语音到文本模型<br><a href="https://zhuanlan.zhihu.com/p/361585021">https://zhuanlan.zhihu.com/p/361585021</a><br>FAIRSEQ S2T: Fast Speech-to-Text Modeling with FAIRSEQ</p><p>自然语言中的强化学习<br><a href="https://zhuanlan.zhihu.com/p/364138298">https://zhuanlan.zhihu.com/p/364138298</a><br>A Survey of Reinforcement Learning Informed by Natural Language</p><p>MAAC注意力的演员评论家: Multi-Agent强化学习<br><a href="https://zhuanlan.zhihu.com/p/366413456">https://zhuanlan.zhihu.com/p/366413456</a><br>Actor-Attention-Critic for Multi-Agent Reinforcement Learning</p><p>mBART：多语言翻译预训练模型<br><a href="https://zhuanlan.zhihu.com/p/366525006">https://zhuanlan.zhihu.com/p/366525006</a><br>Multilingual Denoising Pre-training for Neural Machine Translation</p><p>MobileBERT:用于资源限制设备的紧凑型任务型BERT<br><a href="https://zhuanlan.zhihu.com/p/365329984">https://zhuanlan.zhihu.com/p/365329984</a><br>MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices</p><p>更快的深度自适应transformers<br><a href="https://zhuanlan.zhihu.com/p/364807276">https://zhuanlan.zhihu.com/p/364807276</a><br>Faster Depth-Adaptive Transformers</p><p>利用远端监督的强化学习关系抽取<br><a href="https://zhuanlan.zhihu.com/p/364444877">https://zhuanlan.zhihu.com/p/364444877</a><br>Large Scaled Relation Extraction with Reinforcement Learning</p><p>GLRE模型文档级关系抽取<br><a href="https://zhuanlan.zhihu.com/p/360980109">https://zhuanlan.zhihu.com/p/360980109</a><br>Global-to-Local Neural Networks for Document-Level Relation Extraction</p><p>关系抽取的注意力引导图卷积网络<br><a href="https://zhuanlan.zhihu.com/p/357518473">https://zhuanlan.zhihu.com/p/357518473</a><br>Attention Guided Graph Convolutional Networks for Relation Extraction</p><p>关系抽取Review（附上中文关系抽取的数据及代码)<br><a href="https://zhuanlan.zhihu.com/p/356551233">https://zhuanlan.zhihu.com/p/356551233</a><br>More Data, More Relations, More Context and More Openness: A Review and Outlook for Relation Extraction</p><p>DocRED: 大型文档级关系抽取数据集<br><a href="https://zhuanlan.zhihu.com/p/356077381">https://zhuanlan.zhihu.com/p/356077381</a><br>DocRED: A Large-Scale Document-Level Relation Extraction Dataset</p><p>文档级关系抽取：图增强双重注意力网络<br><a href="https://zhuanlan.zhihu.com/p/355473773">https://zhuanlan.zhihu.com/p/355473773</a><br>Graph Enhanced Dual Attention Network for Document-Level Relation Extraction</p><p>SENTIX:跨领域情感分析预训练模型<br><a href="https://zhuanlan.zhihu.com/p/350924103">https://zhuanlan.zhihu.com/p/350924103</a><br>SENTIX: A Sentiment-Aware Pre-Trained Model for Cross-Domain Sentiment Analysis</p><p>DEBERTA：解耦注意力的解码增强型BERT<br><a href="https://zhuanlan.zhihu.com/p/348704980">https://zhuanlan.zhihu.com/p/348704980</a><br>DEBERTA: DECODING-ENHANCED BERT WITH DISENTANGLED ATTENTION</p><p>SentiBERT： 基于可迁移的transformer的组合的情感语义预训练模型<br><a href="https://zhuanlan.zhihu.com/p/347854488">https://zhuanlan.zhihu.com/p/347854488</a><br>SentiBERT: A Transferable Transformer-Based Architecture for Compositional Sentiment Semantics</p><p>SentiLARE：带有语言知识的情感感知预训练模型<br><a href="https://zhuanlan.zhihu.com/p/346202158">https://zhuanlan.zhihu.com/p/346202158</a><br>SentiLARE: Sentiment-Aware Language Representation Learning with Linguistic Knowledge</p><p>SpanBERT：通过表示和预测跨度来改善预训练的模型(2020年1月修订)<br><a href="https://zhuanlan.zhihu.com/p/345401994">https://zhuanlan.zhihu.com/p/345401994</a><br>SpanBERT: Improving Pre-training by Representing and Predicting Spans</p><p>抱抱脸🤗Transformers论文(2020年)<br><a href="https://zhuanlan.zhihu.com/p/344553832">https://zhuanlan.zhihu.com/p/344553832</a><br>Transformers: State-of-the-Art Natural Language Processing</p><p>SentencePiece:子词tokenizer和detokenizer(2019年12月更新)<br><a href="https://zhuanlan.zhihu.com/p/343634730">https://zhuanlan.zhihu.com/p/343634730</a><br>SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing</p><p>ALBERT: 精简的BERT自监督的语言表示模型(2020年2月更新)<br><a href="https://zhuanlan.zhihu.com/p/343426088">https://zhuanlan.zhihu.com/p/343426088</a><br>ALBERT: A LITE BERT FOR SELF-SUPERVISED LEARNING OF LANGUAGE REPRESENTATIONS</p><p>上下文和实体名称哪个对关系抽取更重要(2020年12月论文)<br><a href="https://zhuanlan.zhihu.com/p/342360873">https://zhuanlan.zhihu.com/p/342360873</a><br>Learning from Context or Names? An Empirical Study on Neural Relation Extraction</p><p>Google Big Bird：长序列的transformers(2020年论文)<br><a href="https://zhuanlan.zhihu.com/p/342005602">https://zhuanlan.zhihu.com/p/342005602</a><br>Big Bird: Transformers for Longer Sequences</p><p>mT5: 多国语言版T5(中文T5)(2020年10月论文)<br><a href="https://zhuanlan.zhihu.com/p/340288423">https://zhuanlan.zhihu.com/p/340288423</a><br>mT5: A massively multilingual pre-trained text-to-text transformer</p><p>Google T5: 统一文本到文本迁移学习研究 (2020年7月论文)-Part3<br><a href="https://zhuanlan.zhihu.com/p/339502041">https://zhuanlan.zhihu.com/p/339502041</a><br>Exploring the Limits of Transfer Learning with a Uniﬁed Text-to-Text Transformer</p><p>CharBERT：字符感知的预训练语言模型(2020年11月论文)<br><a href="https://zhuanlan.zhihu.com/p/337587788">https://zhuanlan.zhihu.com/p/337587788</a><br>CharBERT: Character-aware Pre-trained Language Model</p><p>AdaBERT：可导神经结构搜索的任务自适应BERT压缩(2020年1月论文)<br><a href="https://zhuanlan.zhihu.com/p/337305614">https://zhuanlan.zhihu.com/p/337305614</a><br>AdaBERT: Task-Adaptive BERT Compression with Differentiable Neural Architecture Search</p><p>EasyTransfer–阿里NLP深度迁移学习平台(2020年11月论文)<br><a href="https://zhuanlan.zhihu.com/p/336730123">https://zhuanlan.zhihu.com/p/336730123</a><br>EasyTransfer – A Simple and Scalable Deep Transfer Learning Platform for NLP Applications</p><p>ConvBERT: 基于跨度的动态卷积BERT(2020年11月论文)<br><a href="https://zhuanlan.zhihu.com/p/336409975">https://zhuanlan.zhihu.com/p/336409975</a><br>ConvBERT: Improving BERT with Span-based Dynamic Convolution</p><p>MacBERT: 中文自然语言预训练模型(2020年11月论文)<br><a href="https://zhuanlan.zhihu.com/p/333202482">https://zhuanlan.zhihu.com/p/333202482</a><br>Revisiting Pre-trained Models for Chinese Natural Language Processing</p><p>FLAT: 使用Flat-Lattice Transformer结构中文NER(2020年5月论文)<br><a href="https://zhuanlan.zhihu.com/p/326135985">https://zhuanlan.zhihu.com/p/326135985</a><br>FLAT: Chinese NER Using Flat-Lattice Transformer</p><p>ELECTRA: 区别于BERT，使用判别器构建预训练模型（2020年3月论文)<br><a href="https://zhuanlan.zhihu.com/p/323931207">https://zhuanlan.zhihu.com/p/323931207</a><br>ELECTRA: PRE-TRAINING TEXT ENCODERS AS DISCRIMINATORS RATHER THAN GENERATORS</p><p>无监督的深度嵌入式聚类(2016年论文)<br><a href="https://zhuanlan.zhihu.com/p/313662693">https://zhuanlan.zhihu.com/p/313662693</a><br>Unsupervised Deep Embedding for Clustering Analysis</p><p>BOND：半监督的BERT开放域命名实体识别(2020年6月论文)<br><a href="https://zhuanlan.zhihu.com/p/307454757">https://zhuanlan.zhihu.com/p/307454757</a><br>BOND: BERT-Assisted Open-Domain Named Entity Recognition with Distant Supervision</p><p>使用半监督和监督学习检测虚假的在线评论(2019年2月)<br><a href="https://zhuanlan.zhihu.com/p/301268523">https://zhuanlan.zhihu.com/p/301268523</a><br>Detection of fake online reviews using semi-supervised and supervised learning </p><p>垃圾观点检测：使用基于多次迭代的图模型(2020年论文)<br><a href="https://zhuanlan.zhihu.com/p/300841251">https://zhuanlan.zhihu.com/p/300841251</a><br>Opinion spam detection: Using multi-iterative graph-based model</p><p>基于预训练和序列迁移的语法纠错系统(2019年7月)<br><a href="https://zhuanlan.zhihu.com/p/288219713">https://zhuanlan.zhihu.com/p/288219713</a><br>A Neural Grammatical Error Correction System Built On Better Pre-training and Sequential Transfer Learning</p><p>序列到序列的中文语法纠错(2018年)<br><a href="https://zhuanlan.zhihu.com/p/285211193">https://zhuanlan.zhihu.com/p/285211193</a><br>A Sequence to Sequence Learning for Chinese Grammatical Error Correction</p><p>BERT-of-Theseus: 通过逐步更换模块压缩BERT模型(2020年10月)<br><a href="https://zhuanlan.zhihu.com/p/283118184">https://zhuanlan.zhihu.com/p/283118184</a><br>BERT-of-Theseus: Compressing BERT by Progressive Module Replacing</p><p>TextBrewer：用于自然语言处理的开源知识蒸馏工具包(2020.04)<br><a href="https://zhuanlan.zhihu.com/p/275722016">https://zhuanlan.zhihu.com/p/275722016</a><br>TextBrewer: An Open-Source Knowledge Distillation Toolkit for Natural Language Processing</p><p>TinyBERT(华为)：自然语言理解之BERT蒸馏(2020.10)<br><a href="https://zhuanlan.zhihu.com/p/273467698">https://zhuanlan.zhihu.com/p/273467698</a><br>TinyBERT: Distilling BERT for Natural Language Understanding</p><p>BERT-PKD: BERT模型压缩之耐心知识蒸馏（2019.08）<br><a href="https://zhuanlan.zhihu.com/p/274329168">https://zhuanlan.zhihu.com/p/274329168</a><br>Patient Knowledge Distillation for BERT Model Compression</p><p>distilBert: Bert 蒸馏到简单的BiLSTM(2019.03)<br><a href="https://zhuanlan.zhihu.com/p/273543240">https://zhuanlan.zhihu.com/p/273543240</a><br>Distilling Task-Speciﬁc Knowledge from BERT into Simple Neural Networks</p><p>可转移域的端到端选择性对抗学习的Aspect-based情感分析(2019年10)<br><a href="https://zhuanlan.zhihu.com/p/268320982">https://zhuanlan.zhihu.com/p/268320982</a><br>Transferable End-to-End Aspect-based Sentiment Analysis with Selective Adversarial Learning</p><p>联合Aspect-Sentiment主题嵌入的弱监督的情感分析(2020年10)<br><a href="https://zhuanlan.zhihu.com/p/267744626">https://zhuanlan.zhihu.com/p/267744626</a><br>Weakly-Supervised Aspect-Based Sentiment Analysis via Joint Aspect-Sentiment Topic Embedding</p><p>观点目标提取和情感预测的统一模型(2019年)<br><a href="https://zhuanlan.zhihu.com/p/268580604">https://zhuanlan.zhihu.com/p/268580604</a><br>A Uniﬁed Model for Opinion Target Extraction and Target Sentiment Prediction</p><p>用于目标情感分类的注意力编码器网络(2019年04）<br><a href="https://zhuanlan.zhihu.com/p/270374318">https://zhuanlan.zhihu.com/p/270374318</a><br>Attentional Encoder Network for Targeted Sentiment Classiﬁcation</p><p>评测BERT类细粒度情感分类的语言表示模型(2020.05)<br><a href="https://zhuanlan.zhihu.com/p/268012476">https://zhuanlan.zhihu.com/p/268012476</a><br>Language Representation Models for Fine-Grained Sentiment Classiﬁcation</p><p>利用BERT进行端到端aspect-based的情感分析(2019年10）<br><a href="https://zhuanlan.zhihu.com/p/268801608">https://zhuanlan.zhihu.com/p/268801608</a><br>Exploiting BERT for End-to-End Aspect-based Sentiment Analysis</p><p>Aspect-level基于注意力的LSTM 情感分类(2016年)<br><a href="https://zhuanlan.zhihu.com/p/267254311">https://zhuanlan.zhihu.com/p/267254311</a><br>Attention-based LSTM for Aspect-level Sentiment Classification</p><p>BERT-EMD：多层对多层映射的BERT蒸馏（2020年10月）<br><a href="https://zhuanlan.zhihu.com/p/266602585">https://zhuanlan.zhihu.com/p/266602585</a><br>BERT-EMD: Many-to-Many Layer Mapping for BERT Compression with Earth Mover’s Distance</p><p>媲美GPT-3的变种PET模型(2020年9月论文)<br><a href="https://zhuanlan.zhihu.com/p/265646470">https://zhuanlan.zhihu.com/p/265646470</a><br>It’s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners</p><p>PRADO: 移动设备上的投影注意力文本分类网络(2019年论文)<br><a href="https://zhuanlan.zhihu.com/p/265042724">https://zhuanlan.zhihu.com/p/265042724</a><br>PRADO: Projection Attention Networks for Document Classiﬁcation On-Device</p><p>图神经网络的图归一化(2020.09论文)<br><a href="https://zhuanlan.zhihu.com/p/260811611">https://zhuanlan.zhihu.com/p/260811611</a><br>Learning Graph Normalization for Graph Neural Network</p><p>基于无标签数据Copy-Augmented预训练结构改善语法纠错(2019.06)<br><a href="https://zhuanlan.zhihu.com/p/258091623">https://zhuanlan.zhihu.com/p/258091623</a><br>Improving Grammatical Error Correction via Pre-Training a Copy-Augmented Architecture with Unlabeled Data</p><p>多层卷积编解码器神经网络语法纠错(2018.01论文)<br><a href="https://zhuanlan.zhihu.com/p/248000441">https://zhuanlan.zhihu.com/p/248000441</a><br>A Multilayer Convolutional Encoder-Decoder Neural Network for Grammatical Error Correction</p><p>近域微调的图片表格检测模型<br><a href="https://zhuanlan.zhihu.com/p/248393029">https://zhuanlan.zhihu.com/p/248393029</a><br>The Beneﬁts of Close-Domain Fine-Tuning for Table Detection in Document Images</p><p>IBM基于图片格式的表格识别(2020年03月论文)<br><a href="https://zhuanlan.zhihu.com/p/245032050">https://zhuanlan.zhihu.com/p/245032050</a><br>Image-based table recognition: data, model, and evaluation</p><p>FASPell基于DAE解码器的Spell Checker（2019.09）<br><a href="https://zhuanlan.zhihu.com/p/231626818">https://zhuanlan.zhihu.com/p/231626818</a><br>FASPell: A Fast, Adaptable, Simple, Powerful Chinese Spell Checker Based On DAE-Decoder Paradigm</p><p>个性化语法错误​​纠正（2020.06论文）<br><a href="https://zhuanlan.zhihu.com/p/231190671">https://zhuanlan.zhihu.com/p/231190671</a><br>Personalizing Grammatical Error Correction: Adaptation to Proficiency Level and L1</p><p>Reformer: 搞笑（高效）的transformer结构(2020年2月Google)<br><a href="https://zhuanlan.zhihu.com/p/208134502">https://zhuanlan.zhihu.com/p/208134502</a><br>REFORMER: THE EFFICIENT TRANSFORMER</p><p>2阶段中文纠错模型(2019论文)<br><a href="https://zhuanlan.zhihu.com/p/199551915">https://zhuanlan.zhihu.com/p/199551915</a><br>A Two-Stage Model for Chinese Grammatical Error Correction</p><p>CLUENER2020 2020年汉语NER和Benchmark<br><a href="https://zhuanlan.zhihu.com/p/197488236">https://zhuanlan.zhihu.com/p/197488236</a><br>CLUENER2020: FINE-GRAINED NAMED ENTITY RECOGNITION DATASET AND BENCHMARK FOR CHINESE</p><p>Google 最新 NLP语言模型可解释性可视化分析工具（2020-8月论文）<br><a href="https://zhuanlan.zhihu.com/p/188617204">https://zhuanlan.zhihu.com/p/188617204</a><br>The Language Interpretability Tool: Extensible, Interactive Visualizations and Analysis for NLP Models</p><p>聊天机器人架构设计和开发2-架构和设计（论文By Jack Cahn )<br><a href="https://zhuanlan.zhihu.com/p/181491658">https://zhuanlan.zhihu.com/p/181491658</a><br>CHATBOT: Architecture, Design, &amp; Development By Jack Cahn</p><p>DocBert Bert用作文档分类(2019年8月论文)<br><a href="https://zhuanlan.zhihu.com/p/180475198">https://zhuanlan.zhihu.com/p/180475198</a><br>DocBERT: BERT for Document Classification</p><p>TableBank：用于表检测和识别的基准数据集<br><a href="https://zhuanlan.zhihu.com/p/170365926">https://zhuanlan.zhihu.com/p/170365926</a><br>TableBank: A Benchmark Dataset for Table Detection and Recognition</p><p>LayoutLM 微软预训练模型图片类文档分类和实体识别(2020年6月论文)<br><a href="https://zhuanlan.zhihu.com/p/166128964">https://zhuanlan.zhihu.com/p/166128964</a><br>LayoutLM: Pre-training of Text and Layout for Document Image Understanding</p><p>UNILM 微软预训练的NLU和NLG结合模型(2019-10论文)<br><a href="https://zhuanlan.zhihu.com/p/164736442">https://zhuanlan.zhihu.com/p/164736442</a><br>Unified Language Model Pre-training for Natural Language Understanding and Generation</p><p>DIET模型 rasa 聊天机器人核心模型论文（2020年5月论文)<br><a href="https://zhuanlan.zhihu.com/p/162995854">https://zhuanlan.zhihu.com/p/162995854</a><br>Dual Intent and Entity Transformer</p><p>NLP之MixText 半监督文本分类(2020年4月论文解读)<br><a href="https://zhuanlan.zhihu.com/p/156091468">https://zhuanlan.zhihu.com/p/156091468</a><br>MixText: Linguistically-Informed Interpolation of Hidden Space for Semi-Supervised Text Classification</p><p>NLP 之数据增强算法(论文解读-2019年论文)<br><a href="https://zhuanlan.zhihu.com/p/152633064">https://zhuanlan.zhihu.com/p/152633064</a><br>EDA: Easy Data Augmentation Techniques for Boosting Performance onText Classification Tasks</p><p>TFIDF+Wordembedding无监督多标签文本分类算法（论文解读)<br><a href="https://zhuanlan.zhihu.com/p/152526817">https://zhuanlan.zhihu.com/p/152526817</a><br>Improving Recall and Precision in Unsupervised Multi-Label Document Classifification Tasks by Combining Word Embeddings with TF-IDF</p><p>评估对于少量样本使用Bert进行fine-tunning的优化方法（论文解读)<br><a href="https://zhuanlan.zhihu.com/p/152523646">https://zhuanlan.zhihu.com/p/152523646</a><br>Revisiting Few-sample BERT Fine-tuning</p><p>SYNTHESIZER代替self-attention机制（Google论文解读)<br><a href="https://zhuanlan.zhihu.com/p/152518921">https://zhuanlan.zhihu.com/p/152518921</a><br>Rethinking Self-Attention in Transformer Models</p>]]></content>
    
    
    <categories>
      
      <category>知乎</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>apex兼容torch1.10时的一个bug</title>
    <link href="/2022/03/08/apex%E7%9A%84%E4%B8%80%E4%B8%AAbug/"/>
    <url>/2022/03/08/apex%E7%9A%84%E4%B8%80%E4%B8%AAbug/</url>
    
    <content type="html"><![CDATA[<h1 id="关于apex的一个bug"><a href="#关于apex的一个bug" class="headerlink" title="关于apex的一个bug"></a>关于apex的一个bug</h1><p>具体报错内容如下:</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">    <span class="hljs-keyword">if</span> cached_x<span class="hljs-selector-class">.grad_fn</span><span class="hljs-selector-class">.next_functions</span><span class="hljs-selector-attr">[1]</span><span class="hljs-selector-attr">[0]</span><span class="hljs-selector-class">.variable</span> is not x:<br>IndexError: tuple index out of range<br></code></pre></td></tr></table></figure><p>先说具体的官方的issue和解决方法<br><a href="https://github.com/NVIDIA/apex/issues/1227">https://github.com/NVIDIA/apex/issues/1227</a><br><a href="https://github.com/NVIDIA/apex/issues/694#issuecomment-918833904">https://github.com/NVIDIA/apex/issues/694#issuecomment-918833904</a></p><p>zwithz用户已经指出应该修改这个文件，但是后面的用户classicsong说这个方法是有问题的</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs csharp">apex/amp/utils.py<br><span class="hljs-meta"># change this <span class="hljs-keyword">line</span> (<span class="hljs-keyword">line</span> 113)</span><br>- <span class="hljs-keyword">if</span> cached_x.grad_fn.next_functions[<span class="hljs-number">1</span>][<span class="hljs-number">0</span>].variable <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> x:<br><span class="hljs-meta"># 改成如下:</span><br>+ <span class="hljs-keyword">if</span> cached_x.grad_fn.next_functions[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>].variable <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> x:<br></code></pre></td></tr></table></figure><p>其实zwithz说的是对的，这是apex的一个bug<br>不同版本的torch的grad_fn数量</p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs nix"><span class="hljs-built_in">import</span> torch<br>print(torch.__version__)<br><span class="hljs-attr">x</span> = torch.ones(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-attr">requires_grad=True)</span><br><span class="hljs-attr">y</span> = x + <span class="hljs-number">2</span><br><span class="hljs-attr">z</span> = y * y * <span class="hljs-number">3</span><br><span class="hljs-attr">out</span> = z.mean()<br><span class="hljs-attr">half</span> = out.half()<br>print(len(half.grad_fn.next_functions))<br></code></pre></td></tr></table></figure><ul><li>1.7 版本</li></ul><p>1.7.0+cu110<br>2</p><ul><li>1.8版本</li></ul><p>1.8.0.post3<br>2</p><ul><li>1.9版本</li></ul><p>1.9.0+cu111<br>2</p><ul><li>1.10版本</li></ul><p>1.10.2<br>1</p><h2 id="关于grad-fn"><a href="#关于grad-fn" class="headerlink" title="关于grad_fn"></a>关于grad_fn</h2><p>grad_fn保存了链式计算的图<br>创建一个张量并设置requires_grad&#x3D;True, 那么这个tensor经过计算后的值都会写携带grad_fn属性，，用来追踪计算历史<br>Autograd是反向自动微分系统。从概念上讲，autograd记录了一个图，记录了你执行运算时产生数据的所有运算，给你一个有向无<br>环图，其叶子是输入张量，根是输出张量。通过追踪这个图从根到叶，你可以使用链式规则自动计算梯度。<br>在内部，autograd将这个图表示为Function对象的图（真正的表达式），autograd建立一个代表计算梯度的函数的图（每个torch.Tensor的.grad_fn属性是这个图的入口）。当前向传播完成后，我们在反向传播中评估这个图以计算梯度。</p><h2 id="官方示例"><a href="#官方示例" class="headerlink" title="官方示例"></a>官方示例</h2><p>如果你有一个模型，你按照损失的方向，使用它的.grad_fn属性，你会看到一个计算的图，看起来像这样。</p><figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs xl"><span class="hljs-function"><span class="hljs-title">input</span> -&gt;</span> <span class="hljs-function"><span class="hljs-title">conv2d</span> -&gt;</span> <span class="hljs-function"><span class="hljs-title">relu</span> -&gt;</span> <span class="hljs-function"><span class="hljs-title">maxpool2d</span> -&gt;</span> <span class="hljs-function"><span class="hljs-title">conv2d</span> -&gt;</span> <span class="hljs-function"><span class="hljs-title">relu</span> -&gt;</span> maxpool2d<br>      -&gt; <span class="hljs-function"><span class="hljs-title">flatten</span> -&gt;</span> <span class="hljs-function"><span class="hljs-title">linear</span> -&gt;</span> <span class="hljs-function"><span class="hljs-title">relu</span> -&gt;</span> <span class="hljs-function"><span class="hljs-title">linear</span> -&gt;</span> <span class="hljs-function"><span class="hljs-title">relu</span> -&gt;</span> linear<br>      -&gt; MSELoss<br>      -&gt; loss<br>因此，当我们调用loss.backward()时，整个图被微分，并且图中所有require_grad=True的张量都会有其.grad张量的梯度积累。<br>print(loss.grad_fn)  # MSELoss<br>print(loss.grad_fn.next_functions[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>])  # Linear<br>print(loss.grad_fn.next_functions[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>].next_functions[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>])  # ReLU<br>------&gt;<br>&lt;MseLossBackward0 object <span class="hljs-built_in">at</span> <span class="hljs-number">0</span>x7f09e8c788d0&gt;<br>&lt;AddmmBackward0 object <span class="hljs-built_in">at</span> <span class="hljs-number">0</span>x7f09e8c78978&gt;<br>&lt;AccumulateGrad object <span class="hljs-built_in">at</span> <span class="hljs-number">0</span>x7f09e8c78978&gt;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>torch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>apex</tag>
      
      <tag>fp16</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>信息提取的方式总结</title>
    <link href="/2022/03/08/%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96/"/>
    <url>/2022/03/08/%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96/</url>
    
    <content type="html"><![CDATA[<h1 id="信息抽取"><a href="#信息抽取" class="headerlink" title="信息抽取"></a>信息抽取</h1><p>信息抽取是构建知识图谱的关键一环，目前已实现了3种抽取的方式测试，发现了一些注意事项，总结如下:</p><img src="/2022/03/08/%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96/%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E6%80%BB%E7%BB%93.png" class="">]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>信息抽取</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>显存优化技术盘点</title>
    <link href="/2022/03/04/gpu-optimizer/"/>
    <url>/2022/03/04/gpu-optimizer/</url>
    
    <content type="html"><![CDATA[<h1 id="显存优化技术"><a href="#显存优化技术" class="headerlink" title="显存优化技术"></a>显存优化技术</h1><p>本思维导图总结了显存的占用的分为哪些部分，训练时的流程，和多GPU训练的分类。</p><img src="/2022/03/04/gpu-optimizer/%E6%98%BE%E5%AD%98%E4%BC%98%E5%8C%96%E6%8A%80%E6%9C%AF.png" class="">]]></content>
    
    
    <categories>
      
      <category>cuda</category>
      
    </categories>
    
    
    <tags>
      
      <tag>显存</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>一次pycharm在使用torch Dataloader进行debug时卡住</title>
    <link href="/2022/03/01/pycharm-debug/"/>
    <url>/2022/03/01/pycharm-debug/</url>
    
    <content type="html"><![CDATA[<h1 id="pycharm-debug可能卡住的原因有很多，其中之一是多进程导致的-尤其是我们在使用torch的DataLoader时，如果发生卡住，那么只需检查num-workers是否是0，即可"><a href="#pycharm-debug可能卡住的原因有很多，其中之一是多进程导致的-尤其是我们在使用torch的DataLoader时，如果发生卡住，那么只需检查num-workers是否是0，即可" class="headerlink" title="pycharm debug可能卡住的原因有很多，其中之一是多进程导致的, 尤其是我们在使用torch的DataLoader时，如果发生卡住，那么只需检查num_workers是否是0，即可"></a>pycharm debug可能卡住的原因有很多，其中之一是多进程导致的, 尤其是我们在使用torch的DataLoader时，如果发生卡住，那么只需检查num_workers是否是0，即可</h1><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs routeros">DataLoader(<br>    dataset,<br>    <span class="hljs-attribute">batch_size</span>=1,<br>    <span class="hljs-attribute">shuffle</span>=<span class="hljs-literal">False</span>,<br>    <span class="hljs-attribute">sampler</span>=None,<br>    <span class="hljs-attribute">batch_sampler</span>=None,<br>    <span class="hljs-attribute">num_workers</span>=0,<br>    <span class="hljs-attribute">collate_fn</span>=None,<br>    <span class="hljs-attribute">pin_memory</span>=<span class="hljs-literal">False</span>,<br>    <span class="hljs-attribute">drop_last</span>=<span class="hljs-literal">False</span>,<br>    <span class="hljs-attribute">timeout</span>=0,<br>    <span class="hljs-attribute">worker_init_fn</span>=None,<br>    <span class="hljs-attribute">multiprocessing_context</span>=None,<br>)<br>参数:<br>- dataset : 数据集<br>- batch_size: 批次大小<br>- shuffle: 是否乱序<br>- sampler: 样本采样函数，一般无需设置。<br>- batch_sampler: 批次采样函数，一般无需设置。<br>- num_workers: 使用多进程读取数据，设置的进程数。<br>- collate_fn: 整理一个批次数据的函数。<br>- pin_memory: 是否设置为锁业内存。默认为<span class="hljs-literal">False</span>，锁业内存不会使用虚拟内存(硬盘)，从锁业内存拷贝<br>到GPU上速度会更快。<br>- drop_last: 是否丢弃最后一个样本数量不足batch_size批次数据。<br>- timeout: 加载一个数据批次的最长等待时间，一般无需设置。<br>- worker_init_fn: 每个worker中dataset的初始化函数，常用于 IterableDataset。一般不使用<br></code></pre></td></tr></table></figure><p>根据API可知，num_workers是设置读取数据的并发进程数量，而根据pycharm的官方的issue，<a href="https://youtrack.jetbrains.com/issue/PY-39489%EF%BC%8C%E6%88%91%E4%BB%AC%E5%8F%91%E7%8E%B0pycharm%E5%A4%9A%E8%BF%9B%E7%A8%8B%E7%9A%84debug%E6%9C%89%E6%97%B6%E5%B9%B6%E4%B8%8D%E5%A4%AA%E6%96%B9%E4%BE%BF%EF%BC%8C%E6%89%80%E4%BB%A5%E5%8F%AA%E9%9C%80%E5%9C%A8debug%E6%97%B6%EF%BC%8C%E4%BF%AE%E6%94%B9num_workers%E5%8D%B3%E5%8F%AF%EF%BC%8C%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E5%9C%A8%E6%94%B9%E5%9B%9E%E6%9D%A5%E5%B0%B1%E8%A1%8C%E3%80%82">https://youtrack.jetbrains.com/issue/PY-39489，我们发现pycharm多进程的debug有时并不太方便，所以只需在debug时，修改num_workers即可，生产环境在改回来就行。</a></p>]]></content>
    
    
    <categories>
      
      <category>ide</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>多标签分类的2种简单实现</title>
    <link href="/2022/02/28/multilabel/"/>
    <url>/2022/02/28/multilabel/</url>
    
    <content type="html"><![CDATA[<h1 id="模型的损失函数"><a href="#模型的损失函数" class="headerlink" title="模型的损失函数"></a>模型的损失函数</h1><p>torch.nn.BCEWithLogitsLoss<br>先进行了sigmoid，然后进行了二分类交叉熵损失函数</p><h1 id="评估metric"><a href="#评估metric" class="headerlink" title="评估metric"></a>评估metric</h1><p>hamming score<br>sklearn.metrics.multilabel_confusion_matrix   #多标签混淆矩阵</p><p>#hamming score<br>示例</p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs nix"><span class="hljs-built_in">import</span> numpy as np<br><span class="hljs-attr">truth</span> = [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>] <span class="hljs-comment"># 真实值</span><br><span class="hljs-attr">prediction</span> = [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]  <span class="hljs-comment">#预测值</span><br><span class="hljs-attr">truth</span> = np.array(truth)<br><span class="hljs-attr">prediction</span> = np.array(prediction)<br><span class="hljs-attr">num_classes</span> = len(truth)<br><span class="hljs-attr">num_samples</span> = <span class="hljs-number">1</span><br><span class="hljs-attr">numerator</span> = float(sum(truth &amp; prediction))<br><span class="hljs-attr">denominator</span> = float(sum(truth | prediction))<br><span class="hljs-attr">hamming_score</span> = numerator / denominator<br>------&gt;<br><span class="hljs-number">0.667</span><br>如果是按照准确率计算accuracy_score(truth, prediction)，那么是<span class="hljs-number">0.8</span><br></code></pre></td></tr></table></figure><p>我们的输出是一个批次的，所以是二维的，计算的方法是: score&#x3D;((predicts &amp; labels).sum(axis&#x3D;1) &#x2F; (predicts | labels).sum(axis&#x3D;1)).mean()</p><h1 id="实现方式1：-使用CLS进行分类"><a href="#实现方式1：-使用CLS进行分类" class="headerlink" title="实现方式1： 使用CLS进行分类"></a>实现方式1： 使用CLS进行分类</h1><p>假设我们的示例是商品的购买意向，模型的基本输入是：CLS+句子1+SEP+商品+SEP<br>对CLS进行求sigmoid和二分类交叉熵<br>模型实现逻辑：</p><ol><li>Bert模型编码, last_hidden_state, all_hidden_states &#x3D; self.encode(input_ids, token_type_ids, attention_mask)</li><li>取最后一个隐藏层的CLS向量, first_token_tensor &#x3D; hidden_states[:, 0]  </li><li>进行dropout, self.dropout(first_token_tensor)</li><li>加个全连接层和激活</li><li>线性层映射到标签个数，得到logits, nn.Linear(hidden_size, num_labels)</li><li>计算损失, 反向传播,更新参数</li></ol><h1 id="实现方式2：-每个标签类别向量进行分类"><a href="#实现方式2：-每个标签类别向量进行分类" class="headerlink" title="实现方式2： 每个标签类别向量进行分类"></a>实现方式2： 每个标签类别向量进行分类</h1><p>假设我们的示例是商品的购买意向, 模型的基本输入是: CLS+句子1+SEP+商品+每个标签的id+SEP<br>取出每个标签的向量<br>对每个标签向量进行二分类交叉熵损失<br>模型实现逻辑：</p><ol><li>注意我们在输入的末尾添加了每个标签的id, 所以需要用特殊的token表示这些id, 所以需要增加词表，tokenizer.add_special_tokens({‘additional_special_tokens’:’opinion1’}) 我们用opinion1代表第一个标签，opinion2代表第二个标签，分别都加入到vocab中</li><li>注意在处理数据时，我们还有生成label_mask参数，告知我们关注的label的位置在哪里</li><li>Bert模型编码, last_hidden_state, all_hidden_states &#x3D; self.encode(input_ids, token_type_ids, attention_mask)</li><li>hidden_states 形状 [batch_size, seq_len, last_hidden_size] –&gt; [batch_size, labels_num, last_hidden_size]  加一个维度，然后扩充到hidden_states形状，方便后面取出label_mask需要的维度数据 label_mask_expand &#x3D; label_mask.unsqueeze(-1).expand(hidden_states.size())<br> labels_token_tensor_1d &#x3D; torch.masked_select(hidden_states, (label_mask_expand &#x3D;&#x3D; 1))<br>labels_token_tensor &#x3D; labels_token_tensor_1d.view(batch_size, -1, last_hidden_size)</li><li>加个droput, 全连接层和激活 </li><li>分类层, 最后变成1维度，nn.Linear(hidden_size, 1)</li><li>logits &#x3D; logits.squeeze(-1), 去掉最后一次，得到[batch_size, num_labels] 形状</li><li>计算损失, 反向传播,更新参数</li></ol>]]></content>
    
    
    <categories>
      
      <category>模型</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分类</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>一些论文中的专有名词</title>
    <link href="/2022/02/24/paper-word/"/>
    <url>/2022/02/24/paper-word/</url>
    
    <content type="html"><![CDATA[<h1 id="一些论文中的专有名词的解释或缩写"><a href="#一些论文中的专有名词的解释或缩写" class="headerlink" title="一些论文中的专有名词的解释或缩写"></a>一些论文中的专有名词的解释或缩写</h1><ul><li>low-resource:低资源:有标签或者无标签的训练的数据资源不足</li><li>Distant supervision:远端监督:大多数机器学习技术都需要一组训练数据。收集训练数据的传统方法是让人们标签一组文档。例如，对于婚姻关系，人类标注者可以将“比尔·克林顿”和“希拉里·克林顿”对标签为正的训练样本。这种方法在时间和金钱上都是昂贵的，并且如果我们的语料库很大，将无法产生足够的数据供我们的算法使用。而且由于人为错误，因此产生的训练数据极有可能是噪音的。生成训练数据的另一种方法是远距离监督(远程监督)。在远距离监督中，我们利用一个已经存在的数据库来收集要提取的关系的样本。然后，我们使用这些样本自动生成我们的训练数据。例如，包含巴拉克·奥巴马和米歇尔·奥巴马已婚的事实。我们考虑到这一事实，然后将出现在同一句子中的每对“巴拉克·奥巴马”和“米歇尔·奥巴马”都标签为我们婚姻关系的一个正例子。这样，我们可以轻松生成大量(可能是噪音的)训练数据。运用远距离监督来获得特定关系的正样本很容易，但是产生负样本比较难.即用知识库KG来获取2个实体之间的关系。</li><li>tokenization:分词器:原始raw text叫语料，字典中的单独词叫token，可能是单词，也可能是词语，取决于字典，tokenization是把raw text变成token的过程，假如英语就是把句子用空格切分，每个单词就叫token</li><li>detokenization:分词还原: 就是还原，把分词还原成句子，或者把分词后得到的id还原成原来的句子。</li><li>soft label:软标签:是一个teacher模型预测出来的，类似logits的概率值，是浮点数</li><li>hard label:硬标签:硬标签直接就是整数，就是对应概率最大的位置的索引，例如soft是0.82, hard就是1, <a href="https://arxiv.org/abs/1511.06335">https://arxiv.org/abs/1511.06335</a></li><li>SOTA:state-of-the-art:业界最新的性能，达到最新的模型性能</li><li>FLOPS:floating point operations per second:每秒浮动计算数, 是衡量计算机计算性能的一个指标</li><li>MLM:Masked language modeling, 掩盖语言建模, 也被叫做完形填空测试,cloze test,MLM的任务是根据占位符预测序列中的丢失token</li><li>T5: Text-to-Text Transfer Transformer</li><li>warm-up: 调整学习率的方式，在warm-up步数之前的学习率是恒定或者按照一定规则变大，warm-up之后的步数指数方式衰减和线性衰减</li><li>corruption损坏: 破坏一个原有的句子，例如BERT的MLM的无监督目标，可以对一个句子进行丢弃，替换，交换，添加操作，改变原有语句，然后让模型预测原有句子或改变的部分</li><li>域内数据: 就是一个领域的数据，例如新闻领域的文章和论文领域里的文章是不一样的,他们就是不同的域</li><li>pre-train-then-ﬁne-tune: 首先预训练模型，然后微调模型，预训练模型一般用大量数据做无监督训练，微调模型是用少量数据有监督训练</li><li>零样本学习(zero-shot learning): 即使训练时没有看到目标训练集，也能进行进行模型预测,零次训练或推理,无须训练，直接进行预测或推理。是一种训练策略，它允许机器学习模型预测新的类别，而不需要为新的类别提供任何标注的样本。</li><li>Few-Shot: 少量训练样本进行学习，然后预测，类似于low-resource</li><li>图灵完备性（Turing Completeness）:是针对一套数据操作规则而言的概念。数据操作规则可以是一门编程语言，也可以是计算机里具体实现了的指令集。当这套规则可以实现图灵机模型里的全部功能时，就称它具有图灵完备性。直白一点说，图灵完备性就是我给你一工具箱的东西，包括无限内存、if&#x2F;else 控制流、while 循环; 简单来讲，一切可计算的问题都能计算，这样的虚拟机或者编程语言就叫图灵完备的;举个例子，如果有人说，我的东西是图灵完备的，也就意味着理论上它能够用来解决任何计算性的问题。</li><li>有限状态机（英语：finite-state machine，缩写：FSM）又称有限状态自动机（英语：finite-state automation，缩写：FSA），简称状态机，是表示有限个状态以及在这些状态之间的转移和动作等行为的数学计算模型。</li><li>RE:relation extraction,neural relation extraction (NRE),  从一个句子中判断两个entity是否有关系，一般是一个二分类问题，指定某种关系。</li><li>Entity Mentions: 实体提及,就是句子中的实体, “New York City is good”  New York City就是实体，或者实体提及, 就是实体的名字</li><li>KGs: Knowledge Graph, 知识图谱</li><li>Autograd: 自动微分是训练神经网络的一种机制,自动求导，计算梯度</li><li>Segment: 片段，或者称为句子a，句子b等，例如训练BERT时结构如,“[CLS] x1 [SEP] x2 [SEP]”，x1表示片段1，或句子a，x2表示片段2或句子b。</li><li>Intrinsic tasks vs Downstream Tasks: 固有任务和下游任务，固有任务意思是预训练语言模型时的任务，下游任务是微调模型时的任务。</li><li>WordPiece: 是在自然语言处理中使用的子词分割算法。BERT用的此方法。子词分词的一种方法。 用该语言中的各个字符初始化单词表，然后将单词表中最常见的符号组合迭代添加到单词表中。 该过程是：1.用文本中的所有字符初始化单词清单。2.使用来自上一步的清单在训练数据上构建语言模型。 3. 通过组合当前单词清单中的两个单元, 将单词组装一个单词单元。 在添加到模型中时，从所有可能增加训练数据可能性中选择一个新的词单元。 4. 转到2，直到达到预定义的词单元限制或可能性增加低于某个特定阈值。</li><li>NMT:  Neural machine translation,神经机器翻译, 利用深度神经网络执行的端到端的翻译，例如seq2seq的神经网络翻译。</li><li>SMT: statistical machine translation,传统机器翻译的方法。</li><li>non-segmented语言: 分段语言，即用空格分隔的语言，例如英语，非分段语言，例如中文，日语，韩语。</li><li>NFD:Normalization Form Canonical Decomposition标准化形式规范分解,Unicode字符串标准化的一种算法,字符通过规范等价分解，并且多个组合字符按特定顺序排列</li><li>NFC:Normalization Form Canonical Composition 标准化形式规范组合,Unicode字符串标准化的一种算法, 字符被分解，然后通过规范对等重新组合。 </li><li>NFKD: Normalization Form Compatibility Decomposition: 标准化形式兼容性分解,字符通过兼容性分解，并且多个组合字符按特定顺序排列。 </li><li>NFKC: Normalization Form Compatibility Composition: 标准化形式兼容性组成,字符通过兼容性分解，然后通过规范对等重组。所有这些算法都是幂等转换，这意味着如果以相同算法再次处理，已经处于这些标准化形式之一的字符串将不会被修改。 </li><li>RBT3：由RoBERTa-wwm-ext 3层进行初始化，继续训练了1M步,RBT的名字是RoBERTa三个音节首字母组成，L代表large模型</li><li>RBTL3: 3层RoBERTa-wwm-ext-base&#x2F;large,由RoBERTa-wwm-ext-large 3层进行初始化，继续训练了1M步</li><li>ONNX: Open Neural Network Exchange format,开放式神经网络交换格式,提高模型推理速度的中间模型格式，最高实现4倍的推理加速。</li><li>ABSA: Aspect-based Sentiment Analysis, 给定句子中关心的情感的术语(aspect),即某个词在句子中表达的情感。等同于ALSC, Aspect level sentiment classification</li><li>Sentiment Analysis (SA): 也称为Opinion Mining (OM)</li><li>self-supervised: 类似于BERT的预训练模型的方式，也可以成为无监督,无监督表明我们确实没给BERT提供人工打标签，自监督表明它是用自己随机MASK部分token，然后预测被Mask的方式，所以叫做自监督。</li><li>context-gloss: 上下文的连贯性</li><li>LA-MLM: label-aware masked language model, 标签感知masked语言模型,分2个阶段Early Fusion早期融合和Late Supervision后期监督，它们的主要区别是早期融合阶段是把句子情感也作为输入，后期监督是把句子情感作为预测标签，监督训练句子情感。早期融合和后期监督的目的是让模型能够理解句子级情感和单词级情感和词性之间的内在联系。</li><li>parse tree: 分析树, 具体语法树（concrete syntax tree）,是一个反映某种形式语言字符串的语法关系的有根有序树。分析树一般按照两种相反的法则生成，一种是依存语法,一种是短语结构语法。二分类选举树,binary constituency tree</li><li>PLM: Pre-trained Language Models 预训练语言模型； 排列语言模型(Permutation Language Model) PLM, XLNet使用排列语言模型(PLM)</li><li>DRL: deep reinforcement learning</li><li>市场摩擦（英文：Market Friction）:是指金融资产在交易中存在的难度。它可由交易一定数量某金融资产的最佳占用时间来测定，也可由即时交易所需要的价格让步(Price concession)来测定。</li><li>inductive: 归纳式学习,transductive和inductive的区别在于我们想要预测的样本，是不是我们在训练的时候已经见（用）过的。inductive learning就是只根据现有的ABC，用比如kNN距离算法来预测，在来一个新的数据的时候，还是只根据5个ABC来预测。</li><li>transductive: 直推式学习,transductive learning直接以某种算法观察出数据的分布，这里呈现三个cluster，就根据cluster判定，不会建立一个预测的模型，如果一个新的数据加进来 就必须重新算一遍整个算法，新加的数据也会导致旧的已预测问号的结果改变</li><li>NRE: Neural Relation Extraction Models 神经网络的关系抽取模型</li><li>PCNN: PCNN（Piece-Wise-CNN）</li><li>OMR: 光学音乐识别(OPTICAL MUSIC Recognition，OMR)是将乐谱的扫描图像转换为像MusicXML[9]或MIDI这样的符号代表的问题。这种解决方案有很多明显的实际应用。</li><li>on-policy: 强化学习可以分为off-policy和on-policy的方法。off-policy RL算法意味着用于选择动作的行为策略与学习策略不同。相反，在on-policy RL算法中，行为策略与学习策略是相同的。此外，强化学习还可以分为基于价值的方法和基于策略的方法。在基于价值的RL中，agent更新价值函数来学习合适的策略，而基于策略的RL agent直接学习策略。</li><li>Hierarchical reinforcement learning (HRL): 分层强化学习</li><li>ALE: Atari Learning Environment</li><li>rollout:（就相当于在一个棋局时尝试多次不同路径的走子）类似右图产生多条路径</li><li>Imitation Learning: IL 模仿学习，模仿学习的思想很直观(intuitive)。我们在前面所介绍的Model-free, Model-based强化学习方法都是从零开始(from scratch)探索并学习一个使累计回报最大的策略(policy) [公式] 。 Imitation Learning的想法是，借助人类给出的示范(demonstration)，可以快速地达到这个目的。</li><li>• Forward model: (st, at) → st+1. 前向模型。(st, at) → st+1. 这是在给定当前状态和所选动作的情况下预测下一个状态。这是目前最常见的模型类型，可用于前向规划。</li><li>• Backward&#x2F;reverse model: st+1 → (st, at).  反向模型：st+1 →（st，at）。这个模型预测了哪些状态是某一特定状态的可能前兆。因此，我们可以在反向的方向上进行规划，例如，在prioritized sweeping中就使用了这种方法（Moore和Atkeson，1993）。</li><li>• Inverse model: (st, st+1) → at.  逆向模型。(st, st+1) → at. 逆向模型预测从一个状态到另一个状态需要哪种行动。例如，它被用于RRT规划中（LaValle，1998）。正如我们稍后将看到的那样，这个函数也可以作为表示学习的一部分。</li><li>NP-hard: NP是指非确定性多项式（non-deterministic polynomial，缩写NP）。所谓的非确定性是指，可用一定数量的运算去解决多项式时间内可解决的问题。例如，著名的推销员旅行问题（Travel Saleman Problem or TSP）：假设一个推销员需要从香港出发，经过广州，北京，上海，…，等 n 个城市， 最后返回香港。 任意两个城市之间都有飞机直达，但票价不等。假设公司只给报销 C 元钱，问是否存在一个行程安排，使得他能遍历所有城市，而且总的路费小于 C？ 推销员旅行问题显然是 NP 的。因为如果你任意给出一个行程安排，可以很容易算出旅行总开销。但是，要想知道一条总路费小于 C 的行程是否存在，在最坏情况下，必须检查所有可能的旅行安排！ 这将是个天文数字。</li><li>P类问题：可以找到一个多项式时间复杂度的算法去解决的问题；</li><li>NEXPTIME-complete:如果一个决策问题在NEXPTIME中，那么它就是NEXPTIME完整的，而且NEXPTIME中的每个问题都有一个多项式时间的多对一还原。换句话说，有一种多项式时间的算法可以将一个问题的实例转化为另一个问题的实例，而且答案相同。NEXPTIME-complete的问题可以被认为是NEXPTIME中最难的问题。我们知道NEXPTIME-complete问题不在NP中；根据时间层次定理，已经证明这些问题不能在多项式时间内被验证。 一组重要的NEXPTIME-complete问题与简洁电路有关。简明电路是一种简单的机器，用于在指数级的空间内描述图形。它们接受两个顶点数字作为输入，并输出它们之间是否有一条边。如果在自然表示法（如邻接矩阵）中解决一个图的问题是NP-完全的，那么在简洁电路表示法中解决同样的问题是NEXPTIME-完全的，因为输入是指数级的小（在一些温和的条件下，NP-完全性的减少是通过 “投影 “实现的）。[2][3] 作为一个简单的例子，为一个如此编码的图寻找一个汉密尔顿路径是NEXPTIME-完全的。</li><li>MARL: Multi-Agent Reinforcement Learning 多agent强化学习</li><li>annealed: 退火，意思是超参数随着时间的逐渐变小，参数越来越小。例如强化学习中的Qleanring的Greedy系数。</li><li>优势函数:advantage function , 强化学习 优势函数(Advantage Function),优势函数表达在状态s下，某动作a相对于平均而言的优势。 从数量关系来看，就是随机变量相对均值的偏差。 使用优势函数是深度强化学习极其重要的一种策略，尤其对于基于policy的学习。优势函数其实就是将Q-Value“归一化”到Value baseline上，如上讨论的，这样有助于提高学习效率，同时使学习更加稳定；同时经验表明，优势函数也有助于减小方差，而方差过大导致过拟合的重要因素。Aπ(s,a)&#x3D;Qπ(s,a) - Vπ(s)</li><li>bitext: bidirectional text, 双向语料，即翻译的平行语料，例如中英文翻译语料库</li><li>Dec-POMDP: 一个完全合作的多agent任务可以被描述为一个分散的部分可观察马尔可夫决策过程（Dec-POMDP）</li><li>CTDE: 集中训练和分散执行（CTDE）Kraemer和Banerjee[2016]的范式允许学习过程利用额外的状态信息。CTDE允许学习算法访问所有局部行动观察直方图和全局状态，并共享梯度和参数。然后，在执行阶段，每个单独的agent只能访问其局部行动观察历史τi。</li><li>tile-coding: 强化学习理论扩展到了连续空间（连续空间的泛化）。tile-coding是连续空间强化学习问题中最实用和计算效率最高的工具。本质上，tile-coding是连续状态空间中的特征表示,tile-coding的主要优势之一是其计算效率。一个tiling的意思是一张大网，里面有划分成不同的小网，观察的像素会落到这个tiling中的小网内，就可以用这个小网内的坐标表示这个特征，多个tiling就是用多个小网内的坐标表示这个特征，就像self-attention的多头和卷积中的多个卷积核一样。<a href="https://towardsdatascience.com/reinforcement-learning-tile-coding-implementation-7974b600762b">https://towardsdatascience.com/reinforcement-learning-tile-coding-implementation-7974b600762b</a></li><li>domain adaptation for machine translation (DAMT): 半监督领域适应翻译</li><li>ROUGE-N:系统和参考摘要之间N-grams的重叠。</li><li>ROUGE-1:指的是系统和参考摘要之间的unigram（每个字）的重叠情况。</li><li>ROUGE-2:指的是系统和参考摘要之间的bigram重叠。</li><li>ROUGE-L:基于最长共同子序列（LCS）的统计。最长共同子序列问题自然考虑到了句子层面的结构相似性，并自动识别序列中最长的共同出现的n-grams。</li><li>ROUGE-W:基于加权的LCS统计，倾向于连续的LCSs。</li><li>ROUGE-S:基于 Skip-bigram 的共现统计。Skip-bigram是指任何一对词在其句子中的序列。</li><li>ROUGE-SU:基于 Skip-bigram 和 unigram 的共现统计。</li><li>MTL: Multi-task learning </li><li>SAN: 随机答案网络,用于问答系统，stochastic answer network, Stochastic answer networks for natural language inference</li><li>MTPE:  machine translation post-editing</li><li>MBRL: model-based的强化学习</li><li>CPM:Chinese Pretrained language Model 中文预训练模型</li><li>prompt-tuning:（p-tuning）</li><li>TrGCN: transformer图卷积网络</li><li>NED:命名实体消歧named entity disambiguation</li><li>ERD: Entity Relationship Diagram 实体关系图</li><li>ELBO:  Evidence Lower Bound，即证据下界,这里的证据指数据或可观测变量的概率密度。使用变分推断时，首先需要计算的便是ELBO。<a href="https://blog.csdn.net/qy20115549/article/details/93074519">https://blog.csdn.net/qy20115549/article/details/93074519</a></li><li>New Words Discovery: 新词发现</li><li>ACSA: Aspect category sentiment analysis, 基于属性类别的情感分析</li><li>ABSA: Aspect Based Sentiment Analysis, 基于属性的情感分析</li><li>ATSA: 等同于ABSA，aspect术语情感分析</li><li>capsule Network: 胶囊神经网络,是相对于CNN的改进，综合了CNN的优点的同时，考虑了CNN缺失的相对位置、角度等其他信息，从而使得识别效果有所提升。<a href="https://easyai.tech/ai-definition/capsule/">https://easyai.tech/ai-definition/capsule/</a></li><li>MRR: Mean Reciprocal Rank, 是一个国际上通用的对 搜索算法 进行评价的机制，即第一个结果匹配，分数为1，第二个匹配分数为0.5，第n个匹配分数为1&#x2F;n，如果没有匹配的句子分数为0,最终的分数为所有得分之和</li><li>ER: entity recognition 实体识别</li><li>EL: entity linking 实体链接</li><li>ED: entity disambiguation 实体消歧</li><li>EEs: emerging entities 新出现的实体</li><li>EED: emerging entity discovery 新实体发现,通过对知识库中现有的候选实体进行鉴别,KB外的实体称为新出现的实体。</li><li>BPR: Best Possible Recall</li><li>CMD: Central Moment Discrepancy, 最先进的分布相似度指标,过匹配两个表示的顺序矩差来衡量它们之间的差异,类似KL散度,可以执行高阶矩的明确匹配，而不需要昂贵的距离和核矩阵计算。CMD距离随着两个分布的相似性而变小。</li><li>平凡解: trivial solution, 编码器函数近似于一个不相关的但不具代表性的模态向量，就会出现平凡解的情况，防止平凡解, 经常用于结构非常简单的对象（比如群或拓扑空间），有时亦会用明显或乏趣这两个词代替，但对非数学工作者来说，它们有时可能比其他更复杂的对象更难想象或理解。例如： 明显因数：对于每个正整数 n 来说，1、-1、n 和 -n 都是它的明显因数。 空集：不包含任何元素的集合； 平凡群：只含单位元的群；</li><li>DETR: 端到端目标检测,End-to-end Object Detection with Transformer, 达到与Faster-RCNN等两阶段目标检测相当的性能。</li><li>FGM: Factor Graph Model, 因子图模型,是概率图模型的一种</li><li>IGL: Iterative Grid Labeling 迭代式网关标注方式</li><li>TSA: Text Similarity Approach 文本相似性技术</li><li>MLTC:multi-label text classification 多标签文本分类</li><li>XMC: Extreme multi-label text classification 极端多标签文本分类, 寻求从一个极端大的标签集合中为给定的文本输入找到相关的标签。许多现实世界的应用可以被表述为XMC问题，如推荐系统、文档tagging和语义搜索。</li><li>exposure bias: 暴露偏差:模型训练与预测过程之间的不匹配。在训练时每一个词输入都来自真实样本，但是在推断时当前输入用的却是上一个词的输入</li></ul>]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>知识图谱的构建思路</title>
    <link href="/2022/02/24/knowledge-graph/"/>
    <url>/2022/02/24/knowledge-graph/</url>
    
    <content type="html"><![CDATA[<h1 id="知识图谱"><a href="#知识图谱" class="headerlink" title="知识图谱"></a>知识图谱</h1><ol><li>众所周知，计算机的计算能力比人类强，但是推理能力远不如人类，所以构建知识图谱是为了解决计算机的推理能力。。</li><li>计算机的常识的使用能力也远不如人类，所以经常可以看到构建常识的知识图谱。</li><li>知识图谱在专业领域一般应用较多，例如医疗行业等。</li><li>知识图谱分为构建和应用，其中构建又包括设计本体，知识获取（结构化，非结构化，半结构化）知识存储，知识表示和知识融合等。如今构建知识图谱的技术已经很成熟，部分应用知识图谱的技术也已经成熟，例如利用知识图谱的问题等。</li></ol><img src="/2022/02/24/knowledge-graph/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png" class="">]]></content>
    
    
    <categories>
      
      <category>知识图谱</category>
      
    </categories>
    
    
    <tags>
      
      <tag>构建</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>torch和paddlepaddle的部分API对比</title>
    <link href="/2022/02/23/torch-paddle/"/>
    <url>/2022/02/23/torch-paddle/</url>
    
    <content type="html"><![CDATA[<h1 id="paddlepaddle代码和torch的模型代码相互转换-其实只需要关注这些api的不同，进行相应替换即可"><a href="#paddlepaddle代码和torch的模型代码相互转换-其实只需要关注这些api的不同，进行相应替换即可" class="headerlink" title="paddlepaddle代码和torch的模型代码相互转换, 其实只需要关注这些api的不同，进行相应替换即可"></a>paddlepaddle代码和torch的模型代码相互转换, 其实只需要关注这些api的不同，进行相应替换即可</h1><p>paddlepaddle 封装了类似torch， huggingface transformers 和datasets的接口形式</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-title">torch</span>包和paddle包的对比, 只列出不同的地方<br><span class="hljs-type">PyTorch</span> <span class="hljs-type">PaddlePaddle</span>    说明<br><span class="hljs-title">torch</span>.nn    paddle.nn   包括了神经网络相关的大部分函数<br><span class="hljs-title">nn</span>.<span class="hljs-type">Module</span>   nn.<span class="hljs-type">Layer</span>    搭建网络时集成的父类，包含了初始化等基本功能<br><span class="hljs-title">torch</span>.optim paddle.optimizer    训练优化器<br><span class="hljs-title">torch</span>.optim.<span class="hljs-type">AdamW</span>   paddle.optimizer.<span class="hljs-type">AdamW</span>  参数也不一样<br><span class="hljs-title">torchvision</span>.transforms  paddle.vision.transforms    数据预处理、图片处理<br><span class="hljs-title">torchvision</span>.datasets    paddle.vision.datasets  数据集的加载与处理<br><span class="hljs-title">nn</span>.<span class="hljs-type">Conv2d</span>   nn.<span class="hljs-type">Conv2D</span>   <span class="hljs-number">2</span>维卷积层<br><span class="hljs-title">nn</span>.<span class="hljs-type">BatchNorm2d</span>  nn.<span class="hljs-type">BatchNorm2D</span>  <span class="hljs-type">Batch</span> <span class="hljs-type">Normalization</span> 归一化<br><span class="hljs-title">nn</span>.<span class="hljs-type">MaxPool2d</span>    nn.<span class="hljs-type">MaxPool2D</span>    二维最大池化层<br><span class="hljs-title">nn</span>.<span class="hljs-type">AdaptiveAvgPool2d</span>    nn.<span class="hljs-type">AdaptiveAvgPool2D</span>    自适应二维平均池化（只用给定输出形状即可）<br><span class="hljs-title">torch</span>.flatten   paddle.flatten  展平处理<br><span class="hljs-title">torch</span>.softmax   paddle.softmax  softmax层<br><span class="hljs-title">datasets</span>.<span class="hljs-type">ImageFolder</span>    datasets.<span class="hljs-type">DatasetFolder</span>  指定数据集文件夹<br><span class="hljs-title">torch</span>.utils.<span class="hljs-class"><span class="hljs-keyword">data</span>.<span class="hljs-type">DataLoader</span> paddle.io.<span class="hljs-type">DataLoader</span>    加载数据集, 参数也不一样</span><br>(optimizer).no_grad (optimizer).zero_grad   梯度清零<br><span class="hljs-title">torch</span>.save  paddle.jit.save 说实话，这两个还是有点区别的，使用请看官方文档<br><span class="hljs-title">torch</span>.device    paddle.set_device   指定设备<br><span class="hljs-title">torch</span>.utils.<span class="hljs-class"><span class="hljs-keyword">data</span>.<span class="hljs-type">Dataset</span>    paddle.io.<span class="hljs-type">Dataset</span>   数据集</span><br><span class="hljs-title">torch</span>.utils.<span class="hljs-class"><span class="hljs-keyword">data</span>.<span class="hljs-type">RandomSampler</span>  paddle.io.<span class="hljs-type">RandomSampler</span></span><br><span class="hljs-title">torch</span>.utils.<span class="hljs-class"><span class="hljs-keyword">data</span>.<span class="hljs-type">BatchSampler</span>   paddle.io.<span class="hljs-type">BatchSampler</span>   参数也不一样</span><br><span class="hljs-title">torch</span>.utils.<span class="hljs-class"><span class="hljs-keyword">data</span>.<span class="hljs-type">DataLoader</span> paddle.io.<span class="hljs-type">DataLoader</span>  数据集加载</span><br><span class="hljs-title">tensor</span>.<span class="hljs-class"><span class="hljs-keyword">type</span>(<span class="hljs-title">torch</span>.<span class="hljs-title">float32</span>)  paddle.cast(<span class="hljs-title">mask</span>, &#x27;<span class="hljs-title">float32&#x27;</span>)  数据类型变更</span><br><span class="hljs-title">tensor</span>.cpu().item() tensor.numpy().item()  # 取出数据<br><span class="hljs-title">transformers</span>.get_linear_schedule_with_warmup    paddlenlp.transformers.<span class="hljs-type">LinearDecayWithWarmup</span>   # warmup 函数<br>也不一样<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>torch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>api</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>一个小的子列表位置查找函数</title>
    <link href="/2022/02/22/python-list/"/>
    <url>/2022/02/22/python-list/</url>
    
    <content type="html"><![CDATA[<h1 id="sublist是original列表中的一部分，即子列表，如果存在sublist，那么就返回起始和结束位置，否则返回None"><a href="#sublist是original列表中的一部分，即子列表，如果存在sublist，那么就返回起始和结束位置，否则返回None" class="headerlink" title="sublist是original列表中的一部分，即子列表，如果存在sublist，那么就返回起始和结束位置，否则返回None"></a>sublist是original列表中的一部分，即子列表，如果存在sublist，那么就返回起始和结束位置，否则返回None</h1><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs vim">def index_partof_list(original, sublist):<br>    <span class="hljs-string">&quot;&quot;</span><span class="hljs-comment">&quot;</span><br>    子列表查找, 也可以用于字符串的查找<br>    :param original: 一个列表<br>    :<span class="hljs-built_in">type</span> original:<br>    :param sublist: sublist是original列表中的一部分，即子列表，如果存在sublist，那么就返回起始和结束位置，否<br>则返回None<br>    :<span class="hljs-built_in">type</span> sublist:<br>    :<span class="hljs-keyword">return</span>: 返回<span class="hljs-number">2</span>个值，bool值和查找到的索引值，如果没查找到返回[] 如果找到一个或找到多个，返回 [(x1,y1),(x2,y2)]<br>    :rtype:<br>    <span class="hljs-string">&quot;&quot;</span><span class="hljs-comment">&quot;</span><br>    ori_len = <span class="hljs-built_in">len</span>(original)<br>    sub_len = <span class="hljs-built_in">len</span>(sublist)<br>    find_indexes = []<br>    <span class="hljs-keyword">if</span> ori_len &lt; sub_len:<br>        <span class="hljs-keyword">return</span> find_indexes<br>    <span class="hljs-keyword">for</span> <span class="hljs-built_in">index</span> in <span class="hljs-built_in">range</span>(ori_len-sub_len+<span class="hljs-number">1</span>):<br>        <span class="hljs-keyword">if</span> original[<span class="hljs-built_in">index</span>:<span class="hljs-built_in">index</span> + sub_len] == sublist:<br>            find_indexes.<span class="hljs-keyword">append</span>((<span class="hljs-built_in">index</span>, <span class="hljs-built_in">index</span>+ sub_len))<br>    <span class="hljs-keyword">return</span> find_indexes<br><br>ori = [<span class="hljs-string">&#x27;《&#x27;</span>, <span class="hljs-string">&#x27;邪&#x27;</span>, <span class="hljs-string">&#x27;少&#x27;</span>, <span class="hljs-string">&#x27;兵&#x27;</span>, <span class="hljs-string">&#x27;王&#x27;</span>, <span class="hljs-string">&#x27;》&#x27;</span>, <span class="hljs-string">&#x27;是&#x27;</span>, <span class="hljs-string">&#x27;冰&#x27;</span>, <span class="hljs-string">&#x27;火&#x27;</span>, <span class="hljs-string">&#x27;未&#x27;</span>, <span class="hljs-string">&#x27;央&#x27;</span>, <span class="hljs-string">&#x27;写&#x27;</span>, <span class="hljs-string">&#x27;的&#x27;</span>, <span class="hljs-string">&#x27;网&#x27;</span>, <span class="hljs-string">&#x27;络&#x27;</span>, <span class="hljs-string">&#x27;小&#x27;</span>, <span class="hljs-string">&#x27;说&#x27;</span>, <span class="hljs-string">&#x27;连&#x27;</span>, <span class="hljs-string">&#x27;载&#x27;</span>, <span class="hljs-string">&#x27;于&#x27;</span>, <span class="hljs-string">&#x27;旗&#x27;</span>, <span class="hljs-string">&#x27;峰&#x27;</span>, <span class="hljs-string">&#x27;天&#x27;</span>, <span class="hljs-string">&#x27;下&#x27;</span>]<br>sub = [<span class="hljs-string">&#x27;网&#x27;</span>, <span class="hljs-string">&#x27;络&#x27;</span>, <span class="hljs-string">&#x27;小&#x27;</span>, <span class="hljs-string">&#x27;说&#x27;</span>]<br><span class="hljs-keyword">res</span> = index_partof_list(ori,sub)<br><span class="hljs-keyword">print</span>(<span class="hljs-keyword">res</span>)<br>------&gt;<br>[(<span class="hljs-number">13</span>, <span class="hljs-number">17</span>)]<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>python</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>对存在过合并的excel的单元格进行处理</title>
    <link href="/2022/02/22/pandas-na/"/>
    <url>/2022/02/22/pandas-na/</url>
    
    <content type="html"><![CDATA[<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p>日常我们经常遇到表头是合并的单元格，如左侧表头，或者上测表头都是合并过的，而我们想读取使用pandas读取的excel后，每列都进行对应回原来的数据的结构，那么这时就需要进行填充了，因为读取后，只有合并的单元格的第一行或第一列是有值的，其它都是nan，我们需要用前向填充的方法，ffill()<br>示例如图:</p><img src="/2022/02/22/pandas-na/shili1.png" class=""><h1 id="填充代码，可以给定超参数，填充表头，按行和按列填充"><a href="#填充代码，可以给定超参数，填充表头，按行和按列填充" class="headerlink" title="填充代码，可以给定超参数，填充表头，按行和按列填充"></a>填充代码，可以给定超参数，填充表头，按行和按列填充</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">fill_pdna</span>(<span class="hljs-params">df, row=[], col=[]</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    当excel的表头的行或列有合并单元格的情况时，只有第一个单元格是正确的，值，这时候需要使用前向填充ffill，即使用上一个单元格的内容填充当前为nan的单元格</span><br><span class="hljs-string">    但是填充的时候一般进行限制，只填充表头的前几行，或前几列</span><br><span class="hljs-string">    :param df:</span><br><span class="hljs-string">    :type df:</span><br><span class="hljs-string">    :param row: [] 表示所有行都使用前面的值进行填充，1表示第一行, eg: [1,2] 表示第1，2行用前面的值填充,-1表示不填充</span><br><span class="hljs-string">    :param col: []表示，所有列都使用前面的值填充， 0表示第一列, 注意行和列的其实索引位置不一样, -1表示不填充</span><br><span class="hljs-string">    :return:</span><br><span class="hljs-string">    :rtype:</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 首先对行进行填充，填充哪些行</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> row:<br>        <span class="hljs-comment"># 如果为空，先按行进行填充，行空的时候使用前一个单元格填充</span><br>        df = df.ffill(axis=<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> col:<br>        <span class="hljs-comment"># 然后对列进行填充</span><br>        df = df.ffill(axis=<span class="hljs-number">0</span>)<br>    <span class="hljs-keyword">if</span> col <span class="hljs-keyword">and</span> col != [-<span class="hljs-number">1</span>]:<br>        <span class="hljs-keyword">for</span> col_num <span class="hljs-keyword">in</span> col:<br>            df[col_num] = df[col_num].ffill(axis=<span class="hljs-number">0</span>)<br>    <span class="hljs-keyword">if</span> row <span class="hljs-keyword">and</span> row != [-<span class="hljs-number">1</span>]:<br>        <span class="hljs-keyword">for</span> row_num <span class="hljs-keyword">in</span> row:<br>            df[:row_num] = df[:row_num].ffill(axis=<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> df<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">read_excel</span>(<span class="hljs-params">excel_file</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    读取excel内容</span><br><span class="hljs-string">    :param excel_file:</span><br><span class="hljs-string">    :type excel_file:</span><br><span class="hljs-string">    :return:</span><br><span class="hljs-string">    :rtype:</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;开始读取<span class="hljs-subst">&#123;excel_file&#125;</span>&quot;</span>)<br>    df = pd.read_excel(excel_file, header=<span class="hljs-literal">None</span>)<br>    newdf = fill_pdna(df, row=[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>], col=[<span class="hljs-number">0</span>])<br>    <span class="hljs-built_in">print</span>(newdf)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>python</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>shap值的探索，判断shap值是否符合基本单调递增</title>
    <link href="/2022/02/18/shap-explore2/"/>
    <url>/2022/02/18/shap-explore2/</url>
    
    <content type="html"><![CDATA[<h1 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h1><ol><li>构建一个模型，本示例用的XGBoost，然后构建shap解释模型，使用shap值对模型特征进行解释</li><li>按特征重要性，这里对应的是shap值的绝对值的均值，shap_values.abs.mean，进行排序</li><li>如果特征符合基本单调递增, 不一定是线性的，因为特征之间可能有相关性,打印对应shap值为0附近的原始特征数值，用原始特征的均值代替</li></ol><h1 id="意义"><a href="#意义" class="headerlink" title="意义"></a>意义</h1><p>我们构建的是一个客户满意度模型，使用的是用户对一个商品的整体满意度与商品的各个属性满意度之间的关系，我们想找出当每个属性的满意度达到多少时，才能对整体满意度产生影响，即各个属性满意度的理想值。</p><p>示例代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> xgboost<br><span class="hljs-keyword">import</span> shap<br><span class="hljs-keyword">import</span> pickle<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> matplotlib <span class="hljs-keyword">as</span> mpl<br>mpl.rcParams[<span class="hljs-string">&#x27;font.family&#x27;</span>] = [<span class="hljs-string">&#x27;SimHei&#x27;</span>]<br>mpl.rcParams[<span class="hljs-string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="hljs-literal">False</span><br><br>saved_file = <span class="hljs-string">&#x27;/tmp/adult.pkl&#x27;</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">dump_info</span>(<span class="hljs-params">data</span>):<br>    pickle.dump(data, <span class="hljs-built_in">open</span>(saved_file, <span class="hljs-string">&quot;wb&quot;</span>))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;保存成功&quot;</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_info</span>():<br>    data = pickle.load(<span class="hljs-built_in">open</span>(saved_file, <span class="hljs-string">&quot;rb&quot;</span>))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;加载成功&quot;</span>)<br>    <span class="hljs-keyword">return</span> data<br><br><span class="hljs-keyword">if</span> os.path.exists(saved_file):<br>    X,y = load_info()<br><span class="hljs-keyword">else</span>:<br>    X,y = shap.datasets.adult()<br>    dump_info(data=(X,y))<br>model = xgboost.XGBClassifier().fit(X, y)<br><br><span class="hljs-comment"># compute SHAP values</span><br>explainer = shap.Explainer(model, X)<br>shap_values = explainer(X)<br><span class="hljs-comment"># shap_values [num_samples, num_features]</span><br><span class="hljs-comment"># shap.plots.beeswarm(shap_values)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">find_closely_sublist</span>(<span class="hljs-params">src_list, percent=<span class="hljs-number">0.05</span>, des_num=<span class="hljs-number">0.3</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    找出src_list 中与des_num最接近的数字，找到总数量的为百分之percent</span><br><span class="hljs-string">    :param src_list:</span><br><span class="hljs-string">    :type src_list: list</span><br><span class="hljs-string">    :param percent:</span><br><span class="hljs-string">    :type percent:</span><br><span class="hljs-string">    :param des_num:</span><br><span class="hljs-string">    :type des_num:</span><br><span class="hljs-string">    :return: 返回百分之percent的数据的个数的列表，列表是src_list的子列表</span><br><span class="hljs-string">    :rtype:</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 取值为0范围的%5的数</span><br>    total_num = <span class="hljs-built_in">len</span>(src_list)<br>    got_num = <span class="hljs-built_in">int</span>(total_num * percent)<br>    left_num = right_num = <span class="hljs-built_in">int</span>(got_num/<span class="hljs-number">2</span>)<br>    sorted_l = <span class="hljs-built_in">sorted</span>(src_list)<br>    <span class="hljs-comment">#定位与0最接近的位置的索引</span><br>    min_closest_idx = <span class="hljs-number">0</span><br>    min_closed_distance = <span class="hljs-number">100000</span><br>    <span class="hljs-keyword">for</span> idx, i <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(sorted_l):<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">abs</span>(i - des_num) &lt; min_closed_distance:<br>            min_closed_distance = <span class="hljs-built_in">abs</span>(i - des_num)<br>            min_closest_idx = idx<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;最接近于<span class="hljs-subst">&#123;des_num&#125;</span>的数字是<span class="hljs-subst">&#123;sorted_l[min_closest_idx]&#125;</span>&quot;</span>)<br>    start_idx = min_closest_idx - left_num<br>    <span class="hljs-keyword">if</span> start_idx &lt; <span class="hljs-number">0</span>:<br>        start_idx = <span class="hljs-number">0</span><br>    end_idx = min_closest_idx + right_num<br>    sublist = sorted_l[start_idx:end_idx]<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;收集接近于目标值<span class="hljs-subst">&#123;des_num&#125;</span>, 总数据条数:<span class="hljs-subst">&#123;total_num&#125;</span>, 收集占比为<span class="hljs-subst">&#123;percent&#125;</span>,共收集到数据条数: <span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(sublist)&#125;</span>条，分别是: <span class="hljs-subst">&#123;sublist&#125;</span>&quot;</span>)<br>    <span class="hljs-keyword">return</span> sublist<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_middle_data</span>(<span class="hljs-params">mean_shape</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    根据给定的shap，获取shap值为0时，原始data的值，因为有的值不是单递增的，还要判断是否是单调递增的， 统计的方法判断</span><br><span class="hljs-string">    根据均值和中位数，判断是否是单调递增的，大部分不是线性递增的</span><br><span class="hljs-string">    :param mean_shape:</span><br><span class="hljs-string">    :type mean_shape:</span><br><span class="hljs-string">    :return:</span><br><span class="hljs-string">    :rtype:</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    feature_name = mean_shape.feature_names<br>    shape_value = mean_shape.values<br>    feature_data = mean_shape.data<br>    <span class="hljs-comment"># 按大小排序</span><br>    sort_shap = np.sort(shape_value)<br>    sort_shap = sort_shap.tolist()<br>    <span class="hljs-comment"># 最接近0的shap值，大概5%</span><br>    sublist = find_closely_sublist(src_list=sort_shap,percent=<span class="hljs-number">0.05</span>, des_num=<span class="hljs-number">0</span>)<br>    <span class="hljs-comment"># 取0轴为的5%的数</span><br>    start_threhold, end_threhold = <span class="hljs-built_in">min</span>(sublist), <span class="hljs-built_in">max</span>(sublist)<br>    zero_range_shap_idx = np.where((shape_value &gt;= start_threhold) &amp; (shape_value &lt;= end_threhold))<br>    <span class="hljs-comment">#判断是否单调的问题，大部分shap值小于zero附近shap的，它对应的原始特征数也小于，shap值大于zero附近的，它的原始特征对应的数据也大于zero的原始特征，咱们都用平均值和中位数2个结合判断</span><br>    zero_range_data = feature_data[zero_range_shap_idx]<br>    zero_data_mean = np.mean(zero_range_data)<br>    zero_data_median = np.median(zero_range_data)<br>    less_zero_shap_idx = np.where(shape_value &lt; start_threhold)<br>    biger_zero_shap_idx = np.where(shape_value &gt; end_threhold)<br>    less_zero_data = feature_data[less_zero_shap_idx]<br>    biger_zero_data = feature_data[biger_zero_shap_idx]<br>    less_zero_mean = np.mean(less_zero_data)<br>    less_zero_median = np.median(less_zero_data)<br>    biger_zero_mean = np.mean(biger_zero_data)<br>    biger_zero_median = np.median(biger_zero_data)<br>    <span class="hljs-keyword">if</span> less_zero_mean &lt; zero_data_mean &lt; biger_zero_mean <span class="hljs-keyword">and</span> less_zero_median &lt; zero_data_median &lt; biger_zero_median:<br>        <span class="hljs-comment">#基本上是单调递增的，那么返回0的附近的对应的原始数据的均值, 即zero_data_mean</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span>, zero_data_mean, feature_name<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span>, <span class="hljs-number">0</span>, feature_name<br><br><span class="hljs-comment"># 打印前10个特征，按照shap值的重要性排序</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">10</span>, <span class="hljs-number">1</span>):<br>    mean_shape = shap_values[:, shap_values.<span class="hljs-built_in">abs</span>.mean(<span class="hljs-number">0</span>).argsort[-i]]<br>    is_monotone, middle_data, feature_name = get_middle_data(mean_shape)<br>    fig = plt.gcf()<br>    fig.set_size_inches(<span class="hljs-number">18.5</span>, <span class="hljs-number">10.5</span>, forward=<span class="hljs-literal">True</span>)<br>    ax = fig.gca()<br>    <span class="hljs-keyword">if</span> is_monotone:<br>        title = <span class="hljs-string">f&quot;特征<span class="hljs-subst">&#123;i&#125;</span>_<span class="hljs-subst">&#123;feature_name&#125;</span>是基本上是单调递增的，对应的shap值0附近的原始特征数据均值值是:<span class="hljs-subst">&#123;middle_data&#125;</span>&quot;</span><br>    <span class="hljs-keyword">else</span>:<br>        title = <span class="hljs-string">f&quot;特征<span class="hljs-subst">&#123;i&#125;</span>_<span class="hljs-subst">&#123;feature_name&#125;</span>不是单调递增的&quot;</span><br>    ax.set_title(title)<br>    shap.plots.scatter(shap_values = mean_shape, ax=ax)<br></code></pre></td></tr></table></figure><h1 id="绘图结果，按照特征重要性进行的排序"><a href="#绘图结果，按照特征重要性进行的排序" class="headerlink" title="绘图结果，按照特征重要性进行的排序"></a>绘图结果，按照特征重要性进行的排序</h1><img src="/2022/02/18/shap-explore2/shap1.png" class=""><img src="/2022/02/18/shap-explore2/shap2.png" class=""><img src="/2022/02/18/shap-explore2/shap3.png" class=""><img src="/2022/02/18/shap-explore2/shap4.png" class=""><img src="/2022/02/18/shap-explore2/shap5.png" class=""><img src="/2022/02/18/shap-explore2/shap6.png" class=""><img src="/2022/02/18/shap-explore2/shap7.png" class=""><img src="/2022/02/18/shap-explore2/shap8.png" class=""><img src="/2022/02/18/shap-explore2/shap9.png" class="">]]></content>
    
    
    <categories>
      
      <category>模型</category>
      
    </categories>
    
    
    <tags>
      
      <tag>可解释性</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
