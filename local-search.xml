<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>领域内问答分享</title>
    <link href="/2023/05/24/%E9%A2%86%E5%9F%9F%E5%86%85%E9%97%AE%E7%AD%94%E5%88%86%E4%BA%AB/"/>
    <url>/2023/05/24/%E9%A2%86%E5%9F%9F%E5%86%85%E9%97%AE%E7%AD%94%E5%88%86%E4%BA%AB/</url>
    
    <content type="html"><![CDATA[<h1 id="AIGC"><a href="#AIGC" class="headerlink" title="AIGC"></a>AIGC</h1><p>AIGC在各种方面的应用</p><img src="/2023/05/24/%E9%A2%86%E5%9F%9F%E5%86%85%E9%97%AE%E7%AD%94%E5%88%86%E4%BA%AB/image-20230524151839391.png" class=""><h1 id="领域内问答的是如何实现的"><a href="#领域内问答的是如何实现的" class="headerlink" title="领域内问答的是如何实现的"></a>领域内问答的是如何实现的</h1><h2 id="数据集来源"><a href="#数据集来源" class="headerlink" title="数据集来源"></a>数据集来源</h2><p>A. 内部平台使用教程<br>B. 行业报告，白皮书等<br>C. 美妆专业知识<br>D.所有用户（客户，内部人员）常见问题收集</p><h2 id="不同数据集不同对待，完全训练，微调和提示工程"><a href="#不同数据集不同对待，完全训练，微调和提示工程" class="headerlink" title="不同数据集不同对待，完全训练，微调和提示工程"></a>不同数据集不同对待，完全训练，微调和提示工程</h2><p>对于从0开始学习的大模型来说，最好的方式是完全训练。</p><p>完全训练：针对大公司有超多数据集和计算资源，可以采用完全训练的方式。</p><p>对于基础的专业知识来说，最好的方式是微调训练。</p><p>微调训练：基于大模型的二次训练。主要使用的方法是使用开源大模型，例如<br>Base模型:Facebook的LLama模型，bigScience的Bloom, 清华的GLM等，借助工具库和显存优化算法accelerate,torchrun,DeepSpeed，采用适配器的方式进行微调，典型的包括Huggingface的PEFT库集成,Parameter-Efficient Fine-Tuning 参数高效微调的方法。</p><p>对于部分专业文档问答，教程来说，最好的方式是提示工程，现学现用的方式。</p><h1 id="LLM中的推理生成流程"><a href="#LLM中的推理生成流程" class="headerlink" title="LLM中的推理生成流程"></a>LLM中的推理生成流程</h1><h2 id="输入"><a href="#输入" class="headerlink" title="输入"></a>输入</h2><p>历史聊天和最新问题会转成如下格式进行tokenizer</p><p>例如历史聊天记录为Round 0部分，Round 1 为最新的问题，拼接历史和最新的聊天作为输入:</p><figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs excel">&#x27;[<span class="hljs-built_in">Round</span> <span class="hljs-number">0</span>]<br>问：现在开始,你的任务是提取关键词，提取下列语句中的关键词，并用空格分隔：科普之路是不是任重而道远？<br>答：科普 道路 任重 道远<br>[<span class="hljs-built_in">Round</span> <span class="hljs-number">1</span>]<br>问：提取下列语句中的关键词：简述下噪音污染<br>答：&#x27;<br></code></pre></td></tr></table></figure><h2 id="Tokenizer"><a href="#Tokenizer" class="headerlink" title="Tokenizer"></a>Tokenizer</h2><p> 文字经过tokenizer，进行拆词变成input id</p><h2 id="输入模型generate函数"><a href="#输入模型generate函数" class="headerlink" title="输入模型generate函数"></a>输入模型generate函数</h2><p>重要参数：</p><p>inputs：输入的input id，其实还可以语音到文本，图片到本文，都可以。</p><p>logits_processor：对预测出来的下一个logits的处理，例如使用temperature,topk,topp，或用户对logits进行自定义处理等</p><p>stopping_criteria: 停止生成的条件，例如遇到了EOS的token或用户指定token，或达到最大长度等等。</p><p>is_encoder_decoder：是编码器还是编码器-解码器架构</p><p>While True:<br>​                准备input_id<br>​                模型前向传播<br>​                获取模型返回的logits<br>​                对logits进行处理，例如temperature，topk等<br>​                softmax和Sample token,得到next token id<br>​                更新input_id<br>​                判断停止生成条件，如果没有继续生成，否则break</p><h1 id="LLM中使用的超参数"><a href="#LLM中使用的超参数" class="headerlink" title="LLM中使用的超参数"></a>LLM中使用的超参数</h1><p>对应着New bing中的对话风格。</p><p>创作，平衡和准确，意味着temperature的不同。</p><img src="/2023/05/24/%E9%A2%86%E5%9F%9F%E5%86%85%E9%97%AE%E7%AD%94%E5%88%86%E4%BA%AB/image-20230524154901055.png" class=""><h1 id="Langchain"><a href="#Langchain" class="headerlink" title="Langchain"></a>Langchain</h1><p>集成了最新的使用LLM进行解决复杂问题的方法。Langchain是链式调用工具，整合数据处理，数据调用，提示工程，LLM调用，输出格式化，复杂链式调用等技术，是自然语言和程序之间进行交互的胶水,由语言模型驱动的应用程序的框架,数据感知：将语言模型连接到其他数据源,Agentic：允许语言模型与其环境交互。</p><h1 id="ChatGPT的plugins和LangChain的Tools"><a href="#ChatGPT的plugins和LangChain的Tools" class="headerlink" title="ChatGPT的plugins和LangChain的Tools"></a>ChatGPT的plugins和LangChain的Tools</h1><h2 id="ChatGPT-Plugins"><a href="#ChatGPT-Plugins" class="headerlink" title="ChatGPT Plugins"></a>ChatGPT Plugins</h2><ul><li><p>让Chatgpt使用工具，插件可以成为语言模型的“眼睛和耳朵”，使它们可以访问太新、太个人化或太具体而无法包含在训练数据中的信息</p></li><li><p>检索实时信息；例如，体育比分、股票价格、最新消息等</p></li><li><p>检索知识库信息；例如，公司文档、个人笔记等</p></li><li><p>协助用户采取行动；例如，订机票、订餐等</p></li></ul><img src="/2023/05/24/%E9%A2%86%E5%9F%9F%E5%86%85%E9%97%AE%E7%AD%94%E5%88%86%E4%BA%AB/image-20230524164355115.png" class=""><h2 id="LangChain-tools"><a href="#LangChain-tools" class="headerlink" title="LangChain tools"></a>LangChain tools</h2><p>Agent可以采取的行动，可以定制化开发。有工具tool和工具包toolkits2种概念，工具包就是多个工具的一起协作。工具的类型和Chatgpt的Plugin是一样的。但是工具更多。</p><h1 id="Q-amp-A环节"><a href="#Q-amp-A环节" class="headerlink" title="Q&amp;A环节"></a>Q&amp;A环节</h1>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>LangChain解决问题的思路</title>
    <link href="/2023/05/24/LangChain%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98%E7%9A%84%E6%80%9D%E8%B7%AF/"/>
    <url>/2023/05/24/LangChain%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98%E7%9A%84%E6%80%9D%E8%B7%AF/</url>
    
    <content type="html"><![CDATA[<h1 id="LangChain解决问题的思路"><a href="#LangChain解决问题的思路" class="headerlink" title="LangChain解决问题的思路"></a>LangChain解决问题的思路</h1><p>可以把解决问题当做一个过程，我们可以从不同的角度去观察解决问题的方式，主要分成按数据源，按问题复杂度，按问题的解决方式划分，只是概念上的不同，其实最终解决问题的方式是灵活的，统一的。</p><h2 id="按数据源"><a href="#按数据源" class="headerlink" title="按数据源:"></a>按数据源:</h2><h3 id="非结构化数据–方式1（向量化"><a href="#非结构化数据–方式1（向量化" class="headerlink" title="非结构化数据–方式1（向量化)"></a>非结构化数据–方式1（向量化)</h3><p>Step1：源文档向量化</p><img src="/2023/05/24/LangChain%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98%E7%9A%84%E6%80%9D%E8%B7%AF/image-20230524134103262.png" class=""><p>Step2:  问答时检索相似向量作为context</p><img src="/2023/05/24/LangChain%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98%E7%9A%84%E6%80%9D%E8%B7%AF/image-20230524134147791.png" class=""><p>其它方式: KNN聚类，Time Weighted VectorStore，TFIDF</p><p>非结构化数据：各种文档，电子书，word，pdf, 代码等</p><h3 id="结构化数据–方式1（数据库SQL-知识图谱CQL"><a href="#结构化数据–方式1（数据库SQL-知识图谱CQL" class="headerlink" title="结构化数据–方式1（数据库SQL,知识图谱CQL)"></a>结构化数据–方式1（数据库SQL,知识图谱CQL)</h3><p>自然语言问题–&gt;SQL–&gt;(SQL语法检查)–&gt;查询结果–&gt;自然语言答案</p><h2 id="按问题复杂度"><a href="#按问题复杂度" class="headerlink" title="按问题复杂度"></a>按问题复杂度</h2><h3 id="普通问题"><a href="#普通问题" class="headerlink" title="普通问题"></a>普通问题</h3><p>参考上述按数据源的方式</p><h3 id="复杂问题"><a href="#复杂问题" class="headerlink" title="复杂问题"></a>复杂问题</h3><p>Chains的方式，问题解决步骤较多时，拆分多个子步骤</p><img src="/2023/05/24/LangChain%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98%E7%9A%84%E6%80%9D%E8%B7%AF/image-20230524135929420.png" class=""><p>Chains的种类：SequentialChain，RouterChain，FLARE等</p><p>FLARE: 开始回答问题，如果您开始生成模型不确定的token，请查找相关文档，使用那些文档继续生成，重复直到完成，需要生成答案的 LLM 需要返回 logprobs，这样我们才能识别不确定的token。</p><h2 id="按问题的解决方式-不同的Agent"><a href="#按问题的解决方式-不同的Agent" class="headerlink" title="按问题的解决方式, 不同的Agent"></a>按问题的解决方式, 不同的Agent</h2><p>Agent: 根据用户输入,去调用其它的工具，把Chain，Prompt，model之类的都放在Agent里，Agent负责调用这些，用户只需和Agent对话。可以认为现实世界中的一个人。<br>Action Agents：最终的任务执行的人，例如工程师，操作者。<br>Plan-and-Execute Agents：只做计划的人，例如架构师，领导者。</p><h3 id="Action-Agents"><a href="#Action-Agents" class="headerlink" title="Action Agents"></a>Action Agents</h3><p>执行流程和状态：</p><p>Agent决定使用哪个工具（如果有的话），以及该工具的输入应该是什么；然后使用该工具输入调用该工具，并记录观察结果（这只是使用该工具输入调用该工具的输出）；工具、工具输入和观察的历史被传回Agent，并决定下一步采取什么步骤；重复此操作，直到代理决定不再需要使用工具，然后直接响应用户。</p><img src="/2023/05/24/LangChain%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98%E7%9A%84%E6%80%9D%E8%B7%AF/image-20230524141049847.png" class=""><p>Plan-and-Execute Agents</p><p>收到一些用户输入；计划者列出了要采取的步骤；执行者遍历步骤列表，执行它们</p><img src="/2023/05/24/LangChain%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98%E7%9A%84%E6%80%9D%E8%B7%AF/image-20230524141343054.png" class=""><img src="/2023/05/24/LangChain%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98%E7%9A%84%E6%80%9D%E8%B7%AF/image-20230524141428781.png" class=""><h2 id="有意思的思路1"><a href="#有意思的思路1" class="headerlink" title="有意思的思路1"></a>有意思的思路1</h2><p>Agent Simulations: 构建一个虚拟环境，多个Agent之间进行交互，类强化学习中的多Agent，互相学习。</p><h2 id="有意思的思路2："><a href="#有意思的思路2：" class="headerlink" title="有意思的思路2："></a>有意思的思路2：</h2><p>以协作方式运行 BLOOM-176B 等大型语言模型——您加载模型的一小部分，然后与服务其他部分的人员合作进行推理或微调。</p><h2 id="Autonomous-Agents，自治思想"><a href="#Autonomous-Agents，自治思想" class="headerlink" title="Autonomous Agents，自治思想"></a>Autonomous Agents，自治思想</h2><p>Agent的自治思想是指Agent作为一个独立的个体，能够自主地执行任务并做出决策，而不需要外部干预或控制。这种思想源于人工智能领域中的Agent理论，强调Agent应该具备自主性、灵活性、适应性和自适应性等特点，能够在不断变化的环境中自主地学习、适应和优化自己的行为，以实现预设的目标。<br>在实际应用中，Agent的自治思想通常通过为其设计合适的目标和约束来实现。例如，为Agent设定明确的目标，使其能够自主地根据环境变化调整自己的行为，同时在行为上设定一些约束，以确保其在执行任务时不会对环境和其他Agent造成不良影响。同时，Agent的自治思想也需要考虑到其与其他Agent之间的协作和竞争关系，以实现整个系统的高效运行。<br>Agent的自治思想是为了让Agent能够更加独立、自主地执行任务，更好地适应不断变化的环境，并实现预设的目标。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>聊天机器人问题梳理</title>
    <link href="/2023/05/23/%E8%81%8A%E5%A4%A9%E6%9C%BA%E5%99%A8%E4%BA%BA%E9%97%AE%E9%A2%98%E6%A2%B3%E7%90%86/"/>
    <url>/2023/05/23/%E8%81%8A%E5%A4%A9%E6%9C%BA%E5%99%A8%E4%BA%BA%E9%97%AE%E9%A2%98%E6%A2%B3%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h1 id="使用的技术"><a href="#使用的技术" class="headerlink" title="使用的技术"></a>使用的技术</h1><p>LangChain: 链式调用工具，整合数据处理，数据调用，提示工程，LLM调用，输出格式化，复杂链式调用等技术<br>LLM：Large Language Model，大型生成式语言模型,根据问题生成答案。</p><h1 id="模型开发计划"><a href="#模型开发计划" class="headerlink" title="模型开发计划"></a>模型开发计划</h1><p>A. 基于已有知识的问答<br>B. 类似NewBing结合搜索引擎问答<br>C. 链接备用数据库查询后问答<br>D. 根据专业知识微调模型，模型更懂专业知识<br>E. 接入各个平台,例如爬虫平台的额外功能<br>F. 接入数据处理，绘图等，通过问答的形式操控数据绘图展现<br>G. 多模态能力，可以根据用户提供的图片或视频链接进行回答</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>安防机器人设计</title>
    <link href="/2023/05/23/%E5%AE%89%E9%98%B2%E6%9C%BA%E5%99%A8%E4%BA%BA%E8%AE%BE%E8%AE%A1/"/>
    <url>/2023/05/23/%E5%AE%89%E9%98%B2%E6%9C%BA%E5%99%A8%E4%BA%BA%E8%AE%BE%E8%AE%A1/</url>
    
    <content type="html"><![CDATA[<h1 id="安防项目方案计划书"><a href="#安防项目方案计划书" class="headerlink" title="安防项目方案计划书"></a>安防项目方案计划书</h1><h2 id="一、需求分析"><a href="#一、需求分析" class="headerlink" title="一、需求分析"></a>一、需求分析</h2><h3 id="监控的区域、监控目标和实现的功能说明。"><a href="#监控的区域、监控目标和实现的功能说明。" class="headerlink" title="监控的区域、监控目标和实现的功能说明。"></a>监控的区域、监控目标和实现的功能说明。</h3><h4 id="1-1-监控区域"><a href="#1-1-监控区域" class="headerlink" title="1.1 监控区域"></a>1.1 监控区域</h4><p>该安防项目需要监控的区域是一个大楼内部和周围外部的场景，包括大楼的走廊、房间、楼梯、电梯、停车场等区域，以及大楼周围的室外场景，包括道路、人行道、花园、停车场等区域。</p><h4 id="1-2-监控目标"><a href="#1-2-监控目标" class="headerlink" title="1.2 监控目标"></a>1.2 监控目标</h4><p>该安防项目需要监控的目标有三个：防火、防水和防盗。</p><p>a. 防火：机器人需要通过摄像头监控大楼内外的场景，及时发现任何可能的火灾状况，例如火苗、浓烟等。</p><p>b. 防水：机器人需要通过摄像头监控大楼内外的场景，及时发现任何可能的漏水状况，例如漏水的声音、水迹等。</p><p>c. 防盗：机器人需要通过摄像头监控大楼内外的场景，及时发现任何可疑的人员，例如携带工具、在夜间进出大楼等。</p><h4 id="1-3-实现的功能"><a href="#1-3-实现的功能" class="headerlink" title="1.3 实现的功能"></a>1.3 实现的功能</h4><p>a. 自主巡视：机器人需要能够自主巡视大楼内外的场景，覆盖整个监控区域。</p><p>b. 实时监控：机器人需要能够通过摄像头实时监控监控区域内的情况，及时发现任何可能的火灾、漏水或小偷。</p><p>c. 报警功能：机器人需要能够及时发出警报，提醒安保人员或相关部门处理发现的问题。</p><p>d. 数据存储：机器人需要能够将监控到的数据进行存储，以便后续分析和处理。</p><p>e. 远程控制：机器人需要能够远程控制，以便进行系统维护和升级等操作。</p><p>以上是一个安防项目的可能需求分析，具体实施过程中还需要根据实际情况进行细化和调整。</p><h2 id="二、设备选型"><a href="#二、设备选型" class="headerlink" title="二、设备选型"></a>二、设备选型</h2><h3 id="设备选型相关说明，选定合适的机器人、传感器、摄像头等设备，确保设备能够满足监控要求。"><a href="#设备选型相关说明，选定合适的机器人、传感器、摄像头等设备，确保设备能够满足监控要求。" class="headerlink" title="设备选型相关说明，选定合适的机器人、传感器、摄像头等设备，确保设备能够满足监控要求。"></a>设备选型相关说明，选定合适的机器人、传感器、摄像头等设备，确保设备能够满足监控要求。</h3><h4 id="2-1-机器人部分"><a href="#2-1-机器人部分" class="headerlink" title="2.1 机器人部分"></a>2.1 机器人部分</h4><p>a. 移动机器人平台：建议选择TurtleBot、Pepper、Nao等常见的机器人平台，支持ROS操作系统和多种传感器和模块的添加。</p><p>b. 操作系统：ROS操作系统，方便进行远程控制和编程。</p><p>c. 摄像头模块：建议选择ArduCam、Raspberry Pi Camera等高质量的摄像头模块，具有高分辨率和广角视野，支持夜视和红外线模式。</p><p>d. 声音模块：建议选择高灵敏度的麦克风模块，例如MEMS麦克风，可以捕捉到更广泛的声音范围。</p><p>e. 红外线模块：建议选择高灵敏度的红外线传感器，例如MLX90640，可以捕捉到更广泛的红外线范围。</p><h4 id="2-2-服务器部分"><a href="#2-2-服务器部分" class="headerlink" title="2.2 服务器部分"></a>2.2 服务器部分</h4><p>a. 服务器：建议选择一台高性能的服务器，配备至少一张GPU，以便提高目标模型分析的速度。</p><p>b. GPU：建议选择NVIDIA GPU，例如NVIDIA GeForce RTX 3080，可以快速进行深度学习模型的训练和推理。</p><p>c. 存储容量：服务器需要足够的存储容量，以便存储和处理大量的监控数据和目标模型。</p><p>d. 内存：服务器需要足够的内存，以支持高速数据处理和目标模型分析。</p><p>以上是一个更新后的机器人和服务器的配置要求，根据实际情况还需要进行进一步的细化和调整。</p><h2 id="三、系统设计"><a href="#三、系统设计" class="headerlink" title="三、系统设计"></a>三、系统设计</h2><h3 id="设计机器人的运动路径和监控区域，监控时间，设计数据传输。"><a href="#设计机器人的运动路径和监控区域，监控时间，设计数据传输。" class="headerlink" title="设计机器人的运动路径和监控区域，监控时间，设计数据传输。"></a>设计机器人的运动路径和监控区域，监控时间，设计数据传输。</h3><h4 id="3-1-机器人的运动路径和监控区域"><a href="#3-1-机器人的运动路径和监控区域" class="headerlink" title="3.1 机器人的运动路径和监控区域"></a>3.1 机器人的运动路径和监控区域</h4><p>机器人的运动路径应该覆盖整个监控区域，包括大楼内部和周围外部的场景。可以采用一些常见的路径规划算法，例如A*算法、Dijkstra算法等，以确保机器人能够在最短时间内覆盖整个监控区域。为了提高监控效果，可以根据监控目标的不同，调整机器人的运动路径和监控区域。</p><h4 id="3-2-监控时间"><a href="#3-2-监控时间" class="headerlink" title="3.2 监控时间"></a>3.2 监控时间</h4><p>为了保证全天候的监控效果，机器人应该在24小时内进行巡逻和监控。可以将一天分为若干个时间段，根据不同时间段的监控需求，调整机器人的运动路径和监控区域。例如，在夜间应该增加夜视模式和红外线模式的使用，以提高监控效果。</p><h4 id="3-3-数据传输和存储"><a href="#3-3-数据传输和存储" class="headerlink" title="3.3 数据传输和存储"></a>3.3 数据传输和存储</h4><p>机器人通过摄像头、声音模块和红外线模块等设备采集监控数据，并将数据上传到服务器进行分析和处理。为了提高数据传输和存储的效率，可以采用一些常见的网络传输协议，例如TCP&#x2F;IP、UDP等。数据存储可以选择一些高效的数据库系统，例如MySQL、MongoDB等，以便存储和处理大量的监控数据和目标模型。</p><h2 id="四、软件开发"><a href="#四、软件开发" class="headerlink" title="四、软件开发"></a>四、软件开发</h2><h3 id="机器人的控制软件，包括机器人的运动控制、传感器数据的处理、摄像头图像的处理，模型处理部分。"><a href="#机器人的控制软件，包括机器人的运动控制、传感器数据的处理、摄像头图像的处理，模型处理部分。" class="headerlink" title="机器人的控制软件，包括机器人的运动控制、传感器数据的处理、摄像头图像的处理，模型处理部分。"></a>机器人的控制软件，包括机器人的运动控制、传感器数据的处理、摄像头图像的处理，模型处理部分。</h3><h4 id="4-1-机器人的运动控制"><a href="#4-1-机器人的运动控制" class="headerlink" title="4.1 机器人的运动控制"></a>4.1 机器人的运动控制</h4><p>使用ROS操作系统，通过编写ROS节点，实现机器人的运动控制。可以使用一些常见的ROS软件包，例如MoveIt、ROS Navigation、ROS Control等。通过编写控制程序，以实现机器人的自主导航和巡逻。同时，需要根据实际情况，通过传感器和摄像头等设备获取环境信息，并根据环境信息进行智能决策和控制。</p><h4 id="4-2-传感器数据的处理"><a href="#4-2-传感器数据的处理" class="headerlink" title="4.2 传感器数据的处理"></a>4.2 传感器数据的处理</h4><p>使用ROS操作系统，通过编写ROS节点，实现传感器数据的采集和处理。可以使用一些常见的ROS软件包，例如ROS Sensors、ROS Image等。通过编写数据处理程序，以实现传感器数据的实时处理和分析。同时，需要根据实际情况，根据传感器数据进行智能决策和控制。</p><h4 id="4-3-摄像头图像的处理和数据传输"><a href="#4-3-摄像头图像的处理和数据传输" class="headerlink" title="4.3 摄像头图像的处理和数据传输"></a>4.3 摄像头图像的处理和数据传输</h4><p>使用ROS操作系统，通过编写ROS节点，实现摄像头图像的采集、处理和传输。可以使用一些常见的ROS软件包，例如ROS Image、OpenCV等。通过编写图像处理程序，以实现摄像头图像的实时处理和分析。同时，需要将处理后的图像数据通过网络传输协议，例如TCP&#x2F;IP、UDP等，上传到服务器进行进一步的分析和处理。</p><h4 id="4-4-服务器上的图像数据接收和目标检测模型"><a href="#4-4-服务器上的图像数据接收和目标检测模型" class="headerlink" title="4.4 服务器上的图像数据接收和目标检测模型"></a>4.4 服务器上的图像数据接收和目标检测模型</h4><p>在服务器上，使用Python等编程语言，编写图像数据接收程序，以接收机器人上传的图像数据。同时，使用YOLOv8等深度学习模型，对图像数据进行目标检测。可以使用一些常见的深度学习框架，例如TensorFlow、PyTorch等。通过模型预测，识别出着火、漏水和是否有人出现等目标。</p><h4 id="4-5-目标检测后的操作"><a href="#4-5-目标检测后的操作" class="headerlink" title="4.5 目标检测后的操作"></a>4.5 目标检测后的操作</h4><p>根据目标检测的结果，进行相应的操作，例如报警和自动打电话告警等。可以使用一些常见的软件包和API，例如Twilio、AWS SNS等。通过编写操作程序，以实现智能响应和控制。例如，当检测到着火时，可以自动触发消防系统，并向相关人员发送警报信息；当检测到漏水时，可以自动触发水泵系统，并向相关人员发送警报信息；当检测到有人出现时，可以自动触发摄像头和声音模块，并向相关人员发送警报信息。</p><h2 id="五、系统集成部署测试运维"><a href="#五、系统集成部署测试运维" class="headerlink" title="五、系统集成部署测试运维"></a>五、系统集成部署测试运维</h2><h3 id="本部分包括机器人系统的部署，服务器的部署，系统测试和系统运维。"><a href="#本部分包括机器人系统的部署，服务器的部署，系统测试和系统运维。" class="headerlink" title="本部分包括机器人系统的部署，服务器的部署，系统测试和系统运维。"></a>本部分包括机器人系统的部署，服务器的部署，系统测试和系统运维。</h3><h4 id="5-1-机器人系统集成部署"><a href="#5-1-机器人系统集成部署" class="headerlink" title="5.1 机器人系统集成部署"></a>5.1 机器人系统集成部署</h4><p>首先，将机器人系统的控制软件，包括运动控制、传感器数据处理、摄像头图像处理等程序，编译生成可执行文件。将可执行文件上传到机器人上，并进行安装和配置。根据机器人硬件的实际情况，进行传感器和摄像头等设备的连接和配置。然后，启动机器人控制软件，并进行测试和调试，确保机器人的运动控制、传感器数据采集和图像传输等功能正常运行。</p><h4 id="5-2-服务器系统集成部署"><a href="#5-2-服务器系统集成部署" class="headerlink" title="5.2 服务器系统集成部署"></a>5.2 服务器系统集成部署</h4><p>首先，建立服务器系统的软件环境，包括操作系统、Python环境、深度学习框架和模型等。然后，将服务器系统的图像数据接收程序和目标检测模型部署到服务器上，并进行配置。启动图像数据接收程序，并进行测试和调试，确保服务器能够接收到机器人上传的图像数据，并能够正常运行目标检测模型。</p><h4 id="5-3-系统整体测试"><a href="#5-3-系统整体测试" class="headerlink" title="5.3 系统整体测试"></a>5.3 系统整体测试</h4><p>将机器人和服务器连接起来，测试整个系统的功能是否正常。通过启动机器人控制软件和服务器图像数据接收程序，进行图像数据的传输和目标检测。根据目标检测的结果，进行相应的操作，例如报警和自动打电话告警等。对整个系统进行充分的测试和调试，以保证系统的稳定性和可靠性。</p><h4 id="5-4-系统部署和运维"><a href="#5-4-系统部署和运维" class="headerlink" title="5.4 系统部署和运维"></a>5.4 系统部署和运维</h4><p>完成系统的集成部署后，还需要进行系统的运维和维护。根据实际情况，定期检查机器人和服务器的硬件设备，以确保设备的正常运行。同时，定期更新和优化系统的软件程序和模型，以提高系统的性能和效率。需要注意的是，系统部署和运维需要进行充分的安全性和隐私保护，以保护用户的数据和隐私。</p><h2 id="六、费用预估"><a href="#六、费用预估" class="headerlink" title="六、费用预估"></a>六、费用预估</h2><h3 id="安防机器人的费用评估，需要考虑硬件成本、软件开发成本和后期运维成本。"><a href="#安防机器人的费用评估，需要考虑硬件成本、软件开发成本和后期运维成本。" class="headerlink" title="安防机器人的费用评估，需要考虑硬件成本、软件开发成本和后期运维成本。"></a>安防机器人的费用评估，需要考虑硬件成本、软件开发成本和后期运维成本。</h3><h4 id="6-1-硬件成本"><a href="#6-1-硬件成本" class="headerlink" title="6.1 硬件成本"></a>6.1 硬件成本</h4><p>硬件成本包括机器人平台、传感器和摄像头等设备的购买成本。根据选型方案，可以选择TurtleBot、Pepper、Nao等机器人平台进行构建，预计平台成本在5000元到10000元之间。传感器和摄像头等设备的购买成本大约在500元到1000元之间。</p><h4 id="6-2-软件开发成本"><a href="#6-2-软件开发成本" class="headerlink" title="6.2 软件开发成本"></a>6.2 软件开发成本</h4><p>软件开发成本包括软件开发人员的工资和开发工具的费用。根据项目的规模和复杂度，软件开发人员的工资大约在5000元到20000元之间。同时，需要购买一些常见的软件工具和资源，例如ROS软件包、深度学习框架和模型等，预计成本在1000元到5000元之间。</p><h4 id="6-3-后期运维成本"><a href="#6-3-后期运维成本" class="headerlink" title="6.3 后期运维成本"></a>6.3 后期运维成本</h4><p>后期运维成本包括系统运维和维护的费用。根据实际情况，需要定期检查机器人和服务器的硬件设备，以确保设备的正常运行。同时，需要定期更新和优化系统的软件程序和模型，以提高系统的性能和效率。预计后期运维成本在5000元到10000元之间。</p><h2 id="七、其它"><a href="#七、其它" class="headerlink" title="七、其它"></a>七、其它</h2><h3 id="对于安防机器人的优化，例如硬件优化、算法优化和系统集成优化等。"><a href="#对于安防机器人的优化，例如硬件优化、算法优化和系统集成优化等。" class="headerlink" title="对于安防机器人的优化，例如硬件优化、算法优化和系统集成优化等。"></a>对于安防机器人的优化，例如硬件优化、算法优化和系统集成优化等。</h3><h4 id="7-1-硬件优化"><a href="#7-1-硬件优化" class="headerlink" title="7.1 硬件优化"></a>7.1 硬件优化</h4><p>可以对机器人的硬件进行优化，以提高机器人的性能和效率。例如，可以增加机器人的计算能力，例如添加GPU等硬件设备，以加速图像处理和目标检测等计算密集型任务。同时，可以增加机器人的存储能力，以存储更多的图像和数据。还可以增加机器人的传感器和摄像头等设备，以提高机器人的感知能力和适应性。</p><h4 id="7-2-算法优化"><a href="#7-2-算法优化" class="headerlink" title="7.2 算法优化"></a>7.2 算法优化</h4><p>可以对目标检测算法进行优化，以提高算法的速度和准确性。例如，可以使用更加先进的目标检测算法，例如Faster R-CNN、RetinaNet和EfficientDet等，以提高目标检测的准确性。同时，可以进行算法的优化和加速，例如使用深度学习加速算法、模型量化和模型压缩等技术，以提高算法的速度和效率。</p><h4 id="7-3-系统集成优化"><a href="#7-3-系统集成优化" class="headerlink" title="7.3 系统集成优化"></a>7.3 系统集成优化</h4><p>可以对系统集成进行优化，以提高系统的稳定性和可靠性。例如，可以使用ROS（Robot Operating System）等开源机器人操作系统，以提供可靠的通信和控制机制。同时，可以优化图像传输和目标检测结果的传输机制，例如使用ZeroMQ等高性能消息中间件，以加快数据传输和处理。</p><h4 id="7-4-结果"><a href="#7-4-结果" class="headerlink" title="7.4 结果"></a>7.4 结果</h4><p>如果安防机器人的性能足够，那么可以直接将目标检测模型部署到机器人上，以加快检测流程，检测图像和结果及时上报服务器记录。可以通过在机器人上部署目标检测模型，使用GPU等硬件加速设备，以加快图像处理和目标检测的速度。同时，可以将检测结果和图像数据传输到服务器上，以进行数据分析和存储。需要注意的是，直接在机器人上部署目标检测模型需要考虑机器人的计算能力和存储能力，以确保机器人能够处理和存储大量的图像数据和检测结果。同时，需要进行充分的测试和调试，以保证检测结果的准确性和可靠性。</p><h1 id="其它方案"><a href="#其它方案" class="headerlink" title="其它方案"></a>其它方案</h1><p>实现思路<br>    复杂方案<br>        火灾和漏水的图像识别<br>            使用yolov8训练模型识别着火点和漏水点的图像，判断是否发生火灾和图像<br>            如果机器人有红外感应器，也可以红外线热力图辅助识别火灾，人物<br>            如果有集成声音<br>                可以使用火灾的声音和漏水的声音辅助判断，使用模型声音分类模型<br>        防盗检测<br>            2阶段实现，首先使用yolov8检测出是否有人，第二使用多模态模型图像字幕的方式，对图像中的人物动作进行描述，判断是否可能在实施偷盗。多模态模型例如miniGPT4, BLIP,CLIP模型等<br>        图像，声音，多模态模型<br>            或者自己开发一个多模态模型（实现声音分类，目标检测，和图像字幕）</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>图像标注系统工具开发</title>
    <link href="/2023/05/19/%E5%9B%BE%E5%83%8F%E6%A0%87%E6%B3%A8%E7%B3%BB%E7%BB%9F%E5%B7%A5%E5%85%B7%E5%BC%80%E5%8F%91/"/>
    <url>/2023/05/19/%E5%9B%BE%E5%83%8F%E6%A0%87%E6%B3%A8%E7%B3%BB%E7%BB%9F%E5%B7%A5%E5%85%B7%E5%BC%80%E5%8F%91/</url>
    
    <content type="html"><![CDATA[<h1 id="标注系统开发"><a href="#标注系统开发" class="headerlink" title="标注系统开发"></a>标注系统开发</h1><p>上一个标注系统是单张图片中的目标识别，我们有10万张图片，即使模型准确率较高，也需要10万次确认才能确认所有图片，这不是一个高效的方式。所以开发了这个标注系统。<br>这个标注系统的原理是首先把所有数据进行目标检测，然后按某个商品的一个已标注样本搜索所有相似的项目，然后人为只需要确认哪些是同一商品即可，只需确认2万个商品即可。而且对同一商品的对比更方便观察和确认，效率更高。</p><h1 id="界面效果"><a href="#界面效果" class="headerlink" title="界面效果"></a>界面效果</h1><img src="/2023/05/19/%E5%9B%BE%E5%83%8F%E6%A0%87%E6%B3%A8%E7%B3%BB%E7%BB%9F%E5%B7%A5%E5%85%B7%E5%BC%80%E5%8F%91/%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7.png" class=""><h1 id="设计思路"><a href="#设计思路" class="headerlink" title="设计思路"></a>设计思路</h1><img src="/2023/05/19/%E5%9B%BE%E5%83%8F%E6%A0%87%E6%B3%A8%E7%B3%BB%E7%BB%9F%E5%B7%A5%E5%85%B7%E5%BC%80%E5%8F%91/%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE.png" class="">]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>微软的Low-codeLLM解析</title>
    <link href="/2023/05/17/%E5%BE%AE%E8%BD%AF%E7%9A%84Low-codeLLM%E8%A7%A3%E6%9E%90/"/>
    <url>/2023/05/17/%E5%BE%AE%E8%BD%AF%E7%9A%84Low-codeLLM%E8%A7%A3%E6%9E%90/</url>
    
    <content type="html"><![CDATA[<h1 id="微软写了一个简单的低代码的LLM复杂任务控制流程，类似AutoGPT，对大的任务进行分解成多个子任务。"><a href="#微软写了一个简单的低代码的LLM复杂任务控制流程，类似AutoGPT，对大的任务进行分解成多个子任务。" class="headerlink" title="微软写了一个简单的低代码的LLM复杂任务控制流程，类似AutoGPT，对大的任务进行分解成多个子任务。"></a>微软写了一个简单的低代码的LLM复杂任务控制流程，类似AutoGPT，对大的任务进行分解成多个子任务。</h1><p>一共分成3步：</p><ul><li><ol><li>用户问一个问题，ChatGPT作为规划LLM，出一个SOP的任务规划。</li></ol></li><li><ol start="2"><li>用户对ChatGPT返回的规划LLM进行修改，还可以对简单的逻辑进行修改，即if和else，类似Scratch编程。</li></ol></li><li><ol start="3"><li>用户可以对某个Step进一步扩展成subStep，方便更精细的子任务操作。</li></ol></li><li><ol start="4"><li>当用户实际问一个具体的问题时，按照规划好的SOP进行回答。</li></ol></li></ul><h1 id="代码地址"><a href="#代码地址" class="headerlink" title="代码地址"></a>代码地址</h1><p>代码：<a href="https://github.com/microsoft/TaskMatrix/tree/main/LowCodeLLM">https://github.com/microsoft/TaskMatrix/tree/main/LowCodeLLM</a></p><h1 id="示例截图"><a href="#示例截图" class="headerlink" title="示例截图"></a>示例截图</h1><img src="/2023/05/17/%E5%BE%AE%E8%BD%AF%E7%9A%84Low-codeLLM%E8%A7%A3%E6%9E%90/lowcode.png" class=""><h1 id="代码的结构"><a href="#代码的结构" class="headerlink" title="代码的结构"></a>代码的结构</h1><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs stylus">├── Dockerfile<br>├── README-zh<span class="hljs-selector-class">.md</span><br>├── README<span class="hljs-selector-class">.md</span><br>├── config<span class="hljs-selector-class">.template</span><br>└── <span class="hljs-attribute">src</span><br>    ├── app<span class="hljs-selector-class">.py</span>  主进程<br>    ├── executingLLM<span class="hljs-selector-class">.py</span><br>    ├── index<span class="hljs-selector-class">.html</span><br>    ├── lowCodeLLM<span class="hljs-selector-class">.py</span><br>    ├── openAIWrapper<span class="hljs-selector-class">.py</span><br>    ├── planningLLM<span class="hljs-selector-class">.py</span><br>    ├── requirements<span class="hljs-selector-class">.txt</span><br>    ├── supervisord.conf<br></code></pre></td></tr></table></figure><h1 id="执行流程的示例"><a href="#执行流程的示例" class="headerlink" title="执行流程的示例"></a>执行流程的示例</h1><img src="/2023/05/17/%E5%BE%AE%E8%BD%AF%E7%9A%84Low-codeLLM%E8%A7%A3%E6%9E%90/%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE.png" class=""><h1 id="微软的代码的待完善"><a href="#微软的代码的待完善" class="headerlink" title="微软的代码的待完善"></a>微软的代码的待完善</h1><ol><li>没有对用户修改的Step进行存储。</li><li>最后用户询问时，没有一步步的调用chatgpt进行解答，直接贴上所有的SOP和问题后直接进行回答。</li></ol><h1 id="示例问题，测试的示例其实需要和本地的数据库进行联动的，作为下一步改进的方向。"><a href="#示例问题，测试的示例其实需要和本地的数据库进行联动的，作为下一步改进的方向。" class="headerlink" title="示例问题，测试的示例其实需要和本地的数据库进行联动的，作为下一步改进的方向。"></a>示例问题，测试的示例其实需要和本地的数据库进行联动的，作为下一步改进的方向。</h1>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>transformers的所有模型名称和配置的映射记录</title>
    <link href="/2023/05/16/transformers%E7%9A%84%E6%89%80%E6%9C%89%E6%A8%A1%E5%9E%8B%E5%90%8D%E7%A7%B0%E5%92%8C%E9%85%8D%E7%BD%AE%E7%9A%84%E6%98%A0%E5%B0%84%E8%AE%B0%E5%BD%95/"/>
    <url>/2023/05/16/transformers%E7%9A%84%E6%89%80%E6%9C%89%E6%A8%A1%E5%9E%8B%E5%90%8D%E7%A7%B0%E5%92%8C%E9%85%8D%E7%BD%AE%E7%9A%84%E6%98%A0%E5%B0%84%E8%AE%B0%E5%BD%95/</url>
    
    <content type="html"><![CDATA[<h1 id="方便查看transformers的所有模型"><a href="#方便查看transformers的所有模型" class="headerlink" title="方便查看transformers的所有模型"></a>方便查看transformers的所有模型</h1><figure class="highlight clojure"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br></pre></td><td class="code"><pre><code class="hljs clojure">(<span class="hljs-string">&quot;albert&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;AlbertConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;align&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;AlignConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;altclip&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;AltCLIPConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;audio-spectrogram-transformer&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;ASTConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;bart&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;BartConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;beit&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;BeitConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;bert&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;BertConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;bert-generation&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;BertGenerationConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;big_bird&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;BigBirdConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;bigbird_pegasus&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;BigBirdPegasusConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;biogpt&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;BioGptConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;bit&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;BitConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;blenderbot&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;BlenderbotConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;blenderbot-small&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;BlenderbotSmallConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;blip&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;BlipConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;blip-2&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;Blip2Config&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;bloom&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;BloomConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;bridgetower&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;BridgeTowerConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;camembert&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;CamembertConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;canine&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;CanineConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;chinese_clip&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;ChineseCLIPConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;clap&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;ClapConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;clip&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;CLIPConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;clipseg&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;CLIPSegConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;codegen&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;CodeGenConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;conditional_detr&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;ConditionalDetrConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;convbert&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;ConvBertConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;convnext&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;ConvNextConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;convnextv2&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;ConvNextV2Config&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;cpmant&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;CpmAntConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;ctrl&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;CTRLConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;cvt&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;CvtConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;data2vec-audio&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;Data2VecAudioConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;data2vec-text&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;Data2VecTextConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;data2vec-vision&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;Data2VecVisionConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;deberta&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;DebertaConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;deberta-v2&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;DebertaV2Config&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;decision_transformer&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;DecisionTransformerConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;deformable_detr&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;DeformableDetrConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;deit&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;DeiTConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;deta&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;DetaConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;detr&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;DetrConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;dinat&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;DinatConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;distilbert&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;DistilBertConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;donut-swin&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;DonutSwinConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;dpr&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;DPRConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;dpt&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;DPTConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;efficientformer&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;EfficientFormerConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;efficientnet&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;EfficientNetConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;electra&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;ElectraConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;encoder-decoder&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;EncoderDecoderConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;ernie&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;ErnieConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;ernie_m&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;ErnieMConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;esm&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;EsmConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;flaubert&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;FlaubertConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;flava&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;FlavaConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;fnet&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;FNetConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;focalnet&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;FocalNetConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;fsmt&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;FSMTConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;funnel&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;FunnelConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;git&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;GitConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;glpn&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;GLPNConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;gpt-sw3&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;GPT2Config&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;gpt2&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;GPT2Config&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;gpt_bigcode&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;GPTBigCodeConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;gpt_neo&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;GPTNeoConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;gpt_neox&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;GPTNeoXConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;gpt_neox_japanese&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;GPTNeoXJapaneseConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;gptj&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;GPTJConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;gptsan-japanese&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;GPTSanJapaneseConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;graphormer&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;GraphormerConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;groupvit&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;GroupViTConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;hubert&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;HubertConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;ibert&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;IBertConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;imagegpt&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;ImageGPTConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;informer&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;InformerConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;jukebox&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;JukeboxConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;layoutlm&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;LayoutLMConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;layoutlmv2&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;LayoutLMv2Config&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;layoutlmv3&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;LayoutLMv3Config&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;led&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;LEDConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;levit&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;LevitConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;lilt&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;LiltConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;llama&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;LlamaConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;longformer&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;LongformerConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;longt5&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;LongT5Config&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;luke&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;LukeConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;lxmert&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;LxmertConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;m2m_100&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;M2M100Config&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;marian&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;MarianConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;markuplm&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;MarkupLMConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;mask2former&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;Mask2FormerConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;maskformer&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;MaskFormerConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;maskformer-swin&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;MaskFormerSwinConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;mbart&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;MBartConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;mctct&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;MCTCTConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;mega&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;MegaConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;megatron-bert&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;MegatronBertConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;mgp-str&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;MgpstrConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;mobilebert&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;MobileBertConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;mobilenet_v1&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;MobileNetV1Config&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;mobilenet_v2&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;MobileNetV2Config&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;mobilevit&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;MobileViTConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;mpnet&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;MPNetConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;mt5&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;MT5Config&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;mvp&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;MvpConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;nat&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;NatConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;nezha&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;NezhaConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;nllb-moe&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;NllbMoeConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;nystromformer&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;NystromformerConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;oneformer&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;OneFormerConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;open-llama&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;OpenLlamaConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;openai-gpt&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;OpenAIGPTConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;opt&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;OPTConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;owlvit&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;OwlViTConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;pegasus&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;PegasusConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;pegasus_x&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;PegasusXConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;perceiver&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;PerceiverConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;pix2struct&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;Pix2StructConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;plbart&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;PLBartConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;poolformer&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;PoolFormerConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;prophetnet&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;ProphetNetConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;qdqbert&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;QDQBertConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;rag&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;RagConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;realm&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;RealmConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;reformer&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;ReformerConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;regnet&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;RegNetConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;rembert&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;RemBertConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;resnet&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;ResNetConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;retribert&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;RetriBertConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;roberta&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;RobertaConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;roberta-prelayernorm&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;RobertaPreLayerNormConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;roc_bert&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;RoCBertConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;roformer&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;RoFormerConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;rwkv&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;RwkvConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;sam&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;SamConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;segformer&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;SegformerConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;sew&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;SEWConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;sew-d&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;SEWDConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;speech-encoder-decoder&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;SpeechEncoderDecoderConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;speech_to_text&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;Speech2TextConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;speech_to_text_2&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;Speech2Text2Config&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;speecht5&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;SpeechT5Config&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;splinter&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;SplinterConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;squeezebert&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;SqueezeBertConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;swiftformer&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;SwiftFormerConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;swin&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;SwinConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;swin2sr&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;Swin2SRConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;swinv2&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;Swinv2Config&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;switch_transformers&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;SwitchTransformersConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;t5&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;T5Config&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;table-transformer&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;TableTransformerConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;tapas&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;TapasConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;time_series_transformer&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;TimeSeriesTransformerConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;timesformer&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;TimesformerConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;trajectory_transformer&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;TrajectoryTransformerConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;transfo-xl&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;TransfoXLConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;trocr&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;TrOCRConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;tvlt&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;TvltConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;unispeech&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;UniSpeechConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;unispeech-sat&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;UniSpeechSatConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;upernet&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;UperNetConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;van&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;VanConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;videomae&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;VideoMAEConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;vilt&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;ViltConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;vision-encoder-decoder&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;VisionEncoderDecoderConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;vision-text-dual-encoder&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;VisionTextDualEncoderConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;visual_bert&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;VisualBertConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;vit&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;ViTConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;vit_hybrid&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;ViTHybridConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;vit_mae&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;ViTMAEConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;vit_msn&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;ViTMSNConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;wav2vec2&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;Wav2Vec2Config&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;wav2vec2-conformer&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;Wav2Vec2ConformerConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;wavlm&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;WavLMConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;whisper&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;WhisperConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;xclip&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;XCLIPConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;xglm&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;XGLMConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;xlm&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;XLMConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;xlm-prophetnet&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;XLMProphetNetConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;xlm-roberta&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;XLMRobertaConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;xlm-roberta-xl&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;XLMRobertaXLConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;xlnet&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;XLNetConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;xmod&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;XmodConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;yolos&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;YolosConfig&quot;</span>)<span class="hljs-punctuation">,</span><br>(<span class="hljs-string">&quot;yoso&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;YosoConfig&quot;</span>)<span class="hljs-punctuation">,</span><br></code></pre></td></tr></table></figure><h1 id="saleforce的模型下载地址"><a href="#saleforce的模型下载地址" class="headerlink" title="saleforce的模型下载地址"></a>saleforce的模型下载地址</h1><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs awk">https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/sfr-vision-language-research/</span>LAVIS<span class="hljs-regexp">/models/</span>BLIP2/blip2_pretrained_vitL.pth<br>https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/sfr-vision-language-research/</span>LAVIS<span class="hljs-regexp">/models/</span>BLIP/blip_okvqa.pth<br>https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/sfr-vision-language-research/</span>BLIP<span class="hljs-regexp">/models/m</span>odel_large.pth<br>https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/sfr-vision-language-research/</span>LAVIS<span class="hljs-regexp">/models/</span>BLIP2/blip2_caption_opt6.<span class="hljs-number">7</span>b.pth<br>https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/sfr-vision-language-research/</span>LAVIS<span class="hljs-regexp">/models/</span>BLIP2/blip2_pretrained_flant5xl.pth<br>https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/sfr-vision-language-research/</span>LAVIS<span class="hljs-regexp">/models/</span>BLIP2/blip2_caption_opt2.<span class="hljs-number">7</span>b.pth<br>https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/sfr-vision-language-research/</span>LAVIS<span class="hljs-regexp">/models/</span>ALPRO/alpro_msrvtt_retrieval.pt<br>https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/sfr-vision-language-research/</span>BLIP<span class="hljs-regexp">/models/m</span>odel_large_caption.pth<br>https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/sfr-vision-language-research/</span>LAVIS<span class="hljs-regexp">/models/</span>ALBEF/albef_vqav2_lavis.pt<br>https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/sfr-vision-language-research/</span>LAVIS<span class="hljs-regexp">/models/</span>BLIP/blip_aokvqa.pth<br>https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/sfr-vision-language-research/</span>LAVIS<span class="hljs-regexp">/models/</span>BLIP2/blip2_caption_flant5xl.pth<br>https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/sfr-vision-language-research/</span>LAVIS<span class="hljs-regexp">/models/</span>BLIP2/blip2_finetune_coco.pth<br>https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/sfr-vision-language-research/</span>LAVIS<span class="hljs-regexp">/models/</span>ALBEF/albef_nlvr_lavis.pt<br>https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/sfr-vision-language-research/</span>LAVIS<span class="hljs-regexp">/models/</span>ALPRO/alpro_msvd_qa.pth<br>https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/sfr-vision-language-research/</span>LAVIS<span class="hljs-regexp">/models/</span>ALPRO/alpro_msrvtt_qa.pth<br>https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/sfr-vision-language-research/</span>BLIP<span class="hljs-regexp">/models/m</span>odel_large_retrieval_coco.pth<br>https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/sfr-vision-language-research/</span>LAVIS<span class="hljs-regexp">/models/</span>BLIP2/blip2_pretrained_opt2.<span class="hljs-number">7</span>b.pth<br>https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/sfr-vision-language-research/</span>LAVIS<span class="hljs-regexp">/models/</span>ALBEF/albef_flickr_retrieval_lavis.pt<br>https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/sfr-vision-language-research/</span>LAVIS<span class="hljs-regexp">/models/</span>BLIP2/blip2_pretrained_opt6.<span class="hljs-number">7</span>b.pth<br>https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/sfr-vision-language-research/</span>LAVIS<span class="hljs-regexp">/models/</span>ALBEF/albef_snli_ve_lavis.pt<br>https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/sfr-vision-language-research/</span>LAVIS<span class="hljs-regexp">/models/</span>BLIP2/blip2_pretrained.pth<br>https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/sfr-vision-language-research/</span>LAVIS<span class="hljs-regexp">/models/</span>ALBEF/albef_coco_retrieval_lavis.pt<br>https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/sfr-vision-language-research/</span>LAVIS<span class="hljs-regexp">/models/</span>BLIP2/blip2_pretrained_flant5xl_vitL.pth<br>https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/sfr-vision-language-research/</span>LAVIS<span class="hljs-regexp">/models/</span>BLIP/blip_coco_caption_base.pth<br>https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/sfr-vision-language-research/</span>BLIP<span class="hljs-regexp">/models/m</span>odel_base_retrieval_coco.pth<br>https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/sfr-vision-language-research/</span>BLIP<span class="hljs-regexp">/models/m</span>odel_base_vqa_capfilt_large.pth<br>https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/sfr-vision-language-research/</span>LAVIS<span class="hljs-regexp">/models/</span>BLIP2/blip2_pretrained_flant5xxl.pth<br>openai<br>https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/sfr-vision-language-research/</span>BLIP<span class="hljs-regexp">/models/m</span>odel_base_capfilt_large.pth<br>https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/sfr-vision-language-research/</span>LAVIS<span class="hljs-regexp">/models/</span>ALPRO/alpro_pretrain.pt<br>https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/sfr-pcl-data-research/</span>ALBEF/pretrain_model_nlvr.pth<br>https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/sfr-vision-language-research/</span>LAVIS<span class="hljs-regexp">/models/</span>ALPRO/alpro_didemo_retrieval.pt<br>https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/sfr-vision-language-research/</span>BLIP<span class="hljs-regexp">/models/m</span>odel_base_caption_capfilt_large.pth<br>https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/sfr-vision-language-research/</span>BLIP<span class="hljs-regexp">/models/m</span>odel_base_nlvr.pth<br>https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/sfr-vision-language-research/</span>LAVIS<span class="hljs-regexp">/models/</span>BLIP/blip_coco_retrieval.pth<br>https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/sfr-vision-language-research/</span>LAVIS<span class="hljs-regexp">/models/</span>BLIP/blip_flickr_retrieval.pth<br>https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/sfr-pcl-data-research/</span>ALBEF/ALBEF.pth<br></code></pre></td></tr></table></figure><h1 id="具体模型"><a href="#具体模型" class="headerlink" title="具体模型"></a>具体模型</h1><p>OPT:  Open Pre-trained Transformers (OPT)，Meta开发，参数范围从 125M 到 175B，因果模型，文本生成，分类，问答</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>为什么大模型的推理能力差的思考</title>
    <link href="/2023/05/11/%E4%B8%BA%E4%BB%80%E4%B9%88%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%8E%A8%E7%90%86%E8%83%BD%E5%8A%9B%E5%B7%AE%E7%9A%84%E6%80%9D%E8%80%83/"/>
    <url>/2023/05/11/%E4%B8%BA%E4%BB%80%E4%B9%88%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%8E%A8%E7%90%86%E8%83%BD%E5%8A%9B%E5%B7%AE%E7%9A%84%E6%80%9D%E8%80%83/</url>
    
    <content type="html"><![CDATA[<p>1.首先思考人的大脑原理:<br>左脑主要负责逻辑思考、语言、数学、分析、推理、顺序性等任务。<br>右脑主要负责空间感知、图像处理、想象力、情感、直觉、创造性思维等任务。</p><ol start="2"><li>目前大模型在在逻辑思考，推理，数学上都比较差，但是如果加上Chain-of-Thought，链式思考（CoT），例如Let’s think step by step，效果就会提升很高。另一个证据是现在的大模型都会加上github上的代码进行训练，结果证明对推理能力有较大提高。我觉得这有3个方面的原因，1是我们训练数据上没有或很少教模型的思考过程，直接训练答案，模型缺少思考为什么结果是这样。2是增加多模态的知识，让它对世界的运作有了解，而不是只通过学习语言。 3强化学习和参数更新，现在的推理时模型是固定的参数的，如何更有效的在与人类，与世界交互时进行参数更新，因为人类不仅接收输入，而且还实时处理输入和返回输出。如何动态的更新大模型的参数，只更新部分参数参数，更新哪些参数，例如Lora只更新Q和V，还是最新的关于模型的黑盒研究中关于定位到哪些知识在模型中的哪个参数的位置，对应去更新？这些都是未来需要发展的方向。</li></ol>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Chatgpt分享</title>
    <link href="/2023/05/11/Chatgpt%E5%88%86%E4%BA%AB/"/>
    <url>/2023/05/11/Chatgpt%E5%88%86%E4%BA%AB/</url>
    
    <content type="html"><![CDATA[<h1 id="ChatGPT运行原理"><a href="#ChatGPT运行原理" class="headerlink" title="ChatGPT运行原理"></a>ChatGPT运行原理</h1><p>大语言模型进化树:</p><img src="/2023/05/11/Chatgpt%E5%88%86%E4%BA%AB/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8F%91%E5%B1%95.png" class=""><p>一共三种方式： 编码器，解码器，编码器-解码器</p><h2 id="编码器代表：Bert的训练方式"><a href="#编码器代表：Bert的训练方式" class="headerlink" title="编码器代表：Bert的训练方式:"></a>编码器代表：Bert的训练方式:</h2><p>完形填空： ___________和阿里、腾讯一起并成为中国互联网 BAT 三巨头。<br>随机地扣掉一部分字，形成上面例子的完形填空题型，不断地学习空格处到底该填写什么。所谓语言模型的训练和学习，就是从大量的数据中学习复杂的上下文联系。</p><h2 id="解码器代表-GPT的训练方式"><a href="#解码器代表-GPT的训练方式" class="headerlink" title="解码器代表: GPT的训练方式:"></a>解码器代表: GPT的训练方式:</h2><p>根据已有句子的一部分，来预测下一个单词会是什么。<br>示例：手机上的输入法，它可以根据当前输入的内容智能推荐下一个词。</p><h2 id="编码器-解码器Transformer结构-T5，GLM"><a href="#编码器-解码器Transformer结构-T5，GLM" class="headerlink" title="编码器-解码器Transformer结构: T5，GLM"></a>编码器-解码器Transformer结构: T5，GLM</h2><p>数据—向量—数据</p><img src="/2023/05/11/Chatgpt%E5%88%86%E4%BA%AB/Transformer.png" class=""><p>self-attention和cross-attention其实就是比较表面的意思，self-attention可以理解为自我观察学习，cross-attention是借鉴和学习。<br>把下面这句话当成自己，每个词当成每个生活的部分，相互影响。</p><img src="/2023/05/11/Chatgpt%E5%88%86%E4%BA%AB/self-attention.png" class=""><p>灰色块和蓝色块是来自2个不同的向量，例如2个不同的句子，图片和文本，等等</p><img src="/2023/05/11/Chatgpt%E5%88%86%E4%BA%AB/cross-attention.png" class=""><h1 id="ChatGPT训练方法"><a href="#ChatGPT训练方法" class="headerlink" title="ChatGPT训练方法"></a>ChatGPT训练方法</h1><h2 id="Openai的训练方法"><a href="#Openai的训练方法" class="headerlink" title="Openai的训练方法:"></a>Openai的训练方法:</h2><p>BaseModel:  GPT3.5, 1750亿参数,45TB训练数据<br>SFT: supervised fine-tuning监督微调模型, 大量标注问答对数据<br>RM: Reward Model训练一个奖励模型或者叫做偏好模型, 一个问题生成多个答案，人工排序后，RM模型知道哪个答案更好。<br>RLHF: reinforcement learning from human feedback，人类反馈的强化学习, 对齐AI系统和人类, PPO强化学习算法微调模型SFT，RM反馈，另一个约束是KL散度，即原始当前模型和对比模型的KL散度差。<br>Actor就是我们的模型，update是对比模型，ENV是RM模型，Reward是RM模型的输出。</p><img src="/2023/05/11/Chatgpt%E5%88%86%E4%BA%AB/Actor_Env_reward.png" class=""><p>小知识：PPO算法简单理解:Proximal Policy Optimization Algorithms, 如何更新策略，即如何更新决策，这里就是如何更新模型，KL散度简单理解，衡量两个概率分布之间差异的一种度量方式，这里是训练约束2个模型的差异不要太大。</p><img src="/2023/05/11/Chatgpt%E5%88%86%E4%BA%AB/Reward.png" class=""><h2 id="开源的训练方法"><a href="#开源的训练方法" class="headerlink" title="开源的训练方法:"></a>开源的训练方法:</h2><p>适配器方面，撬动大模型。<br>Huggingface的PEFT库集成,Parameter-Efficient Fine-Tuning 参数高效微调的方法，总的来说就是对模型的部分参数进行微调<br>包括4种适配器方法<br>    PROMPT_TUNING<br>        提示优化,额外的文字和占位符向量<br>    P_TUNING,<a href="https://zhuanlan.zhihu.com/p/610943594">https://zhuanlan.zhihu.com/p/610943594</a><br>        嵌入优化,V1只训练嵌入向量，V2模型每一层添加一个额外的向量<br>    PREFIX_TUNING<br>        提示学习的前缀优化,输入中添加k个位置,注意力层添加对这个k个位置的注意力向量。<br>    LORA: <a href="https://zhuanlan.zhihu.com/p/610943445">https://zhuanlan.zhihu.com/p/610943445</a><br>        来自微软的Low-rank论文,对注意力中的q和v进行添加,低秩矩阵参数量小，降低微调时的计算复杂度和内存消耗<br>        例如训练roberta-large时，使用LoRA微调月10GB显存，总的参数量是3.5亿，其中训练参数是0.5%，其它冻结<br>        如果全部微调，那么使用的显存是18GB</p><p>数据方面:<br>借助ChatGPT生成数据, 斯坦福大学不到 500 美元,使用Facebook开源的LLaMA进行微调。<br><a href="https://github.com/tatsu-lab/stanford_alpaca">https://github.com/tatsu-lab/stanford_alpaca</a><br>instruction: 描述了模型应该执行的任务,共52K指令<br>input: 任务的可选上下文或输入，可以为空<br>output: chatgpt生成的答案</p><p>模型方面:<br>Base模型:Facebook的LLama模型，bigScience的Bloom, 清华的GLM<br>其它模型，有的是微调模型，有的是其它版本模型:Dolly,ChatYuan,ChatGLM-6B,MOSS,RWKV-LM,stanford_alpaca,Chinese-alpaca-lora,Vicuna,Colossal AI,BELLE,Firefly,Phoenix</p><p>训练技术方面: 撬动大模型。<br>混合精度和分布式训练<br>模型的大小由其参数量及其精度决定，精度通常为 float32、float16 或 bfloat16, huggingface的LLM.int8() 方案<br>小知识：1个字节（Byte）等于8个位（bit），即8个二进制数字，每个二进制数字可以表示0或1两种状态,所以FP32占4个字节，int8占1个字节。GLM-6B举例，如果模型使用fp16，全部微调模型，每个参数占大概2个字节，Adam优化器需要8个字节, 60<em>10</em>100000000&#x2F;1024&#x2F;1024&#x2F;1024&#x3D;55.9GB, 加上一些其它并且还可能需要更多用于计算诸如注意力分数的中间值。<br><a href="https://zhuanlan.zhihu.com/p/624929178">https://zhuanlan.zhihu.com/p/624929178</a><br>分布式训练: 模型并行，数据并行，张量并行</p><p>工具库和显存优化算法:<br>accelerate,torchrun,DeepSpeed</p><p>新技术:<br>LangChain: 字面意义，链接模型，数据，和提示链,一个提示接着一个提示。<br>Auto-GPT: 任务分解，将任务分解多个步骤，并对每个步骤进行分析和决策<br>minigpt-4: 多模态的gpt问答<br>imagebind: meta开源,6模态,图像、文本、音频、深度、温度和 IMU 数据<br>图像领域: Segment Anything, stable diffusion, Control Net</p><h1 id="ChatGPT的优缺点"><a href="#ChatGPT的优缺点" class="headerlink" title="ChatGPT的优缺点"></a>ChatGPT的优缺点</h1><p>优点：更智能，更通用<br>缺点：容易胡说，专业度差, 推理能力差，不能真正的实时学习</p><h1 id="术语"><a href="#术语" class="headerlink" title="术语"></a>术语</h1><p>CoT: Chain-of-Thought，链式思考（CoT）,加上“让我们逐步思考”,增加模型的推理能力<br>EA: 涌现能力（Emergent Ability）,指的是当模型参数规模未能达到某个阀值时，模型基本不具备解决此类任务的任何能力，体现为其性能和随机选择答案效果相当，但是当模型规模跨过阀值，LLM模型对此类任务的效果就出现突然的性能增长。<br>AIGC：AI Generated Content ，人工智能自动生成内容<br>NLP：Natural Language Processing，自然语言处理<br>LLM：Large language model，大语言模型<br>AGI：Artificial general intelligence，通用人工智能<br>Prompt：提示词<br>Fine-tuning：模型调优<br>ML：Machine Learning，机器学习<br>DL：Deep Learning，深度学习<br>BERT：Bidirectional Encoder Representations from Transformers”，双向编码器表示<br>RLHF：Reinforcement Learning from Human Feedback，基于人类反馈的强化学习</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>sentence_transformers联网报错问题</title>
    <link href="/2023/05/08/sentence-transformers%E8%81%94%E7%BD%91%E6%8A%A5%E9%94%99%E9%97%AE%E9%A2%98/"/>
    <url>/2023/05/08/sentence-transformers%E8%81%94%E7%BD%91%E6%8A%A5%E9%94%99%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<h1 id="国内由于墙的问题，经常会连接huggingface报错"><a href="#国内由于墙的问题，经常会连接huggingface报错" class="headerlink" title="国内由于墙的问题，经常会连接huggingface报错"></a>国内由于墙的问题，经常会连接huggingface报错</h1><p>类似报错如下：<br>curl: (28) Failed to connect to huggingface.co port 443: Connection timed out</p><p>测试本地网络:<br>curl <a href="https://huggingface.co/api/models/GanymedeNil/text2vec-base-chinese">https://huggingface.co/api/models/GanymedeNil/text2vec-base-chinese</a><br>curl: (28) Failed to connect to huggingface.co port 443: Connection timed out</p><p>确实不同，通过代理访问, 能正常返回</p><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs prolog">&#123;<span class="hljs-string">&quot;_id&quot;</span>:<span class="hljs-string">&quot;6406b3d583b59abcddefab03&quot;</span>,<span class="hljs-string">&quot;id&quot;</span>:<span class="hljs-string">&quot;GanymedeNil/text2vec-base-chinese&quot;</span>,<span class="hljs-string">&quot;modelId&quot;</span>:<span class="hljs-string">&quot;GanymedeNil/text2vec-base-chinese&quot;</span>,<span class="hljs-string">&quot;author&quot;</span>:<span class="hljs-string">&quot;GanymedeNil&quot;</span>,<span class="hljs-string">&quot;sha&quot;</span>:<span class="hljs-string">&quot;63c5640935ea81c04763e9dc3af5a731d93e16bf&quot;</span>,<span class="hljs-string">&quot;lastModified&quot;</span>:<span class="hljs-string">&quot;2023-03-07T04:07:44.000Z&quot;</span>,<span class="hljs-string">&quot;private&quot;</span>:false,<span class="hljs-string">&quot;disabled&quot;</span>:false,<span class="hljs-string">&quot;gated&quot;</span>:false,<span class="hljs-string">&quot;pipeline_tag&quot;</span>:<span class="hljs-string">&quot;sentence-similarity&quot;</span>,<span class="hljs-string">&quot;tags&quot;</span>:[<span class="hljs-string">&quot;pytorch&quot;</span>,<span class="hljs-string">&quot;bert&quot;</span>,<span class="hljs-string">&quot;feature-extraction&quot;</span>,<span class="hljs-string">&quot;zh&quot;</span>,<span class="hljs-string">&quot;transformers&quot;</span>,<span class="hljs-string">&quot;text2vec&quot;</span>,<span class="hljs-string">&quot;sentence-similarity&quot;</span>,<span class="hljs-string">&quot;license:apache-2.0&quot;</span>,<span class="hljs-string">&quot;has_space&quot;</span>],<span class="hljs-string">&quot;downloads&quot;</span>:<span class="hljs-number">15018</span>,<span class="hljs-string">&quot;library_name&quot;</span>:<span class="hljs-string">&quot;transformers&quot;</span>,<span class="hljs-string">&quot;mask_token&quot;</span>:<span class="hljs-string">&quot;[MASK]&quot;</span>,<span class="hljs-string">&quot;widgetData&quot;</span>:[&#123;<span class="hljs-string">&quot;source_sentence&quot;</span>:<span class="hljs-string">&quot;那是 個快樂的人&quot;</span>,<span class="hljs-string">&quot;sentences&quot;</span>:[<span class="hljs-string">&quot;那是 條快樂的狗&quot;</span>,<span class="hljs-string">&quot;那是 個非常幸福的人&quot;</span>,<span class="hljs-string">&quot;今天是晴天&quot;</span>]&#125;],<span class="hljs-string">&quot;likes&quot;</span>:<span class="hljs-number">6</span>,<span class="hljs-string">&quot;model-index&quot;</span>:null,<span class="hljs-string">&quot;config&quot;</span>:&#123;<span class="hljs-string">&quot;architectures&quot;</span>:[<span class="hljs-string">&quot;BertModel&quot;</span>],<span class="hljs-string">&quot;model_type&quot;</span>:<span class="hljs-string">&quot;bert&quot;</span>&#125;,<span class="hljs-string">&quot;cardData&quot;</span>:&#123;<span class="hljs-string">&quot;license&quot;</span>:<span class="hljs-string">&quot;apache-2.0&quot;</span>,<span class="hljs-string">&quot;language&quot;</span>:[<span class="hljs-string">&quot;zh&quot;</span>],<span class="hljs-string">&quot;pipeline_tag&quot;</span>:<span class="hljs-string">&quot;sentence-similarity&quot;</span>,<span class="hljs-string">&quot;tags&quot;</span>:[<span class="hljs-string">&quot;text2vec&quot;</span>,<span class="hljs-string">&quot;feature-extraction&quot;</span>,<span class="hljs-string">&quot;sentence-similarity&quot;</span>,<span class="hljs-string">&quot;transformers&quot;</span>]&#125;,<span class="hljs-string">&quot;transformersInfo&quot;</span>:&#123;<span class="hljs-string">&quot;auto_model&quot;</span>:<span class="hljs-string">&quot;AutoModel&quot;</span>,<span class="hljs-string">&quot;pipeline_tag&quot;</span>:<span class="hljs-string">&quot;feature-extraction&quot;</span>,<span class="hljs-string">&quot;processor&quot;</span>:<span class="hljs-string">&quot;AutoTokenizer&quot;</span>&#125;,<span class="hljs-string">&quot;spaces&quot;</span>:[<span class="hljs-string">&quot;thomas-yanxin/LangChain-ChatLLM&quot;</span>,<span class="hljs-string">&quot;Nicholaspei/LangChain-ChatLLM&quot;</span>,<span class="hljs-string">&quot;ytjoh/LangChain-ChatLLM&quot;</span>,<span class="hljs-string">&quot;chow-q/LangChain-ChatLLM&quot;</span>,<span class="hljs-string">&quot;clc007/LangChain-ChatLLM&quot;</span>],<span class="hljs-string">&quot;siblings&quot;</span>:[&#123;<span class="hljs-string">&quot;rfilename&quot;</span>:<span class="hljs-string">&quot;.gitattributes&quot;</span>&#125;,&#123;<span class="hljs-string">&quot;rfilename&quot;</span>:<span class="hljs-string">&quot;README.md&quot;</span>&#125;,&#123;<span class="hljs-string">&quot;rfilename&quot;</span>:<span class="hljs-string">&quot;config.json&quot;</span>&#125;,&#123;<span class="hljs-string">&quot;rfilename&quot;</span>:<span class="hljs-string">&quot;eval_results.txt&quot;</span>&#125;,&#123;<span class="hljs-string">&quot;rfilename&quot;</span>:<span class="hljs-string">&quot;pytorch_model.bin&quot;</span>&#125;,&#123;<span class="hljs-string">&quot;rfilename&quot;</span>:<span class="hljs-string">&quot;special_tokens_map.json&quot;</span>&#125;,&#123;<span class="hljs-string">&quot;rfilename&quot;</span>:<span class="hljs-string">&quot;tokenizer.json&quot;</span>&#125;,&#123;<span class="hljs-string">&quot;rfilename&quot;</span>:<span class="hljs-string">&quot;tokenizer_config.json&quot;</span>&#125;,&#123;<span class="hljs-string">&quot;rfilename&quot;</span>:<span class="hljs-string">&quot;vocab.txt&quot;</span>&#125;]&#125;<br></code></pre></td></tr></table></figure><p>解决办法</p><h1 id="从其它地方拷贝模型到本地，然后model-name改成本地的模型文件夹位置，不让模型联网进行检查"><a href="#从其它地方拷贝模型到本地，然后model-name改成本地的模型文件夹位置，不让模型联网进行检查" class="headerlink" title="从其它地方拷贝模型到本地，然后model_name改成本地的模型文件夹位置，不让模型联网进行检查"></a>从其它地方拷贝模型到本地，然后model_name改成本地的模型文件夹位置，不让模型联网进行检查</h1><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs lasso"><span class="hljs-keyword">import</span> sentence_transformers<br><span class="hljs-built_in">self</span>.client = sentence_transformers.SentenceTransformer(<br>    model_name, cache_folder=<span class="hljs-built_in">self</span>.cache_folder, **<span class="hljs-built_in">self</span>.model_kwargs<br>)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>openai的价格估计</title>
    <link href="/2023/05/08/openai%E7%9A%84%E4%BB%B7%E6%A0%BC%E4%BC%B0%E8%AE%A1/"/>
    <url>/2023/05/08/openai%E7%9A%84%E4%BB%B7%E6%A0%BC%E4%BC%B0%E8%AE%A1/</url>
    
    <content type="html"><![CDATA[<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>到目前为止，我们利用openai的api做了6个任务，想统计下每个任务的花费情况，现做简单统计和绘图</p><h1 id="一、收集缓存json数据，然后收集需要数据，转换成dataframe格式"><a href="#一、收集缓存json数据，然后收集需要数据，转换成dataframe格式" class="headerlink" title="一、收集缓存json数据，然后收集需要数据，转换成dataframe格式"></a>一、收集缓存json数据，然后收集需要数据，转换成dataframe格式</h1><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs nix">for json_file <span class="hljs-keyword">in</span> json_files:<br>    <span class="hljs-attr">json_data</span> = json.load(open(json_file, <span class="hljs-string">&quot;r&quot;</span>, <span class="hljs-attr">encoding=&quot;utf-8&quot;))</span><br>    src_data.append(json_data)<br><span class="hljs-attr">data</span> = []<br><span class="hljs-attr">cnt</span> = <span class="hljs-number">0</span><br>for one <span class="hljs-keyword">in</span> tqdm(src_data):<br>    <span class="hljs-attr">prompt_prefix</span> = one.get(<span class="hljs-string">&quot;input_prompt&quot;</span>)<br>    <span class="hljs-keyword">if</span> not prompt_prefix:<br>        continue<br>    cnt += <span class="hljs-number">1</span><br>    <span class="hljs-attr">prompt_prefix_len</span> = len(prompt_prefix)<br>    <span class="hljs-attr">question</span> = one[<span class="hljs-string">&quot;input_text&quot;</span>]<br>    <span class="hljs-attr">question_len</span> = len(question)<br>    <span class="hljs-attr">result</span> = one[<span class="hljs-string">&quot;result&quot;</span>]<br>    <span class="hljs-attr">model</span> = result[<span class="hljs-string">&quot;model&quot;</span>]<br>    <span class="hljs-attr">prompt_token_num</span> = result[<span class="hljs-string">&quot;usage&quot;</span>][<span class="hljs-string">&quot;prompt_tokens&quot;</span>]<br>    <span class="hljs-attr">anwser_token_num</span> = result[<span class="hljs-string">&quot;usage&quot;</span>][<span class="hljs-string">&quot;completion_tokens&quot;</span>]<br>    <span class="hljs-attr">total_token_num</span> = result[<span class="hljs-string">&quot;usage&quot;</span>][<span class="hljs-string">&quot;total_tokens&quot;</span>]<br>    <span class="hljs-attr">anwser</span> = result[<span class="hljs-string">&quot;choices&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;message&quot;</span>][<span class="hljs-string">&quot;content&quot;</span>]<br>    <span class="hljs-attr">anwser_len</span> = len(anwser)<br>    <span class="hljs-attr">one_data</span> = &#123;<br>        <span class="hljs-string">&quot;prompt_prefix&quot;</span>: prompt_prefix,<br>        <span class="hljs-string">&quot;prompt_prefix_len&quot;</span>: prompt_prefix_len,<br>        <span class="hljs-string">&quot;question&quot;</span>: question,<br>        <span class="hljs-string">&quot;question_len&quot;</span>: question_len,<br>        <span class="hljs-string">&quot;model&quot;</span>: model,<br>        <span class="hljs-string">&quot;prompt_token_num&quot;</span>: prompt_token_num,<br>        <span class="hljs-string">&quot;anwser_token_num&quot;</span>: anwser_token_num,<br>        <span class="hljs-string">&quot;total_token_num&quot;</span>: total_token_num,<br>        <span class="hljs-string">&quot;anwser&quot;</span>: anwser,<br>        <span class="hljs-string">&quot;anwser_len&quot;</span>: anwser_len,<br>        <span class="hljs-string">&quot;total_length&quot;</span>: prompt_prefix_len + question_len + anwser_len, <span class="hljs-comment">#单词的总长度</span><br>    &#125;<br>    data.append(one_data)<br><span class="hljs-comment"># 转换成Dataframe</span><br><span class="hljs-attr">df</span> = pd.DataFrame(data)<br>print(f<span class="hljs-string">&quot;共收集到&#123;len(df)&#125;条数据，列名是&#123;df.columns&#125;&quot;</span>)<br></code></pre></td></tr></table></figure><p>共收集到9624条数据</p><h1 id="首先对每个任务的问题数量进行统计和绘图"><a href="#首先对每个任务的问题数量进行统计和绘图" class="headerlink" title="首先对每个任务的问题数量进行统计和绘图"></a>首先对每个任务的问题数量进行统计和绘图</h1><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs routeros">def plot_prompt_prefix_freq(df_data):<br>    # 按input_prompt的问题进行统计<br>    #对相似的问题进行合并<br>    # 对prompt_prefix进行修改，如果出现了包含某些关键字的问题，那么就更改prompt_prefix为统一的关键字<br>    df_prompt_prefix_cnt = df_data[<span class="hljs-string">&#x27;prompt_type&#x27;</span>].value_counts().sort_values(<span class="hljs-attribute">ascending</span>=<span class="hljs-literal">False</span>)<br>    <span class="hljs-built_in">print</span>(f<span class="hljs-string">&quot;共有&#123;len(df_prompt_prefix_cnt)&#125;个问题,列名分别是: &#123;df_prompt_prefix_cnt.index&#125;&quot;</span>)<br>    <span class="hljs-built_in">print</span>(f<span class="hljs-string">&quot;去掉结果为1个的的问题&quot;</span>)<br>    df_prompt_prefix_cnt = df_prompt_prefix_cnt[df_prompt_prefix_cnt &gt; 10]<br>    <span class="hljs-built_in">print</span>(f<span class="hljs-string">&quot;剩余共有&#123;len(df_prompt_prefix_cnt)&#125;个问题,列名分别是: &#123;df_prompt_prefix_cnt.index&#125;&quot;</span>)<br>    df_counts = df_prompt_prefix_cnt.reset_index()<br>    df_counts.columns = [<span class="hljs-string">&#x27;prompt_prefix&#x27;</span>, <span class="hljs-string">&#x27;count&#x27;</span>]<br>    fig, ax = plt.subplots(figsize=(20, 10), <span class="hljs-attribute">dpi</span>=100)<br>    df_counts.plot.bar(<span class="hljs-attribute">x</span>=<span class="hljs-string">&#x27;prompt_prefix&#x27;</span>, <span class="hljs-attribute">y</span>=<span class="hljs-string">&#x27;count&#x27;</span>, <span class="hljs-attribute">ax</span>=ax)<br>    plt.xlabel(<span class="hljs-string">&#x27;prompt_prefix&#x27;</span>)<br>    plt.ylabel(<span class="hljs-string">&#x27;Count&#x27;</span>)<br>    plt.xticks(<span class="hljs-attribute">rotation</span>=45)<br>    plt.title(<span class="hljs-string">&#x27;问题分布数量分别&#x27;</span>)<br>    # 保存到图片<br>    png_file = <span class="hljs-string">&quot;/Users/admin/tmp/prompt_prefix_freq.png&quot;</span><br>    plt.savefig(png_file)<br>    <span class="hljs-built_in">print</span>(f<span class="hljs-string">&quot;保存到文件&#123;png_file&#125;&quot;</span>)<br></code></pre></td></tr></table></figure><img src="/2023/05/08/openai%E7%9A%84%E4%BB%B7%E6%A0%BC%E4%BC%B0%E8%AE%A1/prompt_prefix_freq.png" class=""><h1 id="对总的问题数，问题-答案长度和token数量和价格进行绘图"><a href="#对总的问题数，问题-答案长度和token数量和价格进行绘图" class="headerlink" title="对总的问题数，问题+答案长度和token数量和价格进行绘图"></a>对总的问题数，问题+答案长度和token数量和价格进行绘图</h1><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><code class="hljs routeros">def plot_prompt_token_num2(df_data):<br>    <span class="hljs-string">&quot;&quot;</span><span class="hljs-string">&quot;</span><br><span class="hljs-string">    根据prompt类型，统计总的问题长度，prompt长度</span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        df_data ():</span><br><span class="hljs-string">    Returns:</span><br><span class="hljs-string">    &quot;</span><span class="hljs-string">&quot;&quot;</span><br>    df_prompt_prefix_cnt = df_data[<span class="hljs-string">&#x27;prompt_type&#x27;</span>].value_counts().sort_values(<span class="hljs-attribute">ascending</span>=<span class="hljs-literal">False</span>)<br>    df_counts = df_prompt_prefix_cnt.reset_index()<br>    df_counts.columns = [<span class="hljs-string">&#x27;prompt_type&#x27;</span>, <span class="hljs-string">&#x27;count&#x27;</span>]<br>    # 每个token的人民币价格<br>    price_unit = 0.014/1000<br>    #对prompt_type进行groupby，根据groupby的结果对prompt_prefix_len求和，question_len求和，anwser_len求和，prompt_token_numanwser_token_numtotal_token_num<br>    df_sum = df_data.groupby(<span class="hljs-string">&quot;prompt_type&quot;</span>).agg(&#123;<span class="hljs-string">&quot;total_length&quot;</span>: <span class="hljs-string">&quot;sum&quot;</span>, <span class="hljs-string">&quot;total_token_num&quot;</span>: <span class="hljs-string">&quot;sum&quot;</span>&#125;)<br>    df_sum = df_sum.reset_index()<br>    df_sum = df_sum.sort_values(<span class="hljs-attribute">by</span>=<span class="hljs-string">&quot;total_token_num&quot;</span>, <span class="hljs-attribute">ascending</span>=<span class="hljs-literal">False</span>)<br>    # 加上df_counts中的count列<br>    df_sum = pd.merge(df_sum, df_counts, <span class="hljs-attribute">on</span>=<span class="hljs-string">&quot;prompt_type&quot;</span>, <span class="hljs-attribute">how</span>=<span class="hljs-string">&quot;left&quot;</span>)<br>    # 调换列的顺序，让count列在最前面，去掉<span class="hljs-string">&quot;prompt_token_num&quot;</span>, <span class="hljs-string">&quot;anwser_token_num&quot;</span>,<br>    df_sum = df_sum[[<span class="hljs-string">&quot;prompt_type&quot;</span>, <span class="hljs-string">&quot;count&quot;</span>, <span class="hljs-string">&quot;total_length&quot;</span>, <span class="hljs-string">&quot;total_token_num&quot;</span>]]<br>    # 计算总的价格，根据total_token_num乘以price_unit<br>    df_sum[<span class="hljs-string">&quot;total_price&quot;</span>] = df_sum[<span class="hljs-string">&quot;total_token_num&quot;</span>] * price_unit<br>    <span class="hljs-built_in">print</span>(f<span class="hljs-string">&quot;形状是&#123;df_sum.shape&#125;&quot;</span>)<br>    # 重命名列名, 去掉：<span class="hljs-string">&quot;提示token计数&quot;</span>, <span class="hljs-string">&quot;答案token计数&quot;</span>,<br>    df_sum.columns = [<span class="hljs-string">&quot;prompt_type&quot;</span>, <span class="hljs-string">&quot;问题个数&quot;</span>, <span class="hljs-string">&quot;单词总数&quot;</span>, <span class="hljs-string">&quot;总token数&quot;</span>,<span class="hljs-string">&quot;总价格人民币&quot;</span>]<br>    df_list = df_sum.to_dict(<span class="hljs-attribute">orient</span>=<span class="hljs-string">&quot;list&quot;</span>)<br>    prompt_types = df_list.pop(<span class="hljs-string">&quot;prompt_type&quot;</span>)<br>    # 其余的列转换成字典，key是列名，值是列表，list<br>    # 绘图<br>    x = np.arange(len(prompt_types))  # the label locations<br>    width = 0.1  # the width of the bars<br>    multiplier = 0<br><br>    fig, ax = plt.subplots(<span class="hljs-attribute">layout</span>=<span class="hljs-string">&#x27;constrained&#x27;</span>,figsize=(20, 10), <span class="hljs-attribute">dpi</span>=100)<br><br>    <span class="hljs-keyword">for</span> attribute, measurement <span class="hljs-keyword">in</span> df_list.items():<br>        offset = width * multiplier<br>        rects = ax.bar(x + offset, measurement, width, <span class="hljs-attribute">label</span>=attribute)<br>        ax.bar_label(rects, <span class="hljs-attribute">padding</span>=5)<br>        multiplier += 1<br><br>    # <span class="hljs-built_in">Add</span> some text <span class="hljs-keyword">for</span> labels, title <span class="hljs-keyword">and</span> custom x-axis tick labels, etc.<br>    ax.set_ylabel(<span class="hljs-string">&#x27;数量、长度、价格&#x27;</span>)<br>    # 设置标题<br>    ax.set_title(<span class="hljs-string">&#x27;问题类型和价格，问题长度，token数量的关系&#x27;</span>)<br>    ax.set_xticks(x + width, prompt_types)<br>    ax.legend(<span class="hljs-attribute">loc</span>=<span class="hljs-string">&#x27;upper left&#x27;</span>, <span class="hljs-attribute">ncols</span>=5)<br>    # 上限200万<br>    ax.set_ylim(0, 2000000)<br>    png_file = <span class="hljs-string">&quot;/Users/admin/tmp/question_prices2.png&quot;</span><br>    plt.savefig(png_file)<br>    <span class="hljs-built_in">print</span>(f<span class="hljs-string">&quot;保存到文件&#123;png_file&#125;&quot;</span>)<br></code></pre></td></tr></table></figure><img src="/2023/05/08/openai%E7%9A%84%E4%BB%B7%E6%A0%BC%E4%BC%B0%E8%AE%A1/question_prices2.png" class=""><img src="/2023/05/08/openai%E7%9A%84%E4%BB%B7%E6%A0%BC%E4%BC%B0%E8%AE%A1/question_prices.png" class=""><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>我们的任务都是中文的任务，根据单词总数和总的token数量的关系，我们可以算出token和单词总数的占比</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">1</span>.<span class="hljs-number">32419</span>/<span class="hljs-number">1</span>.<span class="hljs-number">70707</span>=<span class="hljs-number">0</span>.<span class="hljs-number">77570</span><br><span class="hljs-attribute">1</span>.<span class="hljs-number">25557</span>/<span class="hljs-number">1</span>.<span class="hljs-number">64893</span>=<span class="hljs-number">0</span>.<span class="hljs-number">76144</span><br></code></pre></td></tr></table></figure><p>所以1000个token大概相当于中文770个单词左右，由于我们的在统计中没有对少量英文进行切词，所以如果纯中文大概还会更多一些，相当于800个中文单词左右。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>利用chatgpt接口做超细粒度情感分析</title>
    <link href="/2023/05/08/%E5%88%A9%E7%94%A8chatgpt%E6%8E%A5%E5%8F%A3%E5%81%9A%E8%B6%85%E7%BB%86%E7%B2%92%E5%BA%A6%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/"/>
    <url>/2023/05/08/%E5%88%A9%E7%94%A8chatgpt%E6%8E%A5%E5%8F%A3%E5%81%9A%E8%B6%85%E7%BB%86%E7%B2%92%E5%BA%A6%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/</url>
    
    <content type="html"><![CDATA[<h1 id="本文主要使用chatpt进行细腻的情感分析"><a href="#本文主要使用chatpt进行细腻的情感分析" class="headerlink" title="本文主要使用chatpt进行细腻的情感分析"></a>本文主要使用chatpt进行细腻的情感分析</h1><p>我们平常做的情感分析主要是积极，消极和中性，其实积极是一个统称，其实有更细的情感，例如喜欢，爱，信任，祝福都表达的是积极，但是都有一些区别，如果客户需要分析哪些积极的因素，那么就需要更细腻的情感分析，因为人的情感是很复杂和微妙的。<br>下面是简要介绍个人总结的情感分析的粒度和强度介绍:</p><img src="/2023/05/08/%E5%88%A9%E7%94%A8chatgpt%E6%8E%A5%E5%8F%A3%E5%81%9A%E8%B6%85%E7%BB%86%E7%B2%92%E5%BA%A6%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90%E7%9A%84%E7%B2%92%E5%BA%A6%E5%92%8C%E5%BC%BA%E5%BA%A6.png" class=""><h1 id="主要步骤"><a href="#主要步骤" class="headerlink" title="主要步骤"></a>主要步骤</h1><ol><li>提取数据</li><li>根据任务设计chatgpt的prompt提示</li><li>对数据进行调用chatgpt的api</li><li>解析chatgpt结果</li><li>保存数据和绘图</li></ol><h2 id="提取数据"><a href="#提取数据" class="headerlink" title="提取数据"></a>提取数据</h2><p>通过hive获取数据，保存成本地的excel文件，方便读取</p><h2 id="设计提示prompt"><a href="#设计提示prompt" class="headerlink" title="设计提示prompt"></a>设计提示prompt</h2><p>我们只分析20个左右的情感维度, 所以prompt设计如下:<br>prompt &#x3D; ‘分析下面的评论中的细微情感，并归类到以下的情感维度中的一个或几个，情感维度包括:开心,愉快,信任,值得,关心,安全,关注,刺激,能量,纵容，感兴趣，探索，不满意，纠结，失望，激怒，压力，不开心，忽视，焦虑， 并给出你认为的情感强度，量化量化上述情绪，值是1-5，答案用json格式返回，示例是:[{“信任”: 1}, {“感兴趣”: 4}, {“失望”: 3}]，并在答案末尾给出导致这种情感的原因？’</p><h1 id="其余步骤的代码如下：注意chatgpt由于是语言模型，不会完全按照prompt进行回答，所以答案有些出入，需要进行特殊处理"><a href="#其余步骤的代码如下：注意chatgpt由于是语言模型，不会完全按照prompt进行回答，所以答案有些出入，需要进行特殊处理" class="headerlink" title="其余步骤的代码如下：注意chatgpt由于是语言模型，不会完全按照prompt进行回答，所以答案有些出入，需要进行特殊处理."></a>其余步骤的代码如下：注意chatgpt由于是语言模型，不会完全按照prompt进行回答，所以答案有些出入，需要进行特殊处理.</h1><p>绘图结果:<br>情感维度平均值:</p><img src="/2023/05/08/%E5%88%A9%E7%94%A8chatgpt%E6%8E%A5%E5%8F%A3%E5%81%9A%E8%B6%85%E7%BB%86%E7%B2%92%E5%BA%A6%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/20230506_%E5%A4%84%E7%90%86%E7%BB%93%E6%9E%9C_%E6%98%A0%E5%B0%84_%E6%83%85%E6%84%9F%E7%BB%B4%E5%BA%A6%E5%B9%B3%E5%9D%87%E5%80%BC.png" class=""><p>情感维度分布图:</p><img src="/2023/05/08/%E5%88%A9%E7%94%A8chatgpt%E6%8E%A5%E5%8F%A3%E5%81%9A%E8%B6%85%E7%BB%86%E7%B2%92%E5%BA%A6%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/20230506_%E5%A4%84%E7%90%86%E7%BB%93%E6%9E%9C_%E6%98%A0%E5%B0%84_%E6%83%85%E6%84%9F%E7%BB%B4%E5%BA%A6%E5%88%86%E5%B8%83%E5%9B%BE.png" class=""><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#!/usr/bin/env python</span><br><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># @Date  : 2023/5/6 14:57</span><br><span class="hljs-comment"># @File  : sentiment_openai.py</span><br><span class="hljs-comment"># @Author: </span><br><span class="hljs-comment"># @Desc  : 使用chatgpt进行细粒度的情感分析</span><br><br><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> collections<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br>sentiment_mapper = &#123;<br>    <span class="hljs-string">&quot;开心&quot;</span>: <span class="hljs-string">&quot;Happy&quot;</span>,<br>    <span class="hljs-string">&quot;满意&quot;</span>: <span class="hljs-string">&quot;Happy&quot;</span>,  <span class="hljs-comment"># 这个是我自己加的</span><br>    <span class="hljs-string">&quot;喜欢&quot;</span>: <span class="hljs-string">&quot;Happy&quot;</span>,  <span class="hljs-comment"># 这个是我自己加的</span><br>    <span class="hljs-string">&quot;愉快&quot;</span>: <span class="hljs-string">&quot;Pleased&quot;</span>,<br>    <span class="hljs-string">&quot;信任&quot;</span>: <span class="hljs-string">&quot;Trusting&quot;</span>,<br>    <span class="hljs-string">&quot;怀念&quot;</span>: <span class="hljs-string">&quot;Trusting&quot;</span>,  <span class="hljs-comment"># 这个是我自己加的</span><br>    <span class="hljs-string">&quot;值得&quot;</span>: <span class="hljs-string">&quot;Valued&quot;</span>,<br>    <span class="hljs-string">&quot;赞叹&quot;</span>: <span class="hljs-string">&quot;Valued&quot;</span>,   <span class="hljs-comment"># 这个是我自己加的</span><br>    <span class="hljs-string">&quot;支持&quot;</span>: <span class="hljs-string">&quot;Valued&quot;</span>,   <span class="hljs-comment"># 这个是我自己加的</span><br>    <span class="hljs-string">&quot;关心&quot;</span>: <span class="hljs-string">&quot;Cared for&quot;</span>,<br>    <span class="hljs-string">&quot;安全&quot;</span>: <span class="hljs-string">&quot;Safe&quot;</span>,<br>    <span class="hljs-string">&quot;关注&quot;</span>: <span class="hljs-string">&quot;Focused&quot;</span>,<br>    <span class="hljs-string">&quot;同情&quot;</span>: <span class="hljs-string">&quot;Focused&quot;</span>,  <span class="hljs-comment"># 这个是我自己加的</span><br>    <span class="hljs-string">&quot;激动&quot;</span>: <span class="hljs-string">&quot;Stimulated&quot;</span>, <span class="hljs-comment"># 这个是我自己加的</span><br>    <span class="hljs-string">&quot;刺激&quot;</span>: <span class="hljs-string">&quot;Stimulated&quot;</span>,<br>    <span class="hljs-string">&quot;能量&quot;</span>: <span class="hljs-string">&quot;Energized&quot;</span>,<br>    <span class="hljs-string">&quot;纵容&quot;</span>: <span class="hljs-string">&quot;Indulged&quot;</span>,<br>    <span class="hljs-string">&quot;感兴趣&quot;</span>: <span class="hljs-string">&quot;Interested&quot;</span>,<br>    <span class="hljs-string">&quot;探索&quot;</span>: <span class="hljs-string">&quot;Exploratory&quot;</span>,<br>    <span class="hljs-string">&quot;不满意&quot;</span>: <span class="hljs-string">&quot;Unsatisfied&quot;</span>,<br>    <span class="hljs-string">&quot;不信任&quot;</span>: <span class="hljs-string">&quot;Unsatisfied&quot;</span>,  <span class="hljs-comment"># 这个是我自己加的</span><br>    <span class="hljs-string">&quot;纠结&quot;</span>: <span class="hljs-string">&quot;Frustrated&quot;</span>,<br>    <span class="hljs-string">&quot;困惑&quot;</span>: <span class="hljs-string">&quot;Frustrated&quot;</span>, <span class="hljs-comment"># 这个是我自己加的</span><br>    <span class="hljs-string">&quot;失望&quot;</span>: <span class="hljs-string">&quot;Disappointed&quot;</span>,<br>    <span class="hljs-string">&quot;激怒&quot;</span>: <span class="hljs-string">&quot;Irritated&quot;</span>,<br>    <span class="hljs-string">&quot;压力&quot;</span>: <span class="hljs-string">&quot;Stressed&quot;</span>,<br>    <span class="hljs-string">&quot;不开心&quot;</span>: <span class="hljs-string">&quot;Unhappy&quot;</span>,<br>    <span class="hljs-string">&quot;无聊&quot;</span>: <span class="hljs-string">&quot;Unhappy&quot;</span>, <span class="hljs-comment"># 这个是我自己加的</span><br>    <span class="hljs-string">&quot;无趣&quot;</span>: <span class="hljs-string">&quot;Unhappy&quot;</span>, <span class="hljs-comment"># 这个是我自己加的</span><br>    <span class="hljs-string">&quot;忽视&quot;</span>: <span class="hljs-string">&quot;Neglected&quot;</span>,<br>    <span class="hljs-string">&quot;焦虑&quot;</span>: <span class="hljs-string">&quot;Hurried&quot;</span>,<br>    <span class="hljs-string">&quot;焦急&quot;</span>: <span class="hljs-string">&quot;Hurried&quot;</span>,<br>&#125;<br><br>sentimeng_group = &#123;<br>    <span class="hljs-string">&quot;Adovcacy&quot;</span>: [<span class="hljs-string">&quot;Happy&quot;</span>,<span class="hljs-string">&quot;Pleased&quot;</span>],<br>    <span class="hljs-string">&quot;Recommendation&quot;</span>: [<span class="hljs-string">&quot;Trusting&quot;</span>,<span class="hljs-string">&quot;Valued&quot;</span>,<span class="hljs-string">&quot;Cared for&quot;</span>, <span class="hljs-string">&quot;Safe&quot;</span>, <span class="hljs-string">&quot;Focused&quot;</span>],<br>    <span class="hljs-string">&quot;Attention&quot;</span>: [<span class="hljs-string">&quot;Stimulated&quot;</span>,<span class="hljs-string">&quot;Energized&quot;</span>,<span class="hljs-string">&quot;Indulged&quot;</span>,<span class="hljs-string">&quot;Interested&quot;</span>,<span class="hljs-string">&quot;Exploratory&quot;</span>],<br>    <span class="hljs-string">&quot;Destroyer&quot;</span>: [<span class="hljs-string">&quot;Unsatisfied&quot;</span>,<span class="hljs-string">&quot;Frustrated&quot;</span>,<span class="hljs-string">&quot;Disappointed&quot;</span>,<span class="hljs-string">&quot;Irritated&quot;</span>,<span class="hljs-string">&quot;Stressed&quot;</span>,<span class="hljs-string">&quot;Unhappy&quot;</span>,<span class="hljs-string">&quot;Neglected&quot;</span>,<span class="hljs-string">&quot;Hurried&quot;</span>],<br>&#125;<br><span class="hljs-comment">#对sentimeng_group中的value每个元素给一个颜色的名称，用于后面的散点图的颜色</span><br>sentiment_color = &#123;<br>    <span class="hljs-string">&quot;Happy&quot;</span>: <span class="hljs-string">&quot;blue&quot;</span>, <span class="hljs-comment"># 蓝色，下一个是天蓝色</span><br>    <span class="hljs-string">&quot;Pleased&quot;</span>: <span class="hljs-string">&quot;skyblue&quot;</span>,<br>    <span class="hljs-string">&quot;Trusting&quot;</span>: <span class="hljs-string">&quot;green&quot;</span>, <span class="hljs-comment"># 绿色，下一个是浅绿色</span><br>    <span class="hljs-string">&quot;Valued&quot;</span>: <span class="hljs-string">&quot;lightgreen&quot;</span>, <span class="hljs-comment">#下一个是墨绿色</span><br>    <span class="hljs-string">&quot;Cared for&quot;</span>: <span class="hljs-string">&quot;darkgreen&quot;</span>,<br>    <span class="hljs-string">&quot;Safe&quot;</span>: <span class="hljs-string">&quot;yellow&quot;</span>, <span class="hljs-comment"># 下一个是金色</span><br>    <span class="hljs-string">&quot;Focused&quot;</span>: <span class="hljs-string">&quot;gold&quot;</span>, <span class="hljs-comment"># 下一个是橙色</span><br>    <span class="hljs-string">&quot;Stimulated&quot;</span>: <span class="hljs-string">&quot;orange&quot;</span>, <span class="hljs-comment"># 下一个是红色</span><br>    <span class="hljs-string">&quot;Energized&quot;</span>: <span class="hljs-string">&quot;red&quot;</span>, <span class="hljs-comment"># 下一个是深红色</span><br>    <span class="hljs-string">&quot;Indulged&quot;</span>: <span class="hljs-string">&quot;darkred&quot;</span>,<br>    <span class="hljs-string">&quot;Interested&quot;</span>: <span class="hljs-string">&quot;purple&quot;</span>, <span class="hljs-comment"># 下一个是青色</span><br>    <span class="hljs-string">&quot;Exploratory&quot;</span>: <span class="hljs-string">&quot;cyan&quot;</span>,<br>    <span class="hljs-string">&quot;Unsatisfied&quot;</span>: <span class="hljs-string">&quot;pink&quot;</span>, <span class="hljs-comment"># 下一个是深粉色</span><br>    <span class="hljs-string">&quot;Frustrated&quot;</span>: <span class="hljs-string">&quot;deeppink&quot;</span>, <span class="hljs-comment"># 下一个是深粉色</span><br>    <span class="hljs-string">&quot;Disappointed&quot;</span>: <span class="hljs-string">&quot;hotpink&quot;</span>, <span class="hljs-comment"># 下一个是深粉色</span><br>    <span class="hljs-string">&quot;Irritated&quot;</span>: <span class="hljs-string">&quot;lightpink&quot;</span>, <span class="hljs-comment"># 下一个是深粉色</span><br>    <span class="hljs-string">&quot;Stressed&quot;</span>: <span class="hljs-string">&quot;deeppink&quot;</span>, <span class="hljs-comment"># 下一个是黄色</span><br>    <span class="hljs-string">&quot;Unhappy&quot;</span>: <span class="hljs-string">&quot;lightyellow&quot;</span>, <span class="hljs-comment"># 下一个是黄色</span><br>    <span class="hljs-string">&quot;Neglected&quot;</span>: <span class="hljs-string">&quot;yellow&quot;</span>, <span class="hljs-comment"># 下一个是淡青色</span><br>    <span class="hljs-string">&quot;Hurried&quot;</span>: <span class="hljs-string">&quot;lightcyan&quot;</span>,<br>&#125;<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict_chat</span>(<span class="hljs-params">excel=<span class="hljs-string">&#x27;/Users/admin/Downloads/20230506原始数据.xlsx&#x27;</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    预测excel中的数据</span><br><span class="hljs-string">    :return:</span><br><span class="hljs-string">    返回结果:</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    save_excel = <span class="hljs-string">&#x27;/Users/admin/Downloads/20230506_处理结果.xlsx&#x27;</span><br>    <span class="hljs-comment">#读取excel中的数据</span><br>    df = pd.read_excel(excel)<br>    <span class="hljs-comment"># 调用do_predict接口</span><br>    prompt = <span class="hljs-string">&#x27;分析下面的评论中的细微情感，并归类到以下的情感维度中的一个或几个，情感维度包括:开心,愉快,信任,值得,关心,安全,关注,刺激,能量,纵容，感兴趣，探索，不满意，纠结，失望，激怒，压力，不开心，忽视，焦虑， 并给出你认为的情感强度，量化量化上述情绪，值是1-5，答案用json格式返回，示例是:[&#123;&quot;信任&quot;: 1&#125;, &#123;&quot;感兴趣&quot;: 4&#125;, &#123;&quot;失望&quot;: 3&#125;]，并在答案末尾给出导致这种情感的原因？&#x27;</span><br>    data = []<br>    <span class="hljs-keyword">for</span> idx, row <span class="hljs-keyword">in</span> df.iterrows():<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;正在处理第<span class="hljs-subst">&#123;idx&#125;</span>条数据&quot;</span>)<br>        start_time = time.time()<br>        text = row[<span class="hljs-string">&#x27;text&#x27;</span>]<br>        result = do_predict(prompt, text)<br>        response = result[<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;result&#x27;</span>][<span class="hljs-string">&#x27;choices&#x27;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;message&#x27;</span>]<br>        content = response[<span class="hljs-string">&quot;content&quot;</span>]<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;content返回结果: <span class="hljs-subst">&#123;content&#125;</span>&quot;</span>)<br>        data.append(&#123;<br>            <span class="hljs-string">&quot;text&quot;</span>: text,<br>            <span class="hljs-string">&quot;response&quot;</span>: content<br>        &#125;)<br>        end_time = time.time()<br>        cost_time = end_time - start_time<br>        <span class="hljs-comment"># if cost_time &gt; 0.5:</span><br>            <span class="hljs-comment"># 如果不是缓存过数据，那么就sleep一段时间</span><br>            <span class="hljs-comment"># time.sleep(15)</span><br>    <span class="hljs-comment"># 保存结果</span><br>    df = pd.DataFrame(data)<br>    df.to_excel(save_excel, index=<span class="hljs-literal">False</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;处理完成, 保存结果到: <span class="hljs-subst">&#123;save_excel&#125;</span>&quot;</span>)<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">do_predict</span>(<span class="hljs-params">prompt, text</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        prompt ():</span><br><span class="hljs-string">        text ():</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Returns:</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    host = <span class="hljs-string">&#x27;mysig&#x27;</span><br>    host_sentiment = <span class="hljs-string">f&#x27;http://<span class="hljs-subst">&#123;host&#125;</span>:4636&#x27;</span><br>    data = [&#123;<span class="hljs-string">&quot;prompt&quot;</span>: prompt,<span class="hljs-string">&quot;text&quot;</span>: text&#125;]<br>    params = &#123;<span class="hljs-string">&#x27;data&#x27;</span>: data&#125;<br>    headers = &#123;<span class="hljs-string">&#x27;content-type&#x27;</span>: <span class="hljs-string">&#x27;application/json&#x27;</span>&#125;<br>    url = <span class="hljs-string">&quot;&#123;&#125;/api/openai&quot;</span>.<span class="hljs-built_in">format</span>(host_sentiment)<br>    r = requests.post(url, headers=headers, data=json.dumps(params), timeout=<span class="hljs-number">1200</span>)<br>    result = r.json()<br>    <span class="hljs-keyword">if</span> r.status_code == <span class="hljs-number">200</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;返回结果: <span class="hljs-subst">&#123;result&#125;</span>&quot;</span>)<br>        <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(result) == <span class="hljs-built_in">len</span>(data), <span class="hljs-string">f&quot;返回结果个数不正确, 期望个数: <span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(data)&#125;</span>, 实际个数: <span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(result)&#125;</span>&quot;</span><br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">print</span>(r.status_code)<br>        <span class="hljs-built_in">print</span>(result)<br>    <span class="hljs-keyword">return</span> result<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">mapper_excel</span>():<br>    db_excel = <span class="hljs-string">&#x27;/Users/admin/Downloads/20230506原始数据.xlsx&#x27;</span><br>    src_excel = <span class="hljs-string">&#x27;/Users/admin/Downloads/20230506_处理结果.xlsx&#x27;</span><br>    save_excel = <span class="hljs-string">&#x27;/Users/admin/Downloads/20230506_处理结果_映射.xlsx&#x27;</span><br>    df = pd.read_excel(src_excel)<br>    <span class="hljs-keyword">for</span> idx, row <span class="hljs-keyword">in</span> df.iterrows():<br>        response = row[<span class="hljs-string">&#x27;response&#x27;</span>]<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;正在处理第<span class="hljs-subst">&#123;idx&#125;</span>条数据,数据是: <span class="hljs-subst">&#123;response&#125;</span>&quot;</span>)<br>        response = response.replace(<span class="hljs-string">&#x27;&#123;\n  &#x27;</span>, <span class="hljs-string">&#x27;&#123;&#x27;</span>).replace(<span class="hljs-string">&#x27;\n&#125;&#x27;</span>, <span class="hljs-string">&#x27;&#125;&#x27;</span>).replace(<span class="hljs-string">&#x27;,\n&#x27;</span>, <span class="hljs-string">&#x27;,&#x27;</span>).replace(<span class="hljs-string">&quot;&#x27;&quot;</span>,<span class="hljs-string">&#x27;&#x27;</span>)<br>        <span class="hljs-comment"># 按照\n进行分割,分成2部分</span><br>        response_split = response.split(<span class="hljs-string">&#x27;\n&#x27;</span>)<br>        <span class="hljs-comment">#第一部分加载成json，第二部分是原因，不需要处理，是text格式</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(response_split) == <span class="hljs-number">1</span>:<br>            response_split = response.split(<span class="hljs-string">&#x27;]，&#x27;</span>)<br>            response_split[<span class="hljs-number">0</span>] = response_split[<span class="hljs-number">0</span>] + <span class="hljs-string">&#x27;]&#x27;</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(response_split) == <span class="hljs-number">1</span>:<br>            response_split = response.split(<span class="hljs-string">&#x27;] 原因&#x27;</span>)<br>            response_split[<span class="hljs-number">0</span>] = response_split[<span class="hljs-number">0</span>] + <span class="hljs-string">&#x27;]&#x27;</span><br>        first_part = response_split[<span class="hljs-number">0</span>]<br>        first_part = first_part.replace(<span class="hljs-string">&#x27;。&#x27;</span>, <span class="hljs-string">&#x27;&#x27;</span>).strip(<span class="hljs-string">&#x27;，&#x27;</span>)<br>        json_data_list = json.loads(first_part)<br>        <span class="hljs-comment"># 对json_data进行处理，映射成英文</span><br>        new_json_data = &#123;&#125;<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(json_data_list, <span class="hljs-built_in">list</span>):<br>            <span class="hljs-keyword">for</span> one_data <span class="hljs-keyword">in</span> json_data_list:<br>                <span class="hljs-keyword">for</span> key, value <span class="hljs-keyword">in</span> one_data.items():<br>                    english_key = sentiment_mapper[key]<br>                    new_json_data[english_key] = value<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-comment"># 字典的格式</span><br>            <span class="hljs-keyword">for</span> key, value <span class="hljs-keyword">in</span> json_data_list.items():<br>                english_key = sentiment_mapper[key]<br>                new_json_data[english_key] = value<br>        reason = <span class="hljs-string">&#x27;。&#x27;</span>.join(response_split[<span class="hljs-number">1</span>:])<br>        df.loc[idx, <span class="hljs-string">&#x27;response&#x27;</span>] = json.dumps(new_json_data)<br>        df.loc[idx, <span class="hljs-string">&#x27;reason&#x27;</span>] = reason<br>    <span class="hljs-comment">#合并db_excel和df</span><br>    db_df = pd.read_excel(db_excel)<br>    <span class="hljs-comment"># 只需要db_df中的channel和text字段</span><br>    db_df = db_df[[<span class="hljs-string">&#x27;channel&#x27;</span>, <span class="hljs-string">&#x27;text&#x27;</span>]]<br>    df = pd.merge(db_df, df, on=<span class="hljs-string">&#x27;text&#x27;</span>, how=<span class="hljs-string">&#x27;left&#x27;</span>)<br>    df.to_excel(save_excel, index=<span class="hljs-literal">False</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;列现在是: <span class="hljs-subst">&#123;df.columns&#125;</span>&quot;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;处理完成, 保存结果到: <span class="hljs-subst">&#123;save_excel&#125;</span>&quot;</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">do_plot</span>():<br>    src_excel = <span class="hljs-string">&#x27;/Users/admin/Downloads/20230506_处理结果_映射.xlsx&#x27;</span><br>    sentiment_mean_png = <span class="hljs-string">&#x27;/Users/admin/Downloads/20230506_处理结果_映射_情感维度平均值.png&#x27;</span><br>    <span class="hljs-comment"># 绘图</span><br>    df = pd.read_excel(src_excel)<br>    <span class="hljs-comment"># 绘制情感维度的分布图</span><br>    sentiments = df[<span class="hljs-string">&#x27;response&#x27;</span>].tolist()<br>    <span class="hljs-comment"># flatten 情感维度</span><br>    sentiments = [json.loads(sentiment) <span class="hljs-keyword">for</span> sentiment <span class="hljs-keyword">in</span> sentiments]<br>    sentiment_list = collections.defaultdict(<span class="hljs-built_in">list</span>)<br>    <span class="hljs-keyword">for</span> sentiment <span class="hljs-keyword">in</span> sentiments:<br>        <span class="hljs-keyword">for</span> key, value <span class="hljs-keyword">in</span> sentiment.items():<br>            sentiment_list[key].append(value)<br>    <span class="hljs-comment"># 绘制情感维度的分布图</span><br>    <span class="hljs-comment"># for key, value in sentiment_list.items():</span><br>    <span class="hljs-comment">#     plt.hist(value, bins=20)</span><br>    <span class="hljs-comment">#     plt.title(f&quot;&#123;key&#125; distribute&quot;)</span><br>    <span class="hljs-comment">#     plt.show()</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;125个数据中，情感维度的分布是: <span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(sentiment_list)&#125;</span>&quot;</span>)<br>    <span class="hljs-comment"># 平均情感强度，然后绘制直方图</span><br>    sentiment_mean = &#123;&#125;<br>    <span class="hljs-keyword">for</span> key, value <span class="hljs-keyword">in</span> sentiment_list.items():<br>        sentiment_mean[key] = np.mean(value)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;情感维度的平均值是: <span class="hljs-subst">&#123;sentiment_mean&#125;</span>&quot;</span>)<br>    <span class="hljs-comment"># 绘制情感维度的分布图, 情感名称作为x轴，情感强度作为y轴</span><br>    x = <span class="hljs-built_in">list</span>(sentiment_mean.keys())<br>    y = <span class="hljs-built_in">list</span>(sentiment_mean.values())<br>    <span class="hljs-comment">#设置图片大一点，分辨率也大一点</span><br>    plt.figure(figsize=(<span class="hljs-number">20</span>, <span class="hljs-number">10</span>), dpi=<span class="hljs-number">100</span>)<br>    plt.bar(x, y)<br>    <span class="hljs-comment"># 倾斜x轴的标签</span><br>    plt.xticks(rotation=<span class="hljs-number">45</span>)<br>    plt.xlabel(<span class="hljs-string">&quot;name&quot;</span>)<br>    plt.ylabel(<span class="hljs-string">&quot;strength&quot;</span>)<br>    <span class="hljs-comment"># 设置图例</span><br>    plt.legend(loc=<span class="hljs-string">&quot;upper right&quot;</span>)<br>    plt.title(<span class="hljs-string">f&quot;125 comments sentiment mean&quot;</span>)<br>    <span class="hljs-comment"># plt.show()</span><br>    <span class="hljs-comment">#保存到图片</span><br>    plt.savefig(sentiment_mean_png)<br>    <span class="hljs-comment"># 绘制情感维度分布图，考虑sentimeng_group对x轴的标签进行分组</span><br>    <span class="hljs-comment"># 绘制情感维度的分布图, 绘制在一张图上</span><br>    plt.clf()<br>    <span class="hljs-comment">#绘制一个散点图，不同情感代表不同的颜色，x轴是情感维度，y轴是情感强度</span><br>    <span class="hljs-comment"># 绘制散点图</span><br>    plt.figure(figsize=(<span class="hljs-number">20</span>, <span class="hljs-number">10</span>), dpi=<span class="hljs-number">100</span>)<br>    plt.rcParams.update(&#123;<span class="hljs-string">&#x27;font.size&#x27;</span>: <span class="hljs-number">12</span>&#125;)<br>    <span class="hljs-keyword">for</span> i, (name, value) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(sentiment_list.items()):<br>        color = sentiment_color[name]<br>        size = [i*random.randint(<span class="hljs-number">1</span>,<span class="hljs-number">10</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> value]<br>        value = [i-random.random() <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> value]<br>        <span class="hljs-comment"># 点变大一些</span><br>        plt.scatter([i+<span class="hljs-number">1</span>]*<span class="hljs-built_in">len</span>(value), value, s=size, c=color, alpha=<span class="hljs-number">0.5</span>, edgecolors=<span class="hljs-string">&#x27;none&#x27;</span>)<br>    <span class="hljs-comment"># 设置x轴的标签</span><br>    plt.xticks(<span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(sentiment_list)+<span class="hljs-number">1</span>), <span class="hljs-built_in">list</span>(sentiment_list.keys()), rotation=<span class="hljs-number">45</span>)<br>    <span class="hljs-comment"># 设置图例和标签</span><br>    plt.legend(sentiment_color, loc=<span class="hljs-string">&quot;upper right&quot;</span>)<br>    plt.xlabel(<span class="hljs-string">&quot;Sentiment&quot;</span>)<br>    plt.ylabel(<span class="hljs-string">&quot;Strength&quot;</span>)<br>    plt.title(<span class="hljs-string">f&quot;Sentiment Strength Distribution&quot;</span>)<br>    <span class="hljs-comment"># 显示图形</span><br>    <span class="hljs-comment"># plt.show()</span><br>    <span class="hljs-comment"># 保存到图片</span><br>    plt.savefig(<span class="hljs-string">&#x27;/Users/admin/Downloads/20230506_处理结果_映射_情感维度分布图.png&#x27;</span>)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    predict_chat()<br>    mapper_excel()<br>    do_plot()<br></code></pre></td></tr></table></figure>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>openai接口使用和价格</title>
    <link href="/2023/05/08/openai%E6%8E%A5%E5%8F%A3%E4%BD%BF%E7%94%A8%E5%92%8C%E4%BB%B7%E6%A0%BC/"/>
    <url>/2023/05/08/openai%E6%8E%A5%E5%8F%A3%E4%BD%BF%E7%94%A8%E5%92%8C%E4%BB%B7%E6%A0%BC/</url>
    
    <content type="html"><![CDATA[<h1 id="本文主要介绍下Openai的接口api和价格信息"><a href="#本文主要介绍下Openai的接口api和价格信息" class="headerlink" title="本文主要介绍下Openai的接口api和价格信息"></a>本文主要介绍下Openai的接口api和价格信息</h1><p>接口主要是列出所有模型，查询某个模型信息，句子补全，聊天接口<br>价格是换算成人民币的价格</p><img src="/2023/05/08/openai%E6%8E%A5%E5%8F%A3%E4%BD%BF%E7%94%A8%E5%92%8C%E4%BB%B7%E6%A0%BC/Openai%E6%8E%A5%E5%8F%A3%E5%92%8C%E4%BB%B7%E6%A0%BC.png" class="">]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>生成语言模型temperature_topp_topk解析</title>
    <link href="/2023/04/28/%E7%94%9F%E6%88%90%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8Btemperature-topp-topk%E8%A7%A3%E6%9E%90/"/>
    <url>/2023/04/28/%E7%94%9F%E6%88%90%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8Btemperature-topp-topk%E8%A7%A3%E6%9E%90/</url>
    
    <content type="html"><![CDATA[<h1 id="在大型生成语言模型中，我们经常用到这些超参数temperature，topk，topp，下面根据源码进行分析"><a href="#在大型生成语言模型中，我们经常用到这些超参数temperature，topk，topp，下面根据源码进行分析" class="headerlink" title="在大型生成语言模型中，我们经常用到这些超参数temperature，topk，topp，下面根据源码进行分析"></a>在大型生成语言模型中，我们经常用到这些超参数temperature，topk，topp，下面根据源码进行分析</h1><p>在huggingface transformers中，这3个对分数的处理时串联的，先进行temperature，然后topk，最后topp,当然，如果用户自己定义了分数过滤器，用户的过滤器优先。</p><h1 id="temperature"><a href="#temperature" class="headerlink" title="temperature"></a>temperature</h1><p>越大，随机性越高，因为scores越接近</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs ruby"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TemperatureLogitsWarper</span>(<span class="hljs-title">LogitsWarper</span>):</span><br>    r<span class="hljs-string">&quot;&quot;</span><span class="hljs-string">&quot;</span><br><span class="hljs-string">    [`LogitsWarper`] for temperature (exponential scaling output probability distribution).</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        temperature (`float`):</span><br><span class="hljs-string">            The value used to module the logits distribution.</span><br><span class="hljs-string">    &quot;</span><span class="hljs-string">&quot;&quot;</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(<span class="hljs-keyword">self</span>, <span class="hljs-symbol">temperature:</span> float)</span></span>:<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> isinstance(temperature, float) <span class="hljs-keyword">or</span> <span class="hljs-keyword">not</span> (temperature &gt; <span class="hljs-number">0</span>):<br>            raise ValueError(f<span class="hljs-string">&quot;`temperature` has to be a strictly positive float, but is &#123;temperature&#125;&quot;</span>)<br><br>        <span class="hljs-keyword">self</span>.temperature = temperature<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__call__</span><span class="hljs-params">(<span class="hljs-keyword">self</span>, <span class="hljs-symbol">input_ids:</span> torch.Tensor, <span class="hljs-symbol">scores:</span> torch.Tensor)</span></span> -&gt; torch.<span class="hljs-symbol">FloatTensor:</span><br>        scores = scores / <span class="hljs-keyword">self</span>.temperature<br>        <span class="hljs-keyword">return</span> scores<br></code></pre></td></tr></table></figure><h1 id="topk"><a href="#topk" class="headerlink" title="topk"></a>topk</h1><p>越大随机性越高，小于topk的都设置成很小的值了</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs vim">class TopKLogitsWarper(LogitsWarper):<br>    r<span class="hljs-string">&quot;&quot;</span><span class="hljs-comment">&quot;</span><br>    [`LogitsWarper`] that performs top-<span class="hljs-keyword">k</span>, i.<span class="hljs-keyword">e</span>. restricting <span class="hljs-keyword">to</span> the <span class="hljs-keyword">k</span> highest probability elements.<br><br>    Args:<br>        top_k (`<span class="hljs-keyword">int</span>`):<br>            The <span class="hljs-keyword">number</span> of highest probability vocabulary tokens <span class="hljs-keyword">to</span> keep <span class="hljs-keyword">for</span> top-<span class="hljs-keyword">k</span>-filtering.<br>        filter_value (`float`, *optional*, defaults <span class="hljs-keyword">to</span> `-float(<span class="hljs-string">&quot;Inf&quot;</span>)`):<br>            All filtered <span class="hljs-built_in">values</span> will <span class="hljs-keyword">be</span> <span class="hljs-keyword">set</span> <span class="hljs-keyword">to</span> this float value.<br>        min_tokens_to_keep (`<span class="hljs-keyword">int</span>`, *optional*, defaults <span class="hljs-keyword">to</span> <span class="hljs-number">1</span>):<br>            Minimum <span class="hljs-keyword">number</span> of tokens that cannot <span class="hljs-keyword">be</span> filtered.<br>    <span class="hljs-string">&quot;&quot;</span><span class="hljs-comment">&quot;</span><br><br>    def __init__(self, top_k: <span class="hljs-keyword">int</span>, filter_value: float = -float(<span class="hljs-string">&quot;Inf&quot;</span>), min_tokens_to_keep: <span class="hljs-keyword">int</span> = <span class="hljs-number">1</span>):<br>        <span class="hljs-keyword">if</span> not isinstance(top_k, <span class="hljs-keyword">int</span>) <span class="hljs-built_in">or</span> top_k &lt;= <span class="hljs-number">0</span>:<br>            raise ValueError(<span class="hljs-keyword">f</span><span class="hljs-string">&quot;`top_k` has to be a strictly positive integer, but is &#123;top_k&#125;&quot;</span>)<br><br>        self.top_k = <span class="hljs-built_in">max</span>(top_k, min_tokens_to_keep)<br>        self.filter_value = filter_value<br><br>    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -&gt; torch.FloatTensor:<br>        top_k = <span class="hljs-built_in">min</span>(self.top_k, scores.size(-<span class="hljs-number">1</span>))  # Safety check<br>        # Remove <span class="hljs-keyword">all</span> tokens with <span class="hljs-keyword">a</span> probability less than the <span class="hljs-keyword">last</span> token of the top-<span class="hljs-keyword">k</span><br>        indices_to_remove = scores &lt; torch.topk(scores, top_k)[<span class="hljs-number">0</span>][..., -<span class="hljs-number">1</span>, None]<br>        scores = scores.masked_fill(indices_to_remove, self.filter_value)<br>        <span class="hljs-keyword">return</span> scores<br></code></pre></td></tr></table></figure><p>示例:</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs ruby">import torch<br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">FilterTokens</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(<span class="hljs-keyword">self</span>, <span class="hljs-symbol">top_k:</span> int, <span class="hljs-symbol">filter_value:</span> float = -float(<span class="hljs-string">&#x27;Inf&#x27;</span>)</span></span>):<br>        <span class="hljs-keyword">self</span>.top_k = top_k   <span class="hljs-comment"># 3</span><br>        <span class="hljs-comment"># 过滤值通常被设置为一个很小的负数，以避免对后续计算产生影响</span><br>        <span class="hljs-keyword">self</span>.filter_value = filter_value   <span class="hljs-comment"># -1e9或者-float(&#x27;Inf&#x27;)</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__call__</span><span class="hljs-params">(<span class="hljs-keyword">self</span>, <span class="hljs-symbol">input_ids:</span> torch.LongTensor, <span class="hljs-symbol">scores:</span> torch.FloatTensor)</span></span> -&gt; torch.<span class="hljs-symbol">FloatTensor:</span><br>        top_k = min(<span class="hljs-keyword">self</span>.top_k, scores.size(-<span class="hljs-number">1</span>))  <span class="hljs-comment"># 防止top_k大于scores的最后一维</span><br>        <span class="hljs-comment"># torch.topk(scores, top_k)返回两个tensor，第一个是top_k个最大值，第二个是对应的索引, 获取第0个tensor，即top_k个最大值</span><br>        <span class="hljs-comment"># [..., -1, None]表示在倒数第二个维度上取最后一个值，即取最后一个维度的值，作为阈值</span><br>        <span class="hljs-comment"># scores &lt; xxxx： 表示scores中小于阈值的值，都设置为False</span><br>        indices_to_remove = scores &lt; torch.topk(scores, top_k)[<span class="hljs-number">0</span>][..., -<span class="hljs-number">1</span>, None]<br>        <span class="hljs-comment"># 将scores中小于阈值的值，都设置为filter_value</span><br>        scores = scores.masked_fill(indices_to_remove, <span class="hljs-keyword">self</span>.filter_value)<br>        <span class="hljs-keyword">return</span> scores<br><br><span class="hljs-comment"># create a FilterTokens object</span><br>filter_tokens = FilterTokens(top_k=<span class="hljs-number">3</span>, filter_value=-<span class="hljs-number">1e9</span>)<br><br><span class="hljs-comment"># create some input ids and scores</span><br>input_ids = torch.tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>], [<span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>, <span class="hljs-number">10</span>]])<br>scores = torch.tensor([[<span class="hljs-number">0.1</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">0.3</span>, <span class="hljs-number">0.4</span>, <span class="hljs-number">0.5</span>], [<span class="hljs-number">0.5</span>, <span class="hljs-number">0.4</span>, <span class="hljs-number">0.3</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">0.1</span>]])<br><br><span class="hljs-comment"># apply the filter</span><br>filtered_scores = filter_tokens(input_ids, scores)<br><br><span class="hljs-comment"># print the result</span><br>print(filtered_scores)<br></code></pre></td></tr></table></figure><h1 id="topp"><a href="#topp" class="headerlink" title="topp"></a>topp</h1><p>可以保证生成的token概率值总和小于等于给定的阈值top_p,越大随机性越高</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs vim">class TopPLogitsWarper(LogitsWarper):<br>    <span class="hljs-string">&quot;&quot;</span><span class="hljs-comment">&quot;</span><br>    [`LogitsWarper`] that performs top-<span class="hljs-keyword">p</span>, i.<span class="hljs-keyword">e</span>. restricting <span class="hljs-keyword">to</span> top tokens summing <span class="hljs-keyword">to</span> prob_cut_off &lt;= prob_cut_off.<br><br>    Args:<br>        top_p (`float`):<br>            If <span class="hljs-keyword">set</span> <span class="hljs-keyword">to</span> &lt; <span class="hljs-number">1</span>, <span class="hljs-keyword">only</span> the smallest <span class="hljs-keyword">set</span> of most probable tokens with probabilities that <span class="hljs-built_in">add</span> <span class="hljs-keyword">up</span> <span class="hljs-keyword">to</span> `top_p` <span class="hljs-built_in">or</span><br>            higher are kept <span class="hljs-keyword">for</span> generation.<br>        filter_value (`float`, *optional*, defaults <span class="hljs-keyword">to</span> `-float(<span class="hljs-string">&quot;Inf&quot;</span>)`):<br>            All filtered <span class="hljs-built_in">values</span> will <span class="hljs-keyword">be</span> <span class="hljs-keyword">set</span> <span class="hljs-keyword">to</span> this float value.<br>        min_tokens_to_keep (`<span class="hljs-keyword">int</span>`, *optional*, defaults <span class="hljs-keyword">to</span> <span class="hljs-number">1</span>):<br>            Minimum <span class="hljs-keyword">number</span> of tokens that cannot <span class="hljs-keyword">be</span> filtered.<br>    <span class="hljs-string">&quot;&quot;</span><span class="hljs-comment">&quot;</span><br><br>    def __init__(self, top_p: float, filter_value: float = -float(<span class="hljs-string">&quot;Inf&quot;</span>), min_tokens_to_keep: <span class="hljs-keyword">int</span> = <span class="hljs-number">1</span>):<br>        top_p = float(top_p)<br>        <span class="hljs-keyword">if</span> top_p &lt; <span class="hljs-number">0</span> <span class="hljs-built_in">or</span> top_p &gt; <span class="hljs-number">1.0</span>:<br>            raise ValueError(<span class="hljs-keyword">f</span><span class="hljs-string">&quot;`top_p` has to be a float &gt; 0 and &lt; 1, but is &#123;top_p&#125;&quot;</span>)<br><br>        self.top_p = top_p<br>        self.filter_value = filter_value<br>        self.min_tokens_to_keep = min_tokens_to_keep<br><br>    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -&gt; torch.FloatTensor:<br># 分数从大到小排序<br>        sorted_logits, sorted_indices = torch.<span class="hljs-keyword">sort</span>(scores, descending=False)<br># 累积下概率值<br>        cumulative_probs = sorted_logits.softmax(dim=-<span class="hljs-number">1</span>).cumsum(dim=-<span class="hljs-number">1</span>)<br><br>        # 计算哪些scores需要被移除,这里的移除就是设置很小的值<br>        sorted_indices_to_remove = cumulative_probs &lt;= (<span class="hljs-number">1</span> - self.top_p)<br># 如果设置了最小保存的token数量，那么就按用户设置的走<br>        <span class="hljs-keyword">if</span> self.min_tokens_to_keep &gt; <span class="hljs-number">1</span>:<br>            # Keep at least min_tokens_to_keep<br>            sorted_indices_to_remove[..., -self.min_tokens_to_keep :] = <span class="hljs-number">0</span><br><br>        #判断那些需要移除的token的位置<br>        indices_to_remove = sorted_indices_to_remove.scatter(<span class="hljs-number">1</span>, sorted_indices, sorted_indices_to_remove)<br># 填充成最小值<br>        scores = scores.masked_fill(indices_to_remove, self.filter_value)<br>        <span class="hljs-keyword">return</span> scores<br></code></pre></td></tr></table></figure><p>测试代码:<br>top_p&#x3D;0.4时的结果是<br>tensor([[  -inf,   -inf,   -inf, 0.4000, 0.5000],<br>        [  -inf,   -inf,   -inf, 0.9000, 1.0000]])<br>top_p&#x3D;0.99时的结果是:<br>tensor([[0.1000, 0.2000, 0.3000, 0.4000, 0.5000],<br>        [0.6000, 0.7000, 0.8000, 0.9000, 1.0000]])</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">import torch<br><br><span class="hljs-keyword">class</span> TopPLogitsWarper:<br>    def <span class="hljs-constructor">__init__(<span class="hljs-params">self</span>, <span class="hljs-params">top_p</span>: <span class="hljs-params">float</span>, <span class="hljs-params">filter_value</span>: <span class="hljs-params">float</span> = -<span class="hljs-params">float</span>(<span class="hljs-string">&quot;Inf&quot;</span>)</span>, min_tokens_to_keep: <span class="hljs-built_in">int</span> = <span class="hljs-number">1</span>):<br>        top_p = <span class="hljs-built_in">float</span>(top_p)<br>        <span class="hljs-keyword">if</span> top_p &lt; <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> top_p &gt; <span class="hljs-number">1.0</span>:<br>            raise <span class="hljs-constructor">ValueError(<span class="hljs-params">f</span><span class="hljs-string">&quot;`top_p` has to be a float &gt; 0 and &lt; 1, but is &#123;top_p&#125;&quot;</span>)</span><br><br>        self.top_p = top_p<br>        self.filter_value = filter_value<br>        self.min_tokens_to_keep = min_tokens_to_keep<br><br>    def <span class="hljs-constructor">__call__(<span class="hljs-params">self</span>, <span class="hljs-params">input_ids</span>: <span class="hljs-params">torch</span>.LongTensor, <span class="hljs-params">scores</span>: <span class="hljs-params">torch</span>.FloatTensor)</span> -&gt; torch.FloatTensor:<br>        sorted_logits, sorted_indices = torch.sort(scores, descending=False)<br>        cumulative_probs = sorted_logits.softmax(dim=-<span class="hljs-number">1</span>).cumsum(dim=-<span class="hljs-number">1</span>)<br><br>        # Remove tokens <span class="hljs-keyword">with</span> cumulative top_p above the threshold (token <span class="hljs-keyword">with</span> <span class="hljs-number">0</span> are kept)<br>        sorted_indices_to_remove = cumulative_probs &lt;= (<span class="hljs-number">1</span> - self.top_p)<br>        <span class="hljs-keyword">if</span> self.min_tokens_to_keep &gt; <span class="hljs-number">1</span>:<br>            # Keep at least min_tokens_to_keep<br>            sorted_indices_to_remove<span class="hljs-literal">[<span class="hljs-operator">...</span>, -<span class="hljs-identifier">self</span>.<span class="hljs-identifier">min_tokens_to_keep</span> :]</span> = <span class="hljs-number">0</span><br><br>        # scatter sorted tensors <span class="hljs-keyword">to</span> original indexing<br>        indices_to_remove = sorted_indices_to_remove.scatter(<span class="hljs-number">1</span>, sorted_indices, sorted_indices_to_remove)<br>        scores = scores.masked<span class="hljs-constructor">_fill(<span class="hljs-params">indices_to_remove</span>, <span class="hljs-params">self</span>.<span class="hljs-params">filter_value</span>)</span><br>        return scores<br><br># Test<br>top_p = <span class="hljs-number">0.4</span><br>filter_value = -<span class="hljs-built_in">float</span>(<span class="hljs-string">&quot;Inf&quot;</span>)<br>min_tokens_to_keep = <span class="hljs-number">1</span><br>input_ids = torch.<span class="hljs-constructor">LongTensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])</span><br>scores = torch.<span class="hljs-constructor">FloatTensor([[0.1, 0.2, 0.3, 0.4, 0.5], [0.6, 0.7, 0.8, 0.9, 1.0]])</span><br>warper = <span class="hljs-constructor">TopPLogitsWarper(<span class="hljs-params">top_p</span>, <span class="hljs-params">filter_value</span>, <span class="hljs-params">min_tokens_to_keep</span>)</span><br>filtered_scores = warper(input_ids, scores)<br>print(filtered_scores)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>chatgpt</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>用lavis实现多模态图文共同检索</title>
    <link href="/2023/04/27/%E7%94%A8lavis%E5%AE%9E%E7%8E%B0%E5%A4%9A%E6%A8%A1%E6%80%81%E5%9B%BE%E6%96%87%E5%85%B1%E5%90%8C%E6%A3%80%E7%B4%A2/"/>
    <url>/2023/04/27/%E7%94%A8lavis%E5%AE%9E%E7%8E%B0%E5%A4%9A%E6%A8%A1%E6%80%81%E5%9B%BE%E6%96%87%E5%85%B1%E5%90%8C%E6%A3%80%E7%B4%A2/</url>
    
    <content type="html"><![CDATA[<h1 id="多模态检索"><a href="#多模态检索" class="headerlink" title="多模态检索"></a>多模态检索</h1><ol><li><p>我们平常常见的多模态检索是，图到文或文到图的检索, 方式如下:<br>文本和图像之间的视觉-语义相似度<br>任务1： 使用句子查询图像<br>任务2：使用图像查询句子<br>搜索关键字: image-text retrieval</p></li><li><p>图文共同检索，这个不太常见，主要是利用图片和单独的文本的特征没有一起使用的特征进行检索的效果好，所以图文共同检索，思路如下：<br>图文匹配本质就是要对图像和文本这两个模态的样本分别或联合进行编码得到其语义表示embedding，同时还要有相应的相似性计算方法来计算这些embedding之间相似度。</p></li></ol><h1 id="依赖的框架LAVIS，Facebook的开源框架"><a href="#依赖的框架LAVIS，Facebook的开源框架" class="headerlink" title="依赖的框架LAVIS，Facebook的开源框架"></a>依赖的框架LAVIS，Facebook的开源框架</h1><p>LAVIS是一个支持多模态学习的开源库。该库支持多种任务、数据集和模型，并不断更新和扩充。</p><p>在支持的任务方面，LAVIS支持以下任务：图像-文本预训练、图像-文本检索、文本-图像检索、视觉问答、图像描述、图像分类、自然语言视觉推理、视觉蕴涵、视觉对话、视频-文本检索、文本-视频检索、视频问答和视频对话。</p><p>在支持的数据集方面，LAVIS支持以下数据集：COCO、VisualGenome、SBU ConceptualCaptions、Flickr30k、VQAv2、OKVQA、A-OKVQA、NoCaps、ImageNet、NLVR2、SNLI-VE、VisDial、MSRVTT、DiDeMo和MSVD等。</p><p>在支持的模型方面，LAVIS支持多种模型，包括ALBEF、BLIP、CLIP、VGD-GPT和ALPRO等。LAVIS还提供了自定义功能，使用户可以根据自己的需求定制自己的多模态学习模型。</p><p>总之，LAVIS是一个非常强大的多模态学习库，为研究者和开发者提供了丰富的任务、数据集和模型选择，可以大大加速多模态学习的研究和应用。</p><h1 id="base模型和设计-我们还设计了使用Lora只微调Qformer即可，使用huggingface的peft插件"><a href="#base模型和设计-我们还设计了使用Lora只微调Qformer即可，使用huggingface的peft插件" class="headerlink" title="base模型和设计, 我们还设计了使用Lora只微调Qformer即可，使用huggingface的peft插件"></a>base模型和设计, 我们还设计了使用Lora只微调Qformer即可，使用huggingface的peft插件</h1><p>使用BLIP2作为base模型,使用BLIP2模型，模型结构是ViT+OPT+Qformer，我们只微调Qformer，大约是5%的参数量，总的参数量是37亿。OPT是多语言模型。损失是arcface损失，优点是不用人工构造样本对。缺点是需要较多的微调，才能使的样本之间的距离拉开。<br>参考Face Recognition (FR) 面部识别的损失设计方法<br><a href="https://neptune.ai/blog/how-to-choose-loss-function-for-face-recognition">https://neptune.ai/blog/how-to-choose-loss-function-for-face-recognition</a>,<br>learn a good representation of the images rather than classify images among a set of predetermined classes</p><h1 id="代码结构"><a href="#代码结构" class="headerlink" title="代码结构"></a>代码结构</h1><p>building_index.py  预训练后的模型构建索引<br>lavis_predict.py   模型预测<br>lavis&#x2F;common&#x2F;lora_utils.py  Lora的模型更改<br>lavis&#x2F;configs&#x2F;datasets&#x2F;coco&#x2F;mini_cap.yaml  #caption的mini数据集<br>lavis&#x2F;configs&#x2F;datasets&#x2F;cosmetic&#x2F;defaults_cos.yaml   #默认训练数据集<br>lavis&#x2F;configs&#x2F;datasets&#x2F;cosmetic&#x2F;mini_cos.yaml   #mini数据集<br>lavis&#x2F;datasets&#x2F;builders&#x2F;caption_builder.py   # 加入自己的数据集的builder<br>lavis&#x2F;datasets&#x2F;datasets&#x2F;comestic_datasets.py  # 自己数据集的构造和读取处理<br>lavis&#x2F;models&#x2F;<strong>init</strong>.py  #加入”Blip2Lora”,模型<br>lavis&#x2F;models&#x2F;blip2_models&#x2F;blip2_lora.py  #具体模型<br>lavis&#x2F;models&#x2F;blip2_models&#x2F;blip2_opt.py   #使用BLIP2的模型，OPT是语义模型，视觉模型是ViT<br>lavis&#x2F;models&#x2F;blip2_models&#x2F;face_head.py   #arcface损失<br>lavis&#x2F;projects&#x2F;blip2&#x2F;eval&#x2F;cosmetic_ft_eval.yaml   评估的配置<br>lavis&#x2F;projects&#x2F;blip2&#x2F;train&#x2F;cosmetic_ft.yaml    微调的配置<br>lavis&#x2F;tasks&#x2F;<strong>init</strong>.py              #加了检索的任务设置<br>lavis&#x2F;tasks&#x2F;base_task.py<br>lavis&#x2F;tasks&#x2F;multimodal_retrieval.py    #MultimodalRetrievalTask检索任务的具体代码</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>开发bbox标注工具</title>
    <link href="/2023/04/25/%E5%BC%80%E5%8F%91bbox%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7/"/>
    <url>/2023/04/25/%E5%BC%80%E5%8F%91bbox%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7/</url>
    
    <content type="html"><![CDATA[<h1 id="主要功能"><a href="#主要功能" class="headerlink" title="主要功能"></a>主要功能</h1><ol><li>支持上一张，下一张图片翻页按钮</li><li>支持bbox的框的绘制，支持bbox的框的移动，bbox的框的缩放，bbox的标签</li><li>图片来自本地文件夹，bbox的标注信息保存到本地文件夹</li><li>如果已有bbox的标注信息，可以直接加载，继续标注</li><li>如果没有bbox的标注信息，会通过bbox的检测算法，自动检测bbox的位置，自动给出一个可能的bbox的标注标签</li><li>支持查看搜索目标图像，方便对比标注</li></ol><h1 id="设计图示"><a href="#设计图示" class="headerlink" title="设计图示"></a>设计图示</h1><img src="/2023/04/25/%E5%BC%80%E5%8F%91bbox%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7/1.png" class=""><img src="/2023/04/25/%E5%BC%80%E5%8F%91bbox%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7/2.png" class=""><h1 id="具体实现思路"><a href="#具体实现思路" class="headerlink" title="具体实现思路"></a>具体实现思路</h1><p>gradio实现界面和模型预测调用，js实现bbox绘制和交互，因为gradio目前还不支持bbox的绘制</p><h1 id="2023-05-05更新"><a href="#2023-05-05更新" class="headerlink" title="2023-05-05更新"></a>2023-05-05更新</h1><ol><li>图片由本地图片搜索改成根据后台请求获取，方便对线上已标注的品牌和bbox的数量进行控制</li><li>标注数据调用后台api，存储的mysql数据库<br>数据库的表结构设计<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> `labeling` (<br>  `id` <span class="hljs-type">int</span>(<span class="hljs-number">11</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">NULL</span> AUTO_INCREMENT,<br>  `url` <span class="hljs-type">varchar</span>(<span class="hljs-number">255</span>) <span class="hljs-keyword">DEFAULT</span> <span class="hljs-keyword">NULL</span> <span class="hljs-keyword">COMMENT</span> <span class="hljs-string">&#x27;商品url&#x27;</span>,<br>  `title` <span class="hljs-type">varchar</span>(<span class="hljs-number">255</span>) <span class="hljs-keyword">DEFAULT</span> <span class="hljs-keyword">NULL</span> <span class="hljs-keyword">COMMENT</span> <span class="hljs-string">&#x27;商品标题&#x27;</span>,<br>  `pic` <span class="hljs-type">varchar</span>(<span class="hljs-number">255</span>) <span class="hljs-keyword">DEFAULT</span> <span class="hljs-keyword">NULL</span> <span class="hljs-keyword">COMMENT</span> <span class="hljs-string">&#x27;商品图片url&#x27;</span>,<br>  `pic_path` <span class="hljs-type">varchar</span>(<span class="hljs-number">255</span>) <span class="hljs-keyword">DEFAULT</span> <span class="hljs-keyword">NULL</span> <span class="hljs-keyword">COMMENT</span> <span class="hljs-string">&#x27;图片路径&#x27;</span>,<br>  `pic_width` <span class="hljs-type">int</span>(<span class="hljs-number">11</span>) <span class="hljs-keyword">DEFAULT</span> <span class="hljs-keyword">NULL</span> <span class="hljs-keyword">COMMENT</span> <span class="hljs-string">&#x27;图片宽度&#x27;</span>,<br>  `pic_height` <span class="hljs-type">int</span>(<span class="hljs-number">11</span>) <span class="hljs-keyword">DEFAULT</span> <span class="hljs-keyword">NULL</span> <span class="hljs-keyword">COMMENT</span> <span class="hljs-string">&#x27;图片高度&#x27;</span>,<br>  `bbox_num` <span class="hljs-type">int</span>(<span class="hljs-number">11</span>) <span class="hljs-keyword">DEFAULT</span> <span class="hljs-keyword">NULL</span> <span class="hljs-keyword">COMMENT</span> <span class="hljs-string">&#x27;bbox目标数量&#x27;</span>,<br>  `bbox` <span class="hljs-type">json</span> <span class="hljs-keyword">DEFAULT</span> <span class="hljs-keyword">NULL</span> <span class="hljs-keyword">COMMENT</span> <span class="hljs-string">&#x27;bbox信息&#x27;</span>,<br>  <span class="hljs-keyword">PRIMARY KEY</span> (`id`)<br>) ENGINE=InnoDB <span class="hljs-keyword">DEFAULT</span> CHARSET=utf8mb4 <span class="hljs-keyword">COMMENT</span>=<span class="hljs-string">&#x27;商品的目标检测结果&#x27;</span>;<br></code></pre></td></tr></table></figure></li><li>用户通过品牌进行搜索，返回同一品牌下未标注的商品，相同的商品名称按顺序返回</li><li>根据bbox数量限制搜索返回的图片，我们可以优先标注简单的商品，这样模型学习后在辅助标注复杂的商品</li><li>上一张和下一张的按钮会优先搜索已标注的数据库，如果存在，那么直接返回，如果不存在，在使用yolo进行辅助标注</li><li>下一张按钮会自动触发当前页面的标注数据保存，并搜索下一张图片</li><li>用户可以输入精确或模糊的商品名称查询，会自动调用图片搜索API进行商品图搜索，方便用户标注时进行对比。</li><li>更改bbox的名称为颜色的名称，方便用户一下就定位到要修改的bbox</li><li>修改图片上显示的标签为左上角，方便查看</li><li>添加w和s的键盘快捷键，当用户点击w时，表示点击了上一张，s表示点击了下一张，加快标注速度</li><li>当用户点击上一张或下一张的时候，同时自动更新参考的显示图片，自动显示最可能的商品的图片,方便用户校对</li><li>涉及的API和页面，一共2个API，一个是YOLO的模型目标检测API，方便后台图片搜索API调用，图片搜索API链接线上库，搜索未标注商品和保存已标注信息到数据库等，gradio页面负责显示bbox的查询商品<img src="/2023/04/25/%E5%BC%80%E5%8F%91bbox%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7/Gradio.jpg" class=""></li></ol>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>transformers_datasets报错</title>
    <link href="/2023/04/24/transformers-datasets%E6%8A%A5%E9%94%99/"/>
    <url>/2023/04/24/transformers-datasets%E6%8A%A5%E9%94%99/</url>
    
    <content type="html"><![CDATA[<h1 id="使用huggingface的时datasets报错如下"><a href="#使用huggingface的时datasets报错如下" class="headerlink" title="使用huggingface的时datasets报错如下:"></a>使用huggingface的时datasets报错如下:</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs bash">multiprocess.pool.RemoteTraceback: <br><span class="hljs-string">&quot;&quot;</span><span class="hljs-string">&quot;</span><br><span class="hljs-string">Traceback (most recent call last):</span><br><span class="hljs-string">  File &quot;</span>/Users/admin/miniforge3/envs/py39/lib/python3.9/site-packages/multiprocess/pool.py<span class="hljs-string">&quot;, line 125, in worker</span><br><span class="hljs-string">    result = (True, func(*args, **kwds))</span><br><span class="hljs-string">  File &quot;</span>/Users/admin/miniforge3/envs/py39/lib/python3.9/site-packages/datasets/utils/py_utils.py<span class="hljs-string">&quot;, line 1353, in _write_generator_to_queue</span><br><span class="hljs-string">    for i, result in enumerate(func(**kwargs)):</span><br><span class="hljs-string">  File &quot;</span>/Users/admin/miniforge3/envs/py39/lib/python3.9/site-packages/datasets/arrow_dataset.py<span class="hljs-string">&quot;, line 3397, in _map_single</span><br><span class="hljs-string">    writer.write_batch(batch)</span><br><span class="hljs-string">  File &quot;</span>/Users/admin/miniforge3/envs/py39/lib/python3.9/site-packages/datasets/arrow_writer.py<span class="hljs-string">&quot;, line 554, in write_batch</span><br><span class="hljs-string">    pa_table = pa.Table.from_arrays(arrays, schema=schema)</span><br><span class="hljs-string">  File &quot;</span>pyarrow/table.pxi<span class="hljs-string">&quot;, line 3657, in pyarrow.lib.Table.from_arrays</span><br><span class="hljs-string">  File &quot;</span>pyarrow/table.pxi<span class="hljs-string">&quot;, line 1416, in pyarrow.lib._sanitize_arrays</span><br><span class="hljs-string">ValueError: Schema and number of arrays unequal</span><br><span class="hljs-string">&quot;</span><span class="hljs-string">&quot;&quot;</span><br></code></pre></td></tr></table></figure><p>这个报错很不明显，官方可能会在最新版本对这个错误的描述进行更改，真正的原因是有的批次数据是空的，检查你的批次数据，确保不为空即可。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>使用gradio开图像分类标注工具</title>
    <link href="/2023/04/21/%E4%BD%BF%E7%94%A8gradio%E5%BC%80%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7/"/>
    <url>/2023/04/21/%E4%BD%BF%E7%94%A8gradio%E5%BC%80%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7/</url>
    
    <content type="html"><![CDATA[<h1 id="利用gradio做一个图像的分类的标注工具"><a href="#利用gradio做一个图像的分类的标注工具" class="headerlink" title="利用gradio做一个图像的分类的标注工具"></a>利用gradio做一个图像的分类的标注工具</h1><ol><li>首先使用少量数据训练一个不太准的分类模型（我们测试的是一个检索模型,先训练模型嵌入，然后得到候选向量，查询数据和候选向量进行相似度对比，返回预测结果）,写好接口，传入图片后能预测图片的类别</li><li>然后自制一个gradio的标注工具，能够读取未标注数据，调用模型接口，预测结果，经过人工判断，是否正确，如果正确，直接点提交按钮，如果不正确，修改成正确的标签<br>左边是方便用户查看标签图片，右边是会显示当前的的图片和预测结果，上一张和下一张可翻页<img src="/2023/04/21/%E4%BD%BF%E7%94%A8gradio%E5%BC%80%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7/1.png" class=""></li></ol>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>对huggingface的训练完成的结果的目录结构进行说明</title>
    <link href="/2023/04/20/%E5%AF%B9huggingface%E7%9A%84%E8%AE%AD%E7%BB%83%E5%AE%8C%E6%88%90%E7%9A%84%E7%BB%93%E6%9E%9C%E7%9A%84%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%E8%BF%9B%E8%A1%8C%E8%AF%B4%E6%98%8E/"/>
    <url>/2023/04/20/%E5%AF%B9huggingface%E7%9A%84%E8%AE%AD%E7%BB%83%E5%AE%8C%E6%88%90%E7%9A%84%E7%BB%93%E6%9E%9C%E7%9A%84%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%E8%BF%9B%E8%A1%8C%E8%AF%B4%E6%98%8E/</url>
    
    <content type="html"><![CDATA[<h1 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h1><p>├── all_results.json<br>├── config.json<br>├── eval_results.json<br>├── preprocessor_config.json<br>├── pytorch_model.bin<br>├── runs<br>│   └── Apr20_11-09-24_wac209<br>│   ├── 1681960165.2226455<br>│   │   └── events.out.tfevents.1681960165.wac209<br>│   ├── events.out.tfevents.1681960165.wac209<br>│   └── events.out.tfevents.1681960176.wac209<br>├── train_results.json<br>├── trainer_state.json<br>└── training_args.bin</p><p>all_results.json：一个JSON文件，包含每个epoch的训练和验证结果。<br>config.json：一个JSON文件，包含模型的配置信息，例如模型的架构、超参数等等。<br>eval_results.json：一个JSON文件，包含验证集上的结果。<br>preprocessor_config.json：一个JSON文件，包含预处理器的配置信息，例如tokenizer的参数等等。<br>pytorch_model.bin：一个二进制文件，包含训练好的PyTorch模型的参数。<br>runs：一个目录，包含TensorBoard日志文件，用于可视化训练过程中的指标和图形。 tensforboard –logdir runs 即可查看<br>train_results.json：一个JSON文件，包含训练集上的结果。<br>trainer_state.json：一个JSON文件，包含训练过程中Trainer对象的状态信息，例如当前epoch、当前step等等。<br>training_args.bin：一个二进制文件，包含训练脚本的参数，例如训练数据的路径、训练的超参数等等。</p><p>#cat all_results.json<br>{<br>    “epoch”: 6.0,<br>    “eval_accuracy”: 0.7272727272727273,<br>    “eval_loss”: 1.4200994968414307,<br>    “eval_runtime”: 0.1368,<br>    “eval_samples_per_second”: 80.438,<br>    “eval_steps_per_second”: 14.625,<br>    “train_loss”: 1.4368099636501737,<br>    “train_runtime”: 10.7547,<br>    “train_samples_per_second”: 49.095,<br>    “train_steps_per_second”: 3.347<br>}%</p><p>#cat eval_results.json<br>{<br>    “epoch”: 6.0,<br>    “eval_accuracy”: 0.7272727272727273,<br>    “eval_loss”: 1.4200994968414307,<br>    “eval_runtime”: 0.1368,<br>    “eval_samples_per_second”: 80.438,<br>    “eval_steps_per_second”: 14.625<br>}%                                                                                                           ➜  vit-base-disney cat trainer_state.json<br>{<br>  “best_metric”: null,<br>  “best_model_checkpoint”: null,<br>  “epoch”: 6.0,<br>  “global_step”: 36,<br>  “is_hyper_param_search”: false,<br>  “is_local_process_zero”: true,<br>  “is_world_process_zero”: true,<br>  “log_history”: [<br>    {<br>      “epoch”: 1.67,<br>      “learning_rate”: 0.00014444444444444444,<br>      “loss”: 2.1824,<br>      “step”: 10<br>    },<br>    {<br>      “epoch”: 3.33,<br>      “learning_rate”: 8.888888888888889e-05,<br>      “loss”: 1.4562,<br>      “step”: 20<br>    },<br>    {<br>      “epoch”: 5.0,<br>      “learning_rate”: 3.3333333333333335e-05,<br>      “loss”: 1.0267,<br>      “step”: 30<br>    },<br>    {<br>      “epoch”: 6.0,<br>      “step”: 36,<br>      “total_flos”: 4.091907095248896e+16,<br>      “train_loss”: 1.4368099636501737,<br>      “train_runtime”: 10.7547,<br>      “train_samples_per_second”: 49.095,<br>      “train_steps_per_second”: 3.347<br>    }<br>  ],<br>  “max_steps”: 36,<br>  “num_train_epochs”: 6,<br>  “total_flos”: 4.091907095248896e+16,<br>  “trial_name”: null,<br>  “trial_params”: null<br>}</p><p>#模型的配置信息<br>cat config.json<br>{<br>  “_name_or_path”: “google&#x2F;vit-base-patch16-224-in21k”,<br>  “architectures”: [<br>    “ViTForImageClassification”<br>  ],<br>  “attention_probs_dropout_prob”: 0.0,<br>  “encoder_stride”: 16,<br>  “hidden_act”: “gelu”,<br>  “hidden_dropout_prob”: 0.0,<br>  “hidden_size”: 768,<br>  “id2label”: {<br>    “0”: “\u514b\u8389\u65af”,<br>    “1”: “\u5510\u8001\u9e2d”,<br>    “10”: “\u9edb\u4e1d”,<br>    “2”: “\u5947\u5947”,<br>    “3”: “\u5e03\u9c81\u6258”,<br>    “4”: “\u661f\u9edb\u9732”,<br>    “5”: “\u73b2\u5a1c\u8d1d\u5c14”,<br>    “6”: “\u7c73\u5947”,<br>    “7”: “\u7c73\u59ae”,<br>    “8”: “\u8482\u8482”,<br>    “9”: “\u9ad8\u98de”<br>  },<br>  “image_size”: 224,<br>  “initializer_range”: 0.02,<br>  “intermediate_size”: 3072,<br>  “label2id”: {<br>    “\u514b\u8389\u65af”: “0”,<br>    “\u5510\u8001\u9e2d”: “1”,<br>    “\u5947\u5947”: “2”,<br>    “\u5e03\u9c81\u6258”: “3”,<br>    “\u661f\u9edb\u9732”: “4”,<br>    “\u73b2\u5a1c\u8d1d\u5c14”: “5”,<br>    “\u7c73\u5947”: “6”,<br>    “\u7c73\u59ae”: “7”,<br>    “\u8482\u8482”: “8”,<br>    “\u9ad8\u98de”: “9”,<br>    “\u9edb\u4e1d”: “10”<br>  },<br>  “layer_norm_eps”: 1e-12,<br>  “model_type”: “vit”,<br>  “num_attention_heads”: 12,<br>  “num_channels”: 3,<br>  “num_hidden_layers”: 12,<br>  “patch_size”: 16,<br>  “problem_type”: “single_label_classification”,<br>  “qkv_bias”: true,<br>  “torch_dtype”: “float32”,<br>  “transformers_version”: “4.28.1”<br>}</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>export_ONNX报错</title>
    <link href="/2023/04/19/export-ONNX%E6%8A%A5%E9%94%99/"/>
    <url>/2023/04/19/export-ONNX%E6%8A%A5%E9%94%99/</url>
    
    <content type="html"><![CDATA[<h1 id="当使用torch导出ONNX模型的时候报错如下"><a href="#当使用torch导出ONNX模型的时候报错如下" class="headerlink" title="当使用torch导出ONNX模型的时候报错如下"></a>当使用torch导出ONNX模型的时候报错如下</h1><pre><code class="hljs">for idx, r_split in enumerate(r_splits):</code></pre><p>TypeError: ‘torch._C.Value’ object is not iterable<br>(Occurred when translating repeat_interleave).</p><p>解决方法：更新torch到2.0即可</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>peft微调Bloom时报错</title>
    <link href="/2023/04/18/peft%E5%BE%AE%E8%B0%83Bloom%E6%97%B6%E6%8A%A5%E9%94%99/"/>
    <url>/2023/04/18/peft%E5%BE%AE%E8%B0%83Bloom%E6%97%B6%E6%8A%A5%E9%94%99/</url>
    
    <content type="html"><![CDATA[<h1 id="报错如下"><a href="#报错如下" class="headerlink" title="报错如下:"></a>报错如下:</h1><p>peft报错<br>RuntimeError: self and mat2 must have the same dtype</p><h1 id="明确禁用下8bit训练即可"><a href="#明确禁用下8bit训练即可" class="headerlink" title="明确禁用下8bit训练即可"></a>明确禁用下8bit训练即可</h1><p>model &#x3D; AutoModelForCausalLM.from_pretrained(<br>    base_model,<br>    load_in_8bit&#x3D;False,<br>    torch_dtype&#x3D;torch.float16,<br>    device_map&#x3D;device_map,<br>)<br>model.is_loaded_in_8bit &#x3D; False   #明确一下，不使用8bit进行训练，因为huggingface的8bit训练不支持<br>model &#x3D; prepare_model_for_int8_training(model)</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>pinecone向量检索工具</title>
    <link href="/2023/04/13/pinecone%E5%90%91%E9%87%8F%E6%A3%80%E7%B4%A2%E5%B7%A5%E5%85%B7/"/>
    <url>/2023/04/13/pinecone%E5%90%91%E9%87%8F%E6%A3%80%E7%B4%A2%E5%B7%A5%E5%85%B7/</url>
    
    <content type="html"><![CDATA[<h1 id="关于Pinecone向量检索工具"><a href="#关于Pinecone向量检索工具" class="headerlink" title="关于Pinecone向量检索工具"></a>关于Pinecone向量检索工具</h1><p>Pinecone：Pinecone是一个托管的向量数据库服务，支持高性能的向量检索和近似最近邻搜索。它提供了Python和REST API，并且可以轻松扩展到数百万个向量。</p><ol><li>是否可以增加向量降维后根据不同距离进行展示的效果，例如PCA二维或3维图，方便对向量进行检查？</li></ol><h1 id="其它类似的向量检索数据库"><a href="#其它类似的向量检索数据库" class="headerlink" title="其它类似的向量检索数据库"></a>其它类似的向量检索数据库</h1><p>Annoy：Annoy是一个C++库，用于高效地进行向量检索。它支持多种距离度量和索引构建算法，可以在大型数据集上进行高性能的近似最近邻搜索。</p><p>Faiss：Faiss是Facebook AI Research开发的一个高性能向量检索库。它支持多种距离度量和索引构建算法，并且可以在多个GPU上进行分布式计算。</p><p>Milvus：Milvus是一个开源的向量数据库，支持高性能的向量检索和近似最近邻搜索。它支持多种距离度量和索引构建算法，并且可以在多个节点上进行分布式计算。</p><p>ScaNN：ScaNN是Google开发的一个高性能向量检索库，支持多种距离度量和索引构建算法，并且可以在多个GPU上进行分布式计算。它还提供了一些实用工具，例如可视化和性能分析。</p><h1 id="Pinecone的现有功能"><a href="#Pinecone的现有功能" class="headerlink" title="Pinecone的现有功能"></a>Pinecone的现有功能</h1><p>安装和使用<br>用户可以通过pip或conda安装Pinecone向量检索工具；<br>用户可以在命令行或脚本中使用Pinecone向量检索工具。<br>初始化<br>用户可以通过初始化方法创建一个向量检索实例；<br>用户可以设置连接Pinecone服务的参数，例如API密钥、服务区域和集合名称。<br>配置索引<br>用户可以通过configure_index方法配置索引的参数；<br>用户可以设置索引的维度、索引类型和检索方法。<br>创建集合<br>用户可以通过create_collection方法创建一个新的集合；<br>用户可以用于存储向量数据。<br>创建索引<br>用户可以通过create_index方法创建一个新的索引；<br>用户可以用于存储向量数据并支持向量检索。<br>删除集合<br>用户可以通过delete_collection方法删除一个集合；<br>同时也会删除其中的所有向量数据和索引。<br>删除索引<br>用户可以通过delete_index方法删除一个索引；<br>同时也会删除其中的所有向量数据。<br>描述集合<br>用户可以通过describe_collection方法获取一个集合的详细信息；<br>例如集合名称、索引类型、向量数量等。<br>描述索引<br>用户可以通过describe_index方法获取一个索引的详细信息；<br>例如索引类型、向量数量等。<br>列出集合<br>用户可以通过list_collections方法获取所有可用的集合列表。<br>列出索引<br>用户可以通过list_indexes方法获取一个集合中所有可用的索引列表。<br>向索引中插入向量<br>用户可以通过Index.upsert方法向索引中插入向量；<br>用户可以插入多个向量，每个向量有一个唯一的ID。<br>从索引中检索向量<br>用户可以通过Index.query方法从索引中检索与查询向量最相似的向量；<br>用户可以指定要检索的查询向量和检索的最相似向量数量。<br>删除向量<br>用户可以通过Index.delete方法从索引中删除向量；<br>用户可以指定要删除的向量ID列表。<br>更新向量<br>用户可以通过Index.update方法更新索引中已存在的向量；<br>用户可以指定要更新的向量ID和更新后的向量值。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>多模态检索模型的设计</title>
    <link href="/2023/04/12/%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A3%80%E7%B4%A2%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AE%BE%E8%AE%A1/"/>
    <url>/2023/04/12/%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A3%80%E7%B4%A2%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AE%BE%E8%AE%A1/</url>
    
    <content type="html"><![CDATA[<h1 id="设计了2种模型分支进行对比-基于VILT和BLIP2的商品相似度模型对比与分析"><a href="#设计了2种模型分支进行对比-基于VILT和BLIP2的商品相似度模型对比与分析" class="headerlink" title="设计了2种模型分支进行对比,基于VILT和BLIP2的商品相似度模型对比与分析"></a>设计了2种模型分支进行对比,基于VILT和BLIP2的商品相似度模型对比与分析</h1><p>本文将对比分析两种基于深度学习的商品相似度模型：基于VILT的模型和基于BLIP2的模型。这两种方法在商品相似度检测任务中具有不同的优缺点，我们将从训练、推理和实际应用等方面进行详细分析。</p><h1 id="基于VILT的模型"><a href="#基于VILT的模型" class="headerlink" title="基于VILT的模型"></a>基于VILT的模型</h1><p>VILT模型通过结合图像和文本信息来学习商品特征。在训练过程中，模型使用了多个分类损失和正负样本的相似度损失。通过保留品牌预测、使用原始商品图片和名称以及别名作为样本，该模型可以学到丰富的商品特征表示。在推理阶段，模型先预测品牌，然后对品牌下所有商品进行相似度检索。实验结果显示，该方法在准确率上取得了较好的效果，达到82.19%。</p><h2 id="VILT模型的优点："><a href="#VILT模型的优点：" class="headerlink" title="VILT模型的优点："></a>VILT模型的优点：</h2><p>通过编码图片和标题为一个向量，可以更好地捕捉商品的多模态信息。<br>使用SimCSE论文中的方法进行训练，可以进一步提高模型的性能。<br>通过使用品牌预测和相似度检索，可以在推理阶段明显提高准确率。</p><h2 id="VILT模型的缺点："><a href="#VILT模型的缺点：" class="headerlink" title="VILT模型的缺点："></a>VILT模型的缺点：</h2><p>需要人工构造样本对和困难样本对，可能无法充分挖掘潜在的信息。<br>训练过程中需要调整多个损失项的权重，可能导致优化困难。</p><h1 id="基于BLIP2的模型"><a href="#基于BLIP2的模型" class="headerlink" title="基于BLIP2的模型"></a>基于BLIP2的模型</h1><p>BLIP2模型受到面部识别任务中损失函数设计的启发，旨在学习图像的良好表示而不是对预定类别进行分类。该模型以BLIP2为基础，结构为ViT+OPT+Qformer，模型参数量为37亿。训练过程中采用arcface损失，可以避免人工构造样本对。实验结果显示，经过微调后，模型的准确率可达52%。</p><h2 id="BLIP2模型的优点："><a href="#BLIP2模型的优点：" class="headerlink" title="BLIP2模型的优点："></a>BLIP2模型的优点：</h2><p>无需人工构造样本对，降低了训练难度。<br>采用arcface损失，可以使样本之间的距离拉开，提高模型性能。<br>BLIP2模型的缺点：<br>训练时间较长，需要48小时才能完成10个epoch的训练。<br>模型参数量较大，计算资源需求高。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>基于VILT的模型和基于BLIP2的模型在商品相似度检测任务中各有优劣。VILT模型可以更好地捕捉商品的多模态信息，但需要人工构造样本对和困难样本对。而BLIP2模型无需人工构造样本对，采用arcface损失可以使样本之间的距离拉开，但训练时间较长，计算资源需求较高。根据实际应用场景和计算资源的限制，可以选择合适的模型进行商品相似度检测任务。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>安装cuda驱动报错</title>
    <link href="/2023/04/11/%E5%AE%89%E8%A3%85cuda%E9%A9%B1%E5%8A%A8%E6%8A%A5%E9%94%99/"/>
    <url>/2023/04/11/%E5%AE%89%E8%A3%85cuda%E9%A9%B1%E5%8A%A8%E6%8A%A5%E9%94%99/</url>
    
    <content type="html"><![CDATA[<h1 id="当安装cuda时报错如下"><a href="#当安装cuda时报错如下" class="headerlink" title="当安装cuda时报错如下"></a>当安装cuda时报错如下</h1><p>sudo sh .&#x2F;cuda_11.7.1_515.65.01_linux.run</p><figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs vbnet">cat /var/log/nvidia-installer.log<br><span class="hljs-keyword">Using</span> built-<span class="hljs-keyword">in</span> stream user <span class="hljs-keyword">interface</span><br>-&gt; Detected <span class="hljs-number">12</span> CPUs online; setting concurrency level <span class="hljs-keyword">to</span> <span class="hljs-number">12</span>.<br><span class="hljs-symbol">ERROR:</span> An NVIDIA kernel <span class="hljs-keyword">module</span> <span class="hljs-comment">&#x27;nvidia-uvm&#x27; appears to already be loaded in your kernel.  This may be because it is in use (for example, by an X server, a CUDA program, or the NVIDIA Persistence Daemon), but this may also happen if your kernel was configured without support for module unloading.  Please be sure to exit any programs that may be using the GPU(s) before attempting to upgrade your driver.  If no GPU-based programs are running, you know that your kernel supports module unloading, and you still receive this message, then an error may have occurred that has corrupted an NVIDIA kernel module&#x27;s usage count, for which the simplest remedy is to reboot your computer.</span><br><span class="hljs-symbol">ERROR:</span> Installation has failed.  Please see the file <span class="hljs-comment">&#x27;/var/log/nvidia-installer.log&#x27; for details.  You may find suggestions on fixing installation problems in the README available on the Linux driver download page at www.nvidia.com.</span><br></code></pre></td></tr></table></figure><p>只需退出所有正在运行的cuda应用即可。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>java版本恢复</title>
    <link href="/2023/04/06/java%E7%89%88%E6%9C%AC%E6%81%A2%E5%A4%8D/"/>
    <url>/2023/04/06/java%E7%89%88%E6%9C%AC%E6%81%A2%E5%A4%8D/</url>
    
    <content type="html"><![CDATA[<h1 id="java-版本问题"><a href="#java-版本问题" class="headerlink" title="java 版本问题"></a>java 版本问题</h1><p>前提: 突然发现一台服务器因为java版本问题导致大数据服务的挂掉,恢复java版本</p><h2 id="查看现有java版本"><a href="#查看现有java版本" class="headerlink" title="查看现有java版本"></a>查看现有java版本</h2><p>java -version<br>java version “17.0.6” 2023-01-17 LTS<br>Java(TM) SE Runtime Environment (build 17.0.6+9-LTS-190)<br>Java HotSpot(TM) 64-Bit Server VM (build 17.0.6+9-LTS-190, mixed mode, sharing)</p><h2 id="查看其它大数据的java版本"><a href="#查看其它大数据的java版本" class="headerlink" title="查看其它大数据的java版本"></a>查看其它大数据的java版本</h2><p>java -version<br>java version “1.8.0_141”<br>Java(TM) SE Runtime Environment (build 1.8.0_141-b15)<br>Java HotSpot(TM) 64-Bit Server VM (build 25.141-b15, mixed mode)</p><h2 id="从官网下载对应版本"><a href="#从官网下载对应版本" class="headerlink" title="从官网下载对应版本"></a>从官网下载对应版本</h2><p><a href="https://www.oracle.com/sg/java/technologies/javase/javase8-archive-downloads.html">https://www.oracle.com/sg/java/technologies/javase/javase8-archive-downloads.html</a><br>下载的文件<br>jdk-8u141-linux-x64.tar.gz</p><h2 id="查看现有java安装路径"><a href="#查看现有java安装路径" class="headerlink" title="查看现有java安装路径"></a>查看现有java安装路径</h2><p>ls -alh &#x2F;usr&#x2F;bin&#x2F;java<br>lrwxrwxrwx 1 root root 22 Apr  6 11:56 &#x2F;usr&#x2F;bin&#x2F;java -&gt; &#x2F;etc&#x2F;alternatives&#x2F;java<br>johnson@wacserver1:~&#x2F;jvm$ ls -alh  &#x2F;etc&#x2F;alternatives&#x2F;java<br>lrwxrwxrwx 1 root root 34 Apr  6 12:06 &#x2F;etc&#x2F;alternatives&#x2F;java -&gt; &#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;jdk-17&#x2F;bin&#x2F;java</p><h2 id="解压tar包到对应目录"><a href="#解压tar包到对应目录" class="headerlink" title="解压tar包到对应目录"></a>解压tar包到对应目录</h2><p>sudo tar -xzf jdk-8u141-linux-x64.tar.gz -C &#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;<br>得到<br>&#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;jdk1.8.0_141</p><h2 id="更新默认java版本"><a href="#更新默认java版本" class="headerlink" title="更新默认java版本"></a>更新默认java版本</h2><p>sudo update-alternatives –install &#x2F;usr&#x2F;bin&#x2F;java java &#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;jdk1.8.0_141&#x2F;bin&#x2F;java 1<br>sudo update-alternatives –install &#x2F;usr&#x2F;bin&#x2F;javac javac &#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;jdk1.8.0_141&#x2F;bin&#x2F;javac 1<br>sudo update-alternatives –config java<br>sudo update-alternatives –config javac</p><h2 id="有时需要系统的环境变量文件-对所有用户生效"><a href="#有时需要系统的环境变量文件-对所有用户生效" class="headerlink" title="有时需要系统的环境变量文件,对所有用户生效"></a>有时需要系统的环境变量文件,对所有用户生效</h2><p>&#x2F;etc&#x2F;profile<br>修改<br>export JAVA_HOME&#x3D;&#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;jdk1.8.0_141<br>export PATH&#x3D;$JAVA_HOME&#x2F;bin:$PATH</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>mongo数据迁移</title>
    <link href="/2023/04/06/mongo%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB/"/>
    <url>/2023/04/06/mongo%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB/</url>
    
    <content type="html"><![CDATA[<h1 id="Mongo占用内存过大，迁移部分collection到其它机器"><a href="#Mongo占用内存过大，迁移部分collection到其它机器" class="headerlink" title="Mongo占用内存过大，迁移部分collection到其它机器"></a>Mongo占用内存过大，迁移部分collection到其它机器</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>mongo和大数据共用一个机器，当mongo中数据较多时，占用内存加到，影响到了大数据机器的稳定性，需要迁移到其它机器</p><h2 id="Mongo和内存之间的关系"><a href="#Mongo和内存之间的关系" class="headerlink" title="Mongo和内存之间的关系"></a>Mongo和内存之间的关系</h2><p>MongoDB数据库占用内存的大小主要依赖于以下几个因素:</p><p>数据量:显然,存储的文档数量越多,占用内存就越大。每个 MongoDB 文档通常占用约为 JSON 对象大小,这通常在 1KB 至 5KB 之间。</p><p>索引: MongoDB 可以在任何字段上创建索引。每个索引本身也会占用一定量的内存。所以,创建过多的索引会增加内存占用。</p><p>文档的平均大小:如果您存储的文档非常大(例如,每个文档包含大量媒体数据),那么整体内存占用将更大。</p><p>是否启用了内存索引:如果启用了内存索引,则 MongoDB 会在内存中缓存一部分的磁盘上索引,以改进查询性能。这会增加内存占用。</p><p>是否启用了内存 mapped view:与内存索引类似,如果启用了内存映射视图,则 MongoDB 也会在内存中缓存一部分数据,以提高视图的性能。这也会增加内存占用。</p><p>分片(如果适用):如果启用了 sharded 集群,每个片段又会有自己的内存占用。所以总体占用会大幅增加。</p><p>集群数(如果适用):如果您有多个互相独立的 MongoDB 集群,那么总的内存占用量将等于每个集群内存占用的总和。</p><h2 id="查看已占用内存"><a href="#查看已占用内存" class="headerlink" title="查看已占用内存"></a>查看已占用内存</h2><p>经过top名称，按内存占用大小查看，mongo占用内存大小约28.2%<br>进入mongo查看某个db占用内存, 单位是B，除以1024&#x2F;1024到MB<br>db.stats().storageSize<br>——&gt;<br>21534863360</p><h2 id="直接导出某个DB或导出某个collection"><a href="#直接导出某个DB或导出某个collection" class="headerlink" title="直接导出某个DB或导出某个collection"></a>直接导出某个DB或导出某个collection</h2><ol><li><p>直接导出某个DB<br>mongodump –db &lt;数据库名称&gt; –out &lt;输出目录&gt;<br>mongodump –db mydatabase –out .&#x2F;data<br>导入命令<br>mongorestore –host &lt;目标主机&gt; –port &lt;目标端口&gt; &lt;输入目录&gt;<br>mongorestore –db mynewdatabase –host localhost –port 27017 .&#x2F;data&#x2F;mydatabase</p></li><li><p>导出占用较大的collection<br>导出db是label,collection是brand的数据<br>mongodump –host localhost –port 27017 –db label –collection brand &gt; brand.bson<br>恢复数据一个collection数据<br>mongorestore –host otherhost –port 27017 –db label roles.bson</p></li></ol><h2 id="启动一个docker的mongo"><a href="#启动一个docker的mongo" class="headerlink" title="启动一个docker的mongo"></a>启动一个docker的mongo</h2><p>sudo docker run -d –name mongodb -v &#x2F;media&#x2F;backup&#x2F;mongo:&#x2F;data&#x2F;db   -p 27017:27017   mongo:4.4.17</p><h2 id="恢复mongo数据"><a href="#恢复mongo数据" class="headerlink" title="恢复mongo数据"></a>恢复mongo数据</h2><p>mongorestore –db label –host newnew –port 27017 .&#x2F;label</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>stable_diffusion</title>
    <link href="/2023/03/31/stable-diffusion/"/>
    <url>/2023/03/31/stable-diffusion/</url>
    
    <content type="html"><![CDATA[<h1 id="安装Stable-Diffusion，确保你已经安装了git-命令行下操作"><a href="#安装Stable-Diffusion，确保你已经安装了git-命令行下操作" class="headerlink" title="安装Stable Diffusion，确保你已经安装了git, 命令行下操作"></a>安装Stable Diffusion，确保你已经安装了git, 命令行下操作</h1><p>git clone <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui">https://github.com/AUTOMATIC1111/stable-diffusion-webui</a></p><h1 id="安装依赖环境，下载conda或miniconda-安装conda后创建虚拟环境"><a href="#安装依赖环境，下载conda或miniconda-安装conda后创建虚拟环境" class="headerlink" title="安装依赖环境，下载conda或miniconda, 安装conda后创建虚拟环境"></a>安装依赖环境，下载conda或miniconda, 安装conda后创建虚拟环境</h1><p>conda create –name webui python&#x3D;3.10<br>conda activate webui</p><h1 id="进入到stable-diffusion-webui目录，安装依赖"><a href="#进入到stable-diffusion-webui目录，安装依赖" class="headerlink" title="进入到stable-diffusion-webui目录，安装依赖"></a>进入到stable-diffusion-webui目录，安装依赖</h1><p>pip install -r requirements.txt</p><h1 id="运行webui"><a href="#运行webui" class="headerlink" title="运行webui"></a>运行webui</h1><p>python webui.py –share –listen –enable-insecure-extension-access</p><h1 id="访问"><a href="#访问" class="headerlink" title="访问"></a>访问</h1><p><a href="http://127.0.0.1:7860/">http://127.0.0.1:7860</a></p><p>#概念解释:</p><h2 id="stable-diffusion"><a href="#stable-diffusion" class="headerlink" title="stable-diffusion:"></a>stable-diffusion:</h2><p>文字生成图像，或图像生成图像,stable-diffusion是一个旨在提供高质量、稳定的人工图像合成的框架和方法<br>官网: <a href="https://stablediffusionweb.com/">https://stablediffusionweb.com</a></p><h2 id="stable-diffusion-webui"><a href="#stable-diffusion-webui" class="headerlink" title="stable-diffusion-webui:"></a>stable-diffusion-webui:</h2><p>操作stable-diffusion的一个网页界面,stable-diffusion-webui是一个基于stable-diffusion开源图像合成框架构建的交互式用户界面。</p><h2 id="下载模型地址-C站"><a href="#下载模型地址-C站" class="headerlink" title="下载模型地址: C站"></a>下载模型地址: C站</h2><p><a href="https://civitai.com/">https://civitai.com/</a></p><h2 id="什么是checkpoint"><a href="#什么是checkpoint" class="headerlink" title="什么是checkpoint"></a>什么是checkpoint</h2><p>即stable diffusion的base模型,大模型&#x2F;底模型 必备 Stable Diffusion V1.4  V1.5   V2.0  V2.1 泛化性、通用性,有的大模型自带VAE模型。不额外挂载,dreambooth可看作大模型</p><h2 id="VAE模型-必备-解码，图像效果更好"><a href="#VAE模型-必备-解码，图像效果更好" class="headerlink" title="VAE模型:必备,解码，图像效果更好"></a>VAE模型:必备,解码，图像效果更好</h2><h2 id="embedding-model"><a href="#embedding-model" class="headerlink" title="embedding model:"></a>embedding model:</h2><p>就是嵌入模型，或者叫Textual inversion，文本到向量模型,embedding: text inversion, 这里<br>是文本反嵌入，就是用一个词代表很多词的意思，就是某个提示词代表了很多提示词的意思，类似别名词, C站可以&gt;下载embedding模型, embedding模型不大</p><h2 id="Lora"><a href="#Lora" class="headerlink" title="Lora"></a>Lora</h2><p>一种训练模型的方法，很小的插件模型,微调模型</p><h2 id="Tag"><a href="#Tag" class="headerlink" title="Tag"></a>Tag</h2><p>提示词，即描述如何生成图像</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>cuda_amp</title>
    <link href="/2023/03/30/cuda-amp/"/>
    <url>/2023/03/30/cuda-amp/</url>
    
    <content type="html"><![CDATA[<h1 id="torch-cuda-amp-cuda的混合精度"><a href="#torch-cuda-amp-cuda的混合精度" class="headerlink" title="torch cuda amp  cuda的混合精度"></a>torch cuda amp  cuda的混合精度</h1><p>torch.cuda.amp.autocast函数：自动将上下文中的计算步骤转换为 FP16 格式，并在计算完成后将结果转换回 FP32 格式，以保证数值精度。需要注意的是，autocast() 只会自动转换支持 FP16 格式的计算步骤，对于不支持 FP16 格式的计算步骤，仍然会使用 FP32 格式进行计算。另外，autocast() 需要与支持 FP16 的硬件和软件环境一起使用，否则可能会导致计算结果的不准确性。</p><p>contextlib.nullcontext(): 用于在不需要执行任何操作的情况下创建上下文。它可以作为一个占位符上下文管理器使用，以便在某些情况下避免代码重复或错误。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">maybe_autocast</span>(<span class="hljs-params">self, dtype=torch.float16</span>):<br>    <span class="hljs-comment"># if on cpu, don&#x27;t use autocast</span><br>    <span class="hljs-comment"># if on gpu, use autocast with dtype if provided, otherwise use torch.float16</span><br>    enable_autocast = self.device != torch.device(<span class="hljs-string">&quot;cpu&quot;</span>)<br><br>    <span class="hljs-keyword">if</span> enable_autocast:<br>        <span class="hljs-keyword">return</span> torch.cuda.amp.autocast(dtype=dtype)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> contextlib.nullcontext()<br><span class="hljs-keyword">with</span> self.maybe_autocast():  <br>    image_embeds = self.ln_vision(self.visual_encoder(image)) <br></code></pre></td></tr></table></figure><p>这里的self.maybe_autocast() 是一个上下文管理器，用于控制模型是否启用自动混合精度（Automatic Mixed Precision，简称 AMP）加速。当启用 AMP 加速时，模型的参数和梯度会以 FP16 格式存储和计算，从而减少计算量和内存占用。但是，由于 FP16 格式的数值精度较低，可能会对模型的精度造成一定影响。<br>self.maybe_autocast() 的作用是判断当前环境是否支持使用 AMP 加速。如果支持，则启用 AMP 加速，否则不启用。这样可以在不同的环境下保持代码的兼容性，并且可以轻松地在支持 AMP 的环境中实现加速。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>webui报错</title>
    <link href="/2023/03/29/webui%E6%8A%A5%E9%94%99/"/>
    <url>/2023/03/29/webui%E6%8A%A5%E9%94%99/</url>
    
    <content type="html"><![CDATA[<h1 id="升级Webui时报错如下时"><a href="#升级Webui时报错如下时" class="headerlink" title="升级Webui时报错如下时"></a>升级Webui时报错如下时</h1><p>升级下gradio即可，pip install -U gradio</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">Traceback (most recent call last):<br>  File <span class="hljs-string">&quot;/user/stable-diffusion-webui/webui.py&quot;</span>, line <span class="hljs-number">340</span>, <span class="hljs-keyword">in</span> &lt;<span class="hljs-keyword">module</span>&gt;<br>    webui<span class="hljs-literal">()</span><br>  File <span class="hljs-string">&quot;/user/stable-diffusion-webui/webui.py&quot;</span>, line <span class="hljs-number">243</span>, <span class="hljs-keyword">in</span> webui<br>    shared.demo = modules.ui.create<span class="hljs-constructor">_ui()</span><br>  File <span class="hljs-string">&quot;/user/stable-diffusion-webui/modules/ui.py&quot;</span>, line <span class="hljs-number">448</span>, <span class="hljs-keyword">in</span> create_ui<br>    <span class="hljs-keyword">with</span> gr.<span class="hljs-constructor">Blocks(<span class="hljs-params">analytics_enabled</span>=False)</span> <span class="hljs-keyword">as</span> txt2img_interface:<br>  File <span class="hljs-string">&quot;/user/anaconda3/envs/webui/lib/python3.10/site-packages/gradio/blocks.py&quot;</span>, line <span class="hljs-number">486</span>, <span class="hljs-keyword">in</span> __init__<br>    super<span class="hljs-literal">()</span>.<span class="hljs-constructor">__init__(<span class="hljs-params">render</span>=False, <span class="hljs-operator">**</span><span class="hljs-params">kwargs</span>)</span><br>  File <span class="hljs-string">&quot;/user/stable-diffusion-webui/modules/scripts.py&quot;</span>, line <span class="hljs-number">561</span>, <span class="hljs-keyword">in</span> BlockContext_init<br>    add<span class="hljs-constructor">_classes_to_gradio_component(<span class="hljs-params">self</span>)</span><br>  File <span class="hljs-string">&quot;/user/stable-diffusion-webui/modules/scripts.py&quot;</span>, line <span class="hljs-number">529</span>, <span class="hljs-keyword">in</span> add_classes_to_gradio_component<br>    comp.elem_classes = <span class="hljs-literal">[&quot;<span class="hljs-identifier">gradio</span>-&quot; + <span class="hljs-identifier">comp</span>.<span class="hljs-identifier">get_block_name</span>(), <span class="hljs-operator">*</span>(<span class="hljs-identifier">comp</span>.<span class="hljs-identifier">elem_classes</span> <span class="hljs-identifier">or</span> []</span>)]<br>AttributeError: &#x27;Blocks&#x27; <span class="hljs-keyword">object</span> has no attribute &#x27;elem_classes<br><br><br>Traceback (most recent call last):<br>  File <span class="hljs-string">&quot;/user/stable-diffusion-webui/modules/ui.py&quot;</span>, line <span class="hljs-number">460</span>, <span class="hljs-keyword">in</span> create_ui<br>    txt2img_prompt, txt2img_prompt_styles, txt2img_negative_prompt, submit, _, _, txt2img_prompt_style_apply, txt2img_save_style, txt2img_paste, extra_networks_button, token_counter, token_button, negative_token_counter, negative_token_button = create<span class="hljs-constructor">_toprow(<span class="hljs-params">is_img2img</span>=False)</span><br>  File <span class="hljs-string">&quot;/user/stable-diffusion-webui/modules/ui.py&quot;</span>, line <span class="hljs-number">288</span>, <span class="hljs-keyword">in</span> create_toprow<br>    prompt = gr.<span class="hljs-constructor">Textbox(<span class="hljs-params">label</span>=<span class="hljs-string">&quot;Prompt&quot;</span>, <span class="hljs-params">elem_id</span>=<span class="hljs-params">f</span><span class="hljs-string">&quot;&#123;id_part&#125;_prompt&quot;</span>, <span class="hljs-params">show_label</span>=False, <span class="hljs-params">lines</span>=3, <span class="hljs-params">placeholder</span>=<span class="hljs-string">&quot;Prompt (press Ctrl+Enter or Alt+Enter to generate)&quot;</span>)</span><br>  File <span class="hljs-string">&quot;/user/anaconda3/envs/webui/lib/python3.10/site-packages/gradio/components.py&quot;</span>, line <span class="hljs-number">300</span>, <span class="hljs-keyword">in</span> __init__<br>    <span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">IOComponent</span>.</span><span class="hljs-module"><span class="hljs-identifier">__init__</span>(</span></span><br>  File <span class="hljs-string">&quot;/user/stable-diffusion-webui/modules/scripts.py&quot;</span>, line <span class="hljs-number">536</span>, <span class="hljs-keyword">in</span> IOComponent_init<br>    add<span class="hljs-constructor">_classes_to_gradio_component(<span class="hljs-params">self</span>)</span><br>  File <span class="hljs-string">&quot;/user/stable-diffusion-webui/modules/scripts.py&quot;</span>, line <span class="hljs-number">521</span>, <span class="hljs-keyword">in</span> add_classes_to_gradio_component<br>    comp.elem_classes = <span class="hljs-literal">[&quot;<span class="hljs-identifier">gradio</span>-&quot; + <span class="hljs-identifier">comp</span>.<span class="hljs-identifier">get_block_name</span>(), <span class="hljs-operator">*</span>(<span class="hljs-identifier">comp</span>.<span class="hljs-identifier">elem_classes</span> <span class="hljs-identifier">or</span> []</span>)]<br>AttributeError: &#x27;Textbox&#x27; <span class="hljs-keyword">object</span> has no attribute &#x27;elem_classes&#x27;<br><br>During handling <span class="hljs-keyword">of</span> the above <span class="hljs-keyword">exception</span>, another <span class="hljs-keyword">exception</span> occurred:<br><br>Traceback (most recent call last):<br>  File <span class="hljs-string">&quot;/user/stable-diffusion-webui/webui.py&quot;</span>, line <span class="hljs-number">337</span>, <span class="hljs-keyword">in</span> &lt;<span class="hljs-keyword">module</span>&gt;<br>    webui<span class="hljs-literal">()</span><br>  File <span class="hljs-string">&quot;/user/stable-diffusion-webui/webui.py&quot;</span>, line <span class="hljs-number">240</span>, <span class="hljs-keyword">in</span> webui<br>    shared.demo = modules.ui.create<span class="hljs-constructor">_ui()</span><br>  File <span class="hljs-string">&quot;/user/stable-diffusion-webui/modules/ui.py&quot;</span>, line <span class="hljs-number">459</span>, <span class="hljs-keyword">in</span> create_ui<br>    <span class="hljs-keyword">with</span> gr.<span class="hljs-constructor">Blocks(<span class="hljs-params">analytics_enabled</span>=False)</span> <span class="hljs-keyword">as</span> txt2img_interface:<br>  File <span class="hljs-string">&quot;/user/anaconda3/envs/webui/lib/python3.10/site-packages/gradio/blocks.py&quot;</span>, line <span class="hljs-number">1097</span>, <span class="hljs-keyword">in</span> __exit__<br>    self.config = self.get<span class="hljs-constructor">_config_file()</span><br>  File <span class="hljs-string">&quot;/user/anaconda3/envs/webui/lib/python3.10/site-packages/gradio/blocks.py&quot;</span>, line <span class="hljs-number">1073</span>, <span class="hljs-keyword">in</span> get_config_file<br>    <span class="hljs-string">&quot;props&quot;</span>: utils.delete<span class="hljs-constructor">_none(<span class="hljs-params">block</span>.<span class="hljs-params">get_config</span>()</span>)<br>  File <span class="hljs-string">&quot;/user/anaconda3/envs/webui/lib/python3.10/site-packages/gradio/components.py&quot;</span>, line <span class="hljs-number">322</span>, <span class="hljs-keyword">in</span> get_config<br>    <span class="hljs-string">&quot;type&quot;</span>: self.<span class="hljs-keyword">type</span>,<br>AttributeError: &#x27;Textbox&#x27; <span class="hljs-keyword">object</span> has no attribute &#x27;<span class="hljs-keyword">type</span>&#x27;. Did you mean: &#x27;style&#x27;?<br></code></pre></td></tr></table></figure>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>lavis和transformers的冲突</title>
    <link href="/2023/03/27/lavis%E5%92%8Ctransformers%E7%9A%84%E5%86%B2%E7%AA%81/"/>
    <url>/2023/03/27/lavis%E5%92%8Ctransformers%E7%9A%84%E5%86%B2%E7%AA%81/</url>
    
    <content type="html"><![CDATA[<p>salesforce的LAVIS包，<a href="https://github.com/salesforce/LAVIS%E6%98%AF%E4%B8%80%E4%B8%AA%E5%A4%9A%E6%A8%A1%E6%80%81%E7%9A%84%E5%BA%93%EF%BC%8C%E5%85%B6%E4%B8%AD%E7%9A%84BLIP2%E6%A8%A1%E5%9D%97%E9%83%A8%E5%88%86%E5%92%8Chuggingface%E7%9A%84trasformers==4.27.1%E4%B8%8D%E5%85%BC%E5%AE%B9,%E4%B8%8D%E5%85%BC%E5%AE%B9%E9%83%A8%E5%88%86%E6%98%AF,%E5%8E%9F%E5%9B%A0%E6%98%AFquery_embeds%E8%A2%ABrepeat%E4%BA%86%E7%BB%B4%E5%BA%A60%E4%B8%A4%E6%AC%A1%EF%BC%8C%E6%89%80%E4%BB%A5%E9%80%A0%E6%88%90torch.cat%E6%8B%BC%E6%8E%A5%E6%97%B6%E5%86%B2%E7%AA%81%E3%80%82">https://github.com/salesforce/LAVIS是一个多模态的库，其中的BLIP2模块部分和huggingface的trasformers==4.27.1不兼容,不兼容部分是,原因是query_embeds被repeat了维度0两次，所以造成torch.cat拼接时冲突。</a></p><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs maxima">lavis/models/blip2_models/blip2_opt.py<br>的第<span class="hljs-number">217</span>和<span class="hljs-number">218</span>行<br>            # <span class="hljs-keyword">else</span>:<br>            #     query_embeds = inputs_opt.repeat_interleave(num_beams, <span class="hljs-built_in">dim</span>=<span class="hljs-number">0</span>)<br>和trasformers==<span class="hljs-number">4.27</span><span class="hljs-number">.1</span>的<span class="hljs-number">679</span>到<span class="hljs-number">683</span>冲突<br>        def _expand_dict_for_generation(dict_to_expand):<br>            <span class="hljs-keyword">for</span> <span class="hljs-built_in">key</span> <span class="hljs-keyword">in</span> dict_to_expand:<br>                <span class="hljs-keyword">if</span> dict_to_expand[<span class="hljs-built_in">key</span>] <span class="hljs-built_in">is</span> <span class="hljs-keyword">not</span> None <span class="hljs-keyword">and</span> isinstance(dict_to_expand[<span class="hljs-built_in">key</span>], torch.Tensor):<br>                    dict_to_expand[<span class="hljs-built_in">key</span>] = dict_to_expand[<span class="hljs-built_in">key</span>].repeat_interleave(expand_size, <span class="hljs-built_in">dim</span>=<span class="hljs-number">0</span>)<br>            <span class="hljs-built_in">return</span> dict_to_expand<br><br>造成 lavis/models/blip2_models/modeling_opt.py 的<span class="hljs-number">703</span>到<span class="hljs-number">705</span>行 cat拼接时维度不一致<br>        <span class="hljs-keyword">if</span> query_embeds <span class="hljs-built_in">is</span> <span class="hljs-keyword">not</span> None:<br>            inputs_embeds = torch.cat([query_embeds, inputs_embeds], <span class="hljs-built_in">dim</span>=<span class="hljs-number">1</span>)<br>            input_shape = inputs_embeds.size()[:-<span class="hljs-number">1</span>]<br></code></pre></td></tr></table></figure><p>repeat_interleave()是PyTorch中的一个函数，用于将张量中的元素沿某一维度复制n次，即复制后的张量沿该维度.<br>这个函数有两个参数，第一个参数是重复的次数，第二个参数是重复的维度 (pytorch.org).<br>例如，如果你有一个形状为(3, 4)的张量，你可以使用repeat_interleave()函数将其中的每个元素沿着第0维重复2次，如下所示：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs stylus">import torch<br><br>x = torch<span class="hljs-selector-class">.tensor</span>(<span class="hljs-selector-attr">[[1, 2, 3, 4]</span>,<br><span class="hljs-selector-attr">[5, 6, 7, 8]</span>,<br><span class="hljs-selector-attr">[9, 10, 11, 12]</span>])<br><br>y = torch<span class="hljs-selector-class">.repeat_interleave</span>(x, repeats=<span class="hljs-number">2</span>, dim=<span class="hljs-number">0</span>)<br><br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(y)</span></span><br></code></pre></td></tr></table></figure><p>输出结果为：</p><p>tensor([[ 1,  2,  3,  4],<br>[ 1,  2,  3,  4],<br>[ 5,  6,  7,  8],<br>[ 5,  6,  7,  8],<br>[ 9, 10, 11, 12],<br>[ 9, 10, 11, 12]])<br>在这个例子中，我们将x沿着第0维重复了2次，因此输出结果中每个元素都被重复了2次</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>知识点总结</title>
    <link href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/"/>
    <url>/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/</url>
    
    <content type="html"><![CDATA[<h1 id="NLP方向总结-其它"><a href="#NLP方向总结-其它" class="headerlink" title="NLP方向总结-其它"></a>NLP方向总结-其它</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E5%85%B6%E5%AE%83.pdf" title="[NLP方向总结-其它.pdf]">[NLP方向总结-其它.pdf]</a><h1 id="NLP方向总结-对比学习"><a href="#NLP方向总结-对比学习" class="headerlink" title="NLP方向总结-对比学习"></a>NLP方向总结-对比学习</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0.pdf" title="[NLP方向总结-对比学习.pdf]">[NLP方向总结-对比学习.pdf]</a><h1 id="NLP方向总结-翻译"><a href="#NLP方向总结-翻译" class="headerlink" title="NLP方向总结-翻译"></a>NLP方向总结-翻译</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E7%BF%BB%E8%AF%91.pdf" title="[NLP方向总结-翻译.pdf]">[NLP方向总结-翻译.pdf]</a><h1 id="NLP方向总结-多模态"><a href="#NLP方向总结-多模态" class="headerlink" title="NLP方向总结-多模态"></a>NLP方向总结-多模态</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E5%A4%9A%E6%A8%A1%E6%80%81.pdf" title="[NLP方向总结-多模态.pdf]">[NLP方向总结-多模态.pdf]</a><h1 id="NLP方向总结-显存优化"><a href="#NLP方向总结-显存优化" class="headerlink" title="NLP方向总结-显存优化"></a>NLP方向总结-显存优化</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E6%98%BE%E5%AD%98%E4%BC%98%E5%8C%96.pdf" title="[NLP方向总结-显存优化.pdf]">[NLP方向总结-显存优化.pdf]</a><h1 id="NLP方向总结-数据结构"><a href="#NLP方向总结-数据结构" class="headerlink" title="NLP方向总结-数据结构"></a>NLP方向总结-数据结构</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.pdf" title="[NLP方向总结-数据结构.pdf]">[NLP方向总结-数据结构.pdf]</a><h1 id="NLP方向总结-文本摘要"><a href="#NLP方向总结-文本摘要" class="headerlink" title="NLP方向总结-文本摘要"></a>NLP方向总结-文本摘要</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E6%96%87%E6%9C%AC%E6%91%98%E8%A6%81.pdf" title="[NLP方向总结-文本摘要.pdf]">[NLP方向总结-文本摘要.pdf]</a><h1 id="NLP方向总结-注意力机制"><a href="#NLP方向总结-注意力机制" class="headerlink" title="NLP方向总结-注意力机制"></a>NLP方向总结-注意力机制</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6.pdf" title="[NLP方向总结-注意力机制.pdf]">[NLP方向总结-注意力机制.pdf]</a><h1 id="量化金融总结"><a href="#量化金融总结" class="headerlink" title="量化金融总结"></a>量化金融总结</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/%E9%87%8F%E5%8C%96%E9%87%91%E8%9E%8D%E6%80%BB%E7%BB%93.pdf" title="[量化金融总结.pdf]">[量化金融总结.pdf]</a><h1 id="NLP方向总结-新词发现"><a href="#NLP方向总结-新词发现" class="headerlink" title="NLP方向总结-新词发现"></a>NLP方向总结-新词发现</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E6%96%B0%E8%AF%8D%E5%8F%91%E7%8E%B0.pdf" title="[NLP方向总结-新词发现.pdf]">[NLP方向总结-新词发现.pdf]</a><h1 id="NLP方向总结-损失函数"><a href="#NLP方向总结-损失函数" class="headerlink" title="NLP方向总结-损失函数"></a>NLP方向总结-损失函数</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0.pdf" title="[NLP方向总结-损失函数.pdf]">[NLP方向总结-损失函数.pdf]</a><h1 id="NLP方向总结-模型蒸馏"><a href="#NLP方向总结-模型蒸馏" class="headerlink" title="NLP方向总结-模型蒸馏"></a>NLP方向总结-模型蒸馏</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F.pdf" title="[NLP方向总结-模型蒸馏.pdf]">[NLP方向总结-模型蒸馏.pdf]</a><h1 id="NLP方向总结-主体"><a href="#NLP方向总结-主体" class="headerlink" title="NLP方向总结-主体"></a>NLP方向总结-主体</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E4%B8%BB%E4%BD%93.pdf" title="[NLP方向总结-主体.pdf]">[NLP方向总结-主体.pdf]</a><h1 id="NLP方向总结-对抗学习"><a href="#NLP方向总结-对抗学习" class="headerlink" title="NLP方向总结-对抗学习"></a>NLP方向总结-对抗学习</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E5%AF%B9%E6%8A%97%E5%AD%A6%E4%B9%A0.pdf" title="[NLP方向总结-对抗学习.pdf]">[NLP方向总结-对抗学习.pdf]</a><h1 id="NLP方向总结-数据增强"><a href="#NLP方向总结-数据增强" class="headerlink" title="NLP方向总结-数据增强"></a>NLP方向总结-数据增强</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA.pdf" title="[NLP方向总结-数据增强.pdf]">[NLP方向总结-数据增强.pdf]</a><h1 id="NLP方向总结-问答"><a href="#NLP方向总结-问答" class="headerlink" title="NLP方向总结-问答"></a>NLP方向总结-问答</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E9%97%AE%E7%AD%94.pdf" title="[NLP方向总结-问答.pdf]">[NLP方向总结-问答.pdf]</a><h1 id="3D领域总结"><a href="#3D领域总结" class="headerlink" title="3D领域总结"></a>3D领域总结</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/3D%E9%A2%86%E5%9F%9F%E6%80%BB%E7%BB%93.pdf" title="[3D领域总结.pdf]">[3D领域总结.pdf]</a><h1 id="NLP方向总结-分词"><a href="#NLP方向总结-分词" class="headerlink" title="NLP方向总结-分词"></a>NLP方向总结-分词</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E5%88%86%E8%AF%8D.pdf" title="[NLP方向总结-分词.pdf]">[NLP方向总结-分词.pdf]</a><h1 id="强化学习总结"><a href="#强化学习总结" class="headerlink" title="强化学习总结"></a>强化学习总结</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93.pdf" title="[强化学习总结.pdf]">[强化学习总结.pdf]</a><h1 id="NLP方向总结-检索"><a href="#NLP方向总结-检索" class="headerlink" title="NLP方向总结-检索"></a>NLP方向总结-检索</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E6%A3%80%E7%B4%A2.pdf" title="[NLP方向总结-检索.pdf]">[NLP方向总结-检索.pdf]</a><h1 id="NLP方向总结-数据标注"><a href="#NLP方向总结-数据标注" class="headerlink" title="NLP方向总结-数据标注"></a>NLP方向总结-数据标注</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E6%95%B0%E6%8D%AE%E6%A0%87%E6%B3%A8.pdf" title="[NLP方向总结-数据标注.pdf]">[NLP方向总结-数据标注.pdf]</a><h1 id="NLP方向总结-优化器"><a href="#NLP方向总结-优化器" class="headerlink" title="NLP方向总结-优化器"></a>NLP方向总结-优化器</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E4%BC%98%E5%8C%96%E5%99%A8.pdf" title="[NLP方向总结-优化器.pdf]">[NLP方向总结-优化器.pdf]</a><h1 id="NLP方向总结-矩阵"><a href="#NLP方向总结-矩阵" class="headerlink" title="NLP方向总结-矩阵"></a>NLP方向总结-矩阵</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E7%9F%A9%E9%98%B5.pdf" title="[NLP方向总结-矩阵.pdf]">[NLP方向总结-矩阵.pdf]</a><h1 id="NLP方向总结-transformer"><a href="#NLP方向总结-transformer" class="headerlink" title="NLP方向总结-transformer"></a>NLP方向总结-transformer</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-transformer.pdf" title="[NLP方向总结-transformer.pdf]">[NLP方向总结-transformer.pdf]</a><h1 id="NLP方向总结-机器学习"><a href="#NLP方向总结-机器学习" class="headerlink" title="NLP方向总结-机器学习"></a>NLP方向总结-机器学习</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.pdf" title="[NLP方向总结-机器学习.pdf]">[NLP方向总结-机器学习.pdf]</a><h1 id="NLP方向总结-情感分析"><a href="#NLP方向总结-情感分析" class="headerlink" title="NLP方向总结-情感分析"></a>NLP方向总结-情感分析</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90.pdf" title="[NLP方向总结-情感分析.pdf]">[NLP方向总结-情感分析.pdf]</a><h1 id="NLP方向总结-CNN"><a href="#NLP方向总结-CNN" class="headerlink" title="NLP方向总结-CNN"></a>NLP方向总结-CNN</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-CNN.pdf" title="[NLP方向总结-CNN.pdf]">[NLP方向总结-CNN.pdf]</a><h1 id="NLP方向总结-提示学习"><a href="#NLP方向总结-提示学习" class="headerlink" title="NLP方向总结-提示学习"></a>NLP方向总结-提示学习</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0.pdf" title="[NLP方向总结-提示学习.pdf]">[NLP方向总结-提示学习.pdf]</a><h1 id="NLP方向总结-知识图谱"><a href="#NLP方向总结-知识图谱" class="headerlink" title="NLP方向总结-知识图谱"></a>NLP方向总结-知识图谱</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1.pdf" title="[NLP方向总结-知识图谱.pdf]">[NLP方向总结-知识图谱.pdf]</a><h1 id="NLP方向总结-激活函数"><a href="#NLP方向总结-激活函数" class="headerlink" title="NLP方向总结-激活函数"></a>NLP方向总结-激活函数</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0.pdf" title="[NLP方向总结-激活函数.pdf]">[NLP方向总结-激活函数.pdf]</a><h1 id="计算机视觉总结"><a href="#计算机视觉总结" class="headerlink" title="计算机视觉总结"></a>计算机视觉总结</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%80%BB%E7%BB%93.pdf" title="[计算机视觉总结.pdf]">[计算机视觉总结.pdf]</a><h1 id="NLP方向总结-训练"><a href="#NLP方向总结-训练" class="headerlink" title="NLP方向总结-训练"></a>NLP方向总结-训练</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E8%AE%AD%E7%BB%83.pdf" title="[NLP方向总结-训练.pdf]">[NLP方向总结-训练.pdf]</a><h1 id="NLP方向总结-实体链接"><a href="#NLP方向总结-实体链接" class="headerlink" title="NLP方向总结-实体链接"></a>NLP方向总结-实体链接</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E5%AE%9E%E4%BD%93%E9%93%BE%E6%8E%A5.pdf" title="[NLP方向总结-实体链接.pdf]">[NLP方向总结-实体链接.pdf]</a><h1 id="NLP方向总结-文本生成"><a href="#NLP方向总结-文本生成" class="headerlink" title="NLP方向总结-文本生成"></a>NLP方向总结-文本生成</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90.pdf" title="[NLP方向总结-文本生成.pdf]">[NLP方向总结-文本生成.pdf]</a><h1 id="NLP方向总结-Metric"><a href="#NLP方向总结-Metric" class="headerlink" title="NLP方向总结-Metric"></a>NLP方向总结-Metric</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-Metric.pdf" title="[NLP方向总结-Metric.pdf]">[NLP方向总结-Metric.pdf]</a><h1 id="NLP方向总结-信息抽取"><a href="#NLP方向总结-信息抽取" class="headerlink" title="NLP方向总结-信息抽取"></a>NLP方向总结-信息抽取</h1><a href="/2023/03/21/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/NLP%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93-%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96.pdf" title="[NLP方向总结-信息抽取.pdf]">[NLP方向总结-信息抽取.pdf]</a>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>NLP项目和论文搜索</title>
    <link href="/2023/03/21/NLP%E9%A1%B9%E7%9B%AE%E5%92%8C%E8%AE%BA%E6%96%87%E6%90%9C%E7%B4%A2/"/>
    <url>/2023/03/21/NLP%E9%A1%B9%E7%9B%AE%E5%92%8C%E8%AE%BA%E6%96%87%E6%90%9C%E7%B4%A2/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
    <tags>
      
      <tag>summary</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>chatgpt</title>
    <link href="/2023/03/02/chatgpt/"/>
    <url>/2023/03/02/chatgpt/</url>
    
    <content type="html"><![CDATA[<hr><h1 id="一、ChatGPT介绍"><a href="#一、ChatGPT介绍" class="headerlink" title="一、ChatGPT介绍"></a>一、ChatGPT介绍</h1><h2 id="1-什么是ChatGPT"><a href="#1-什么是ChatGPT" class="headerlink" title="1. 什么是ChatGPT?"></a>1. 什么是ChatGPT?</h2><p><a href="https://openai.com/blog/chatgpt/">https://openai.com/blog/chatgpt/</a></p><ol><li>来自官网介绍：<br> 我们已经训练了一个叫做ChatGPT的模型，它以对话的方式进行互动。对话的形式使ChatGPT有可能回答后续问题，承认自己的错误，挑战不正确的前提，并拒绝不适当的请求。ChatGPT是InstructGPT的兄弟姐妹模型，InstructGPT被训练成能够遵循提示中的指令并提供详细的回应。</li><li>ChatGPT自己介绍自己：<br> ChatGPT是一种基于自然语言处理（NLP）的人工智能模型，它是基于GPT模型（Generative Pre-trained Transformer）和聊天机器人技术的结合而产生的。ChatGPT模型使用大规模的文本数据进行预训练，然后可以生成具有连贯性和逻辑性的自然语言响应，以进行人机交互和对话。</li><li>更智能的全面知识面的个人助手， 本文80%以上内容来自ChatGPT的回答。</li></ol><h2 id="2-ChatGPT示例"><a href="#2-ChatGPT示例" class="headerlink" title="2. ChatGPT示例"></a>2. ChatGPT示例</h2><p>【（真·人工智能）】<a href="https://b23.tv/As9Tqm5">https://b23.tv/As9Tqm5</a><br>【试用了集合ChatGPT的Bing搜索后，感觉潘多拉魔盒已经打开了】 <a href="https://b23.tv/aDMiJ4p">https://b23.tv/aDMiJ4p</a></p><img src="/2023/03/02/chatgpt/chatgpt10.png" class=""><img src="/2023/03/02/chatgpt/chatgpt9.png" class=""><p>NLP任务处理</p><img src="/2023/03/02/chatgpt/chatgpt8.png" class=""><img src="/2023/03/02/chatgpt/chatgpt7.png" class=""><img src="/2023/03/02/chatgpt/chatgpt3.png" class=""><p>计算器</p><img src="/2023/03/02/chatgpt/image-20230215150045240.png" class=""><h2 id="3-ChatGPT注册"><a href="#3-ChatGPT注册" class="headerlink" title="3. ChatGPT注册"></a>3. ChatGPT注册</h2><p>由于ChatGPT暂不支持国内用户，需要使用国外代理，然后注册ChatGPT账号，还需使用国外手机验证一下，然后就可以直接使用了。</p><p>附件： [OpenAI Chatgpt注册及使用教程.pdf](..&#x2F;..&#x2F;..&#x2F;Users&#x2F;admin&#x2F;Downloads&#x2F;ChatGPT&#x2F;OpenAI Chatgpt注册及使用教程.pdf) </p><h2 id="4-专有名词"><a href="#4-专有名词" class="headerlink" title="4. 专有名词"></a>4. 专有名词</h2><p><strong>AIGC</strong>即AI Generated Content，是指利用人工智能技术来生成内容，AIGC也被认为是继UGC、PGC之后的新型内容生产方式，AI绘画(<strong>Stable Diffusion，根据用户文字生成图片</strong>)、AI写作等都属于AIGC的分支。 对AIGC来说，2022年被认为是其发展速度惊人的一年。</p><p><strong>Few-shot，one-shot，zero-shot Learning</strong><br>Few-shot learning（少样本学习）是指通过少量的样本（通常是几十个到几百个）来训练一个模型，使其能够在新任务上进行准确的预测。这通常涉及到对预训练模型进行微调，以适应新任务的要求。<br>One-shot learning（单样本学习）是指通过仅一个样本来学习一个新类别。这对于那些数据量有限、样本获取困难的任务尤为有用，但是由于训练样本极少，因此需要具有较强的泛化能力的模型。<strong>（就是我们常说的举个例子看看）</strong><br>Zero-shot learning（零样本学习）是指通过学习没有样本的新任务或新类别。在这种情况下，模型需要利用先前学习到的知识和先验信息来推断新任务或新类别的属性和特征。</p><p><strong>提示学习</strong>（Prompt Learning）是指一种基于自然语言提示（即提示语或样例）来指导神经网络进行生成或分类任务的学习方法。它是自然语言处理领域中的一种新兴研究方向，旨在缓解深度学习模型的数据需求和泛化能力问题，同时可以提高模型的可解释性和人机交互性。</p><hr><h1 id="二、ChatGPT基础"><a href="#二、ChatGPT基础" class="headerlink" title="二、ChatGPT基础"></a>二、ChatGPT基础</h1><h2 id="1-OpenAI介绍"><a href="#1-OpenAI介绍" class="headerlink" title="1. OpenAI介绍"></a>1. OpenAI介绍</h2><p>OpenAI是一个非营利性研究组织，致力于研究人工智能（AI）的安全性和可控性，并推动AI技术的全面发展。该组织成立于2015年，总部位于美国旧金山。OpenAI由众多顶尖的科学家和工程师组成，包括<strong>Elon Musk</strong>、Sam Altman、Greg Brockman等知名人士，同时获得了多个知名公司的资助，如<strong>微软</strong>、亚马逊等。该组织致力于开发人工智能系统，使之更加智能、<strong>安全、透明和可控</strong>。</p><p>其它产品： <a href="https://openai.com/dall-e-2/%EF%BC%8C">https://openai.com/dall-e-2/，</a> <a href="https://openai.com/blog/openai-codex/">https://openai.com/blog/openai-codex/</a></p><p><a href="https://fortune.com/2023/02/17/chatgpt-elon-musk-openai-microsoft-company-regulator-oversight/">Elon Musk just disowned ChatGPT parent company OpenAI | Fortune</a></p><p>不再像他曾经在2015年12月共同创立的那样。据马斯克说，它被设计成一个开源的非营利组织，这正是它被称为OpenAI的原因。<br>“现在，它已经成为一个由微软有效控制的闭源、最高利润的公司，”他在Twitter上发帖。”完全不是我的初衷。”—OpenAI失去初心。</p><p>Google 投资 <a href="https://www.anthropic.com/">Anthropic</a></p><h2 id="2-ChatGPT的起源"><a href="#2-ChatGPT的起源" class="headerlink" title="2. ChatGPT的起源"></a>2. ChatGPT的起源</h2><ol><li><p>2018年6月：OpenAI发布了第一代GPT模型（Generative Pre-trained Transformer），可以用于自然语言处理任务，如文本分类、语言翻译等。</p></li><li><p>2019年2月：OpenAI发布了GPT-2模型，拥有超过15亿个参数，可以生成高质量的自然语言文本，引起了广泛的关注和讨论。</p></li><li><p>2019年11月：OpenAI发布了GPT-2的一部分模型，用于构建生成式聊天机器人，该模型名为DialoGPT。</p></li><li><p>2020年2月：OpenAI发布了DialoGPT的改进版本，即DialoGPT-2，引入了多个新的技术和策略，可以更好地生成连贯和有意义的对话。</p></li><li><p>2020年5月：OpenAI推出了GPT-3模型，它是迄今为止最大的模型，拥有1750亿个参数，可以生成更加逼真和多样化的自然语言文本，同时也可以用于构建聊天机器人。</p></li><li><p>2021年1月：OpenAI发布了DialoGPT-3模型，它是基于GPT-3的改进版本，可以生成更加准确和多样化的自然语言响应，被广泛应用于人机交互和智能客服等场景。</p></li></ol><table><thead><tr><th>模型</th><th>发布时间</th><th>参数量</th><th>预训练数据量</th></tr></thead><tbody><tr><td>GPT</td><td>2018 年 6 月</td><td>1.17 亿</td><td>约 5GB</td></tr><tr><td>GPT-2</td><td>2019 年 2 月</td><td>15 亿</td><td>40GB</td></tr><tr><td>GPT-3</td><td>2020 年 5 月</td><td>1,750 亿</td><td>45TB</td></tr></tbody></table><h2 id="3-GPT原理"><a href="#3-GPT原理" class="headerlink" title="3. GPT原理"></a>3. GPT原理</h2><ol><li><p>什么是GPT</p><p>GPT（Generative Pre-trained Transformer）是一种基于Transformer结构的自然语言处理模型，其原理主要包括两个部分：预训练和微调。</p><p>预训练部分是指使用大规模的文本数据对模型进行无监督的预训练。具体来说，GPT使用了一种被称为“掩码语言建模”（Masked Language Modeling，MLM）的技术，即在输入的文本序列中随机掩盖一些词汇，并让模型预测这些被掩盖的词汇。通过这种方式，模型可以学习到词汇之间的上下文信息和语言规律。</p><p>微调部分是指在完成预训练后，将模型用于特定的自然语言处理任务，如文本分类、命名实体识别、情感分析等，通过反向传播算法对模型参数进行微调，使其适应具体任务的要求。</p></li><li><p>什么是Bert</p><p>BERT（Bidirectional Encoder Representations from Transformers）是一种基于Transformer结构的预训练语言模型，由Google研究团队在2018年提出。BERT可以用于多种自然语言处理任务，如文本分类、问答系统、语言翻译等，取得了很好的效果，并在自然语言处理领域引起了广泛关注。</p><p>与之前的自然语言处理模型不同，BERT使用了一种双向预训练的方式，即通过联合训练两个方向的语言模型（从左到右和从右到左），来学习词汇之间的上下文信息。这种方法可以更好地捕捉文本序列中的语言规律和语义信息，并在下游任务中提高模型的泛化能力。</p><p>BERT模型由多个Transformer编码器组成，其中每个编码器由多个自注意力层和前馈神经网络层组成。自注意力层用于学习输入序列中不同位置之间的交互关系，前馈神经网络层用于对特征进行非线性变换。BERT使用了大规模的文本数据进行预训练，并使用了多种技术和策略来优化模型的预训练和微调过程，如掩码语言模型（Masked Language Model，MLM）、下一句预测（Next Sentence Prediction，NSP）等。</p><p>由于BERT具有较强的语义理解和泛化能力，可以对多种自然语言处理任务进行有效处理，因此在自然语言处理领域得到了广泛应用，并成为了自然语言处理领域的重要里程碑。</p></li><li><p>Transformer结构<br>Transformer是一种基于自注意力机制（self-attention）的神经网络模型，主要用于自然语言处理（NLP）任务中的序列建模和序列到序列学习。它于2017年由Google提出，是一种与循环神经网络（RNN）和卷积神经网络（CNN）不同的新型序列建模方法。Transformer模型通过自注意力机制可以在不依赖顺序的情况下对输入序列中的任意位置进行建模，使其具有更好的并行性和效率。同时，它还采用了残差连接和层归一化等技术来缓解梯度消失和梯度爆炸等训练中的常见问题，使得模型训练更加稳定和快速。</p><p>完型填空(BERT已经上下文);根据前文预测后文(GPT预测以后的事)</p></li></ol><img src="/2023/03/02/chatgpt/image-20230215095051761.png" class=""><hr><h1 id="三、ChatGPT原理"><a href="#三、ChatGPT原理" class="headerlink" title="三、ChatGPT原理"></a>三、ChatGPT原理</h1><h2 id="1-RLHF，ChatGPT更懂交流"><a href="#1-RLHF，ChatGPT更懂交流" class="headerlink" title="1. RLHF，ChatGPT更懂交流"></a>1. RLHF，ChatGPT更懂交流</h2><p>reinforcement learning from human feedback，人类反馈的强化学习, 对齐AI系统和人类，即AI系统更懂人类，因为人类很难直接评估。<br>为什么要用RLHF<br>语言模型生成文字的的好坏，很难定义的，因为它是主观的，而且取决于上下文，如写故事，你希望有创意，信息性的文本应该是真实的，或者我们希望代码片段是可执行的。<br>编写一个损失函数来捕捉这些好的属性很难，例如交叉熵损失，评价指标如BLEU或ROUGE，这些指标只是将生成的文本与具有简单规则的参考进行比较，所以提出将这种反馈作为损失来优化模型，使语言模型的答案与复杂的人类价值相一致</p><h2 id="2-ChatGPT的训练过程"><a href="#2-ChatGPT的训练过程" class="headerlink" title="2. ChatGPT的训练过程"></a>2. ChatGPT的训练过程</h2><img src="/2023/03/02/chatgpt/image-20230215102827587.png" class=""><p>Step1: 训练一个supervised fine-tuning监督微调模型，主要目的是学习基本的人类问答知识。使用监督学习在人工标注的数据上微调预训练的GPT-3 1750亿参数模型，大约13000个训练提示，即用户的提出的问题，问题的多样性，生成性问题，开放式问答，头脑风暴，闲聊，重写，总结摘要，分类，封闭式问答，信息提取，99%的问题是英语，其它语种比较少，问题的长度最小是1，最大长度是2039个字，不同的任务长度都有所不同。<br>Step2: 训练一个奖励模型或者叫做偏好模型，主要目的是对模型的回答进行打分，为最后一步强化学习训练提供评判标准。标注者指出他们对一个给定的输入更喜欢哪一个模型的输出。然后我们训练一个奖励模型来预测人类喜欢的输出。用排序的方式代替评分，解决不同人对同一问题的评分不同的而产生的噪声。人工根据模型的不同回答打分，然后对回答得分进行排序,然后训练奖励模型（gpt-3，60亿参数），大约数据集需要33000个训练提示。<br>Step3：训练最终的ChatGPT模型，即RLHF模型，用强化学习对模型进行微调，使用RM的输出作为一个标量奖励,使用PPO算法微调SFT模型。</p><p>整个强化学习系统由智能体（Agent）、状态（State）、奖赏（Reward）、动作（Action）和环境（Environment）五部分组成。</p><h2 id="3-ChatGPT的测试过程"><a href="#3-ChatGPT的测试过程" class="headerlink" title="3.ChatGPT的测试过程"></a>3.ChatGPT的测试过程</h2><p>模型测试<br>    毒性测试：有害的回答，消极的回答，诋毁，暴力内容等<br>    隐私测试：泄露隐私数据<br>    偏见测试：例如性别种族歧视等<br>    真实性测试：不编造事实，以事实为依据的回答，使用封闭领域任务中进行测试，例如TruthfulQA数据集<br>    对齐测试： 不是答非所问，正确的废话，就是回答符合用户意图<br>    其它问题<br>    模型有时会错误地假定前提是真的，例如马斯克出生在中国哪个地区？<br>        Elon Musk was not born in China. He was born on June 28, 1971 in Pretoria, South Africa.<br>    对语言模型使用约束条件，例如，用指定的句子数量写一个摘要，模型的性能就会下降。<br>    人们不可能一下子就训练出一个符合每个人偏好的系统<br>    ChatGPT有时会写出听起来很有道理但不正确或无意义的答案<br>        1）RL训练期间，加上答案的参考来源<br>        2）模型回答的置信度调整，这可能导致它拒绝它可以正确回答的问题<br>        3）监督训练的误差，模型的答案类型取决于标注者<br>    对用户的模糊问题，会猜测一个意图，而不是让用户澄清更具体的问题</p><h2 id="4-ChatGPT模型的优点和局限性"><a href="#4-ChatGPT模型的优点和局限性" class="headerlink" title="4. ChatGPT模型的优点和局限性"></a>4. ChatGPT模型的优点和局限性</h2><p>优点：智能，全面的聊天机器人<br>缺点：ChatGPT有时答案没有依据或随意幻想答案。</p><p>其它疑问： ChatGPT是如何学会承认错误的。</p><hr><h1 id="四、使用ChatGPT模型"><a href="#四、使用ChatGPT模型" class="headerlink" title="四、使用ChatGPT模型"></a>四、使用ChatGPT模型</h1><h2 id="1-体验账号"><a href="#1-体验账号" class="headerlink" title="1. 体验账号"></a>1. 体验账号</h2><p><a href="https://chat.openai.com/">https://chat.openai.com</a></p><h2 id="2-其它使用案例"><a href="#2-其它使用案例" class="headerlink" title="2. 其它使用案例"></a>2. 其它使用案例</h2><p>难记的正则表达式</p><img src="/2023/03/02/chatgpt/image-20230215104822863.png" class=""><p>创作一首歌曲。它应该以一个纺织机操作员和一个落后的手工编织者之间的竞争为特色。它应该包含押韵的诙谐笑话。包括与之相配的钢琴和弦。</p><p>教毕达哥拉斯定理，包括最后的测验，但不要给我答案，然后在我回答时告诉我|是否答对了答案。<br>ChatGPT当导游，各学科老师，写作，写诗，写邮件，改写邮件更正式，写markdown，写sql，角色扮演游戏（当只猫，或Siri），让它有幽默感的段子手。</p><p>工具类使用：Toolformer</p><hr><h1 id="五、ChatGPT模型的发展和未来"><a href="#五、ChatGPT模型的发展和未来" class="headerlink" title="五、ChatGPT模型的发展和未来"></a>五、ChatGPT模型的发展和未来</h1><h2 id="1-国内外进展新闻"><a href="#1-国内外进展新闻" class="headerlink" title="1. 国内外进展新闻"></a>1. 国内外进展新闻</h2><ul><li>百度将发布“中国版ChatGPT”，三月完成内测，定名为“文心一言”</li><li>挑战ChatGPT，谷歌正式发布Bard</li><li>首个中文版ChatGPT来了：大模型的中国元“Yuan”</li><li>京东将发布ChatJD</li><li>阿里内测版本ChatGPT</li><li>正式发布！北京：支持头部企业打造对标ChatGPT的大模型</li></ul><h2 id="2-New-Bing（ChatGPT-4-0"><a href="#2-New-Bing（ChatGPT-4-0" class="headerlink" title="2. New Bing（ChatGPT 4.0)"></a>2. New Bing（ChatGPT 4.0)</h2><ul><li>全语言支持（如英语，中文，日本语，西班牙语，法语或德语），ChatGPT也可以</li><li>Bing chat可以为你搜索网络结果，并提供网站的引用和来源。</li><li>你可以给Bing chat发送一个链接，它会给你一个简短的摘要</li><li>Bing chat可以帮助你进行更自然和流畅的对话，它可以理解你的意图和(情感)，具有人类的同理心。</li><li>加入NewBing的体验,  <a href="https://www.bing.com/new">https://www.bing.com/new</a></li></ul><h2 id="3-未来发展"><a href="#3-未来发展" class="headerlink" title="3. 未来发展"></a>3. 未来发展</h2><p>Step1: (加上答案的来源依据，实施联网获取最新知识)，个人化，例如钢铁侠中的贾维斯（符合你的幽默感，知道你的问答风格， VR虚拟助手）<br>Step2: 结合多模态知识，图片，声音，视频，进行学习，也可以产出图片，声音，视频，成为一个全能的聊天机器人。<br>Step3: 结合波士顿动力的机器人动作，加上全能的ChatGPT进化版，成为会带来AI的革命。<br>Step4: 自我进化，目前的AI模型都是固定好的神经参数，人工来提供训练语料，然后进行训练，当模型会自我获取数据自我训练时，科技将指数级发展，AI的危险也随之到来。</p><hr><h1 id="六、参考"><a href="#六、参考" class="headerlink" title="六、参考"></a>六、参考</h1><p>Training language models to follow instructions with human feedback<br>Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback<br>Learning to summarize from human feedback<br><a href="https://openai.com/blog/chatgpt/">https://openai.com/blog/chatgpt/</a></p><hr>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>多模态项目记录</title>
    <link href="/2022/10/13/%E5%A4%9A%E6%A8%A1%E6%80%81%E9%A1%B9%E7%9B%AE%E8%AE%B0%E5%BD%95/"/>
    <url>/2022/10/13/%E5%A4%9A%E6%A8%A1%E6%80%81%E9%A1%B9%E7%9B%AE%E8%AE%B0%E5%BD%95/</url>
    
    <content type="html"><![CDATA[<h1 id="项目目的，根据给定的图片和标题，判断所属的商品是库中的哪个商品"><a href="#项目目的，根据给定的图片和标题，判断所属的商品是库中的哪个商品" class="headerlink" title="项目目的，根据给定的图片和标题，判断所属的商品是库中的哪个商品"></a>项目目的，根据给定的图片和标题，判断所属的商品是库中的哪个商品</h1><h1 id="数据标注"><a href="#数据标注" class="headerlink" title="数据标注"></a>数据标注</h1><p>开发一个前后端，前端标注人员可以根据提供的关键字进行搜索，搜索通过后端调取爬虫平台，实时获取爬取结果，因为爬取不稳定，添加额外缓存系统，当爬取过一次后，可以直接读取缓存，用户也可以不读取缓存，用户标注的结果提交到后台的mongo中保存<br>标注工具示例:</p><img src="/2022/10/13/%E5%A4%9A%E6%A8%A1%E6%80%81%E9%A1%B9%E7%9B%AE%E8%AE%B0%E5%BD%95/labeltool.png" class=""><p>优化:<br>    0. 提交按钮是浮动状态，方便用户下拉选中后也可以提交<br>    1. 图标加上tmall官方链接，方便标注人员点击查看<br>    2. 标注人员提交标注结果后，给与成功提示，否则给与失败提示，然后清空搜索框<br>    3.Flask接口失败时，也会给与友好提示<br>    4. 当用户搜索关键字为空时，默认给一个搜搜关键字示例<br>    5. 给列表中每个搜索结果的a标签图片都加上点击事件，当是非checked状态时，点击后，变成checked状态，当是checked状态时，点击后变成非checked状态<br>    6. 如果给的关键字在天猫中没有搜索到，返回也是空的，那么给出友好提示<br>    7.判断用户提交的关联商品的名称是否为空，如果为空，提示一下<br>    8. 追加原始的天猫的店铺的url链接，方便标注后一同导入到数据库中<br>    9. 翻页后标签图片的点击事件失效问题修复<br>    10. 增加强制爬取按钮：爬虫搜索（表示不使用缓存直接爬取）<br>        1. 因为缓存的结果可能不存在，那么直接使用强制爬取<br>        html中增加一个div，里面有一个button按钮<br>        css中对这个div浮动，对button更改大小<br>        js中添加事件，点击这个button后，传入的url多加一个spider&#x3D;ture的参数<br>        js通过DOM的location.search解析url参数，获取spider关键字状态，发送请求时根据spdier状态判断请求的force_update参数</p><h1 id="使用模型"><a href="#使用模型" class="headerlink" title="使用模型"></a>使用模型</h1><ol><li>使用的Vilt模型，对比了单流架构和双流架构，单流架构更符合本项目，因为单流架构是汇总了一个文本和图片的高阶特征，而不是2个特征</li><li>首先使用模型继续预训练，我们下载了约70G数据，然后按照Vilt论文中所述，继续预训练，使其适应我们自己的数据集。</li><li>微调模型训练，自定义2个损失，品牌分类损失+商品分类损失，如果只是商品分类损失，模型没有学到品牌的信息点，很容易在品牌上就预测错了，那么商品上更预测错误了，结果能够比单纯的预测商品分类损失准确率提高10%左右</li><li>损失的权重，商品分类损失权重更大一些，因为品牌分类损失更简单，模型很容易就拟合了，结果证明商品分类损失权重大一些的话，准确率提高2%左右。</li><li>损失和训练step的对比图, 使用Visdom绘图, 明显损失相同的情况下，更难的任务拟合更慢<br>图0：预训练模型的MLM和ITM损失<img src="/2022/10/13/%E5%A4%9A%E6%A8%A1%E6%80%81%E9%A1%B9%E7%9B%AE%E8%AE%B0%E5%BD%95/pretrain_loss.png" class=""></li></ol><p>图1：损失权重相同的情况</p><img src="/2022/10/13/%E5%A4%9A%E6%A8%A1%E6%80%81%E9%A1%B9%E7%9B%AE%E8%AE%B0%E5%BD%95/loss1.png" class=""><p>图2：损失权重不同的情况</p><img src="/2022/10/13/%E5%A4%9A%E6%A8%A1%E6%80%81%E9%A1%B9%E7%9B%AE%E8%AE%B0%E5%BD%95/loss.png" class=""><p>Vilt总结:<br>ViLT：没有卷积或区域监督的视觉和语言transformer<br>    定义<br>        视觉和语言预训练（VLP），Vision-and-Language Pre-training<br>        Vision-and-Language Transformer (ViLT)<br>            以一种统一的方式处理两种模态<br>            与以前的VLP模型的主要区别在于它对像素级输入的浅层无卷积嵌入。去除仅用于视觉输入的深层嵌入，通过设计大大减少了模型的大小和运行时间<br>            图2d类型，原始像素的嵌入层很浅，计算量也很小，与文本token一样，将大部分的计算集中在模态交互的建模上<br>        VSE：visual semantic embedding，视觉语义嵌入<br>        MI：modality interaction 模态交互<br>            单流方法: Single-Stream<br>                各层操作图像和文本输入的拼接，例如UNITER<br>            双流方法: Dual-stream<br>                两种模态在输入层面没有拼接起来,类似ViLBERT，LXMERT<br>        TE: textual embedder 文本嵌入器<br>        VE: visual embedder 视觉嵌入器<br>            使用碎片投影减小开销，使用一个32×32的补丁投影，只需要2.4M的参数<br>            传统的区域特征需要步骤（参数量大）：<br>                一个区域建议网络（RPN）根据从CNN主干网汇集的网格特征提出感兴趣的区域（RoI）<br>                非最大限度的抑制（NMS）将RoI的数量减少到几千个<br>                RoI经过RoI头，成为区域特征<br>                NMS再次应用于每个类别，最终将特征的数量减少到一百个以下<br>        MSA: multiheaded self-attention 多头自注意力<br>        ITM: Image Text Match: 图像文本匹配<br>        ViT-B&#x2F;32：代表Patch大小为32，即图片的每个碎片的大小，即32*32像素的，使用Conv2d即可<br>    模型（图3）<br>        模型结构<br>            文本嵌入：词嵌入+位置嵌入+模态类型嵌入<br>            视觉嵌入：图片切成块，线性投影嵌入+位置嵌入+模态类型嵌入<br>            被串联成一个组合序列z0<br>            transformer层<br>                由多个块组成，每个块包含一个多头self-attention(MSA)和一个多层感知器(MLP)<br>                层归一化（LN）在MSA和MLP之前<br>                输出上下文序列zD<br>        预训练目标<br>            图像文本匹配（ITM）<br>                以0.5的概率随机地用不同的图像来替换对齐的图像。一个单一的线性层ITM头将汇集的输出特征p投射到二分类的logits上，我们计算出负logits可能性损失作为我们的ITM损失<br>                word patch alignment 词块对齐（WPA）损失<br>                    计算文本子集和视觉子集两个子集之间的对齐分数，使用非精确近似点法进行最优转译optimal transports（IPOT），并将近似的Wasserstein距离乘以0.1加到ITM损失中<br>                    可视化对齐结果见图4，图像部分和词进行了对齐<br>            mask语言模型（MLM）<br>                0.15的概率随机mask，预测被masked的文本ground truth标签<br>                全词mask，而不是仅仅是词片wordpiecemask<br>        使用RandAugment进行图像增强<br>    数据集<br>        预训练<br>            微软COCO（MSCOCO），视觉基因组（VG），SBU字幕（SBU），以及谷歌概念字幕（GCC）<br>        微调测试任务：<br>            分类任务：VQAv2，NLVR2<br>            检索任务: MSCOCO, Flickr30K</p><h1 id="开发多模态模型评估系统"><a href="#开发多模态模型评估系统" class="headerlink" title="开发多模态模型评估系统"></a>开发多模态模型评估系统</h1><ol start="3"><li>开发2个Tab标签，一个是测试预测，一个是统计<ol><li>测试预测逻辑<br> 用户提交关键词<br> 调用&#x2F;api&#x2F;goodslist获取爬取结果<br> 对爬取结果的图片进行本地缓存<br> 对结果处理后提交多模态模型预测品牌和所属商品<br> 对预测结果进行展示<br> 展示预测结果<br> 展示图片，title，价格，店铺<br> 用户判断预测结果是否正确<br> 如果错误，给出正确的预测商品<br> 提交用户判断结果到后台<br> 统计逻辑<br> 从mongo中读取用户人工判断的结果<br> 展示所有数据的表格形式<br> 统计模型判断正确和错误的结果，显示准确率<img src="/2022/10/13/%E5%A4%9A%E6%A8%A1%E6%80%81%E9%A1%B9%E7%9B%AE%E8%AE%B0%E5%BD%95/eval1.png" class=""><img src="/2022/10/13/%E5%A4%9A%E6%A8%A1%E6%80%81%E9%A1%B9%E7%9B%AE%E8%AE%B0%E5%BD%95/eval2.png" class=""></li></ol></li></ol>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>一个transformers报错</title>
    <link href="/2022/07/04/%E4%B8%80%E4%B8%AAtransformers%E6%8A%A5%E9%94%99/"/>
    <url>/2022/07/04/%E4%B8%80%E4%B8%AAtransformers%E6%8A%A5%E9%94%99/</url>
    
    <content type="html"><![CDATA[<h1 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h1><p>我们在使用huggiface transformers时, 有时会报错<br>transformers报错如下：</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">    <span class="hljs-keyword">raise</span> ValueError(&quot;got_ver is None&quot;)<br>ValueError: got_ver <span class="hljs-keyword">is</span> <span class="hljs-keyword">None</span><br></code></pre></td></tr></table></figure><h1 id="错误分析"><a href="#错误分析" class="headerlink" title="错误分析"></a>错误分析</h1><p>这是由于transformers使用时，会检查需要依赖的依赖包版本是否满足要求，使用的是importlib_metadata库，<br>没有获取到给定的包的名字的版本号，例如pkg是numpy，而numpy安装不正确，或者importlib_metadata有问题，获取numpy的版本为None，那么就报错如上，got_ver &#x3D; importlib_metadata.version(pkg)</p><h1 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h1><p>请查看是否混用了conda和pip，混用是没有问题的，但是有时它们还是会有部分兼容性问题，我报错的原因是importlib_metadata无法检查到conda安装的numpy的版本，改成使用pip重新安装numpy，然后手动测试是否能成功检查版本</p><figure class="highlight python-repl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python-repl">python<br><span class="hljs-meta">&gt;&gt;&gt;</span> <span class="language-python"><span class="hljs-keyword">import</span> importlib_metadata</span><br><span class="hljs-meta">&gt;&gt;&gt;</span> <span class="language-python">importlib_metadata.version(<span class="hljs-string">&#x27;numpy&#x27;</span>)</span><br>&#x27;1.23.0&#x27;<br><span class="hljs-meta">&gt;&gt;&gt;</span><br></code></pre></td></tr></table></figure><p>如果能够检查到，说明问题解决</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>满意度预测模型</title>
    <link href="/2022/07/04/%E6%BB%A1%E6%84%8F%E5%BA%A6%E9%A2%84%E6%B5%8B%E6%A8%A1%E5%9E%8B/"/>
    <url>/2022/07/04/%E6%BB%A1%E6%84%8F%E5%BA%A6%E9%A2%84%E6%B5%8B%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="更多信息参见公众号原文"><a href="#更多信息参见公众号原文" class="headerlink" title="更多信息参见公众号原文"></a>更多信息参见公众号原文</h1><p><a href="https://mp.weixin.qq.com/s/IHcioj1-i0HzloSQ3gu7tw">https://mp.weixin.qq.com/s/IHcioj1-i0HzloSQ3gu7tw</a></p><h1 id="实现意义"><a href="#实现意义" class="headerlink" title="实现意义"></a>实现意义</h1><p>结果： 应该把提升用户满意度的钱花在哪个方面，即产品的哪个属性上，然后再哪个属性上应该提升多少，为提升客户对某产品的整体满意度，对用户评论进行分析，判断出用户对产品的哪些属性的满意度较差，提升哪些属性的产品满意度，能显著影响产品的整体满意度。</p><h1 id="实现思路"><a href="#实现思路" class="headerlink" title="实现思路"></a>实现思路</h1><p>主要分为4个模型</p><h2 id="Aspect情感模型"><a href="#Aspect情感模型" class="headerlink" title="Aspect情感模型"></a>Aspect情感模型</h2><p>预测属性词在句子中的情感, 标签:积极，消极，中性</p><h2 id="整体情感模型"><a href="#整体情感模型" class="headerlink" title="整体情感模型"></a>整体情感模型</h2><p>表达对这个产品的整体情感， 标签:整体积极，整体消极，整体中性，无整体情感<br>   eg: 东西还不错，就是洗了脸有点干干的，也洗的很干净</p><h2 id="贡献度模型"><a href="#贡献度模型" class="headerlink" title="贡献度模型"></a>贡献度模型</h2><p>预测每个aspect对整体情感的贡献度,使用普通线性回归模型，决策树和集成学习模型，深度学习模型分别进行实验<br>线性回归模型<br>    普通线性回归模型<br>    LASSO回归<br>    Ridge回归<br>    ElasticNet<br>    多项式回归<br>    Bayesian回归<br>    Bayesian ARD回归<br>    主成分回归<br>    偏最小二乘回归</p><p>决策树和集成学习模型： 使用特征重要性作为系数, feature_importance_<br>        Decision Tree<br>        Random Forest<br>        GradientBoosting<br>        AdaBoost<br>        XGBRegressor<br>        LightGBM<br>深度学习</p><h2 id="模型的可解释性"><a href="#模型的可解释性" class="headerlink" title="模型的可解释性"></a>模型的可解释性</h2><p>基于shapley值的可解释性，探讨属性的重要程度<br>特征重要性<br>    SHAP的特征重要性是shapley值的大小，或这说绝对值的大小，0表示这个特征可有可无，因为是加性归因，shapley值的特征重要性是累加思想，即每个特征的重要性是可以累加的。<br>        Shapley值是从整体考虑的特征重要性<br>    而原始的XGBoost树模型的特征重要性，是来自该特征在所有树的节点分割中使用的平均增益, 平均增益越大，那么就越重要<br>        表明每个特征在模型内构建提升决策树时的有用性或价值。一个属性特征越是用于决策树的关键决策，其相对重要性就越高<br>        重要性是通过每个属性分割点提高性能指标的量来计算的，性能指标衡量分割点“纯度”，例如信息增益<br>        集成树模型是从局部考虑特征重要性，然后做的加权平均</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>PCA和xlstat</title>
    <link href="/2022/06/24/PCA%E5%92%8Cxlstat/"/>
    <url>/2022/06/24/PCA%E5%92%8Cxlstat/</url>
    
    <content type="html"><![CDATA[<h1 id="PCA和xlsxstat分析"><a href="#PCA和xlsxstat分析" class="headerlink" title="PCA和xlsxstat分析"></a>PCA和xlsxstat分析</h1><img src="/2022/06/24/PCA%E5%92%8Cxlstat/PCA%E5%92%8Cxlstat.png" class="">]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>torch版本和随机数</title>
    <link href="/2022/04/14/torch%E7%89%88%E6%9C%AC%E5%92%8C%E9%9A%8F%E6%9C%BA%E6%95%B0/"/>
    <url>/2022/04/14/torch%E7%89%88%E6%9C%AC%E5%92%8C%E9%9A%8F%E6%9C%BA%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="在不同的PyTorch版本或不同的平台上，不保证完全可重复的结果。此外，即使使用相同的种子，在CPU和GPU的执行中，结果也可能无法重现。"><a href="#在不同的PyTorch版本或不同的平台上，不保证完全可重复的结果。此外，即使使用相同的种子，在CPU和GPU的执行中，结果也可能无法重现。" class="headerlink" title="在不同的PyTorch版本或不同的平台上，不保证完全可重复的结果。此外，即使使用相同的种子，在CPU和GPU的执行中，结果也可能无法重现。"></a>在不同的PyTorch版本或不同的平台上，不保证完全可重复的结果。此外，即使使用相同的种子，在CPU和GPU的执行中，结果也可能无法重现。</h1><p>以下在6台机器上实验，不设置随机数种子, 有的机器是torch相同的版本，有的不是,对比预测的logits分数和最终的预测结果。测试的是情感模型的预测结果.<br>不同的torch版本，也会导致预测有一些差异，但是差异很小，预测的分数有14%的差异，但是数千条数据，预测的结果只有一条有差异</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">w69</span> | CHANGED | rc=<span class="hljs-number">0</span> &gt;&gt;<br><span class="hljs-attribute">torch</span>==<span class="hljs-number">1</span>.<span class="hljs-number">8</span>.<span class="hljs-number">1</span><br><br><span class="hljs-attribute">w79</span> | CHANGED | rc=<span class="hljs-number">0</span> &gt;&gt;<br><span class="hljs-attribute">torch</span>==<span class="hljs-number">1</span>.<span class="hljs-number">8</span>.<span class="hljs-number">1</span><br><br><span class="hljs-attribute">w19</span> | CHANGED | rc=<span class="hljs-number">0</span> &gt;&gt;<br><span class="hljs-attribute">torch</span>==<span class="hljs-number">1</span>.<span class="hljs-number">8</span>.<span class="hljs-number">1</span><br><br><span class="hljs-attribute">w39</span> | CHANGED | rc=<span class="hljs-number">0</span> &gt;&gt;<br><span class="hljs-attribute">torch</span>==<span class="hljs-number">1</span>.<span class="hljs-number">7</span>.<span class="hljs-number">0</span>+cu110<br><br><span class="hljs-attribute">w09</span> | CHANGED | rc=<span class="hljs-number">0</span> &gt;&gt;<br><span class="hljs-attribute">torch</span>==<span class="hljs-number">1</span>.<span class="hljs-number">9</span>.<span class="hljs-number">0</span>+cu111<br><br><span class="hljs-attribute">w89</span> | CHANGED | rc=<span class="hljs-number">0</span> &gt;&gt;<br><span class="hljs-attribute">torch</span>==<span class="hljs-number">1</span>.<span class="hljs-number">9</span>.<span class="hljs-number">0</span>+cu111<br><br><span class="hljs-attribute">w99</span> | CHANGED | rc=<span class="hljs-number">0</span> &gt;&gt;<br><span class="hljs-attribute">torch</span>==<span class="hljs-number">1</span>.<span class="hljs-number">9</span>.<span class="hljs-number">0</span><br></code></pre></td></tr></table></figure><p>预测结果如下：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs stylus">主机<span class="hljs-number">19</span>的结果保存到: <span class="hljs-number">19</span>_result<span class="hljs-selector-class">.xlsx</span>, 标签占比是<span class="hljs-built_in">Counter</span>(&#123;<span class="hljs-string">&#x27;积极&#x27;</span>: <span class="hljs-number">351</span>, <span class="hljs-string">&#x27;中性&#x27;</span>: <span class="hljs-number">109</span>, <span class="hljs-string">&#x27;消极&#x27;</span>: <span class="hljs-number">40</span>&#125;)<br>主机<span class="hljs-number">39</span>的结果保存到: <span class="hljs-number">39</span>_result<span class="hljs-selector-class">.xlsx</span>, 标签占比是<span class="hljs-built_in">Counter</span>(&#123;<span class="hljs-string">&#x27;积极&#x27;</span>: <span class="hljs-number">351</span>, <span class="hljs-string">&#x27;中性&#x27;</span>: <span class="hljs-number">109</span>, <span class="hljs-string">&#x27;消极&#x27;</span>: <span class="hljs-number">40</span>&#125;)<br>主机<span class="hljs-number">69</span>的结果保存到: <span class="hljs-number">69</span>_result<span class="hljs-selector-class">.xlsx</span>, 标签占比是<span class="hljs-built_in">Counter</span>(&#123;<span class="hljs-string">&#x27;积极&#x27;</span>: <span class="hljs-number">351</span>, <span class="hljs-string">&#x27;中性&#x27;</span>: <span class="hljs-number">109</span>, <span class="hljs-string">&#x27;消极&#x27;</span>: <span class="hljs-number">40</span>&#125;)<br>主机<span class="hljs-number">79</span>的结果保存到: <span class="hljs-number">79</span>_result<span class="hljs-selector-class">.xlsx</span>, 标签占比是<span class="hljs-built_in">Counter</span>(&#123;<span class="hljs-string">&#x27;积极&#x27;</span>: <span class="hljs-number">351</span>, <span class="hljs-string">&#x27;中性&#x27;</span>: <span class="hljs-number">109</span>, <span class="hljs-string">&#x27;消极&#x27;</span>: <span class="hljs-number">40</span>&#125;)<br>主机<span class="hljs-number">89</span>的结果保存到: <span class="hljs-number">89</span>_result<span class="hljs-selector-class">.xlsx</span>, 标签占比是<span class="hljs-built_in">Counter</span>(&#123;<span class="hljs-string">&#x27;积极&#x27;</span>: <span class="hljs-number">352</span>, <span class="hljs-string">&#x27;中性&#x27;</span>: <span class="hljs-number">109</span>, <span class="hljs-string">&#x27;消极&#x27;</span>: <span class="hljs-number">39</span>&#125;)<br>主机<span class="hljs-number">09</span>的结果保存到: <span class="hljs-number">09</span>_result<span class="hljs-selector-class">.xlsx</span>, 标签占比是<span class="hljs-built_in">Counter</span>(&#123;<span class="hljs-string">&#x27;积极&#x27;</span>: <span class="hljs-number">352</span>, <span class="hljs-string">&#x27;中性&#x27;</span>: <span class="hljs-number">109</span>, <span class="hljs-string">&#x27;消极&#x27;</span>: <span class="hljs-number">39</span>&#125;)<br></code></pre></td></tr></table></figure><h1 id="对比预测结果和logits"><a href="#对比预测结果和logits" class="headerlink" title="对比预测结果和logits"></a>对比预测结果和logits</h1><p>相同的torch版本，预测结果相同</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">diff <span class="hljs-number">09</span>_result<span class="hljs-selector-class">.xlsx</span><span class="hljs-selector-class">.json</span> <span class="hljs-number">89</span>_result<span class="hljs-selector-class">.xlsx</span>.json<br></code></pre></td></tr></table></figure><p>不同的torch版本，预测结果不同</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">diff -<span class="hljs-selector-tag">q</span> <span class="hljs-number">09</span>_result<span class="hljs-selector-class">.xlsx</span><span class="hljs-selector-class">.json</span> <span class="hljs-number">19</span>_result<span class="hljs-selector-class">.xlsx</span><span class="hljs-selector-class">.json</span><br>Files <span class="hljs-number">09</span>_result<span class="hljs-selector-class">.xlsx</span><span class="hljs-selector-class">.json</span> and <span class="hljs-number">19</span>_result<span class="hljs-selector-class">.xlsx</span><span class="hljs-selector-class">.json</span> differ<br></code></pre></td></tr></table></figure><h1 id="所以我们在复现实验的时候，最好设定随机数种子-例如"><a href="#所以我们在复现实验的时候，最好设定随机数种子-例如" class="headerlink" title="所以我们在复现实验的时候，最好设定随机数种子, 例如"></a>所以我们在复现实验的时候，最好设定随机数种子, 例如</h1><p>设置random_seed</p><figure class="highlight monkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs monkey"><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> numpy as np<br><span class="hljs-built_in">seed</span>=<span class="hljs-number">100</span><span class="hljs-meta"></span><br><span class="hljs-meta"># torch的随机数种子固定，torch.manual_seed已经是支持CPU和GPU了，不需要设置这个torch.cuda.manual_seed_all了</span><br>torch.manual_seed(<span class="hljs-built_in">seed</span>)<span class="hljs-meta"></span><br><span class="hljs-meta"># numpy的随机数种子</span><br>np.random.<span class="hljs-built_in">seed</span>(<span class="hljs-built_in">seed</span>)<span class="hljs-meta"></span><br><span class="hljs-meta"># python的随机数种子</span><br>random.<span class="hljs-built_in">seed</span>(<span class="hljs-built_in">seed</span>)<span class="hljs-meta"></span><br><span class="hljs-meta"># cuDNN的保证每次实验使用相同的算法</span><br>torch.backends.cudnn.benchmark = <span class="hljs-literal">False</span><span class="hljs-meta">   # 如果改为True，表示速度提升，但是不是同一算法</span><span class="hljs-meta"></span><br><span class="hljs-meta"># 保证每个算法的确定性</span><br>torch.backends.cudnn.deterministic = <span class="hljs-literal">True</span> 或torch.use_deterministic_algorithms(<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>torch</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>apex报错</title>
    <link href="/2022/04/12/apex%E6%8A%A5%E9%94%99/"/>
    <url>/2022/04/12/apex%E6%8A%A5%E9%94%99/</url>
    
    <content type="html"><![CDATA[<h1 id="apex-报错"><a href="#apex-报错" class="headerlink" title="apex 报错"></a>apex 报错</h1><p>当使用pytorch_transformers时，遇到报错如下<br>ModuleNotFoundError: No module named ‘fused_layer_norm_cuda’</p><h1 id="解决方式"><a href="#解决方式" class="headerlink" title="解决方式"></a>解决方式</h1><p>手动编译安装apex</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli">git clone https:<span class="hljs-string">//github.com/NVIDIA/apex</span><br><span class="hljs-keyword">cd</span> apex<br>CUDA_HOME=<span class="hljs-string">/usr/local/cuda-11.2</span> pip install -v <span class="hljs-params">--no-cache-dir</span> <span class="hljs-params">--global-option=</span><span class="hljs-string">&quot;--cpp_ext&quot;</span> <span class="hljs-params">--global-option=</span><span class="hljs-string">&quot;--cuda_ext&quot;</span> <span class="hljs-string">./</span><br></code></pre></td></tr></table></figure><h1 id="安装时对不同的cuda版本的需求会导致apex报错"><a href="#安装时对不同的cuda版本的需求会导致apex报错" class="headerlink" title="安装时对不同的cuda版本的需求会导致apex报错"></a>安装时对不同的cuda版本的需求会导致apex报错</h1><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs awk">    Traceback (most recent call last):<br>      File <span class="hljs-string">&quot;&lt;string&gt;&quot;</span>, line <span class="hljs-number">1</span>, <span class="hljs-keyword">in</span> &lt;module&gt;<br>      File <span class="hljs-string">&quot;/media/backup/john/project/apex/setup.py&quot;</span>, line <span class="hljs-number">177</span>, <span class="hljs-keyword">in</span> &lt;module&gt;<br>        check_cuda_torch_binary_vs_bare_metal(CUDA_HOME)<br>      File <span class="hljs-string">&quot;/media/backup/john/project/apex/setup.py&quot;</span>, line <span class="hljs-number">34</span>, <span class="hljs-keyword">in</span> check_cuda_torch_binary_vs_bare_metal<br>        raise RuntimeError(<br>    RuntimeError: Cuda extensions are being compiled with a version of Cuda that does not match the version used to compile Pytorch binaries.  Pytorch binaries were compiled with Cuda <span class="hljs-number">11.3</span>.<br>    In some cases, a minor-version mismatch will not cause later errors:  https:<span class="hljs-regexp">//gi</span>thub.com<span class="hljs-regexp">/NVIDIA/</span>apex<span class="hljs-regexp">/pull/</span><span class="hljs-number">323</span><span class="hljs-comment">#discussion_r287021798.  You can try commenting out this check (at your own risk).</span><br>ERROR: Command errored out with <span class="hljs-keyword">exit</span> status <span class="hljs-number">1</span>: <span class="hljs-regexp">/home/</span>anaconda3<span class="hljs-regexp">/envs/</span>py38<span class="hljs-regexp">/bin/</span>python -u -c <span class="hljs-string">&#x27;import io, os, sys, setuptools, tokenize; sys.argv[0] = &#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;/media//john/project/apex/setup.py&#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;; __file__=&#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;/media//john/project/apex/setup.py&#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;;f = getattr(tokenize, &#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;open&#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;, open)(__file__) if os.path.exists(__file__) else io.StringIO(&#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;from setuptools import setup; setup()&#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;);code = f.read().replace(&#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;\r\n&#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;, &#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;\n&#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;);f.close();exec(compile(code, __file__, &#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;exec&#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;))&#x27;</span> --cpp_ext --cuda_ext install --record <span class="hljs-regexp">/tmp/</span>pip-record-rw1s_hs_<span class="hljs-regexp">/install-record.txt --single-version-externally-managed --compile --install-headers /</span>home<span class="hljs-regexp">//</span>anaconda3<span class="hljs-regexp">/envs/</span>py38<span class="hljs-regexp">/include/</span>python3.<span class="hljs-number">8</span>/apex Check the logs <span class="hljs-keyword">for</span> full command output.<br></code></pre></td></tr></table></figure><p>解决方式，注销掉检查cuda版本的语句即可，例如根据提示，注销掉setup.py的177行，检查cuda版本的句子, 重新编译安装即可</p>]]></content>
    
    
    <categories>
      
      <category>apex</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>neo4j的构建的知识图谱的语法示例</title>
    <link href="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/"/>
    <url>/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="查询包含甘油的产品"><a href="#查询包含甘油的产品" class="headerlink" title="查询包含甘油的产品"></a>查询包含甘油的产品</h1><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">MATCH p=()-[r:PRODUCT_COMPONENT_IS] -&gt;(n:Component &#123;<span class="hljs-type">name</span>:&quot;甘油&quot;&#125;) <span class="hljs-keyword">return</span> p <span class="hljs-keyword">limit</span> <span class="hljs-number">50</span><br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/gan.png" class=""><p>#查看2个品牌之间有什么共同点</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs stylus">MATCH<br>(n:Brand &#123;name:<span class="hljs-string">&quot;希思黎&quot;</span>&#125;), (<span class="hljs-selector-tag">b</span>:Brand &#123;name:<span class="hljs-string">&#x27;欧莱雅&#x27;</span>&#125;), <span class="hljs-selector-tag">p</span> = <span class="hljs-built_in">allShortestPaths</span>((n)-<span class="hljs-selector-attr">[*]</span><span class="hljs-built_in">-</span>(b))<br>RETURN <span class="hljs-selector-tag">p</span> <br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/pin.png" class=""><h1 id="法国品牌"><a href="#法国品牌" class="headerlink" title="法国品牌"></a>法国品牌</h1><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">MATCH p=()-[r:BRAND_COUNTRY_IS]-&gt;(c:Country &#123;<span class="hljs-type">name</span>:&quot;法国&quot;&#125;) <span class="hljs-keyword">RETURN</span> p <span class="hljs-keyword">LIMIT</span> <span class="hljs-number">25</span><br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/fa.png" class=""><h1 id="collect-统计-各个品牌关于手部护理的产品的价格统计"><a href="#collect-统计-各个品牌关于手部护理的产品的价格统计" class="headerlink" title="collect 统计, 各个品牌关于手部护理的产品的价格统计"></a>collect 统计, 各个品牌关于手部护理的产品的价格统计</h1><figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs livescript">MATCH <span class="hljs-function"><span class="hljs-params">(:ProductCategory &#123;name:<span class="hljs-string">&quot;手部护理&quot;</span>&#125;)</span>--&gt;</span><span class="hljs-function"><span class="hljs-params">(:ProductCategory)</span>&lt;--<span class="hljs-params">(p:Product)</span>--&gt;</span>(b:Brand)<br>RETURN b.name <span class="hljs-keyword">as</span> Brand, collect(distinct p.price) <span class="hljs-keyword">as</span> Price<br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/price.png" class=""><h1 id="价格在200-300之间"><a href="#价格在200-300之间" class="headerlink" title="价格在200-300之间"></a>价格在200-300之间</h1><figure class="highlight fortran"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs fortran">MATCH (n:<span class="hljs-built_in">Product</span>) <span class="hljs-keyword">WHERE</span> n.price &gt;= <span class="hljs-number">200</span> AND n.price &lt; <span class="hljs-number">300</span> <span class="hljs-keyword">RETURN</span> n<br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/pris.png" class=""><h1 id="欧莱雅商品"><a href="#欧莱雅商品" class="headerlink" title="欧莱雅商品"></a>欧莱雅商品</h1><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs css">MATCH (n:Brand &#123;name:<span class="hljs-string">&quot;欧莱雅&quot;</span>&#125;) &lt;-<span class="hljs-selector-attr">[:PRODUCT_BRAND_IS]</span>-(<span class="hljs-selector-tag">p</span>) RETURN n,<span class="hljs-selector-tag">p</span> LIMIT <span class="hljs-number">25</span><br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/ou.png" class=""><h1 id="同样功效的产品"><a href="#同样功效的产品" class="headerlink" title="同样功效的产品"></a>同样功效的产品</h1><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs css">MATCH (n:Product &#123;name:<span class="hljs-string">&quot;欧莱雅强韧柔顺洗发露&quot;</span>&#125;)-<span class="hljs-selector-attr">[:PRODUCT_EFFECT_IS]</span>-&gt;(m)&lt;-<span class="hljs-selector-attr">[:PRODUCT_EFFECT_IS]</span>-(<span class="hljs-selector-tag">p</span>) RETURN n,<span class="hljs-selector-tag">p</span><br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/same.png" class=""><h1 id="同样功效，价格便宜"><a href="#同样功效，价格便宜" class="headerlink" title="同样功效，价格便宜"></a>同样功效，价格便宜</h1><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs css">MATCH (n:Product &#123;name:<span class="hljs-string">&quot;倩碧水嫩保湿水精萃&quot;</span>&#125;)-<span class="hljs-selector-attr">[:PRODUCT_EFFECT_IS]</span>-&gt;(m)&lt;-<span class="hljs-selector-attr">[:PRODUCT_EFFECT_IS]</span>-(<span class="hljs-selector-tag">p</span>) WHERE <span class="hljs-selector-tag">p</span><span class="hljs-selector-class">.price</span> &lt;n<span class="hljs-selector-class">.price</span> RETURN n,<span class="hljs-selector-tag">p</span> Limit <span class="hljs-number">10</span><br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/smae.png" class=""><h1 id="希思黎生产过哪些类型产品"><a href="#希思黎生产过哪些类型产品" class="headerlink" title="希思黎生产过哪些类型产品"></a>希思黎生产过哪些类型产品</h1><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs lisp">MATCH (<span class="hljs-name">c</span><span class="hljs-symbol">:Brand</span> &#123;name:<span class="hljs-string">&quot;希思黎&quot;</span>&#125;)&lt;--(<span class="hljs-symbol">:Product</span>)--&gt;(<span class="hljs-name">s</span><span class="hljs-symbol">:ProductCategory</span>)<br>RETURN DISTINCT s<br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/xisi.png" class=""><h1 id="小众品牌"><a href="#小众品牌" class="headerlink" title="小众品牌"></a>小众品牌</h1><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">MATCH p=()-[r:BRAND_POPULARITY_IS]-&gt;(b:BrandPopularity &#123;<span class="hljs-type">name</span>:&quot;小众&quot;&#125;) <span class="hljs-keyword">RETURN</span> p <span class="hljs-keyword">LIMIT</span> <span class="hljs-number">25</span><br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/xiaozhong.png" class=""><h1 id="找2个产品2跳以内的共同点"><a href="#找2个产品2跳以内的共同点" class="headerlink" title="找2个产品2跳以内的共同点"></a>找2个产品2跳以内的共同点</h1><figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs excel"><span class="hljs-built_in">MATCH</span> p=(<br>(<span class="hljs-symbol">n:Pr</span>oduct &#123;<span class="hljs-built_in">na</span><span class="hljs-symbol">me:</span><span class="hljs-string">&quot;倩碧水嫩保湿水精萃&quot;</span>&#125;)-[*<span class="hljs-number">1</span>..<span class="hljs-number">2</span>]-(<span class="hljs-symbol">m:Pr</span>oduct &#123;<span class="hljs-built_in">na</span><span class="hljs-symbol">me:</span><span class="hljs-string">&quot;蒂迩肌男士水油平衡洁面泡沫&quot;</span>&#125;)<br>)<br>RETURN p<br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/liangtiao.png" class=""><h1 id="找2个产品的一个共同点"><a href="#找2个产品的一个共同点" class="headerlink" title="找2个产品的一个共同点"></a>找2个产品的一个共同点</h1><figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs excel"><span class="hljs-built_in">MATCH</span> p=shortestPath(<br>(<span class="hljs-symbol">n:Pr</span>oduct &#123;<span class="hljs-built_in">na</span><span class="hljs-symbol">me:</span><span class="hljs-string">&quot;倩碧水嫩保湿水精萃&quot;</span>&#125;)-[*]-(<span class="hljs-symbol">m:Pr</span>oduct &#123;<span class="hljs-built_in">na</span><span class="hljs-symbol">me:</span><span class="hljs-string">&quot;蒂迩肌男士水油平衡洁面泡沫&quot;</span>&#125;)<br>)<br>RETURN p<br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/yige.png" class=""><h1 id="总产品数"><a href="#总产品数" class="headerlink" title="总产品数"></a>总产品数</h1><figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs excel"><span class="hljs-built_in">MATCH</span> (<span class="hljs-symbol">n:Pr</span>oduct)<br>RETURN <span class="hljs-built_in">count</span>(<span class="hljs-built_in">n</span>)<br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/az.png" class=""><h1 id="总成分数"><a href="#总成分数" class="headerlink" title="总成分数"></a>总成分数</h1><figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs excel"><span class="hljs-built_in">MATCH</span> (<span class="hljs-symbol">n:Co</span>mponent)<br>RETURN <span class="hljs-built_in">count</span>(<span class="hljs-built_in">n</span>)<br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/chf.png" class=""><h1 id="meta-graph，元图"><a href="#meta-graph，元图" class="headerlink" title="meta-graph，元图"></a>meta-graph，元图</h1><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">CALL</span> db.<span class="hljs-keyword">schema</span>.visualization()<br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/zitu.png" class="">]]></content>
    
    
    <categories>
      
      <category>知识图谱</category>
      
    </categories>
    
    
    <tags>
      
      <tag>cql语法</tag>
      
      <tag>neo4j</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ubuntu20.04的Realtek网卡驱动安装</title>
    <link href="/2022/03/14/ubuntu20-04%E7%9A%84Realtek%E7%BD%91%E5%8D%A1%E9%A9%B1%E5%8A%A8%E5%AE%89%E8%A3%85/"/>
    <url>/2022/03/14/ubuntu20-04%E7%9A%84Realtek%E7%BD%91%E5%8D%A1%E9%A9%B1%E5%8A%A8%E5%AE%89%E8%A3%85/</url>
    
    <content type="html"><![CDATA[<h1 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h1><p>ubuntu的20.04版本对部分网卡的驱动没有默认集成，需要手动安装, 记录下安装流程</p><h2 id="查看网卡型号"><a href="#查看网卡型号" class="headerlink" title="查看网卡型号"></a>查看网卡型号</h2><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs dts">sudo lshw -C network<br>  *-network                 <br><span class="hljs-symbol">       description:</span> Ethernet interface<br><span class="hljs-symbol">       product:</span> RTL8125 <span class="hljs-number">2.5</span>GbE Controller<br><span class="hljs-symbol">       vendor:</span> Realtek Semiconductor Co., Ltd.<br></code></pre></td></tr></table></figure><h2 id="得知型号是RTL8125-2-5G，然后去官方网站下载对应的驱动"><a href="#得知型号是RTL8125-2-5G，然后去官方网站下载对应的驱动" class="headerlink" title="得知型号是RTL8125 2.5G，然后去官方网站下载对应的驱动"></a>得知型号是RTL8125 2.5G，然后去官方网站下载对应的驱动</h2><p><a href="https://www.realtek.com/en/component/zoo/category/network-interface-controllers-10-100-1000m-gigabit-ethernet-pci-express-software">https://www.realtek.com/en/component/zoo/category/network-interface-controllers-10-100-1000m-gigabit-ethernet-pci-express-software</a></p><h2 id="在你的机器上首先确保有make相关组件-新安装系统时需要安装好一些编译的包，也可以按下列方式重新安装"><a href="#在你的机器上首先确保有make相关组件-新安装系统时需要安装好一些编译的包，也可以按下列方式重新安装" class="headerlink" title="在你的机器上首先确保有make相关组件,新安装系统时需要安装好一些编译的包，也可以按下列方式重新安装"></a>在你的机器上首先确保有make相关组件,新安装系统时需要安装好一些编译的包，也可以按下列方式重新安装</h2><h3 id="首先，你网卡没法联网，只能使用本地镜像，本地镜像的构建方式如下"><a href="#首先，你网卡没法联网，只能使用本地镜像，本地镜像的构建方式如下" class="headerlink" title="首先，你网卡没法联网，只能使用本地镜像，本地镜像的构建方式如下:"></a>首先，你网卡没法联网，只能使用本地镜像，本地镜像的构建方式如下:</h3><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment">#挂载镜像</span><br>mkdir <span class="hljs-regexp">/media/i</span>so<br>sudo mount  ~<span class="hljs-regexp">/Desktop/u</span>buntu-<span class="hljs-number">20.04</span>.<span class="hljs-number">2.0</span>-desktop-amd64.iso <span class="hljs-regexp">/media/i</span>so<br></code></pre></td></tr></table></figure><p>#focal是ubtunu20.04的版本的名称<br>sudo vim &#x2F;etc&#x2F;apt&#x2F;sources.list<br>deb file:&#x2F;media&#x2F;iso&#x2F; focal main contrib</p><p>#更新下包的缓存<br>sudo apt update</p><p>#安装make命令, build-essential是编译代码所需的包，iso镜像中自带了，其实可以在安装系统时安装上<br>sudo apt install build-essential 或者make</p><h2 id="然把你下载的驱动拷贝到服务器，我的对应驱动是r8125-9-005-06-tar-bz2"><a href="#然把你下载的驱动拷贝到服务器，我的对应驱动是r8125-9-005-06-tar-bz2" class="headerlink" title="然把你下载的驱动拷贝到服务器，我的对应驱动是r8125-9.005.06.tar.bz2"></a>然把你下载的驱动拷贝到服务器，我的对应驱动是r8125-9.005.06.tar.bz2</h2><p>解压<br>tar jxvf r8125-9.005.06.tar.bz2</p><h2 id="编译和安装"><a href="#编译和安装" class="headerlink" title="编译和安装"></a>编译和安装</h2><p>cd r8125-9.005.06<br>sudo make<br>sudo .&#x2F;autorun.sh</p><h2 id="正常查看网络，或者手动配置ip"><a href="#正常查看网络，或者手动配置ip" class="headerlink" title="正常查看网络，或者手动配置ip"></a>正常查看网络，或者手动配置ip</h2><p>ip a</p>]]></content>
    
    
    <categories>
      
      <category>linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ubuntu</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ubuntu远程桌面的三种实现方式</title>
    <link href="/2022/03/14/ubuntu%E8%BF%9C%E7%A8%8B%E6%A1%8C%E9%9D%A2/"/>
    <url>/2022/03/14/ubuntu%E8%BF%9C%E7%A8%8B%E6%A1%8C%E9%9D%A2/</url>
    
    <content type="html"><![CDATA[<h1 id="方式1：-ubuntu-自带的vino的版本的vnc"><a href="#方式1：-ubuntu-自带的vino的版本的vnc" class="headerlink" title="方式1： ubuntu 自带的vino的版本的vnc"></a>方式1： ubuntu 自带的vino的版本的vnc</h1><h2 id="步骤1，需要登录到ubuntu的桌面环境，找到设置-然后找到Sharing选项"><a href="#步骤1，需要登录到ubuntu的桌面环境，找到设置-然后找到Sharing选项" class="headerlink" title="步骤1，需要登录到ubuntu的桌面环境，找到设置, 然后找到Sharing选项"></a>步骤1，需要登录到ubuntu的桌面环境，找到设置, 然后找到Sharing选项</h2><p>点击Screen Sharing，设置一个密码，注意Network选项是开启的</p><h2 id="步骤2-取消加密协议"><a href="#步骤2-取消加密协议" class="headerlink" title="步骤2,取消加密协议"></a>步骤2,取消加密协议</h2><p>不用root用户运行，取消加密</p><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs lasso">gsettings <span class="hljs-built_in">set</span> org.gnome.Vino <span class="hljs-keyword">require</span><span class="hljs-params">-encryption</span> <span class="hljs-literal">false</span><br></code></pre></td></tr></table></figure><h2 id="步骤3，使用苹果的屏幕共享货vnc-viewer连接即可-端口5900"><a href="#步骤3，使用苹果的屏幕共享货vnc-viewer连接即可-端口5900" class="headerlink" title="步骤3，使用苹果的屏幕共享货vnc viewer连接即可, 端口5900"></a>步骤3，使用苹果的屏幕共享货vnc viewer连接即可, 端口5900</h2><h1 id="方式2：-使用tigervnc"><a href="#方式2：-使用tigervnc" class="headerlink" title="方式2： 使用tigervnc"></a>方式2： 使用tigervnc</h1><h2 id="安装tigervnc-vncserver和vncconfig命令安装成功"><a href="#安装tigervnc-vncserver和vncconfig命令安装成功" class="headerlink" title="安装tigervnc, vncserver和vncconfig命令安装成功"></a>安装tigervnc, vncserver和vncconfig命令安装成功</h2><figure class="highlight axapta"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs axapta">apt install tigervnc-standalone-<span class="hljs-keyword">server</span><br></code></pre></td></tr></table></figure><p>其它机器可以安装 客户端，如果需要连接vncserver</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake">apt <span class="hljs-keyword">install</span> tigervnc-viewer<br></code></pre></td></tr></table></figure><p>默认使用当前用户连接VNC，如果需要使用其它用户连接VNC server，那么需要建立新的用户<br>设置VNC的连接密码</p><figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs vbnet">vncpasswd<br><span class="hljs-symbol">Password:</span><br><span class="hljs-symbol">Verify:</span><br>Would you <span class="hljs-built_in">like</span> <span class="hljs-keyword">to</span> enter a view-only password (y/n)? n  #不设置只能查看的vnc密码<br></code></pre></td></tr></table></figure><h2 id="编辑用户下的配置文件"><a href="#编辑用户下的配置文件" class="headerlink" title="编辑用户下的配置文件"></a>编辑用户下的配置文件</h2><p>.vnc&#x2F;xstartup<br>内容如下，这是专为Gnome准备的</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment">#!/bin/sh</span><br><span class="hljs-comment"># Start Gnome 3 Desktop </span><br>[ -x <span class="hljs-regexp">/etc/</span>vnc<span class="hljs-regexp">/xstartup ] &amp;&amp; exec /</span>etc<span class="hljs-regexp">/vnc/</span>xstartup<br>[ -r <span class="hljs-variable">$HOME</span><span class="hljs-regexp">/.Xresources ] &amp;&amp; xrdb $HOME/</span>.Xresources<br>vncconfig -iconic &amp;<br>dbus-launch --<span class="hljs-keyword">exit</span>-with-session gnome-session &amp;<br></code></pre></td></tr></table></figure><p>可执行权限<br>chmod a+x .vnc&#x2F;xstartup</p><h2 id="启动vncserver"><a href="#启动vncserver" class="headerlink" title="启动vncserver"></a>启动vncserver</h2><p>vncserver -localhost no  #不是只监听localhost的端口</p><p>#查看启动的VNCserver<br>vncserver -list</p><p>#如果不使用VNC，可以选择kill掉, :1代表kill 5901端口<br>vncserver -kill :1</p><p>#vncserver的自启动服务<br>mkdir -p .local&#x2F;share&#x2F;systemd&#x2F;user&#x2F;</p><h2 id="步骤4-作为服务启动"><a href="#步骤4-作为服务启动" class="headerlink" title="步骤4: 作为服务启动"></a>步骤4: 作为服务启动</h2><p>#编辑用户的service<br>#cat .local&#x2F;share&#x2F;systemd&#x2F;user&#x2F;vncserver@.service</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-section">[Unit]</span><br><span class="hljs-attr">Description</span>=TigerVNC Service<br><br><span class="hljs-section">[Service]</span><br><span class="hljs-attr">Type</span>=forking<br><span class="hljs-attr">ExecStartPre</span>=-/usr/bin/vncserver -kill :%i &gt; /dev/null <span class="hljs-number">2</span>&gt;&amp;<span class="hljs-number">1</span><br><span class="hljs-attr">ExecStart</span>=/usr/bin/vncserver :%i -localhost <span class="hljs-literal">no</span><br><span class="hljs-attr">ExecStop</span>=/usr/bin/vncserver -kill :%i<br><br><span class="hljs-section">[Install]</span><br><span class="hljs-attr">WantedBy</span>=default.target<br></code></pre></td></tr></table></figure><p>#vim ~&#x2F;.xinitrc   #启动VNC的时候使用x11的session<br>export XDG_SESSION_TYPE&#x3D;x11</p><p>#创建服务的xtartup脚本, 这个是用于服务的<br>sudo mkdir &#x2F;etc&#x2F;vnc<br>sudo cat &#x2F;etc&#x2F;vnc&#x2F;xstartup</p><figure class="highlight d"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs d"><span class="hljs-meta">#!/bin/sh</span><br>test x<span class="hljs-string">&quot;$SHELL&quot;</span> = <span class="hljs-string">x&quot;&quot;</span> &amp;&amp; SHELL=/bin/bash<br>test x<span class="hljs-string">&quot;$1&quot;</span>     = <span class="hljs-string">x&quot;&quot;</span> &amp;&amp; set -- <span class="hljs-keyword">default</span><br><br>vncconfig -iconic &amp;<br><span class="hljs-string">&quot;$SHELL&quot;</span> -l &lt;&lt; EOF<br><span class="hljs-keyword">export</span> XDG_SESSION_TYPE=x11<br><span class="hljs-keyword">export</span> GNOME_SHELL_SESSION_MODE=ubuntu<br>dbus-launch --exit-<span class="hljs-keyword">with</span>-session gnome-session --session=ubuntu<br>EOF<br>vncserver -kill $DISPLAY<br></code></pre></td></tr></table></figure><p>#设置可执行<br>sudo chmod a+x  &#x2F;etc&#x2F;vnc&#x2F;xstartup</p><p>#用户的服务reload, 只能这个用户启动<br>systemctl daemon-reload –user<br>systemctl restart <a href="mailto:&#x76;&#x6e;&#99;&#x73;&#101;&#114;&#x76;&#x65;&#x72;&#x40;&#x31;&#46;&#x73;&#101;&#x72;&#x76;&#x69;&#99;&#101;">&#x76;&#x6e;&#99;&#x73;&#101;&#114;&#x76;&#x65;&#x72;&#x40;&#x31;&#46;&#x73;&#101;&#x72;&#x76;&#x69;&#99;&#101;</a> –user<br>systemctl status <a href="mailto:&#118;&#110;&#x63;&#115;&#101;&#114;&#x76;&#x65;&#x72;&#64;&#x31;&#46;&#x73;&#101;&#x72;&#118;&#x69;&#x63;&#x65;">&#118;&#110;&#x63;&#115;&#101;&#114;&#x76;&#x65;&#x72;&#64;&#x31;&#46;&#x73;&#101;&#x72;&#118;&#x69;&#x63;&#x65;</a> –user<br>#加到开机启动<br>systemctl enable <a href="mailto:&#118;&#110;&#99;&#x73;&#101;&#114;&#x76;&#101;&#114;&#64;&#x31;&#46;&#115;&#x65;&#114;&#118;&#105;&#99;&#x65;">&#118;&#110;&#99;&#x73;&#101;&#114;&#x76;&#101;&#114;&#64;&#x31;&#46;&#115;&#x65;&#114;&#118;&#105;&#99;&#x65;</a> –user</p><h1 id="方法3：Ubuntu-xrdp的安装方法-xrdp等同于vnc-server，只是需要用微软的remote-desktop工具连接"><a href="#方法3：Ubuntu-xrdp的安装方法-xrdp等同于vnc-server，只是需要用微软的remote-desktop工具连接" class="headerlink" title="方法3：Ubuntu xrdp的安装方法, xrdp等同于vnc server，只是需要用微软的remote desktop工具连接"></a>方法3：Ubuntu xrdp的安装方法, xrdp等同于vnc server，只是需要用微软的remote desktop工具连接</h1><h2 id="如果没安装Desktop环境，需要安装"><a href="#如果没安装Desktop环境，需要安装" class="headerlink" title="如果没安装Desktop环境，需要安装"></a>如果没安装Desktop环境，需要安装</h2><p>sudo apt install tasksel -y<br>tasksel   #选中Ubuntu desktop，然后开始安装<br>systemctl set-default graphical.target #  启动图像界面作为默认</p><h2 id="安装xrdp"><a href="#安装xrdp" class="headerlink" title="安装xrdp"></a>安装xrdp</h2><p>sudo apt install xrdp -y<br>sudo systemctl status xrdp<br>sudo systemctl enable xrdp<br>sudo usermod -a -G ssl-cert xxx   #把你的当前用户xxx用户加入到ssl用户组，例如johnson<br>sudo vim &#x2F;etc&#x2F;xrdp&#x2F;startwm.sh<br>#在前2行加入如下配置<br>Unset DBUS_SESSION_ADDRESS<br>Unset XDG_RUNTIME_DIR</p><p>sudo systemctl restart xrdp</p><h2 id="如果启用了防火墙，需要配置3389可以访问"><a href="#如果启用了防火墙，需要配置3389可以访问" class="headerlink" title="如果启用了防火墙，需要配置3389可以访问"></a>如果启用了防火墙，需要配置3389可以访问</h2><p>sudo ufw allow from 192.168.1.0&#x2F;24 to any port 3389<br>sudo ufw reload</p><h2 id="完成，可以用微软的远程桌面客户端工具开始连接-也可以通过NAT映射出去一个端口，那么连接的时候直接用IP-PORT的"><a href="#完成，可以用微软的远程桌面客户端工具开始连接-也可以通过NAT映射出去一个端口，那么连接的时候直接用IP-PORT的" class="headerlink" title="完成，可以用微软的远程桌面客户端工具开始连接, 也可以通过NAT映射出去一个端口，那么连接的时候直接用IP:PORT的"></a>完成，可以用微软的远程桌面客户端工具开始连接, 也可以通过NAT映射出去一个端口，那么连接的时候直接用IP:PORT的</h2><p>方式连接就可以</p><p>#日志位置<br>sudo tail -f &#x2F;var&#x2F;log&#x2F;xrdp.log</p><p>#如果连接进行是黑屏，处理方法<br>echo “gnome-session -–session&#x3D;gnome-fallback” &gt; ~&#x2F;.xsession<br>sudo &#x2F;etc&#x2F;init.d&#x2F;xrdp restart</p><h1 id="然后再删掉-xsession-重启后就恢复了"><a href="#然后再删掉-xsession-重启后就恢复了" class="headerlink" title="然后再删掉.xsession, 重启后就恢复了"></a>然后再删掉.xsession, 重启后就恢复了</h1>]]></content>
    
    
    <categories>
      
      <category>linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ubuntu</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>知乎博客检索</title>
    <link href="/2022/03/11/%E7%9F%A5%E4%B9%8E%E5%8D%9A%E5%AE%A2%E6%A3%80%E7%B4%A2/"/>
    <url>/2022/03/11/%E7%9F%A5%E4%B9%8E%E5%8D%9A%E5%AE%A2%E6%A3%80%E7%B4%A2/</url>
    
    <content type="html"><![CDATA[<p>具有交叉注意力控制功能的提示-提示图像编辑<br><a href="https://zhuanlan.zhihu.com/p/577527077">https://zhuanlan.zhihu.com/p/577527077</a><br>PROMPT-TO-PROMPT IMAGE EDITING WITH CROSS-ATTENTION CONTROL</p><p>知识图谱在食品科学与工业中的应用<br><a href="https://zhuanlan.zhihu.com/p/591966904">https://zhuanlan.zhihu.com/p/591966904</a><br>APPLICATIONS OF KNOWLEDGE GRAPHS FOR THE FOOD SCIENCE AND INDUSTRY</p><p>AltCLIP：改变CLIP中的语言编码器以扩展语言能力<br><a href="https://zhuanlan.zhihu.com/p/589700046">https://zhuanlan.zhihu.com/p/589700046</a><br>AltCLIP：Altering the Language Encoder in CLIP for Extended Language Capabilities</p><p>使用Attention-RPN和多关系检测器进行few-shot目标检测<br><a href="https://zhuanlan.zhihu.com/p/588230585">https://zhuanlan.zhihu.com/p/588230585</a><br>Few-Shot Object Detection with Attention-RPN and Multi-Relation Detector</p><p>FSCE: 通过对比性建议编码进行的few-shot目标检测<br><a href="https://zhuanlan.zhihu.com/p/588231035">https://zhuanlan.zhihu.com/p/588231035</a><br>FSCE： Few-Shot Object Detection via Contrastive Proposal Encoding</p><p>AliMe Assist：打造创新电商体验的智能助手<br><a href="https://zhuanlan.zhihu.com/p/587596523">https://zhuanlan.zhihu.com/p/587596523</a><br>AliMe Assist： An Intelligent Assistant for Creating an Innovative E-commerce Experience</p><p>社交聊天机器人小冰的设计与实现<br><a href="https://zhuanlan.zhihu.com/p/587595835">https://zhuanlan.zhihu.com/p/587595835</a><br>The Design and Implementation of XiaoIce, an Empathetic Social Chatbot</p><p>用于多目标跟踪的准密集相似性学习<br><a href="https://zhuanlan.zhihu.com/p/586082025">https://zhuanlan.zhihu.com/p/586082025</a><br>Quasi-Dense Similarity Learning for Multiple Object Tracking</p><p>深度感知的生成对抗网络用于口播视频的生成<br><a href="https://zhuanlan.zhihu.com/p/569320116">https://zhuanlan.zhihu.com/p/569320116</a><br>Depth-Aware Generative Adversarial Network for Talking Head Video Generation</p><p>使用 Vision Transformers 进行简单的开放式单词表目标检测<br><a href="https://zhuanlan.zhihu.com/p/586087658">https://zhuanlan.zhihu.com/p/586087658</a><br>Simple Open-Vocabulary Object Detection with Vision Transformers</p><p>用于one-shot目标检测的平衡和层次关系学习<br><a href="https://zhuanlan.zhihu.com/p/586094468">https://zhuanlan.zhihu.com/p/586094468</a><br>Balanced and Hierarchical Relation Learning for One-shot Object Detection</p><p>用于one-shot目标检测的自适应图像transformer<br><a href="https://zhuanlan.zhihu.com/p/585327946">https://zhuanlan.zhihu.com/p/585327946</a><br>Adaptive Image Transformer for One-Shot Object Detection</p><p>roformer：带有旋转位置嵌入的增强型transformer<br><a href="https://zhuanlan.zhihu.com/p/574478161">https://zhuanlan.zhihu.com/p/574478161</a><br>ROFORMER： ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING</p><p>用于One-shot目标检测的语义对齐融合transformer<br><a href="https://zhuanlan.zhihu.com/p/585256263">https://zhuanlan.zhihu.com/p/585256263</a><br>Semantic-aligned Fusion Transformer for One-shot Object Detection</p><p>PIFuHD：用于高分辨率三维人体数字化的多级像素对齐隐式函数<br><a href="https://zhuanlan.zhihu.com/p/566093991">https://zhuanlan.zhihu.com/p/566093991</a><br>PIFuHD： Multi-Level Pixel-Aligned Implicit Function for High-Resolution 3D Human Digitization</p><p>Imagic: 基于文本的真实图像编辑与扩散模型<br><a href="https://zhuanlan.zhihu.com/p/576710237">https://zhuanlan.zhihu.com/p/576710237</a><br>Imagic: Text-Based Real Image Editing with Diffusion Models</p><p>多模态对比学习LIMoE: 图像-语言的混合专家<br><a href="https://zhuanlan.zhihu.com/p/583728857">https://zhuanlan.zhihu.com/p/583728857</a><br>Multimodal Contrastive Learning with LIMoE：the Language-Image Mixture of Experts</p><p>统一的多选视角实现自然语言理解的zero-shot学习<br><a href="https://zhuanlan.zhihu.com/p/577097077">https://zhuanlan.zhihu.com/p/577097077</a><br>Zero-Shot Learners for Natural Language Understanding via a Uniﬁed Multiple Choice Perspective</p><p>用于通用信息提取的统一结构生成<br><a href="https://zhuanlan.zhihu.com/p/569268582">https://zhuanlan.zhihu.com/p/569268582</a><br>Uniﬁed Structure Generation for Universal Information Extraction</p><p>Copilot: 评估在代码上训练的大型语言模型<br><a href="https://zhuanlan.zhihu.com/p/571373422">https://zhuanlan.zhihu.com/p/571373422</a><br>Evaluating Large Language Models Trained on Code</p><p>视觉表示学习的多模态对比性训练<br><a href="https://zhuanlan.zhihu.com/p/544355035">https://zhuanlan.zhihu.com/p/544355035</a><br>Multimodal Contrastive Training for Visual Representation Learning</p><p>KenLM：更快、更小的语言模型查询<br><a href="https://zhuanlan.zhihu.com/p/564731709">https://zhuanlan.zhihu.com/p/564731709</a><br>KenLM： Faster and Smaller Language Model Queries</p><p>GenIE: 生成式信息提取<br><a href="https://zhuanlan.zhihu.com/p/562155662">https://zhuanlan.zhihu.com/p/562155662</a><br>GenIE： Generative Information Extraction</p><p>通过路由不确定性意识的交易专家进行量化股票投资的多任务学习方法<br><a href="https://zhuanlan.zhihu.com/p/543453690">https://zhuanlan.zhihu.com/p/543453690</a><br>Quantitative Stock Investment by Routing Uncertainty-Aware Trading Experts： A Multi-Task Learning Approach</p><p>ViLBERT: 视觉和语言任务的预训练任务无关的视觉语言学表示<br><a href="https://zhuanlan.zhihu.com/p/545869261">https://zhuanlan.zhihu.com/p/545869261</a><br>ViLBERT： Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks</p><p>用于手写2202数学表达式识别的计数感知网络<br><a href="https://zhuanlan.zhihu.com/p/546590327">https://zhuanlan.zhihu.com/p/546590327</a><br>When Counting Meets HMER：Counting-Aware Network for Handwritten 2202 Mathematical Expression Recognition</p><p>OpenPose: 使用部分亲和域的实时多人二维姿势估计<br><a href="https://zhuanlan.zhihu.com/p/561804021">https://zhuanlan.zhihu.com/p/561804021</a><br>OpenPose： Realtime Multi-Person 2D Pose Estimation using Part Afﬁnity Fields</p><p>使用二维动漫人物表的协作式神经渲染模型<br><a href="https://zhuanlan.zhihu.com/p/560585021">https://zhuanlan.zhihu.com/p/560585021</a><br>Collaborative Neural Rendering using 2D Anime Character Sheets</p><p>GLM: 自回归空白填充的通用语言模型预训练<br><a href="https://zhuanlan.zhihu.com/p/560559133">https://zhuanlan.zhihu.com/p/560559133</a><br>GLM： General Language Model Pretraining with Autoregressive Blank Inﬁlling</p><p>图像作为一种外语: 所有视觉和视觉语言任务的BEIT预训练<br><a href="https://zhuanlan.zhihu.com/p/559116135">https://zhuanlan.zhihu.com/p/559116135</a><br>Image as a Foreign Language： BEIT Pretraining for All Vision and Vision-Language Tasks</p><p>多粒度视觉语言预训练：将文本与视觉概念联系起来<br><a href="https://zhuanlan.zhihu.com/p/554130166">https://zhuanlan.zhihu.com/p/554130166</a><br>Multi-Grained Vision Language Pre-Training：Aligning Texts with Visual Concepts</p><p>ERNIE-ViL：通过场景图的知识强化视觉语言表述<br><a href="https://zhuanlan.zhihu.com/p/554100902">https://zhuanlan.zhihu.com/p/554100902</a><br>ERNIE-ViL： Knowledge Enhanced Vision-Language Representations through Scene Graphs</p><p>OFA：通过一个简单的seq2seq的学习框架来统一架构、任务和模态<br><a href="https://zhuanlan.zhihu.com/p/548392602">https://zhuanlan.zhihu.com/p/548392602</a><br>OFA： UNIFYING ARCHITECTURES, TASKS, AND MODALITIES THROUGH A SIMPLE SEQUENCE-TO-SEQUENCE LEARNING FRAMEWORK</p><p>Wukong：一亿规模的中文跨模态预训练基准<br><a href="https://zhuanlan.zhihu.com/p/551622338">https://zhuanlan.zhihu.com/p/551622338</a><br>Wukong：A 100 Million Large-scale Chinese Cross-modal Pre-training Benchmark</p><p>YOLOv7：可训练的bag-of-freebies为实时目标检测器树立了新的榜样<br><a href="https://zhuanlan.zhihu.com/p/546609857">https://zhuanlan.zhihu.com/p/546609857</a><br>YOLOv7： Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors</p><p>ReFNet:多模态融合精炼网络<br><a href="https://zhuanlan.zhihu.com/p/545135269">https://zhuanlan.zhihu.com/p/545135269</a><br>Multimodal Fusion Refiner Networks</p><p>SimCLR:视觉表示对比学习的简单框架<br><a href="https://zhuanlan.zhihu.com/p/544005001">https://zhuanlan.zhihu.com/p/544005001</a><br>A Simple Framework for Contrastive Learning of Visual Representations</p><p>有监督的对比学习<br><a href="https://zhuanlan.zhihu.com/p/543961298">https://zhuanlan.zhihu.com/p/543961298</a><br>Supervised Contrastive Learning</p><p>仅从字幕中训练视觉语言transformer模型<br><a href="https://zhuanlan.zhihu.com/p/540718732">https://zhuanlan.zhihu.com/p/540718732</a><br>Training Vision-Language Transformers from Captions Alone</p><p>MS-COCO的扩展模态内和模态间语义相似性判断<br><a href="https://zhuanlan.zhihu.com/p/540954741">https://zhuanlan.zhihu.com/p/540954741</a><br>Crisscrossed Captions：Extended Intramodal and Intermodal Semantic Similarity Judgments for MS-COCO</p><p>利用表示编码簿进行多模态对齐<br><a href="https://zhuanlan.zhihu.com/p/540703003">https://zhuanlan.zhihu.com/p/540703003</a><br>Multi-modal Alignment using Representation Codebook</p><p>M6: 一个中文的多模态预训练模型<br><a href="https://zhuanlan.zhihu.com/p/541143888">https://zhuanlan.zhihu.com/p/541143888</a><br>M6： A Chinese Multimodal Pretrainer</p><p>通过文本生成将视觉和语言任务统一起来<br><a href="https://zhuanlan.zhihu.com/p/540679125">https://zhuanlan.zhihu.com/p/540679125</a><br>Unifying Vision-and-Language Tasks via Text Generation</p><p>利用噪声文本监督扩大视觉和视觉语言表示学习的规模<br><a href="https://zhuanlan.zhihu.com/p/540570838">https://zhuanlan.zhihu.com/p/540570838</a><br>Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision</p><p>Pixel-BERT:通过深度多模态变换将图像像素与文本对齐<br><a href="https://zhuanlan.zhihu.com/p/539102716">https://zhuanlan.zhihu.com/p/539102716</a><br>Pixel-BERT: Aligning Image Pixels with Text by Deep Multi-Modal Transformers</p><p>通过模型不确定性融合的多任务密集检索用于开放领域的问答<br><a href="https://zhuanlan.zhihu.com/p/538610416">https://zhuanlan.zhihu.com/p/538610416</a><br>Multi-Task Dense Retrieval via Model Uncertainty Fusion for Open-Domain Question Answering</p><p>使用CLIP Latent的分层文本条件的图像生成<br><a href="https://zhuanlan.zhihu.com/p/538403355">https://zhuanlan.zhihu.com/p/538403355</a><br>Hierarchical Text-Conditional Image Generation with CLIP Latents</p><p>RNG-KBQA: 用于知识库问答的生成增强型迭代排名<br><a href="https://zhuanlan.zhihu.com/p/535420059">https://zhuanlan.zhihu.com/p/535420059</a><br>RNG-KBQA: Generation Augmented Iterative Ranking for Knowledge Base Question Answering</p><p>ViLT：没有卷积或区域监督的视觉和语言transformer<br><a href="https://zhuanlan.zhihu.com/p/537416032">https://zhuanlan.zhihu.com/p/537416032</a><br>ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision</p><p>图像-文本匹配的相似性推理和过滤<br><a href="https://zhuanlan.zhihu.com/p/537392389">https://zhuanlan.zhihu.com/p/537392389</a><br>Similarity Reasoning and Filtration for Image-Text Matching</p><p>关于图像-文本检索的可复现性问题<br><a href="https://zhuanlan.zhihu.com/p/535969785">https://zhuanlan.zhihu.com/p/535969785</a><br>Where Does the Performance Improvement Come From? - A Reproducibility Concern about Image-Text Retrieval</p><p>多模态检索的跨语言跨模态预训练<br><a href="https://zhuanlan.zhihu.com/p/535949214">https://zhuanlan.zhihu.com/p/535949214</a><br>Cross-lingual Cross-modal Pretraining for Multimodal Retrieval</p><p>检索和阅读：关于开放域问答的综合调查<br><a href="https://zhuanlan.zhihu.com/p/535315271">https://zhuanlan.zhihu.com/p/535315271</a><br>Retrieving and Reading ： A Comprehensive Survey on Open-domain Question Answering</p><p>扩散-LM改善可控文本的生成<br><a href="https://zhuanlan.zhihu.com/p/532644454">https://zhuanlan.zhihu.com/p/532644454</a><br>Diffusion-LM Improves Controllable Text Generation</p><p>通过随机过程建立的语言模型<br><a href="https://zhuanlan.zhihu.com/p/507834523">https://zhuanlan.zhihu.com/p/507834523</a><br>LANGUAGE MODELING VIA STOCHASTIC PROCESSES</p><p>UNITER: 通用图像-文本表示法学习<br><a href="https://zhuanlan.zhihu.com/p/510622677">https://zhuanlan.zhihu.com/p/510622677</a><br>UNITER： UNiversal Image-TExt Representation Learning</p><p>重新审视无监督的关系抽取<br><a href="https://zhuanlan.zhihu.com/p/527512757">https://zhuanlan.zhihu.com/p/527512757</a><br>Revisiting Unsupervised Relation Extraction</p><p>Hateful Memes 多模态数据集<br><a href="https://zhuanlan.zhihu.com/p/509654285">https://zhuanlan.zhihu.com/p/509654285</a><br>The Hateful Memes Challenge: Detecting Hate Speech in Multimodal Memes</p><p>OCR-VQA: 通过阅读图像中的文字进行可视化答题<br><a href="https://zhuanlan.zhihu.com/p/506453197">https://zhuanlan.zhihu.com/p/506453197</a><br>OCR-VQA： Visual Question Answering by Reading Text in Images</p><p>PaLM：大模型的规模探索<br><a href="https://zhuanlan.zhihu.com/p/503968575">https://zhuanlan.zhihu.com/p/503968575</a><br>PaLM： Scaling Language Modeling with Pathways</p><p>PICARD: 文本到SQL的自回归解码语言模型<br><a href="https://zhuanlan.zhihu.com/p/504133233">https://zhuanlan.zhihu.com/p/504133233</a><br>PICARD:Parsing Incrementally for Constrained Auto-Regressive Decoding from Language Models</p><p>Survey：复杂知识库问答<br><a href="https://zhuanlan.zhihu.com/p/503965660">https://zhuanlan.zhihu.com/p/503965660</a><br>A Survey on Complex Knowledge Base Question Answering： Methods, Challenges and Solutions</p><p>Tweets的多模态实体链接<br><a href="https://zhuanlan.zhihu.com/p/502269546">https://zhuanlan.zhihu.com/p/502269546</a><br>Multimodal Entity Linking for Tweets</p><p>ELQ: 高效的一次性端到端实体链接的问题<br><a href="https://zhuanlan.zhihu.com/p/497708749">https://zhuanlan.zhihu.com/p/497708749</a><br>Efﬁcient One-Pass End-to-End Entity Linking for Questions</p><p>可扩展的zero-shot实体链接与密集实体检索<br><a href="https://zhuanlan.zhihu.com/p/495291925">https://zhuanlan.zhihu.com/p/495291925</a><br>Scalable Zero-shot Entity Linking with Dense Entity Retrieval</p><p>实体链接技术和解决方案<br><a href="https://zhuanlan.zhihu.com/p/495278919">https://zhuanlan.zhihu.com/p/495278919</a><br>Entity Linking Meets Deep Learning： Techniques and Solutions</p><p>多模态实体链接: 一个新的数据集和一个基线<br><a href="https://zhuanlan.zhihu.com/p/494415154">https://zhuanlan.zhihu.com/p/494415154</a><br>Multimodal Entity Linking：A New Dataset and A Baseline</p><p>Zeroshot多模态命名实体歧义的社交媒体帖子<br><a href="https://zhuanlan.zhihu.com/p/494350411">https://zhuanlan.zhihu.com/p/494350411</a><br>Zeroshot Multimodal Named Entity Disambiguation for Noisy Social Media Posts</p><p>Survey:多模态知识图谱的构建和应用<br><a href="https://zhuanlan.zhihu.com/p/491610188">https://zhuanlan.zhihu.com/p/491610188</a><br>Multi-Modal Knowledge Graph Construction and Application： A Survey</p><p>多模态知识图谱完成<br><a href="https://zhuanlan.zhihu.com/p/490909554">https://zhuanlan.zhihu.com/p/490909554</a><br>Embedding Multimodal Relational Data for Knowledge Base Completion</p><p>从Tweets中建立一个多模态实体链接数据集<br><a href="https://zhuanlan.zhihu.com/p/490888754">https://zhuanlan.zhihu.com/p/490888754</a><br>Building a Multimodal Entity Linking Dataset From Tweets</p><p>ConVSE：视觉-语义嵌入的对比性学习<br><a href="https://zhuanlan.zhihu.com/p/490315692">https://zhuanlan.zhihu.com/p/490315692</a><br>Contrastive Learning of Visual-Semantic Embeddings</p><p>用于图像-文本匹配的视觉语义推理<br><a href="https://zhuanlan.zhihu.com/p/490302244">https://zhuanlan.zhihu.com/p/490302244</a><br>Visual Semantic Reasoning for Image-Text Matching</p><p>CLIP:从自然语言监督中学习可迁移的视觉模型<br><a href="https://zhuanlan.zhihu.com/p/478889210">https://zhuanlan.zhihu.com/p/478889210</a><br>Learning Transferable Visual Models From Natural Language Supervision</p><p>VisualSem: 用于视觉和语言的高质量知识图谱<br><a href="https://zhuanlan.zhihu.com/p/478679587">https://zhuanlan.zhihu.com/p/478679587</a><br>VisualSem： A High-quality Knowledge Graph for Vision &amp; Language</p><p>MET:用多模态知识库进行多模态实体标注<br><a href="https://zhuanlan.zhihu.com/p/478627581">https://zhuanlan.zhihu.com/p/478627581</a><br>Multimodal Entity Tagging with Multimodal Knowledge Base</p><p>M4C多模态transformer对TextVQA进行迭代式答案预测<br><a href="https://zhuanlan.zhihu.com/p/477062474">https://zhuanlan.zhihu.com/p/477062474</a><br>Iterative Answer Prediction with Pointer-Augmented Multimodal Transformers for TextVQA</p><p>TPLinker: 通过token对链接的单阶段联合提取实体和关系<br><a href="https://zhuanlan.zhihu.com/p/471975897">https://zhuanlan.zhihu.com/p/471975897</a><br>TPLinker：Single-stage Joint Extraction of Entities and Relations Through Token Pair Linking</p><p>UNIRE：实体关系抽取的统一标签空间<br><a href="https://zhuanlan.zhihu.com/p/454398188">https://zhuanlan.zhihu.com/p/454398188</a><br>UNIRE： A Uniﬁed Label Space for Entity Relation Extraction</p><p>SCIERC实体识别和关系抽取的英文数据集<br><a href="https://zhuanlan.zhihu.com/p/462638191">https://zhuanlan.zhihu.com/p/462638191</a><br>Multi-Task Identiﬁcation of Entities, Relations, and Coreference for Scientiﬁc Knowledge Graph Construction</p><p>SHAP解释树模型<br><a href="https://zhuanlan.zhihu.com/p/459470781">https://zhuanlan.zhihu.com/p/459470781</a><br>A Unified Approach to Interpreting Model Predictions</p><p>HySPA：用于可扩展的文本到图提取的混合跨度生成<br><a href="https://zhuanlan.zhihu.com/p/454339907">https://zhuanlan.zhihu.com/p/454339907</a><br>HySPA： Hybrid Span Generation for Scalable Text-to-Graph Extraction</p><p>对树模型进行局部解释<br><a href="https://zhuanlan.zhihu.com/p/458958125">https://zhuanlan.zhihu.com/p/458958125</a><br>From local explanations to global understanding with explainable AI for trees</p><p>XGBoost 一个可扩展的tree boosting系统<br><a href="https://zhuanlan.zhihu.com/p/459470547">https://zhuanlan.zhihu.com/p/459470547</a><br>XGBoost： A Scalable Tree Boosting System</p><p>用图卷积网络进行联合信息提取<br><a href="https://zhuanlan.zhihu.com/p/454304430">https://zhuanlan.zhihu.com/p/454304430</a><br>Cross-Task Instance Representation Interactions and Label Dependencies for Joint Information Extraction with Graph Convolutional Networks</p><p>用全局特征进行信息提取的联合神经模型<br><a href="https://zhuanlan.zhihu.com/p/454108143">https://zhuanlan.zhihu.com/p/454108143</a><br>A Joint Neural Model for Information Extraction with Global Features</p><p>利用打包浮动标记进行实体和关系抽取<br><a href="https://zhuanlan.zhihu.com/p/454398356">https://zhuanlan.zhihu.com/p/454398356</a><br>Pack Together： Entity and Relation Extraction with Levitated Marker</p><p>社媒的热点主题预测<br><a href="https://zhuanlan.zhihu.com/p/453417760">https://zhuanlan.zhihu.com/p/453417760</a><br>Hot topic prediction considering influence and expertise in social media</p><p>社交媒体大数据分析<br><a href="https://zhuanlan.zhihu.com/p/453838204">https://zhuanlan.zhihu.com/p/453838204</a><br>Big Social Media Data Analytics</p><p>PRCA和IGA联合建模分析顾客满意度<br><a href="https://zhuanlan.zhihu.com/p/449441801">https://zhuanlan.zhihu.com/p/449441801</a><br>Integrating methods for the prioritization of innovations and improvements in services</p><p>基于实体相对位置表示的多头选择的联合实体和关系抽取<br><a href="https://zhuanlan.zhihu.com/p/448112834">https://zhuanlan.zhihu.com/p/448112834</a><br>Entity Relative Position Representation based Multi-head Selection for Joint Entity and Relation Extraction</p><p>Kano加诺模型与数据挖掘的整合来预测客户满意度<br><a href="https://zhuanlan.zhihu.com/p/448486378">https://zhuanlan.zhihu.com/p/448486378</a><br>Concept Paper Kano Model Integration with Data Mining to Predict Customer Satisfaction</p><p>PRCA惩罚-奖励-对比分析：在顾客满意度研究中的应用<br><a href="https://zhuanlan.zhihu.com/p/449242532">https://zhuanlan.zhihu.com/p/449242532</a><br>Penalty–Reward-Contrast Analysis： a review of its application in customer satisfaction research</p><p>极端多标签文本分类的快速多分辨率transformer微调技术<br><a href="https://zhuanlan.zhihu.com/p/445661903">https://zhuanlan.zhihu.com/p/445661903</a><br>Fast Multi-Resolution Transformer Fine-tuning for Extreme Multi-label Text Classiﬁcation</p><p>多任务学习加强多标签文本分类<br><a href="https://zhuanlan.zhihu.com/p/445661700">https://zhuanlan.zhihu.com/p/445661700</a><br>Enhancing Label Correlation Feedback in Multi-Label Text Classiﬁcation via Multi-Task Learning</p><p>基于TFIDF和GloVe的多标签文本分类<br><a href="https://zhuanlan.zhihu.com/p/445587449">https://zhuanlan.zhihu.com/p/445587449</a><br>Deep Learning Based Multi-Label Text Classification of UNGA Resolutions</p><p>动态语义表示和深度神经网络结合的多标签文本分类方法<br><a href="https://zhuanlan.zhihu.com/p/445517482">https://zhuanlan.zhihu.com/p/445517482</a><br>A multi-label text classification method via dynamic semantic representation model and deep neural network</p><p>表-序列编码器联合提取实体和关系<br><a href="https://zhuanlan.zhihu.com/p/440722315">https://zhuanlan.zhihu.com/p/440722315</a><br>Two are Better than One：Joint Entity and Relation Extraction with Table-Sequence Encoders</p><p>用上下文跨度表示的实体、关系和事件提取<br><a href="https://zhuanlan.zhihu.com/p/443573825">https://zhuanlan.zhihu.com/p/443573825</a><br>Entity, Relation, and Event Extraction with Contextualized Span Representations</p><p>多头选择框架的BERT联合实体关系抽取<br><a href="https://zhuanlan.zhihu.com/p/443577609">https://zhuanlan.zhihu.com/p/443577609</a><br>BERT-Based Multi-Head Selection for Joint Entity-Relation Extraction</p><p>实体和关系抽取的简单方法<br><a href="https://zhuanlan.zhihu.com/p/440704543">https://zhuanlan.zhihu.com/p/440704543</a><br>A Frustratingly Easy Approach for Entity and Relation Extraction</p><p>BenchIE：基于事实而非token的开放式信息提取评估<br><a href="https://zhuanlan.zhihu.com/p/438437407">https://zhuanlan.zhihu.com/p/438437407</a><br>BenchIE： Open Information Extraction Evaluation Based on Facts, Not Tokens</p><p>OpenIE6：用于开放信息提取的迭代网格标签和协调分析<br><a href="https://zhuanlan.zhihu.com/p/438007291">https://zhuanlan.zhihu.com/p/438007291</a><br>OpenIE6: Iterative Grid Labeling and Coordination Analysis for Open Information Extraction</p><p>医学放射科报告生成与知识图谱<br><a href="https://zhuanlan.zhihu.com/p/436319124">https://zhuanlan.zhihu.com/p/436319124</a><br>When Radiology Report Generation Meets Knowledge Graph</p><p>BUTD：自下而上和自上而下的注意力多模态模型<br><a href="https://zhuanlan.zhihu.com/p/435174845">https://zhuanlan.zhihu.com/p/435174845</a><br>Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering</p><p>UniT：多模态多任务模型<br><a href="https://zhuanlan.zhihu.com/p/434243735">https://zhuanlan.zhihu.com/p/434243735</a><br>UniT: Multimodal Multitask Learning with a Uniﬁed Transformer</p><p>ACT: 自适应聚类transformer端到端目标检测<br><a href="https://zhuanlan.zhihu.com/p/435175009">https://zhuanlan.zhihu.com/p/435175009</a><br>End-to-End Object Detection with Adaptive Clustering Transformer</p><p>VisualBert: 经过预训练的多模态模型<br><a href="https://zhuanlan.zhihu.com/p/434272329">https://zhuanlan.zhihu.com/p/434272329</a><br>VISUALBERT: A SIMPLE AND PERFORMANT BASELINE FOR VISION AND LANGUAGE</p><p>双线性注意力网络（多模态）<br><a href="https://zhuanlan.zhihu.com/p/432970660">https://zhuanlan.zhihu.com/p/432970660</a><br>Bilinear Attention Networks</p><p>OpenUE：从文本中提取通用信息的开放工具箱<br><a href="https://zhuanlan.zhihu.com/p/431805279">https://zhuanlan.zhihu.com/p/431805279</a><br>OpenUE: An Open Toolkit of Universal Extraction from Text</p><p>多模态分类的跨模态检索增强功能<br><a href="https://zhuanlan.zhihu.com/p/432389016">https://zhuanlan.zhihu.com/p/432389016</a><br>Cross-Modal Retrieval Augmentation for Multi-Modal Classiﬁcation</p><p>艺术品类图像的双流多模态模型情感分析<br><a href="https://zhuanlan.zhihu.com/p/432373663">https://zhuanlan.zhihu.com/p/432373663</a><br>Understanding of Emotion Perception from Art</p><p>基于远端监督的开放领域数据的命名实体识别<br><a href="https://zhuanlan.zhihu.com/p/428925959">https://zhuanlan.zhihu.com/p/428925959</a><br>Named Entity Recognition for Open Domain Data Based on Distant Supervision</p><p>MISA: 多模态情感分析的模态不变和模态特定表示<br><a href="https://zhuanlan.zhihu.com/p/430407430">https://zhuanlan.zhihu.com/p/430407430</a><br>MISA: Modality-Invariant and -Specific Representations for Multimodal Sentiment Analysis</p><p>利用网络资源发现新的实体<br><a href="https://zhuanlan.zhihu.com/p/428861588">https://zhuanlan.zhihu.com/p/428861588</a><br>Emerging Entity Discovery Using Web Sources</p><p>知识图谱完成方法的重新评估<br><a href="https://zhuanlan.zhihu.com/p/428088532">https://zhuanlan.zhihu.com/p/428088532</a><br>A Re-evaluation of Knowledge Graph Completion Methods</p><p>Info-HCVAE问答对生成<br><a href="https://zhuanlan.zhihu.com/p/421265798">https://zhuanlan.zhihu.com/p/421265798</a><br>Generating Diverse and Consistent QA pairs from Contexts with Information-Maximizing Hierarchical Conditional VAEs</p><p>多任务学习框架下的观点三元组提取<br><a href="https://zhuanlan.zhihu.com/p/426376153">https://zhuanlan.zhihu.com/p/426376153</a><br>A Multi-task Learning Framework for Opinion Triplet Extraction</p><p>ASAP: 中文评论数据集：aspect的情感分析<br><a href="https://zhuanlan.zhihu.com/p/425981216">https://zhuanlan.zhihu.com/p/425981216</a><br>ASAP: A Chinese Review Dataset Towards Aspect Category Sentiment Analysis and Rating Prediction</p><p>DiaKG：用于构建医学知识图谱的糖尿病标注数据集<br><a href="https://zhuanlan.zhihu.com/p/424733768">https://zhuanlan.zhihu.com/p/424733768</a><br>DiaKG: an Annotated Diabetes Dataset for Medical Knowledge Graph Construction</p><p>P-Tuning v2: 与微调性能相等的提示性优化<br><a href="https://zhuanlan.zhihu.com/p/423902902">https://zhuanlan.zhihu.com/p/423902902</a><br>P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks</p><p>TechKG：一个大规模的中文技术导向的知识图谱<br><a href="https://zhuanlan.zhihu.com/p/420557472">https://zhuanlan.zhihu.com/p/420557472</a><br>TechKG: A Large-Scale Chinese Technology-Oriented Knowledge Graph</p><p>知识图谱增强的aspect情感分析<br><a href="https://zhuanlan.zhihu.com/p/414252384">https://zhuanlan.zhihu.com/p/414252384</a><br>Scalable End-to-End Training of Knowledge Graph-Enhanced Aspect Embedding for Aspect Level Sentiment Analysis</p><p>Pre-train, Prompt, and Predict: 自然语言处理中prompting方法总结<br><a href="https://zhuanlan.zhihu.com/p/411341801">https://zhuanlan.zhihu.com/p/411341801</a><br>Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing</p><p>用常识性知识图谱进行zero-shot学习<br><a href="https://zhuanlan.zhihu.com/p/410561852">https://zhuanlan.zhihu.com/p/410561852</a><br>Zero-Shot Learning with Common Sense Knowledge Graphs</p><p>用于自然语言推理的随机答案网络<br><a href="https://zhuanlan.zhihu.com/p/409085184">https://zhuanlan.zhihu.com/p/409085184</a><br>Stochastic Answer Networks for Natural Language Inference</p><p>用于自然语言理解的微软多任务深度神经网络工具包<br><a href="https://zhuanlan.zhihu.com/p/408851910">https://zhuanlan.zhihu.com/p/408851910</a><br>The Microsoft Toolkit of Multi-Task Deep Neural Networks for Natural Language Understanding</p><p>大型神经语言模型的对抗性训练<br><a href="https://zhuanlan.zhihu.com/p/408582923">https://zhuanlan.zhihu.com/p/408582923</a><br>Adversarial Training for Large Neural Language Models</p><p>行为克隆强化学习玩CS反恐精英<br><a href="https://zhuanlan.zhihu.com/p/403123868">https://zhuanlan.zhihu.com/p/403123868</a><br>Counter-Strike Deathmatch with Large-Scale Behavioural Cloning</p><p>HyperTools: 可视化和操作高维度据的Python工具箱<br><a href="https://zhuanlan.zhihu.com/p/407691325">https://zhuanlan.zhihu.com/p/407691325</a><br>HyperTools: A Python toolbox for visualizing and manipulating high-dimensional data</p><p>显存优化<br><a href="https://zhuanlan.zhihu.com/p/407429742">https://zhuanlan.zhihu.com/p/407429742</a><br>Training Deep Nets with Sublinear Memory Cost</p><p>自然语言查询问答模型<br><a href="https://zhuanlan.zhihu.com/p/406453009">https://zhuanlan.zhihu.com/p/406453009</a><br>Database Reasoning Over Text</p><p>Transformer Survey<br><a href="https://zhuanlan.zhihu.com/p/405623198">https://zhuanlan.zhihu.com/p/405623198</a><br>A Survey of Transformers</p><p>X-modaler: 用于跨模态分析的多功能和高性能的代码库<br><a href="https://zhuanlan.zhihu.com/p/402620759">https://zhuanlan.zhihu.com/p/402620759</a><br>X-modaler: A Versatile and High-performance Codebase for Cross-modal Analytics</p><p>PonderNet：适应性模型，提高模型计算效率<br><a href="https://zhuanlan.zhihu.com/p/401874414">https://zhuanlan.zhihu.com/p/401874414</a><br>PonderNet: Learning to Ponder</p><p>模式引导下的多领域对话数据集<br><a href="https://zhuanlan.zhihu.com/p/401779764">https://zhuanlan.zhihu.com/p/401779764</a><br>Towards Scalable Multi-Domain Conversational Agents: The Schema-Guided Dialogue Dataset</p><p>新冠COVID-19文献知识图谱构建<br><a href="https://zhuanlan.zhihu.com/p/400944819">https://zhuanlan.zhihu.com/p/400944819</a><br>COVID-19 Literature Knowledge Graph Construction and Drug Repurposing Report Generation</p><p>AutoKnow: 上千种产品的自动知识收集<br><a href="https://zhuanlan.zhihu.com/p/399419662">https://zhuanlan.zhihu.com/p/399419662</a><br>AutoKnow: Self-Driving Knowledge Collection for Products of Thousands of Types</p><p>用于联合意向分类和槽位填充的BERT<br><a href="https://zhuanlan.zhihu.com/p/399103189">https://zhuanlan.zhihu.com/p/399103189</a><br>BERT for Joint Intent Classiﬁcation and Slot Filling</p><p>数据标注的质量控制案例:TDT语料<br><a href="https://zhuanlan.zhihu.com/p/398515851">https://zhuanlan.zhihu.com/p/398515851</a><br>Quality Control in Large Annotation Projects Involving Multiple Judges: The Case of the TDT Corpora</p><p>DeiT: 蒸馏的图像transformer模型<br><a href="https://zhuanlan.zhihu.com/p/394627382">https://zhuanlan.zhihu.com/p/394627382</a><br>Training data-efﬁcient image transformers &amp; distillation through attention</p><p>ViT: transformer用于图像识别<br><a href="https://zhuanlan.zhihu.com/p/394288661">https://zhuanlan.zhihu.com/p/394288661</a><br>AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE</p><p>YOLOX<br><a href="https://zhuanlan.zhihu.com/p/393955749">https://zhuanlan.zhihu.com/p/393955749</a><br>YOLOX: Exceeding YOLO Series in 2021</p><p>完善知识图谱总结<br><a href="https://zhuanlan.zhihu.com/p/393885109">https://zhuanlan.zhihu.com/p/393885109</a><br>Knowledge Graph Refinement: A Survey of Approaches and Evaluation Methods</p><p>AdaShare: 高效的深度多任务学习<br><a href="https://zhuanlan.zhihu.com/p/393243186">https://zhuanlan.zhihu.com/p/393243186</a><br>AdaShare: Learning What To Share For Efﬁcient Deep Multi-Task Learning</p><p>知识图谱总结： 表示、获取和应用<br><a href="https://zhuanlan.zhihu.com/p/392429070">https://zhuanlan.zhihu.com/p/392429070</a><br>A Survey on Knowledge Graphs: Representation, Acquisition and Applications</p><p>REPAINT：深度强化学习中的知识迁移<br><a href="https://zhuanlan.zhihu.com/p/391824772">https://zhuanlan.zhihu.com/p/391824772</a><br>REPAINT: Knowledge Transfer in Deep Reinforcement Learning</p><p>重新审视Rainbow<br><a href="https://zhuanlan.zhihu.com/p/391126427">https://zhuanlan.zhihu.com/p/391126427</a><br>Revisiting Rainbow: Promoting more Insightful and Inclusive Deep Reinforcement Learning Research</p><p>遗传进化强化学习算法<br><a href="https://zhuanlan.zhihu.com/p/389895408">https://zhuanlan.zhihu.com/p/389895408</a><br>EVOLVING REINFORCEMENT LEARNING ALGORITHMS</p><p>强化学习环境：Google足球游戏<br><a href="https://zhuanlan.zhihu.com/p/389567798">https://zhuanlan.zhihu.com/p/389567798</a><br>Google Research Football: A Novel Reinforcement Learning Environment</p><p>无监督文本摘要<br><a href="https://zhuanlan.zhihu.com/p/388911963">https://zhuanlan.zhihu.com/p/388911963</a><br>Learning to Encode Text as Human-Readable Summaries using Generative Adversarial Networks</p><p>ERNIE 3.0: 用于语言理解和生成的大规模知识强化预训练<br><a href="https://zhuanlan.zhihu.com/p/388172601">https://zhuanlan.zhihu.com/p/388172601</a><br>ERNIE 3.0: LARGE-SCALE KNOWLEDGE ENHANCED PRE-TRAINING FOR LANGUAGE UNDERSTANDING AND GENERATION</p><p>COMET：自动构建知识图谱的常识transformer<br><a href="https://zhuanlan.zhihu.com/p/388106049">https://zhuanlan.zhihu.com/p/388106049</a><br>COMET : Commonsense Transformers for Automatic Knowledge Graph Construction</p><p>D2S: 通过基于查询的文本总结进行文档到幻灯片的生成<br><a href="https://zhuanlan.zhihu.com/p/387544973">https://zhuanlan.zhihu.com/p/387544973</a><br>D2S: Document-to-Slide Generation Via Query-Based Text Summarization</p><p>斗地主强化学习<br><a href="https://zhuanlan.zhihu.com/p/385496621">https://zhuanlan.zhihu.com/p/385496621</a><br>DouZero: Mastering DouDizhu with Self-Play Deep Reinforcement Learning</p><p>通过知识蒸馏改进多任务深度神经网络以促进自然语言理解<br><a href="https://zhuanlan.zhihu.com/p/384120253">https://zhuanlan.zhihu.com/p/384120253</a><br>Improving Multi-Task Deep Neural Networks via Knowledge Distillation for Natural Language Understanding</p><p>使用深度强化学习玩MOBA游戏<br><a href="https://zhuanlan.zhihu.com/p/378789632">https://zhuanlan.zhihu.com/p/378789632</a><br>Towards Playing Full MOBA Games with Deep Reinforcement Learning</p><p>MOBA游戏的复杂控制与深度强化学习<br><a href="https://zhuanlan.zhihu.com/p/379091485">https://zhuanlan.zhihu.com/p/379091485</a><br>Mastering Complex Control in MOBA Games with Deep Reinforcement Learning</p><p>用强化学习玩英雄联盟<br><a href="https://zhuanlan.zhihu.com/p/363495437">https://zhuanlan.zhihu.com/p/363495437</a><br>Deep Learning Bot for League of Legends</p><p>ATARI游戏的Model based的强化学习<br><a href="https://zhuanlan.zhihu.com/p/363279136">https://zhuanlan.zhihu.com/p/363279136</a><br>MODEL BASED REINFORCEMENT LEARNING FOR ATARI</p><p>关于视频游戏的深度强化学习算法<br><a href="https://zhuanlan.zhihu.com/p/363115461">https://zhuanlan.zhihu.com/p/363115461</a><br>A Survey of Deep Reinforcement Learning in Video Games</p><p>用于自然语言理解的多任务深度神经网络<br><a href="https://zhuanlan.zhihu.com/p/383137481">https://zhuanlan.zhihu.com/p/383137481</a><br>Multi-Task Deep Neural Networks for Natural Language Understanding</p><p>模仿学习: 自动排序的演示学习<br><a href="https://zhuanlan.zhihu.com/p/382272429">https://zhuanlan.zhihu.com/p/382272429</a><br>Better-than-Demonstrator Imitation Learning via Automatically-Ranked Demonstrations</p><p>预训练编码器文本摘要<br><a href="https://zhuanlan.zhihu.com/p/381490918">https://zhuanlan.zhihu.com/p/381490918</a><br>Text Summarization with Pretrained Encoders</p><p>Survey: 多任务学习<br><a href="https://zhuanlan.zhihu.com/p/381229374">https://zhuanlan.zhihu.com/p/381229374</a><br>A Survey on Multi-Task Learning</p><p>DDPG论文: 深强化学习连续控制<br><a href="https://zhuanlan.zhihu.com/p/371451813">https://zhuanlan.zhihu.com/p/371451813</a><br>CONTINUOUS CONTROL WITH DEEP REINFORCEMENT LEARNING</p><p>使用图像做无地图导航的强化学习<br><a href="https://zhuanlan.zhihu.com/p/379270657">https://zhuanlan.zhihu.com/p/379270657</a><br>Using RGB Image as Visual Input for Mapless Robot Navigation</p><p>Pettingzoo：类似gym的多Agent强化学习的环境<br><a href="https://zhuanlan.zhihu.com/p/375049925">https://zhuanlan.zhihu.com/p/375049925</a><br>PettingZoo: Gym for Multi-Agent Reinforcement Learning</p><p>RIIT: 最新的多Agent合作控制强化学习算法<br><a href="https://zhuanlan.zhihu.com/p/368284926">https://zhuanlan.zhihu.com/p/368284926</a><br>RIIT: Rethinking the Importance of Implementation Tricks in Multi-Agent Reinforcement Learning</p><p>复现深度强化学习算法效果的因素<br><a href="https://zhuanlan.zhihu.com/p/377369590">https://zhuanlan.zhihu.com/p/377369590</a><br>Deep Reinforcement Learning that Matters</p><p>PPO算法<br><a href="https://zhuanlan.zhihu.com/p/376978985">https://zhuanlan.zhihu.com/p/376978985</a><br>Proximal Policy Optimization Algorithms</p><p>交互式的强化学习<br><a href="https://zhuanlan.zhihu.com/p/379871647">https://zhuanlan.zhihu.com/p/379871647</a><br>REINFORCEMENT LEARNING WITH HUMAN ADVICE: A SURVEY</p><p>半监督机器翻译的简单基准<br><a href="https://zhuanlan.zhihu.com/p/378838885">https://zhuanlan.zhihu.com/p/378838885</a><br>A Simple Baseline to Semi-Supervised Domain Adaptation for Machine Translation</p><p>Survey: 深度神经网络翻译<br><a href="https://zhuanlan.zhihu.com/p/378524968">https://zhuanlan.zhihu.com/p/378524968</a><br>A Survey of Deep Learning Techniques for Neural Machine Translation</p><p>MMBT: 用于图像和文本分类的有监督多模态双向Transformer<br><a href="https://zhuanlan.zhihu.com/p/373581881">https://zhuanlan.zhihu.com/p/373581881</a><br>Supervised Multimodal Bitransformers for Classifying Images and Text</p><p>XLM-R: 大规模无监督跨语言表示模型<br><a href="https://zhuanlan.zhihu.com/p/372978148">https://zhuanlan.zhihu.com/p/372978148</a><br>Unsupervised Cross-lingual Representation Learning at Scale</p><p>跨语言的语言模型预训练<br><a href="https://zhuanlan.zhihu.com/p/372001934">https://zhuanlan.zhihu.com/p/372001934</a><br>Cross-lingual Language Model Pretraining</p><p>神经机器翻译的无监督领域适应<br><a href="https://zhuanlan.zhihu.com/p/371626610">https://zhuanlan.zhihu.com/p/371626610</a><br>Unsupervised Domain Adaptation for Neural Machine Translation with Domain-Aware Feature Embeddings</p><p>域适应翻译中的单词表适应方法<br><a href="https://zhuanlan.zhihu.com/p/371392857">https://zhuanlan.zhihu.com/p/371392857</a><br>Vocabulary Adaptation for Domain Adaptation in Neural Machine Translation</p><p>使用术语限制的神经网络翻译<br><a href="https://zhuanlan.zhihu.com/p/370661928">https://zhuanlan.zhihu.com/p/370661928</a><br>Training Neural Machine Translation To Apply Terminology Constraints</p><p>Survey: 机器翻译的领域适应和多领域适应<br><a href="https://zhuanlan.zhihu.com/p/370390321">https://zhuanlan.zhihu.com/p/370390321</a><br>Domain Adaptation and Multi-Domain Adaptation for Neural Machine Translation: A Survey</p><p>M2M-100: 多语言翻译模型<br><a href="https://zhuanlan.zhihu.com/p/368226087">https://zhuanlan.zhihu.com/p/368226087</a><br>Beyond English-Centric Multilingual Machine Translation</p><p>FAIRSEQ 语音到文本模型<br><a href="https://zhuanlan.zhihu.com/p/361585021">https://zhuanlan.zhihu.com/p/361585021</a><br>FAIRSEQ S2T: Fast Speech-to-Text Modeling with FAIRSEQ</p><p>自然语言中的强化学习<br><a href="https://zhuanlan.zhihu.com/p/364138298">https://zhuanlan.zhihu.com/p/364138298</a><br>A Survey of Reinforcement Learning Informed by Natural Language</p><p>MAAC注意力的演员评论家: Multi-Agent强化学习<br><a href="https://zhuanlan.zhihu.com/p/366413456">https://zhuanlan.zhihu.com/p/366413456</a><br>Actor-Attention-Critic for Multi-Agent Reinforcement Learning</p><p>mBART：多语言翻译预训练模型<br><a href="https://zhuanlan.zhihu.com/p/366525006">https://zhuanlan.zhihu.com/p/366525006</a><br>Multilingual Denoising Pre-training for Neural Machine Translation</p><p>MobileBERT:用于资源限制设备的紧凑型任务型BERT<br><a href="https://zhuanlan.zhihu.com/p/365329984">https://zhuanlan.zhihu.com/p/365329984</a><br>MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices</p><p>更快的深度自适应transformers<br><a href="https://zhuanlan.zhihu.com/p/364807276">https://zhuanlan.zhihu.com/p/364807276</a><br>Faster Depth-Adaptive Transformers</p><p>利用远端监督的强化学习关系抽取<br><a href="https://zhuanlan.zhihu.com/p/364444877">https://zhuanlan.zhihu.com/p/364444877</a><br>Large Scaled Relation Extraction with Reinforcement Learning</p><p>GLRE模型文档级关系抽取<br><a href="https://zhuanlan.zhihu.com/p/360980109">https://zhuanlan.zhihu.com/p/360980109</a><br>Global-to-Local Neural Networks for Document-Level Relation Extraction</p><p>关系抽取的注意力引导图卷积网络<br><a href="https://zhuanlan.zhihu.com/p/357518473">https://zhuanlan.zhihu.com/p/357518473</a><br>Attention Guided Graph Convolutional Networks for Relation Extraction</p><p>关系抽取Review（附上中文关系抽取的数据及代码)<br><a href="https://zhuanlan.zhihu.com/p/356551233">https://zhuanlan.zhihu.com/p/356551233</a><br>More Data, More Relations, More Context and More Openness: A Review and Outlook for Relation Extraction</p><p>DocRED: 大型文档级关系抽取数据集<br><a href="https://zhuanlan.zhihu.com/p/356077381">https://zhuanlan.zhihu.com/p/356077381</a><br>DocRED: A Large-Scale Document-Level Relation Extraction Dataset</p><p>文档级关系抽取：图增强双重注意力网络<br><a href="https://zhuanlan.zhihu.com/p/355473773">https://zhuanlan.zhihu.com/p/355473773</a><br>Graph Enhanced Dual Attention Network for Document-Level Relation Extraction</p><p>SENTIX:跨领域情感分析预训练模型<br><a href="https://zhuanlan.zhihu.com/p/350924103">https://zhuanlan.zhihu.com/p/350924103</a><br>SENTIX: A Sentiment-Aware Pre-Trained Model for Cross-Domain Sentiment Analysis</p><p>DEBERTA：解耦注意力的解码增强型BERT<br><a href="https://zhuanlan.zhihu.com/p/348704980">https://zhuanlan.zhihu.com/p/348704980</a><br>DEBERTA: DECODING-ENHANCED BERT WITH DISENTANGLED ATTENTION</p><p>SentiBERT： 基于可迁移的transformer的组合的情感语义预训练模型<br><a href="https://zhuanlan.zhihu.com/p/347854488">https://zhuanlan.zhihu.com/p/347854488</a><br>SentiBERT: A Transferable Transformer-Based Architecture for Compositional Sentiment Semantics</p><p>SentiLARE：带有语言知识的情感感知预训练模型<br><a href="https://zhuanlan.zhihu.com/p/346202158">https://zhuanlan.zhihu.com/p/346202158</a><br>SentiLARE: Sentiment-Aware Language Representation Learning with Linguistic Knowledge</p><p>SpanBERT：通过表示和预测跨度来改善预训练的模型(2020年1月修订)<br><a href="https://zhuanlan.zhihu.com/p/345401994">https://zhuanlan.zhihu.com/p/345401994</a><br>SpanBERT: Improving Pre-training by Representing and Predicting Spans</p><p>抱抱脸🤗Transformers论文(2020年)<br><a href="https://zhuanlan.zhihu.com/p/344553832">https://zhuanlan.zhihu.com/p/344553832</a><br>Transformers: State-of-the-Art Natural Language Processing</p><p>SentencePiece:子词tokenizer和detokenizer(2019年12月更新)<br><a href="https://zhuanlan.zhihu.com/p/343634730">https://zhuanlan.zhihu.com/p/343634730</a><br>SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing</p><p>ALBERT: 精简的BERT自监督的语言表示模型(2020年2月更新)<br><a href="https://zhuanlan.zhihu.com/p/343426088">https://zhuanlan.zhihu.com/p/343426088</a><br>ALBERT: A LITE BERT FOR SELF-SUPERVISED LEARNING OF LANGUAGE REPRESENTATIONS</p><p>上下文和实体名称哪个对关系抽取更重要(2020年12月论文)<br><a href="https://zhuanlan.zhihu.com/p/342360873">https://zhuanlan.zhihu.com/p/342360873</a><br>Learning from Context or Names? An Empirical Study on Neural Relation Extraction</p><p>Google Big Bird：长序列的transformers(2020年论文)<br><a href="https://zhuanlan.zhihu.com/p/342005602">https://zhuanlan.zhihu.com/p/342005602</a><br>Big Bird: Transformers for Longer Sequences</p><p>mT5: 多国语言版T5(中文T5)(2020年10月论文)<br><a href="https://zhuanlan.zhihu.com/p/340288423">https://zhuanlan.zhihu.com/p/340288423</a><br>mT5: A massively multilingual pre-trained text-to-text transformer</p><p>Google T5: 统一文本到文本迁移学习研究 (2020年7月论文)-Part3<br><a href="https://zhuanlan.zhihu.com/p/339502041">https://zhuanlan.zhihu.com/p/339502041</a><br>Exploring the Limits of Transfer Learning with a Uniﬁed Text-to-Text Transformer</p><p>CharBERT：字符感知的预训练语言模型(2020年11月论文)<br><a href="https://zhuanlan.zhihu.com/p/337587788">https://zhuanlan.zhihu.com/p/337587788</a><br>CharBERT: Character-aware Pre-trained Language Model</p><p>AdaBERT：可导神经结构搜索的任务自适应BERT压缩(2020年1月论文)<br><a href="https://zhuanlan.zhihu.com/p/337305614">https://zhuanlan.zhihu.com/p/337305614</a><br>AdaBERT: Task-Adaptive BERT Compression with Differentiable Neural Architecture Search</p><p>EasyTransfer–阿里NLP深度迁移学习平台(2020年11月论文)<br><a href="https://zhuanlan.zhihu.com/p/336730123">https://zhuanlan.zhihu.com/p/336730123</a><br>EasyTransfer – A Simple and Scalable Deep Transfer Learning Platform for NLP Applications</p><p>ConvBERT: 基于跨度的动态卷积BERT(2020年11月论文)<br><a href="https://zhuanlan.zhihu.com/p/336409975">https://zhuanlan.zhihu.com/p/336409975</a><br>ConvBERT: Improving BERT with Span-based Dynamic Convolution</p><p>MacBERT: 中文自然语言预训练模型(2020年11月论文)<br><a href="https://zhuanlan.zhihu.com/p/333202482">https://zhuanlan.zhihu.com/p/333202482</a><br>Revisiting Pre-trained Models for Chinese Natural Language Processing</p><p>FLAT: 使用Flat-Lattice Transformer结构中文NER(2020年5月论文)<br><a href="https://zhuanlan.zhihu.com/p/326135985">https://zhuanlan.zhihu.com/p/326135985</a><br>FLAT: Chinese NER Using Flat-Lattice Transformer</p><p>ELECTRA: 区别于BERT，使用判别器构建预训练模型（2020年3月论文)<br><a href="https://zhuanlan.zhihu.com/p/323931207">https://zhuanlan.zhihu.com/p/323931207</a><br>ELECTRA: PRE-TRAINING TEXT ENCODERS AS DISCRIMINATORS RATHER THAN GENERATORS</p><p>无监督的深度嵌入式聚类(2016年论文)<br><a href="https://zhuanlan.zhihu.com/p/313662693">https://zhuanlan.zhihu.com/p/313662693</a><br>Unsupervised Deep Embedding for Clustering Analysis</p><p>BOND：半监督的BERT开放域命名实体识别(2020年6月论文)<br><a href="https://zhuanlan.zhihu.com/p/307454757">https://zhuanlan.zhihu.com/p/307454757</a><br>BOND: BERT-Assisted Open-Domain Named Entity Recognition with Distant Supervision</p><p>使用半监督和监督学习检测虚假的在线评论(2019年2月)<br><a href="https://zhuanlan.zhihu.com/p/301268523">https://zhuanlan.zhihu.com/p/301268523</a><br>Detection of fake online reviews using semi-supervised and supervised learning </p><p>垃圾观点检测：使用基于多次迭代的图模型(2020年论文)<br><a href="https://zhuanlan.zhihu.com/p/300841251">https://zhuanlan.zhihu.com/p/300841251</a><br>Opinion spam detection: Using multi-iterative graph-based model</p><p>基于预训练和序列迁移的语法纠错系统(2019年7月)<br><a href="https://zhuanlan.zhihu.com/p/288219713">https://zhuanlan.zhihu.com/p/288219713</a><br>A Neural Grammatical Error Correction System Built On Better Pre-training and Sequential Transfer Learning</p><p>序列到序列的中文语法纠错(2018年)<br><a href="https://zhuanlan.zhihu.com/p/285211193">https://zhuanlan.zhihu.com/p/285211193</a><br>A Sequence to Sequence Learning for Chinese Grammatical Error Correction</p><p>BERT-of-Theseus: 通过逐步更换模块压缩BERT模型(2020年10月)<br><a href="https://zhuanlan.zhihu.com/p/283118184">https://zhuanlan.zhihu.com/p/283118184</a><br>BERT-of-Theseus: Compressing BERT by Progressive Module Replacing</p><p>TextBrewer：用于自然语言处理的开源知识蒸馏工具包(2020.04)<br><a href="https://zhuanlan.zhihu.com/p/275722016">https://zhuanlan.zhihu.com/p/275722016</a><br>TextBrewer: An Open-Source Knowledge Distillation Toolkit for Natural Language Processing</p><p>TinyBERT(华为)：自然语言理解之BERT蒸馏(2020.10)<br><a href="https://zhuanlan.zhihu.com/p/273467698">https://zhuanlan.zhihu.com/p/273467698</a><br>TinyBERT: Distilling BERT for Natural Language Understanding</p><p>BERT-PKD: BERT模型压缩之耐心知识蒸馏（2019.08）<br><a href="https://zhuanlan.zhihu.com/p/274329168">https://zhuanlan.zhihu.com/p/274329168</a><br>Patient Knowledge Distillation for BERT Model Compression</p><p>distilBert: Bert 蒸馏到简单的BiLSTM(2019.03)<br><a href="https://zhuanlan.zhihu.com/p/273543240">https://zhuanlan.zhihu.com/p/273543240</a><br>Distilling Task-Speciﬁc Knowledge from BERT into Simple Neural Networks</p><p>可转移域的端到端选择性对抗学习的Aspect-based情感分析(2019年10)<br><a href="https://zhuanlan.zhihu.com/p/268320982">https://zhuanlan.zhihu.com/p/268320982</a><br>Transferable End-to-End Aspect-based Sentiment Analysis with Selective Adversarial Learning</p><p>联合Aspect-Sentiment主题嵌入的弱监督的情感分析(2020年10)<br><a href="https://zhuanlan.zhihu.com/p/267744626">https://zhuanlan.zhihu.com/p/267744626</a><br>Weakly-Supervised Aspect-Based Sentiment Analysis via Joint Aspect-Sentiment Topic Embedding</p><p>观点目标提取和情感预测的统一模型(2019年)<br><a href="https://zhuanlan.zhihu.com/p/268580604">https://zhuanlan.zhihu.com/p/268580604</a><br>A Uniﬁed Model for Opinion Target Extraction and Target Sentiment Prediction</p><p>用于目标情感分类的注意力编码器网络(2019年04）<br><a href="https://zhuanlan.zhihu.com/p/270374318">https://zhuanlan.zhihu.com/p/270374318</a><br>Attentional Encoder Network for Targeted Sentiment Classiﬁcation</p><p>评测BERT类细粒度情感分类的语言表示模型(2020.05)<br><a href="https://zhuanlan.zhihu.com/p/268012476">https://zhuanlan.zhihu.com/p/268012476</a><br>Language Representation Models for Fine-Grained Sentiment Classiﬁcation</p><p>利用BERT进行端到端aspect-based的情感分析(2019年10）<br><a href="https://zhuanlan.zhihu.com/p/268801608">https://zhuanlan.zhihu.com/p/268801608</a><br>Exploiting BERT for End-to-End Aspect-based Sentiment Analysis</p><p>Aspect-level基于注意力的LSTM 情感分类(2016年)<br><a href="https://zhuanlan.zhihu.com/p/267254311">https://zhuanlan.zhihu.com/p/267254311</a><br>Attention-based LSTM for Aspect-level Sentiment Classification</p><p>BERT-EMD：多层对多层映射的BERT蒸馏（2020年10月）<br><a href="https://zhuanlan.zhihu.com/p/266602585">https://zhuanlan.zhihu.com/p/266602585</a><br>BERT-EMD: Many-to-Many Layer Mapping for BERT Compression with Earth Mover’s Distance</p><p>媲美GPT-3的变种PET模型(2020年9月论文)<br><a href="https://zhuanlan.zhihu.com/p/265646470">https://zhuanlan.zhihu.com/p/265646470</a><br>It’s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners</p><p>PRADO: 移动设备上的投影注意力文本分类网络(2019年论文)<br><a href="https://zhuanlan.zhihu.com/p/265042724">https://zhuanlan.zhihu.com/p/265042724</a><br>PRADO: Projection Attention Networks for Document Classiﬁcation On-Device</p><p>图神经网络的图归一化(2020.09论文)<br><a href="https://zhuanlan.zhihu.com/p/260811611">https://zhuanlan.zhihu.com/p/260811611</a><br>Learning Graph Normalization for Graph Neural Network</p><p>基于无标签数据Copy-Augmented预训练结构改善语法纠错(2019.06)<br><a href="https://zhuanlan.zhihu.com/p/258091623">https://zhuanlan.zhihu.com/p/258091623</a><br>Improving Grammatical Error Correction via Pre-Training a Copy-Augmented Architecture with Unlabeled Data</p><p>多层卷积编解码器神经网络语法纠错(2018.01论文)<br><a href="https://zhuanlan.zhihu.com/p/248000441">https://zhuanlan.zhihu.com/p/248000441</a><br>A Multilayer Convolutional Encoder-Decoder Neural Network for Grammatical Error Correction</p><p>近域微调的图片表格检测模型<br><a href="https://zhuanlan.zhihu.com/p/248393029">https://zhuanlan.zhihu.com/p/248393029</a><br>The Beneﬁts of Close-Domain Fine-Tuning for Table Detection in Document Images</p><p>IBM基于图片格式的表格识别(2020年03月论文)<br><a href="https://zhuanlan.zhihu.com/p/245032050">https://zhuanlan.zhihu.com/p/245032050</a><br>Image-based table recognition: data, model, and evaluation</p><p>FASPell基于DAE解码器的Spell Checker（2019.09）<br><a href="https://zhuanlan.zhihu.com/p/231626818">https://zhuanlan.zhihu.com/p/231626818</a><br>FASPell: A Fast, Adaptable, Simple, Powerful Chinese Spell Checker Based On DAE-Decoder Paradigm</p><p>个性化语法错误​​纠正（2020.06论文）<br><a href="https://zhuanlan.zhihu.com/p/231190671">https://zhuanlan.zhihu.com/p/231190671</a><br>Personalizing Grammatical Error Correction: Adaptation to Proficiency Level and L1</p><p>Reformer: 搞笑（高效）的transformer结构(2020年2月Google)<br><a href="https://zhuanlan.zhihu.com/p/208134502">https://zhuanlan.zhihu.com/p/208134502</a><br>REFORMER: THE EFFICIENT TRANSFORMER</p><p>2阶段中文纠错模型(2019论文)<br><a href="https://zhuanlan.zhihu.com/p/199551915">https://zhuanlan.zhihu.com/p/199551915</a><br>A Two-Stage Model for Chinese Grammatical Error Correction</p><p>CLUENER2020 2020年汉语NER和Benchmark<br><a href="https://zhuanlan.zhihu.com/p/197488236">https://zhuanlan.zhihu.com/p/197488236</a><br>CLUENER2020: FINE-GRAINED NAMED ENTITY RECOGNITION DATASET AND BENCHMARK FOR CHINESE</p><p>Google 最新 NLP语言模型可解释性可视化分析工具（2020-8月论文）<br><a href="https://zhuanlan.zhihu.com/p/188617204">https://zhuanlan.zhihu.com/p/188617204</a><br>The Language Interpretability Tool: Extensible, Interactive Visualizations and Analysis for NLP Models</p><p>聊天机器人架构设计和开发2-架构和设计（论文By Jack Cahn )<br><a href="https://zhuanlan.zhihu.com/p/181491658">https://zhuanlan.zhihu.com/p/181491658</a><br>CHATBOT: Architecture, Design, &amp; Development By Jack Cahn</p><p>DocBert Bert用作文档分类(2019年8月论文)<br><a href="https://zhuanlan.zhihu.com/p/180475198">https://zhuanlan.zhihu.com/p/180475198</a><br>DocBERT: BERT for Document Classification</p><p>TableBank：用于表检测和识别的基准数据集<br><a href="https://zhuanlan.zhihu.com/p/170365926">https://zhuanlan.zhihu.com/p/170365926</a><br>TableBank: A Benchmark Dataset for Table Detection and Recognition</p><p>LayoutLM 微软预训练模型图片类文档分类和实体识别(2020年6月论文)<br><a href="https://zhuanlan.zhihu.com/p/166128964">https://zhuanlan.zhihu.com/p/166128964</a><br>LayoutLM: Pre-training of Text and Layout for Document Image Understanding</p><p>UNILM 微软预训练的NLU和NLG结合模型(2019-10论文)<br><a href="https://zhuanlan.zhihu.com/p/164736442">https://zhuanlan.zhihu.com/p/164736442</a><br>Unified Language Model Pre-training for Natural Language Understanding and Generation</p><p>DIET模型 rasa 聊天机器人核心模型论文（2020年5月论文)<br><a href="https://zhuanlan.zhihu.com/p/162995854">https://zhuanlan.zhihu.com/p/162995854</a><br>Dual Intent and Entity Transformer</p><p>NLP之MixText 半监督文本分类(2020年4月论文解读)<br><a href="https://zhuanlan.zhihu.com/p/156091468">https://zhuanlan.zhihu.com/p/156091468</a><br>MixText: Linguistically-Informed Interpolation of Hidden Space for Semi-Supervised Text Classification</p><p>NLP 之数据增强算法(论文解读-2019年论文)<br><a href="https://zhuanlan.zhihu.com/p/152633064">https://zhuanlan.zhihu.com/p/152633064</a><br>EDA: Easy Data Augmentation Techniques for Boosting Performance onText Classification Tasks</p><p>TFIDF+Wordembedding无监督多标签文本分类算法（论文解读)<br><a href="https://zhuanlan.zhihu.com/p/152526817">https://zhuanlan.zhihu.com/p/152526817</a><br>Improving Recall and Precision in Unsupervised Multi-Label Document Classifification Tasks by Combining Word Embeddings with TF-IDF</p><p>评估对于少量样本使用Bert进行fine-tunning的优化方法（论文解读)<br><a href="https://zhuanlan.zhihu.com/p/152523646">https://zhuanlan.zhihu.com/p/152523646</a><br>Revisiting Few-sample BERT Fine-tuning</p><p>SYNTHESIZER代替self-attention机制（Google论文解读)<br><a href="https://zhuanlan.zhihu.com/p/152518921">https://zhuanlan.zhihu.com/p/152518921</a><br>Rethinking Self-Attention in Transformer Models</p>]]></content>
    
    
    <categories>
      
      <category>知乎</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>apex兼容torch1.10时的一个bug</title>
    <link href="/2022/03/08/apex%E7%9A%84%E4%B8%80%E4%B8%AAbug/"/>
    <url>/2022/03/08/apex%E7%9A%84%E4%B8%80%E4%B8%AAbug/</url>
    
    <content type="html"><![CDATA[<h1 id="关于apex的一个bug"><a href="#关于apex的一个bug" class="headerlink" title="关于apex的一个bug"></a>关于apex的一个bug</h1><p>具体报错内容如下:</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">    <span class="hljs-keyword">if</span> cached_x<span class="hljs-selector-class">.grad_fn</span><span class="hljs-selector-class">.next_functions</span><span class="hljs-selector-attr">[1]</span><span class="hljs-selector-attr">[0]</span><span class="hljs-selector-class">.variable</span> is not x:<br>IndexError: tuple index out of range<br></code></pre></td></tr></table></figure><p>先说具体的官方的issue和解决方法<br><a href="https://github.com/NVIDIA/apex/issues/1227">https://github.com/NVIDIA/apex/issues/1227</a><br><a href="https://github.com/NVIDIA/apex/issues/694#issuecomment-918833904">https://github.com/NVIDIA/apex/issues/694#issuecomment-918833904</a></p><p>zwithz用户已经指出应该修改这个文件，但是后面的用户classicsong说这个方法是有问题的</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs csharp">apex/amp/utils.py<br><span class="hljs-meta"># change this <span class="hljs-keyword">line</span> (<span class="hljs-keyword">line</span> 113)</span><br>- <span class="hljs-keyword">if</span> cached_x.grad_fn.next_functions[<span class="hljs-number">1</span>][<span class="hljs-number">0</span>].variable <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> x:<br><span class="hljs-meta"># 改成如下:</span><br>+ <span class="hljs-keyword">if</span> cached_x.grad_fn.next_functions[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>].variable <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> x:<br></code></pre></td></tr></table></figure><p>其实zwithz说的是对的，这是apex的一个bug<br>不同版本的torch的grad_fn数量</p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs nix"><span class="hljs-built_in">import</span> torch<br>print(torch.__version__)<br><span class="hljs-attr">x</span> = torch.ones(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-attr">requires_grad=True)</span><br><span class="hljs-attr">y</span> = x + <span class="hljs-number">2</span><br><span class="hljs-attr">z</span> = y * y * <span class="hljs-number">3</span><br><span class="hljs-attr">out</span> = z.mean()<br><span class="hljs-attr">half</span> = out.half()<br>print(len(half.grad_fn.next_functions))<br></code></pre></td></tr></table></figure><ul><li>1.7 版本</li></ul><p>1.7.0+cu110<br>2</p><ul><li>1.8版本</li></ul><p>1.8.0.post3<br>2</p><ul><li>1.9版本</li></ul><p>1.9.0+cu111<br>2</p><ul><li>1.10版本</li></ul><p>1.10.2<br>1</p><h2 id="关于grad-fn"><a href="#关于grad-fn" class="headerlink" title="关于grad_fn"></a>关于grad_fn</h2><p>grad_fn保存了链式计算的图<br>创建一个张量并设置requires_grad&#x3D;True, 那么这个tensor经过计算后的值都会写携带grad_fn属性，，用来追踪计算历史<br>Autograd是反向自动微分系统。从概念上讲，autograd记录了一个图，记录了你执行运算时产生数据的所有运算，给你一个有向无<br>环图，其叶子是输入张量，根是输出张量。通过追踪这个图从根到叶，你可以使用链式规则自动计算梯度。<br>在内部，autograd将这个图表示为Function对象的图（真正的表达式），autograd建立一个代表计算梯度的函数的图（每个torch.Tensor的.grad_fn属性是这个图的入口）。当前向传播完成后，我们在反向传播中评估这个图以计算梯度。</p><h2 id="官方示例"><a href="#官方示例" class="headerlink" title="官方示例"></a>官方示例</h2><p>如果你有一个模型，你按照损失的方向，使用它的.grad_fn属性，你会看到一个计算的图，看起来像这样。</p><figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs xl"><span class="hljs-function"><span class="hljs-title">input</span> -&gt;</span> <span class="hljs-function"><span class="hljs-title">conv2d</span> -&gt;</span> <span class="hljs-function"><span class="hljs-title">relu</span> -&gt;</span> <span class="hljs-function"><span class="hljs-title">maxpool2d</span> -&gt;</span> <span class="hljs-function"><span class="hljs-title">conv2d</span> -&gt;</span> <span class="hljs-function"><span class="hljs-title">relu</span> -&gt;</span> maxpool2d<br>      -&gt; <span class="hljs-function"><span class="hljs-title">flatten</span> -&gt;</span> <span class="hljs-function"><span class="hljs-title">linear</span> -&gt;</span> <span class="hljs-function"><span class="hljs-title">relu</span> -&gt;</span> <span class="hljs-function"><span class="hljs-title">linear</span> -&gt;</span> <span class="hljs-function"><span class="hljs-title">relu</span> -&gt;</span> linear<br>      -&gt; MSELoss<br>      -&gt; loss<br>因此，当我们调用loss.backward()时，整个图被微分，并且图中所有require_grad=True的张量都会有其.grad张量的梯度积累。<br>print(loss.grad_fn)  # MSELoss<br>print(loss.grad_fn.next_functions[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>])  # Linear<br>print(loss.grad_fn.next_functions[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>].next_functions[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>])  # ReLU<br>------&gt;<br>&lt;MseLossBackward0 object <span class="hljs-built_in">at</span> <span class="hljs-number">0</span>x7f09e8c788d0&gt;<br>&lt;AddmmBackward0 object <span class="hljs-built_in">at</span> <span class="hljs-number">0</span>x7f09e8c78978&gt;<br>&lt;AccumulateGrad object <span class="hljs-built_in">at</span> <span class="hljs-number">0</span>x7f09e8c78978&gt;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>torch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>apex</tag>
      
      <tag>fp16</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>信息提取的方式总结</title>
    <link href="/2022/03/08/%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96/"/>
    <url>/2022/03/08/%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96/</url>
    
    <content type="html"><![CDATA[<h1 id="信息抽取"><a href="#信息抽取" class="headerlink" title="信息抽取"></a>信息抽取</h1><p>信息抽取是构建知识图谱的关键一环，目前已实现了3种抽取的方式测试，发现了一些注意事项，总结如下:</p><img src="/2022/03/08/%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96/%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E6%80%BB%E7%BB%93.png" class="">]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>信息抽取</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>显存优化技术盘点</title>
    <link href="/2022/03/04/gpu-optimizer/"/>
    <url>/2022/03/04/gpu-optimizer/</url>
    
    <content type="html"><![CDATA[<h1 id="显存优化技术"><a href="#显存优化技术" class="headerlink" title="显存优化技术"></a>显存优化技术</h1><p>本思维导图总结了显存的占用的分为哪些部分，训练时的流程，和多GPU训练的分类。</p><img src="/2022/03/04/gpu-optimizer/%E6%98%BE%E5%AD%98%E4%BC%98%E5%8C%96%E6%8A%80%E6%9C%AF.png" class="">]]></content>
    
    
    <categories>
      
      <category>cuda</category>
      
    </categories>
    
    
    <tags>
      
      <tag>显存</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>一次pycharm在使用torch Dataloader进行debug时卡住</title>
    <link href="/2022/03/01/pycharm-debug/"/>
    <url>/2022/03/01/pycharm-debug/</url>
    
    <content type="html"><![CDATA[<h1 id="pycharm-debug可能卡住的原因有很多，其中之一是多进程导致的-尤其是我们在使用torch的DataLoader时，如果发生卡住，那么只需检查num-workers是否是0，即可"><a href="#pycharm-debug可能卡住的原因有很多，其中之一是多进程导致的-尤其是我们在使用torch的DataLoader时，如果发生卡住，那么只需检查num-workers是否是0，即可" class="headerlink" title="pycharm debug可能卡住的原因有很多，其中之一是多进程导致的, 尤其是我们在使用torch的DataLoader时，如果发生卡住，那么只需检查num_workers是否是0，即可"></a>pycharm debug可能卡住的原因有很多，其中之一是多进程导致的, 尤其是我们在使用torch的DataLoader时，如果发生卡住，那么只需检查num_workers是否是0，即可</h1><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs routeros">DataLoader(<br>    dataset,<br>    <span class="hljs-attribute">batch_size</span>=1,<br>    <span class="hljs-attribute">shuffle</span>=<span class="hljs-literal">False</span>,<br>    <span class="hljs-attribute">sampler</span>=None,<br>    <span class="hljs-attribute">batch_sampler</span>=None,<br>    <span class="hljs-attribute">num_workers</span>=0,<br>    <span class="hljs-attribute">collate_fn</span>=None,<br>    <span class="hljs-attribute">pin_memory</span>=<span class="hljs-literal">False</span>,<br>    <span class="hljs-attribute">drop_last</span>=<span class="hljs-literal">False</span>,<br>    <span class="hljs-attribute">timeout</span>=0,<br>    <span class="hljs-attribute">worker_init_fn</span>=None,<br>    <span class="hljs-attribute">multiprocessing_context</span>=None,<br>)<br>参数:<br>- dataset : 数据集<br>- batch_size: 批次大小<br>- shuffle: 是否乱序<br>- sampler: 样本采样函数，一般无需设置。<br>- batch_sampler: 批次采样函数，一般无需设置。<br>- num_workers: 使用多进程读取数据，设置的进程数。<br>- collate_fn: 整理一个批次数据的函数。<br>- pin_memory: 是否设置为锁业内存。默认为<span class="hljs-literal">False</span>，锁业内存不会使用虚拟内存(硬盘)，从锁业内存拷贝<br>到GPU上速度会更快。<br>- drop_last: 是否丢弃最后一个样本数量不足batch_size批次数据。<br>- timeout: 加载一个数据批次的最长等待时间，一般无需设置。<br>- worker_init_fn: 每个worker中dataset的初始化函数，常用于 IterableDataset。一般不使用<br></code></pre></td></tr></table></figure><p>根据API可知，num_workers是设置读取数据的并发进程数量，而根据pycharm的官方的issue，<a href="https://youtrack.jetbrains.com/issue/PY-39489%EF%BC%8C%E6%88%91%E4%BB%AC%E5%8F%91%E7%8E%B0pycharm%E5%A4%9A%E8%BF%9B%E7%A8%8B%E7%9A%84debug%E6%9C%89%E6%97%B6%E5%B9%B6%E4%B8%8D%E5%A4%AA%E6%96%B9%E4%BE%BF%EF%BC%8C%E6%89%80%E4%BB%A5%E5%8F%AA%E9%9C%80%E5%9C%A8debug%E6%97%B6%EF%BC%8C%E4%BF%AE%E6%94%B9num_workers%E5%8D%B3%E5%8F%AF%EF%BC%8C%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E5%9C%A8%E6%94%B9%E5%9B%9E%E6%9D%A5%E5%B0%B1%E8%A1%8C%E3%80%82">https://youtrack.jetbrains.com/issue/PY-39489，我们发现pycharm多进程的debug有时并不太方便，所以只需在debug时，修改num_workers即可，生产环境在改回来就行。</a></p>]]></content>
    
    
    <categories>
      
      <category>ide</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>多标签分类的2种简单实现</title>
    <link href="/2022/02/28/multilabel/"/>
    <url>/2022/02/28/multilabel/</url>
    
    <content type="html"><![CDATA[<h1 id="模型的损失函数"><a href="#模型的损失函数" class="headerlink" title="模型的损失函数"></a>模型的损失函数</h1><p>torch.nn.BCEWithLogitsLoss<br>先进行了sigmoid，然后进行了二分类交叉熵损失函数</p><h1 id="评估metric"><a href="#评估metric" class="headerlink" title="评估metric"></a>评估metric</h1><p>hamming score<br>sklearn.metrics.multilabel_confusion_matrix   #多标签混淆矩阵</p><p>#hamming score<br>示例</p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs nix"><span class="hljs-built_in">import</span> numpy as np<br><span class="hljs-attr">truth</span> = [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>] <span class="hljs-comment"># 真实值</span><br><span class="hljs-attr">prediction</span> = [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]  <span class="hljs-comment">#预测值</span><br><span class="hljs-attr">truth</span> = np.array(truth)<br><span class="hljs-attr">prediction</span> = np.array(prediction)<br><span class="hljs-attr">num_classes</span> = len(truth)<br><span class="hljs-attr">num_samples</span> = <span class="hljs-number">1</span><br><span class="hljs-attr">numerator</span> = float(sum(truth &amp; prediction))<br><span class="hljs-attr">denominator</span> = float(sum(truth | prediction))<br><span class="hljs-attr">hamming_score</span> = numerator / denominator<br>------&gt;<br><span class="hljs-number">0.667</span><br>如果是按照准确率计算accuracy_score(truth, prediction)，那么是<span class="hljs-number">0.8</span><br></code></pre></td></tr></table></figure><p>我们的输出是一个批次的，所以是二维的，计算的方法是: score&#x3D;((predicts &amp; labels).sum(axis&#x3D;1) &#x2F; (predicts | labels).sum(axis&#x3D;1)).mean()</p><h1 id="实现方式1：-使用CLS进行分类"><a href="#实现方式1：-使用CLS进行分类" class="headerlink" title="实现方式1： 使用CLS进行分类"></a>实现方式1： 使用CLS进行分类</h1><p>假设我们的示例是商品的购买意向，模型的基本输入是：CLS+句子1+SEP+商品+SEP<br>对CLS进行求sigmoid和二分类交叉熵<br>模型实现逻辑：</p><ol><li>Bert模型编码, last_hidden_state, all_hidden_states &#x3D; self.encode(input_ids, token_type_ids, attention_mask)</li><li>取最后一个隐藏层的CLS向量, first_token_tensor &#x3D; hidden_states[:, 0]  </li><li>进行dropout, self.dropout(first_token_tensor)</li><li>加个全连接层和激活</li><li>线性层映射到标签个数，得到logits, nn.Linear(hidden_size, num_labels)</li><li>计算损失, 反向传播,更新参数</li></ol><h1 id="实现方式2：-每个标签类别向量进行分类"><a href="#实现方式2：-每个标签类别向量进行分类" class="headerlink" title="实现方式2： 每个标签类别向量进行分类"></a>实现方式2： 每个标签类别向量进行分类</h1><p>假设我们的示例是商品的购买意向, 模型的基本输入是: CLS+句子1+SEP+商品+每个标签的id+SEP<br>取出每个标签的向量<br>对每个标签向量进行二分类交叉熵损失<br>模型实现逻辑：</p><ol><li>注意我们在输入的末尾添加了每个标签的id, 所以需要用特殊的token表示这些id, 所以需要增加词表，tokenizer.add_special_tokens({‘additional_special_tokens’:’opinion1’}) 我们用opinion1代表第一个标签，opinion2代表第二个标签，分别都加入到vocab中</li><li>注意在处理数据时，我们还有生成label_mask参数，告知我们关注的label的位置在哪里</li><li>Bert模型编码, last_hidden_state, all_hidden_states &#x3D; self.encode(input_ids, token_type_ids, attention_mask)</li><li>hidden_states 形状 [batch_size, seq_len, last_hidden_size] –&gt; [batch_size, labels_num, last_hidden_size]  加一个维度，然后扩充到hidden_states形状，方便后面取出label_mask需要的维度数据 label_mask_expand &#x3D; label_mask.unsqueeze(-1).expand(hidden_states.size())<br> labels_token_tensor_1d &#x3D; torch.masked_select(hidden_states, (label_mask_expand &#x3D;&#x3D; 1))<br>labels_token_tensor &#x3D; labels_token_tensor_1d.view(batch_size, -1, last_hidden_size)</li><li>加个droput, 全连接层和激活 </li><li>分类层, 最后变成1维度，nn.Linear(hidden_size, 1)</li><li>logits &#x3D; logits.squeeze(-1), 去掉最后一次，得到[batch_size, num_labels] 形状</li><li>计算损失, 反向传播,更新参数</li></ol>]]></content>
    
    
    <categories>
      
      <category>模型</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分类</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>一些论文中的专有名词</title>
    <link href="/2022/02/24/paper-word/"/>
    <url>/2022/02/24/paper-word/</url>
    
    <content type="html"><![CDATA[<h1 id="一些论文中的专有名词的解释或缩写"><a href="#一些论文中的专有名词的解释或缩写" class="headerlink" title="一些论文中的专有名词的解释或缩写"></a>一些论文中的专有名词的解释或缩写</h1><ul><li>low-resource:低资源:有标签或者无标签的训练的数据资源不足</li><li>Distant supervision:远端监督:大多数机器学习技术都需要一组训练数据。收集训练数据的传统方法是让人们标签一组文档。例如，对于婚姻关系，人类标注者可以将“比尔·克林顿”和“希拉里·克林顿”对标签为正的训练样本。这种方法在时间和金钱上都是昂贵的，并且如果我们的语料库很大，将无法产生足够的数据供我们的算法使用。而且由于人为错误，因此产生的训练数据极有可能是噪音的。生成训练数据的另一种方法是远距离监督(远程监督)。在远距离监督中，我们利用一个已经存在的数据库来收集要提取的关系的样本。然后，我们使用这些样本自动生成我们的训练数据。例如，包含巴拉克·奥巴马和米歇尔·奥巴马已婚的事实。我们考虑到这一事实，然后将出现在同一句子中的每对“巴拉克·奥巴马”和“米歇尔·奥巴马”都标签为我们婚姻关系的一个正例子。这样，我们可以轻松生成大量(可能是噪音的)训练数据。运用远距离监督来获得特定关系的正样本很容易，但是产生负样本比较难.即用知识库KG来获取2个实体之间的关系。</li><li>tokenization:分词器:原始raw text叫语料，字典中的单独词叫token，可能是单词，也可能是词语，取决于字典，tokenization是把raw text变成token的过程，假如英语就是把句子用空格切分，每个单词就叫token</li><li>detokenization:分词还原: 就是还原，把分词还原成句子，或者把分词后得到的id还原成原来的句子。</li><li>soft label:软标签:是一个teacher模型预测出来的，类似logits的概率值，是浮点数</li><li>hard label:硬标签:硬标签直接就是整数，就是对应概率最大的位置的索引，例如soft是0.82, hard就是1, <a href="https://arxiv.org/abs/1511.06335">https://arxiv.org/abs/1511.06335</a></li><li>SOTA:state-of-the-art:业界最新的性能，达到最新的模型性能</li><li>FLOPS:floating point operations per second:每秒浮动计算数, 是衡量计算机计算性能的一个指标</li><li>MLM:Masked language modeling, 掩盖语言建模, 也被叫做完形填空测试,cloze test,MLM的任务是根据占位符预测序列中的丢失token</li><li>T5: Text-to-Text Transfer Transformer</li><li>warm-up: 调整学习率的方式，在warm-up步数之前的学习率是恒定或者按照一定规则变大，warm-up之后的步数指数方式衰减和线性衰减</li><li>corruption损坏: 破坏一个原有的句子，例如BERT的MLM的无监督目标，可以对一个句子进行丢弃，替换，交换，添加操作，改变原有语句，然后让模型预测原有句子或改变的部分</li><li>域内数据: 就是一个领域的数据，例如新闻领域的文章和论文领域里的文章是不一样的,他们就是不同的域</li><li>pre-train-then-ﬁne-tune: 首先预训练模型，然后微调模型，预训练模型一般用大量数据做无监督训练，微调模型是用少量数据有监督训练</li><li>零样本学习(zero-shot learning): 即使训练时没有看到目标训练集，也能进行进行模型预测,零次训练或推理,无须训练，直接进行预测或推理。是一种训练策略，它允许机器学习模型预测新的类别，而不需要为新的类别提供任何标注的样本。</li><li>Few-Shot: 少量训练样本进行学习，然后预测，类似于low-resource</li><li>图灵完备性（Turing Completeness）:是针对一套数据操作规则而言的概念。数据操作规则可以是一门编程语言，也可以是计算机里具体实现了的指令集。当这套规则可以实现图灵机模型里的全部功能时，就称它具有图灵完备性。直白一点说，图灵完备性就是我给你一工具箱的东西，包括无限内存、if&#x2F;else 控制流、while 循环; 简单来讲，一切可计算的问题都能计算，这样的虚拟机或者编程语言就叫图灵完备的;举个例子，如果有人说，我的东西是图灵完备的，也就意味着理论上它能够用来解决任何计算性的问题。</li><li>有限状态机（英语：finite-state machine，缩写：FSM）又称有限状态自动机（英语：finite-state automation，缩写：FSA），简称状态机，是表示有限个状态以及在这些状态之间的转移和动作等行为的数学计算模型。</li><li>RE:relation extraction,neural relation extraction (NRE),  从一个句子中判断两个entity是否有关系，一般是一个二分类问题，指定某种关系。</li><li>Entity Mentions: 实体提及,就是句子中的实体, “New York City is good”  New York City就是实体，或者实体提及, 就是实体的名字</li><li>KGs: Knowledge Graph, 知识图谱</li><li>Autograd: 自动微分是训练神经网络的一种机制,自动求导，计算梯度</li><li>Segment: 片段，或者称为句子a，句子b等，例如训练BERT时结构如,“[CLS] x1 [SEP] x2 [SEP]”，x1表示片段1，或句子a，x2表示片段2或句子b。</li><li>Intrinsic tasks vs Downstream Tasks: 固有任务和下游任务，固有任务意思是预训练语言模型时的任务，下游任务是微调模型时的任务。</li><li>WordPiece: 是在自然语言处理中使用的子词分割算法。BERT用的此方法。子词分词的一种方法。 用该语言中的各个字符初始化单词表，然后将单词表中最常见的符号组合迭代添加到单词表中。 该过程是：1.用文本中的所有字符初始化单词清单。2.使用来自上一步的清单在训练数据上构建语言模型。 3. 通过组合当前单词清单中的两个单元, 将单词组装一个单词单元。 在添加到模型中时，从所有可能增加训练数据可能性中选择一个新的词单元。 4. 转到2，直到达到预定义的词单元限制或可能性增加低于某个特定阈值。</li><li>NMT:  Neural machine translation,神经机器翻译, 利用深度神经网络执行的端到端的翻译，例如seq2seq的神经网络翻译。</li><li>SMT: statistical machine translation,传统机器翻译的方法。</li><li>non-segmented语言: 分段语言，即用空格分隔的语言，例如英语，非分段语言，例如中文，日语，韩语。</li><li>NFD:Normalization Form Canonical Decomposition标准化形式规范分解,Unicode字符串标准化的一种算法,字符通过规范等价分解，并且多个组合字符按特定顺序排列</li><li>NFC:Normalization Form Canonical Composition 标准化形式规范组合,Unicode字符串标准化的一种算法, 字符被分解，然后通过规范对等重新组合。 </li><li>NFKD: Normalization Form Compatibility Decomposition: 标准化形式兼容性分解,字符通过兼容性分解，并且多个组合字符按特定顺序排列。 </li><li>NFKC: Normalization Form Compatibility Composition: 标准化形式兼容性组成,字符通过兼容性分解，然后通过规范对等重组。所有这些算法都是幂等转换，这意味着如果以相同算法再次处理，已经处于这些标准化形式之一的字符串将不会被修改。 </li><li>RBT3：由RoBERTa-wwm-ext 3层进行初始化，继续训练了1M步,RBT的名字是RoBERTa三个音节首字母组成，L代表large模型</li><li>RBTL3: 3层RoBERTa-wwm-ext-base&#x2F;large,由RoBERTa-wwm-ext-large 3层进行初始化，继续训练了1M步</li><li>ONNX: Open Neural Network Exchange format,开放式神经网络交换格式,提高模型推理速度的中间模型格式，最高实现4倍的推理加速。</li><li>ABSA: Aspect-based Sentiment Analysis, 给定句子中关心的情感的术语(aspect),即某个词在句子中表达的情感。等同于ALSC, Aspect level sentiment classification</li><li>Sentiment Analysis (SA): 也称为Opinion Mining (OM)</li><li>self-supervised: 类似于BERT的预训练模型的方式，也可以成为无监督,无监督表明我们确实没给BERT提供人工打标签，自监督表明它是用自己随机MASK部分token，然后预测被Mask的方式，所以叫做自监督。</li><li>context-gloss: 上下文的连贯性</li><li>LA-MLM: label-aware masked language model, 标签感知masked语言模型,分2个阶段Early Fusion早期融合和Late Supervision后期监督，它们的主要区别是早期融合阶段是把句子情感也作为输入，后期监督是把句子情感作为预测标签，监督训练句子情感。早期融合和后期监督的目的是让模型能够理解句子级情感和单词级情感和词性之间的内在联系。</li><li>parse tree: 分析树, 具体语法树（concrete syntax tree）,是一个反映某种形式语言字符串的语法关系的有根有序树。分析树一般按照两种相反的法则生成，一种是依存语法,一种是短语结构语法。二分类选举树,binary constituency tree</li><li>PLM: Pre-trained Language Models 预训练语言模型； 排列语言模型(Permutation Language Model) PLM, XLNet使用排列语言模型(PLM)</li><li>DRL: deep reinforcement learning</li><li>市场摩擦（英文：Market Friction）:是指金融资产在交易中存在的难度。它可由交易一定数量某金融资产的最佳占用时间来测定，也可由即时交易所需要的价格让步(Price concession)来测定。</li><li>inductive: 归纳式学习,transductive和inductive的区别在于我们想要预测的样本，是不是我们在训练的时候已经见（用）过的。inductive learning就是只根据现有的ABC，用比如kNN距离算法来预测，在来一个新的数据的时候，还是只根据5个ABC来预测。</li><li>transductive: 直推式学习,transductive learning直接以某种算法观察出数据的分布，这里呈现三个cluster，就根据cluster判定，不会建立一个预测的模型，如果一个新的数据加进来 就必须重新算一遍整个算法，新加的数据也会导致旧的已预测问号的结果改变</li><li>NRE: Neural Relation Extraction Models 神经网络的关系抽取模型</li><li>PCNN: PCNN（Piece-Wise-CNN）</li><li>OMR: 光学音乐识别(OPTICAL MUSIC Recognition，OMR)是将乐谱的扫描图像转换为像MusicXML[9]或MIDI这样的符号代表的问题。这种解决方案有很多明显的实际应用。</li><li>on-policy: 强化学习可以分为off-policy和on-policy的方法。off-policy RL算法意味着用于选择动作的行为策略与学习策略不同。相反，在on-policy RL算法中，行为策略与学习策略是相同的。此外，强化学习还可以分为基于价值的方法和基于策略的方法。在基于价值的RL中，agent更新价值函数来学习合适的策略，而基于策略的RL agent直接学习策略。</li><li>Hierarchical reinforcement learning (HRL): 分层强化学习</li><li>ALE: Atari Learning Environment</li><li>rollout:（就相当于在一个棋局时尝试多次不同路径的走子）类似右图产生多条路径</li><li>Imitation Learning: IL 模仿学习，模仿学习的思想很直观(intuitive)。我们在前面所介绍的Model-free, Model-based强化学习方法都是从零开始(from scratch)探索并学习一个使累计回报最大的策略(policy) [公式] 。 Imitation Learning的想法是，借助人类给出的示范(demonstration)，可以快速地达到这个目的。</li><li>• Forward model: (st, at) → st+1. 前向模型。(st, at) → st+1. 这是在给定当前状态和所选动作的情况下预测下一个状态。这是目前最常见的模型类型，可用于前向规划。</li><li>• Backward&#x2F;reverse model: st+1 → (st, at).  反向模型：st+1 →（st，at）。这个模型预测了哪些状态是某一特定状态的可能前兆。因此，我们可以在反向的方向上进行规划，例如，在prioritized sweeping中就使用了这种方法（Moore和Atkeson，1993）。</li><li>• Inverse model: (st, st+1) → at.  逆向模型。(st, st+1) → at. 逆向模型预测从一个状态到另一个状态需要哪种行动。例如，它被用于RRT规划中（LaValle，1998）。正如我们稍后将看到的那样，这个函数也可以作为表示学习的一部分。</li><li>NP-hard: NP是指非确定性多项式（non-deterministic polynomial，缩写NP）。所谓的非确定性是指，可用一定数量的运算去解决多项式时间内可解决的问题。例如，著名的推销员旅行问题（Travel Saleman Problem or TSP）：假设一个推销员需要从香港出发，经过广州，北京，上海，…，等 n 个城市， 最后返回香港。 任意两个城市之间都有飞机直达，但票价不等。假设公司只给报销 C 元钱，问是否存在一个行程安排，使得他能遍历所有城市，而且总的路费小于 C？ 推销员旅行问题显然是 NP 的。因为如果你任意给出一个行程安排，可以很容易算出旅行总开销。但是，要想知道一条总路费小于 C 的行程是否存在，在最坏情况下，必须检查所有可能的旅行安排！ 这将是个天文数字。</li><li>P类问题：可以找到一个多项式时间复杂度的算法去解决的问题；</li><li>NEXPTIME-complete:如果一个决策问题在NEXPTIME中，那么它就是NEXPTIME完整的，而且NEXPTIME中的每个问题都有一个多项式时间的多对一还原。换句话说，有一种多项式时间的算法可以将一个问题的实例转化为另一个问题的实例，而且答案相同。NEXPTIME-complete的问题可以被认为是NEXPTIME中最难的问题。我们知道NEXPTIME-complete问题不在NP中；根据时间层次定理，已经证明这些问题不能在多项式时间内被验证。 一组重要的NEXPTIME-complete问题与简洁电路有关。简明电路是一种简单的机器，用于在指数级的空间内描述图形。它们接受两个顶点数字作为输入，并输出它们之间是否有一条边。如果在自然表示法（如邻接矩阵）中解决一个图的问题是NP-完全的，那么在简洁电路表示法中解决同样的问题是NEXPTIME-完全的，因为输入是指数级的小（在一些温和的条件下，NP-完全性的减少是通过 “投影 “实现的）。[2][3] 作为一个简单的例子，为一个如此编码的图寻找一个汉密尔顿路径是NEXPTIME-完全的。</li><li>MARL: Multi-Agent Reinforcement Learning 多agent强化学习</li><li>annealed: 退火，意思是超参数随着时间的逐渐变小，参数越来越小。例如强化学习中的Qleanring的Greedy系数。</li><li>优势函数:advantage function , 强化学习 优势函数(Advantage Function),优势函数表达在状态s下，某动作a相对于平均而言的优势。 从数量关系来看，就是随机变量相对均值的偏差。 使用优势函数是深度强化学习极其重要的一种策略，尤其对于基于policy的学习。优势函数其实就是将Q-Value“归一化”到Value baseline上，如上讨论的，这样有助于提高学习效率，同时使学习更加稳定；同时经验表明，优势函数也有助于减小方差，而方差过大导致过拟合的重要因素。Aπ(s,a)&#x3D;Qπ(s,a) - Vπ(s)</li><li>bitext: bidirectional text, 双向语料，即翻译的平行语料，例如中英文翻译语料库</li><li>Dec-POMDP: 一个完全合作的多agent任务可以被描述为一个分散的部分可观察马尔可夫决策过程（Dec-POMDP）</li><li>CTDE: 集中训练和分散执行（CTDE）Kraemer和Banerjee[2016]的范式允许学习过程利用额外的状态信息。CTDE允许学习算法访问所有局部行动观察直方图和全局状态，并共享梯度和参数。然后，在执行阶段，每个单独的agent只能访问其局部行动观察历史τi。</li><li>tile-coding: 强化学习理论扩展到了连续空间（连续空间的泛化）。tile-coding是连续空间强化学习问题中最实用和计算效率最高的工具。本质上，tile-coding是连续状态空间中的特征表示,tile-coding的主要优势之一是其计算效率。一个tiling的意思是一张大网，里面有划分成不同的小网，观察的像素会落到这个tiling中的小网内，就可以用这个小网内的坐标表示这个特征，多个tiling就是用多个小网内的坐标表示这个特征，就像self-attention的多头和卷积中的多个卷积核一样。<a href="https://towardsdatascience.com/reinforcement-learning-tile-coding-implementation-7974b600762b">https://towardsdatascience.com/reinforcement-learning-tile-coding-implementation-7974b600762b</a></li><li>domain adaptation for machine translation (DAMT): 半监督领域适应翻译</li><li>ROUGE-N:系统和参考摘要之间N-grams的重叠。</li><li>ROUGE-1:指的是系统和参考摘要之间的unigram（每个字）的重叠情况。</li><li>ROUGE-2:指的是系统和参考摘要之间的bigram重叠。</li><li>ROUGE-L:基于最长共同子序列（LCS）的统计。最长共同子序列问题自然考虑到了句子层面的结构相似性，并自动识别序列中最长的共同出现的n-grams。</li><li>ROUGE-W:基于加权的LCS统计，倾向于连续的LCSs。</li><li>ROUGE-S:基于 Skip-bigram 的共现统计。Skip-bigram是指任何一对词在其句子中的序列。</li><li>ROUGE-SU:基于 Skip-bigram 和 unigram 的共现统计。</li><li>MTL: Multi-task learning </li><li>SAN: 随机答案网络,用于问答系统，stochastic answer network, Stochastic answer networks for natural language inference</li><li>MTPE:  machine translation post-editing</li><li>MBRL: model-based的强化学习</li><li>CPM:Chinese Pretrained language Model 中文预训练模型</li><li>prompt-tuning:（p-tuning）</li><li>TrGCN: transformer图卷积网络</li><li>NED:命名实体消歧named entity disambiguation</li><li>ERD: Entity Relationship Diagram 实体关系图</li><li>ELBO:  Evidence Lower Bound，即证据下界,这里的证据指数据或可观测变量的概率密度。使用变分推断时，首先需要计算的便是ELBO。<a href="https://blog.csdn.net/qy20115549/article/details/93074519">https://blog.csdn.net/qy20115549/article/details/93074519</a></li><li>New Words Discovery: 新词发现</li><li>ACSA: Aspect category sentiment analysis, 基于属性类别的情感分析</li><li>ABSA: Aspect Based Sentiment Analysis, 基于属性的情感分析</li><li>ATSA: 等同于ABSA，aspect术语情感分析</li><li>capsule Network: 胶囊神经网络,是相对于CNN的改进，综合了CNN的优点的同时，考虑了CNN缺失的相对位置、角度等其他信息，从而使得识别效果有所提升。<a href="https://easyai.tech/ai-definition/capsule/">https://easyai.tech/ai-definition/capsule/</a></li><li>MRR: Mean Reciprocal Rank, 是一个国际上通用的对 搜索算法 进行评价的机制，即第一个结果匹配，分数为1，第二个匹配分数为0.5，第n个匹配分数为1&#x2F;n，如果没有匹配的句子分数为0,最终的分数为所有得分之和</li><li>ER: entity recognition 实体识别</li><li>EL: entity linking 实体链接</li><li>ED: entity disambiguation 实体消歧</li><li>EEs: emerging entities 新出现的实体</li><li>EED: emerging entity discovery 新实体发现,通过对知识库中现有的候选实体进行鉴别,KB外的实体称为新出现的实体。</li><li>BPR: Best Possible Recall</li><li>CMD: Central Moment Discrepancy, 最先进的分布相似度指标,过匹配两个表示的顺序矩差来衡量它们之间的差异,类似KL散度,可以执行高阶矩的明确匹配，而不需要昂贵的距离和核矩阵计算。CMD距离随着两个分布的相似性而变小。</li><li>平凡解: trivial solution, 编码器函数近似于一个不相关的但不具代表性的模态向量，就会出现平凡解的情况，防止平凡解, 经常用于结构非常简单的对象（比如群或拓扑空间），有时亦会用明显或乏趣这两个词代替，但对非数学工作者来说，它们有时可能比其他更复杂的对象更难想象或理解。例如： 明显因数：对于每个正整数 n 来说，1、-1、n 和 -n 都是它的明显因数。 空集：不包含任何元素的集合； 平凡群：只含单位元的群；</li><li>DETR: 端到端目标检测,End-to-end Object Detection with Transformer, 达到与Faster-RCNN等两阶段目标检测相当的性能。</li><li>FGM: Factor Graph Model, 因子图模型,是概率图模型的一种</li><li>IGL: Iterative Grid Labeling 迭代式网关标注方式</li><li>TSA: Text Similarity Approach 文本相似性技术</li><li>MLTC:multi-label text classification 多标签文本分类</li><li>XMC: Extreme multi-label text classification 极端多标签文本分类, 寻求从一个极端大的标签集合中为给定的文本输入找到相关的标签。许多现实世界的应用可以被表述为XMC问题，如推荐系统、文档tagging和语义搜索。</li><li>exposure bias: 暴露偏差:模型训练与预测过程之间的不匹配。在训练时每一个词输入都来自真实样本，但是在推断时当前输入用的却是上一个词的输入</li></ul>]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>知识图谱的构建思路</title>
    <link href="/2022/02/24/knowledge-graph/"/>
    <url>/2022/02/24/knowledge-graph/</url>
    
    <content type="html"><![CDATA[<h1 id="知识图谱"><a href="#知识图谱" class="headerlink" title="知识图谱"></a>知识图谱</h1><ol><li>众所周知，计算机的计算能力比人类强，但是推理能力远不如人类，所以构建知识图谱是为了解决计算机的推理能力。。</li><li>计算机的常识的使用能力也远不如人类，所以经常可以看到构建常识的知识图谱。</li><li>知识图谱在专业领域一般应用较多，例如医疗行业等。</li><li>知识图谱分为构建和应用，其中构建又包括设计本体，知识获取（结构化，非结构化，半结构化）知识存储，知识表示和知识融合等。如今构建知识图谱的技术已经很成熟，部分应用知识图谱的技术也已经成熟，例如利用知识图谱的问题等。</li></ol><img src="/2022/02/24/knowledge-graph/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png" class="">]]></content>
    
    
    <categories>
      
      <category>知识图谱</category>
      
    </categories>
    
    
    <tags>
      
      <tag>构建</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>torch和paddlepaddle的部分API对比</title>
    <link href="/2022/02/23/torch-paddle/"/>
    <url>/2022/02/23/torch-paddle/</url>
    
    <content type="html"><![CDATA[<h1 id="paddlepaddle代码和torch的模型代码相互转换-其实只需要关注这些api的不同，进行相应替换即可"><a href="#paddlepaddle代码和torch的模型代码相互转换-其实只需要关注这些api的不同，进行相应替换即可" class="headerlink" title="paddlepaddle代码和torch的模型代码相互转换, 其实只需要关注这些api的不同，进行相应替换即可"></a>paddlepaddle代码和torch的模型代码相互转换, 其实只需要关注这些api的不同，进行相应替换即可</h1><p>paddlepaddle 封装了类似torch， huggingface transformers 和datasets的接口形式</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-title">torch</span>包和paddle包的对比, 只列出不同的地方<br><span class="hljs-type">PyTorch</span> <span class="hljs-type">PaddlePaddle</span>    说明<br><span class="hljs-title">torch</span>.nn    paddle.nn   包括了神经网络相关的大部分函数<br><span class="hljs-title">nn</span>.<span class="hljs-type">Module</span>   nn.<span class="hljs-type">Layer</span>    搭建网络时集成的父类，包含了初始化等基本功能<br><span class="hljs-title">torch</span>.optim paddle.optimizer    训练优化器<br><span class="hljs-title">torch</span>.optim.<span class="hljs-type">AdamW</span>   paddle.optimizer.<span class="hljs-type">AdamW</span>  参数也不一样<br><span class="hljs-title">torchvision</span>.transforms  paddle.vision.transforms    数据预处理、图片处理<br><span class="hljs-title">torchvision</span>.datasets    paddle.vision.datasets  数据集的加载与处理<br><span class="hljs-title">nn</span>.<span class="hljs-type">Conv2d</span>   nn.<span class="hljs-type">Conv2D</span>   <span class="hljs-number">2</span>维卷积层<br><span class="hljs-title">nn</span>.<span class="hljs-type">BatchNorm2d</span>  nn.<span class="hljs-type">BatchNorm2D</span>  <span class="hljs-type">Batch</span> <span class="hljs-type">Normalization</span> 归一化<br><span class="hljs-title">nn</span>.<span class="hljs-type">MaxPool2d</span>    nn.<span class="hljs-type">MaxPool2D</span>    二维最大池化层<br><span class="hljs-title">nn</span>.<span class="hljs-type">AdaptiveAvgPool2d</span>    nn.<span class="hljs-type">AdaptiveAvgPool2D</span>    自适应二维平均池化（只用给定输出形状即可）<br><span class="hljs-title">torch</span>.flatten   paddle.flatten  展平处理<br><span class="hljs-title">torch</span>.softmax   paddle.softmax  softmax层<br><span class="hljs-title">datasets</span>.<span class="hljs-type">ImageFolder</span>    datasets.<span class="hljs-type">DatasetFolder</span>  指定数据集文件夹<br><span class="hljs-title">torch</span>.utils.<span class="hljs-class"><span class="hljs-keyword">data</span>.<span class="hljs-type">DataLoader</span> paddle.io.<span class="hljs-type">DataLoader</span>    加载数据集, 参数也不一样</span><br>(optimizer).no_grad (optimizer).zero_grad   梯度清零<br><span class="hljs-title">torch</span>.save  paddle.jit.save 说实话，这两个还是有点区别的，使用请看官方文档<br><span class="hljs-title">torch</span>.device    paddle.set_device   指定设备<br><span class="hljs-title">torch</span>.utils.<span class="hljs-class"><span class="hljs-keyword">data</span>.<span class="hljs-type">Dataset</span>    paddle.io.<span class="hljs-type">Dataset</span>   数据集</span><br><span class="hljs-title">torch</span>.utils.<span class="hljs-class"><span class="hljs-keyword">data</span>.<span class="hljs-type">RandomSampler</span>  paddle.io.<span class="hljs-type">RandomSampler</span></span><br><span class="hljs-title">torch</span>.utils.<span class="hljs-class"><span class="hljs-keyword">data</span>.<span class="hljs-type">BatchSampler</span>   paddle.io.<span class="hljs-type">BatchSampler</span>   参数也不一样</span><br><span class="hljs-title">torch</span>.utils.<span class="hljs-class"><span class="hljs-keyword">data</span>.<span class="hljs-type">DataLoader</span> paddle.io.<span class="hljs-type">DataLoader</span>  数据集加载</span><br><span class="hljs-title">tensor</span>.<span class="hljs-class"><span class="hljs-keyword">type</span>(<span class="hljs-title">torch</span>.<span class="hljs-title">float32</span>)  paddle.cast(<span class="hljs-title">mask</span>, &#x27;<span class="hljs-title">float32&#x27;</span>)  数据类型变更</span><br><span class="hljs-title">tensor</span>.cpu().item() tensor.numpy().item()  # 取出数据<br><span class="hljs-title">transformers</span>.get_linear_schedule_with_warmup    paddlenlp.transformers.<span class="hljs-type">LinearDecayWithWarmup</span>   # warmup 函数<br>也不一样<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>torch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>api</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>一个小的子列表位置查找函数</title>
    <link href="/2022/02/22/python-list/"/>
    <url>/2022/02/22/python-list/</url>
    
    <content type="html"><![CDATA[<h1 id="sublist是original列表中的一部分，即子列表，如果存在sublist，那么就返回起始和结束位置，否则返回None"><a href="#sublist是original列表中的一部分，即子列表，如果存在sublist，那么就返回起始和结束位置，否则返回None" class="headerlink" title="sublist是original列表中的一部分，即子列表，如果存在sublist，那么就返回起始和结束位置，否则返回None"></a>sublist是original列表中的一部分，即子列表，如果存在sublist，那么就返回起始和结束位置，否则返回None</h1><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs vim">def index_partof_list(original, sublist):<br>    <span class="hljs-string">&quot;&quot;</span><span class="hljs-comment">&quot;</span><br>    子列表查找, 也可以用于字符串的查找<br>    :param original: 一个列表<br>    :<span class="hljs-built_in">type</span> original:<br>    :param sublist: sublist是original列表中的一部分，即子列表，如果存在sublist，那么就返回起始和结束位置，否<br>则返回None<br>    :<span class="hljs-built_in">type</span> sublist:<br>    :<span class="hljs-keyword">return</span>: 返回<span class="hljs-number">2</span>个值，bool值和查找到的索引值，如果没查找到返回[] 如果找到一个或找到多个，返回 [(x1,y1),(x2,y2)]<br>    :rtype:<br>    <span class="hljs-string">&quot;&quot;</span><span class="hljs-comment">&quot;</span><br>    ori_len = <span class="hljs-built_in">len</span>(original)<br>    sub_len = <span class="hljs-built_in">len</span>(sublist)<br>    find_indexes = []<br>    <span class="hljs-keyword">if</span> ori_len &lt; sub_len:<br>        <span class="hljs-keyword">return</span> find_indexes<br>    <span class="hljs-keyword">for</span> <span class="hljs-built_in">index</span> in <span class="hljs-built_in">range</span>(ori_len-sub_len+<span class="hljs-number">1</span>):<br>        <span class="hljs-keyword">if</span> original[<span class="hljs-built_in">index</span>:<span class="hljs-built_in">index</span> + sub_len] == sublist:<br>            find_indexes.<span class="hljs-keyword">append</span>((<span class="hljs-built_in">index</span>, <span class="hljs-built_in">index</span>+ sub_len))<br>    <span class="hljs-keyword">return</span> find_indexes<br><br>ori = [<span class="hljs-string">&#x27;《&#x27;</span>, <span class="hljs-string">&#x27;邪&#x27;</span>, <span class="hljs-string">&#x27;少&#x27;</span>, <span class="hljs-string">&#x27;兵&#x27;</span>, <span class="hljs-string">&#x27;王&#x27;</span>, <span class="hljs-string">&#x27;》&#x27;</span>, <span class="hljs-string">&#x27;是&#x27;</span>, <span class="hljs-string">&#x27;冰&#x27;</span>, <span class="hljs-string">&#x27;火&#x27;</span>, <span class="hljs-string">&#x27;未&#x27;</span>, <span class="hljs-string">&#x27;央&#x27;</span>, <span class="hljs-string">&#x27;写&#x27;</span>, <span class="hljs-string">&#x27;的&#x27;</span>, <span class="hljs-string">&#x27;网&#x27;</span>, <span class="hljs-string">&#x27;络&#x27;</span>, <span class="hljs-string">&#x27;小&#x27;</span>, <span class="hljs-string">&#x27;说&#x27;</span>, <span class="hljs-string">&#x27;连&#x27;</span>, <span class="hljs-string">&#x27;载&#x27;</span>, <span class="hljs-string">&#x27;于&#x27;</span>, <span class="hljs-string">&#x27;旗&#x27;</span>, <span class="hljs-string">&#x27;峰&#x27;</span>, <span class="hljs-string">&#x27;天&#x27;</span>, <span class="hljs-string">&#x27;下&#x27;</span>]<br>sub = [<span class="hljs-string">&#x27;网&#x27;</span>, <span class="hljs-string">&#x27;络&#x27;</span>, <span class="hljs-string">&#x27;小&#x27;</span>, <span class="hljs-string">&#x27;说&#x27;</span>]<br><span class="hljs-keyword">res</span> = index_partof_list(ori,sub)<br><span class="hljs-keyword">print</span>(<span class="hljs-keyword">res</span>)<br>------&gt;<br>[(<span class="hljs-number">13</span>, <span class="hljs-number">17</span>)]<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>python</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>对存在过合并的excel的单元格进行处理</title>
    <link href="/2022/02/22/pandas-na/"/>
    <url>/2022/02/22/pandas-na/</url>
    
    <content type="html"><![CDATA[<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p>日常我们经常遇到表头是合并的单元格，如左侧表头，或者上测表头都是合并过的，而我们想读取使用pandas读取的excel后，每列都进行对应回原来的数据的结构，那么这时就需要进行填充了，因为读取后，只有合并的单元格的第一行或第一列是有值的，其它都是nan，我们需要用前向填充的方法，ffill()<br>示例如图:</p><img src="/2022/02/22/pandas-na/shili1.png" class=""><h1 id="填充代码，可以给定超参数，填充表头，按行和按列填充"><a href="#填充代码，可以给定超参数，填充表头，按行和按列填充" class="headerlink" title="填充代码，可以给定超参数，填充表头，按行和按列填充"></a>填充代码，可以给定超参数，填充表头，按行和按列填充</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">fill_pdna</span>(<span class="hljs-params">df, row=[], col=[]</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    当excel的表头的行或列有合并单元格的情况时，只有第一个单元格是正确的，值，这时候需要使用前向填充ffill，即使用上一个单元格的内容填充当前为nan的单元格</span><br><span class="hljs-string">    但是填充的时候一般进行限制，只填充表头的前几行，或前几列</span><br><span class="hljs-string">    :param df:</span><br><span class="hljs-string">    :type df:</span><br><span class="hljs-string">    :param row: [] 表示所有行都使用前面的值进行填充，1表示第一行, eg: [1,2] 表示第1，2行用前面的值填充,-1表示不填充</span><br><span class="hljs-string">    :param col: []表示，所有列都使用前面的值填充， 0表示第一列, 注意行和列的其实索引位置不一样, -1表示不填充</span><br><span class="hljs-string">    :return:</span><br><span class="hljs-string">    :rtype:</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 首先对行进行填充，填充哪些行</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> row:<br>        <span class="hljs-comment"># 如果为空，先按行进行填充，行空的时候使用前一个单元格填充</span><br>        df = df.ffill(axis=<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> col:<br>        <span class="hljs-comment"># 然后对列进行填充</span><br>        df = df.ffill(axis=<span class="hljs-number">0</span>)<br>    <span class="hljs-keyword">if</span> col <span class="hljs-keyword">and</span> col != [-<span class="hljs-number">1</span>]:<br>        <span class="hljs-keyword">for</span> col_num <span class="hljs-keyword">in</span> col:<br>            df[col_num] = df[col_num].ffill(axis=<span class="hljs-number">0</span>)<br>    <span class="hljs-keyword">if</span> row <span class="hljs-keyword">and</span> row != [-<span class="hljs-number">1</span>]:<br>        <span class="hljs-keyword">for</span> row_num <span class="hljs-keyword">in</span> row:<br>            df[:row_num] = df[:row_num].ffill(axis=<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> df<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">read_excel</span>(<span class="hljs-params">excel_file</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    读取excel内容</span><br><span class="hljs-string">    :param excel_file:</span><br><span class="hljs-string">    :type excel_file:</span><br><span class="hljs-string">    :return:</span><br><span class="hljs-string">    :rtype:</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;开始读取<span class="hljs-subst">&#123;excel_file&#125;</span>&quot;</span>)<br>    df = pd.read_excel(excel_file, header=<span class="hljs-literal">None</span>)<br>    newdf = fill_pdna(df, row=[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>], col=[<span class="hljs-number">0</span>])<br>    <span class="hljs-built_in">print</span>(newdf)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>python</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>shap值的探索，判断shap值是否符合基本单调递增</title>
    <link href="/2022/02/18/shap-explore2/"/>
    <url>/2022/02/18/shap-explore2/</url>
    
    <content type="html"><![CDATA[<h1 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h1><ol><li>构建一个模型，本示例用的XGBoost，然后构建shap解释模型，使用shap值对模型特征进行解释</li><li>按特征重要性，这里对应的是shap值的绝对值的均值，shap_values.abs.mean，进行排序</li><li>如果特征符合基本单调递增, 不一定是线性的，因为特征之间可能有相关性,打印对应shap值为0附近的原始特征数值，用原始特征的均值代替</li></ol><h1 id="意义"><a href="#意义" class="headerlink" title="意义"></a>意义</h1><p>我们构建的是一个客户满意度模型，使用的是用户对一个商品的整体满意度与商品的各个属性满意度之间的关系，我们想找出当每个属性的满意度达到多少时，才能对整体满意度产生影响，即各个属性满意度的理想值。</p><p>示例代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> xgboost<br><span class="hljs-keyword">import</span> shap<br><span class="hljs-keyword">import</span> pickle<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> matplotlib <span class="hljs-keyword">as</span> mpl<br>mpl.rcParams[<span class="hljs-string">&#x27;font.family&#x27;</span>] = [<span class="hljs-string">&#x27;SimHei&#x27;</span>]<br>mpl.rcParams[<span class="hljs-string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="hljs-literal">False</span><br><br>saved_file = <span class="hljs-string">&#x27;/tmp/adult.pkl&#x27;</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">dump_info</span>(<span class="hljs-params">data</span>):<br>    pickle.dump(data, <span class="hljs-built_in">open</span>(saved_file, <span class="hljs-string">&quot;wb&quot;</span>))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;保存成功&quot;</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_info</span>():<br>    data = pickle.load(<span class="hljs-built_in">open</span>(saved_file, <span class="hljs-string">&quot;rb&quot;</span>))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;加载成功&quot;</span>)<br>    <span class="hljs-keyword">return</span> data<br><br><span class="hljs-keyword">if</span> os.path.exists(saved_file):<br>    X,y = load_info()<br><span class="hljs-keyword">else</span>:<br>    X,y = shap.datasets.adult()<br>    dump_info(data=(X,y))<br>model = xgboost.XGBClassifier().fit(X, y)<br><br><span class="hljs-comment"># compute SHAP values</span><br>explainer = shap.Explainer(model, X)<br>shap_values = explainer(X)<br><span class="hljs-comment"># shap_values [num_samples, num_features]</span><br><span class="hljs-comment"># shap.plots.beeswarm(shap_values)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">find_closely_sublist</span>(<span class="hljs-params">src_list, percent=<span class="hljs-number">0.05</span>, des_num=<span class="hljs-number">0.3</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    找出src_list 中与des_num最接近的数字，找到总数量的为百分之percent</span><br><span class="hljs-string">    :param src_list:</span><br><span class="hljs-string">    :type src_list: list</span><br><span class="hljs-string">    :param percent:</span><br><span class="hljs-string">    :type percent:</span><br><span class="hljs-string">    :param des_num:</span><br><span class="hljs-string">    :type des_num:</span><br><span class="hljs-string">    :return: 返回百分之percent的数据的个数的列表，列表是src_list的子列表</span><br><span class="hljs-string">    :rtype:</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 取值为0范围的%5的数</span><br>    total_num = <span class="hljs-built_in">len</span>(src_list)<br>    got_num = <span class="hljs-built_in">int</span>(total_num * percent)<br>    left_num = right_num = <span class="hljs-built_in">int</span>(got_num/<span class="hljs-number">2</span>)<br>    sorted_l = <span class="hljs-built_in">sorted</span>(src_list)<br>    <span class="hljs-comment">#定位与0最接近的位置的索引</span><br>    min_closest_idx = <span class="hljs-number">0</span><br>    min_closed_distance = <span class="hljs-number">100000</span><br>    <span class="hljs-keyword">for</span> idx, i <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(sorted_l):<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">abs</span>(i - des_num) &lt; min_closed_distance:<br>            min_closed_distance = <span class="hljs-built_in">abs</span>(i - des_num)<br>            min_closest_idx = idx<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;最接近于<span class="hljs-subst">&#123;des_num&#125;</span>的数字是<span class="hljs-subst">&#123;sorted_l[min_closest_idx]&#125;</span>&quot;</span>)<br>    start_idx = min_closest_idx - left_num<br>    <span class="hljs-keyword">if</span> start_idx &lt; <span class="hljs-number">0</span>:<br>        start_idx = <span class="hljs-number">0</span><br>    end_idx = min_closest_idx + right_num<br>    sublist = sorted_l[start_idx:end_idx]<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;收集接近于目标值<span class="hljs-subst">&#123;des_num&#125;</span>, 总数据条数:<span class="hljs-subst">&#123;total_num&#125;</span>, 收集占比为<span class="hljs-subst">&#123;percent&#125;</span>,共收集到数据条数: <span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(sublist)&#125;</span>条，分别是: <span class="hljs-subst">&#123;sublist&#125;</span>&quot;</span>)<br>    <span class="hljs-keyword">return</span> sublist<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_middle_data</span>(<span class="hljs-params">mean_shape</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    根据给定的shap，获取shap值为0时，原始data的值，因为有的值不是单递增的，还要判断是否是单调递增的， 统计的方法判断</span><br><span class="hljs-string">    根据均值和中位数，判断是否是单调递增的，大部分不是线性递增的</span><br><span class="hljs-string">    :param mean_shape:</span><br><span class="hljs-string">    :type mean_shape:</span><br><span class="hljs-string">    :return:</span><br><span class="hljs-string">    :rtype:</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    feature_name = mean_shape.feature_names<br>    shape_value = mean_shape.values<br>    feature_data = mean_shape.data<br>    <span class="hljs-comment"># 按大小排序</span><br>    sort_shap = np.sort(shape_value)<br>    sort_shap = sort_shap.tolist()<br>    <span class="hljs-comment"># 最接近0的shap值，大概5%</span><br>    sublist = find_closely_sublist(src_list=sort_shap,percent=<span class="hljs-number">0.05</span>, des_num=<span class="hljs-number">0</span>)<br>    <span class="hljs-comment"># 取0轴为的5%的数</span><br>    start_threhold, end_threhold = <span class="hljs-built_in">min</span>(sublist), <span class="hljs-built_in">max</span>(sublist)<br>    zero_range_shap_idx = np.where((shape_value &gt;= start_threhold) &amp; (shape_value &lt;= end_threhold))<br>    <span class="hljs-comment">#判断是否单调的问题，大部分shap值小于zero附近shap的，它对应的原始特征数也小于，shap值大于zero附近的，它的原始特征对应的数据也大于zero的原始特征，咱们都用平均值和中位数2个结合判断</span><br>    zero_range_data = feature_data[zero_range_shap_idx]<br>    zero_data_mean = np.mean(zero_range_data)<br>    zero_data_median = np.median(zero_range_data)<br>    less_zero_shap_idx = np.where(shape_value &lt; start_threhold)<br>    biger_zero_shap_idx = np.where(shape_value &gt; end_threhold)<br>    less_zero_data = feature_data[less_zero_shap_idx]<br>    biger_zero_data = feature_data[biger_zero_shap_idx]<br>    less_zero_mean = np.mean(less_zero_data)<br>    less_zero_median = np.median(less_zero_data)<br>    biger_zero_mean = np.mean(biger_zero_data)<br>    biger_zero_median = np.median(biger_zero_data)<br>    <span class="hljs-keyword">if</span> less_zero_mean &lt; zero_data_mean &lt; biger_zero_mean <span class="hljs-keyword">and</span> less_zero_median &lt; zero_data_median &lt; biger_zero_median:<br>        <span class="hljs-comment">#基本上是单调递增的，那么返回0的附近的对应的原始数据的均值, 即zero_data_mean</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span>, zero_data_mean, feature_name<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span>, <span class="hljs-number">0</span>, feature_name<br><br><span class="hljs-comment"># 打印前10个特征，按照shap值的重要性排序</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">10</span>, <span class="hljs-number">1</span>):<br>    mean_shape = shap_values[:, shap_values.<span class="hljs-built_in">abs</span>.mean(<span class="hljs-number">0</span>).argsort[-i]]<br>    is_monotone, middle_data, feature_name = get_middle_data(mean_shape)<br>    fig = plt.gcf()<br>    fig.set_size_inches(<span class="hljs-number">18.5</span>, <span class="hljs-number">10.5</span>, forward=<span class="hljs-literal">True</span>)<br>    ax = fig.gca()<br>    <span class="hljs-keyword">if</span> is_monotone:<br>        title = <span class="hljs-string">f&quot;特征<span class="hljs-subst">&#123;i&#125;</span>_<span class="hljs-subst">&#123;feature_name&#125;</span>是基本上是单调递增的，对应的shap值0附近的原始特征数据均值值是:<span class="hljs-subst">&#123;middle_data&#125;</span>&quot;</span><br>    <span class="hljs-keyword">else</span>:<br>        title = <span class="hljs-string">f&quot;特征<span class="hljs-subst">&#123;i&#125;</span>_<span class="hljs-subst">&#123;feature_name&#125;</span>不是单调递增的&quot;</span><br>    ax.set_title(title)<br>    shap.plots.scatter(shap_values = mean_shape, ax=ax)<br></code></pre></td></tr></table></figure><h1 id="绘图结果，按照特征重要性进行的排序"><a href="#绘图结果，按照特征重要性进行的排序" class="headerlink" title="绘图结果，按照特征重要性进行的排序"></a>绘图结果，按照特征重要性进行的排序</h1><img src="/2022/02/18/shap-explore2/shap1.png" class=""><img src="/2022/02/18/shap-explore2/shap2.png" class=""><img src="/2022/02/18/shap-explore2/shap3.png" class=""><img src="/2022/02/18/shap-explore2/shap4.png" class=""><img src="/2022/02/18/shap-explore2/shap5.png" class=""><img src="/2022/02/18/shap-explore2/shap6.png" class=""><img src="/2022/02/18/shap-explore2/shap7.png" class=""><img src="/2022/02/18/shap-explore2/shap8.png" class=""><img src="/2022/02/18/shap-explore2/shap9.png" class="">]]></content>
    
    
    <categories>
      
      <category>模型</category>
      
    </categories>
    
    
    <tags>
      
      <tag>可解释性</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
