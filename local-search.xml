<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>满意度预测模型</title>
    <link href="/2022/07/04/%E6%BB%A1%E6%84%8F%E5%BA%A6%E9%A2%84%E6%B5%8B%E6%A8%A1%E5%9E%8B/"/>
    <url>/2022/07/04/%E6%BB%A1%E6%84%8F%E5%BA%A6%E9%A2%84%E6%B5%8B%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="参加公众号原文"><a href="#参加公众号原文" class="headerlink" title="参加公众号原文"></a>参加公众号原文</h1><p><a href="https://mp.weixin.qq.com/s/IHcioj1-i0HzloSQ3gu7tw">https://mp.weixin.qq.com/s/IHcioj1-i0HzloSQ3gu7tw</a></p><h1 id="实现意义"><a href="#实现意义" class="headerlink" title="实现意义"></a>实现意义</h1><p>结果： 应该把提升用户满意度的钱花在哪个方面，即产品的哪个属性上，然后再哪个属性上应该提升多少，为提升客户对某产品的整体满意度，对用户评论进行分析，判断出用户对产品的哪些属性的满意度较差，提升哪些属性的产品满意度，能显著影响产品的整体满意度。</p><h1 id="实现思路"><a href="#实现思路" class="headerlink" title="实现思路"></a>实现思路</h1><p>主要分为4个模型</p><h2 id="Aspect情感模型"><a href="#Aspect情感模型" class="headerlink" title="Aspect情感模型"></a>Aspect情感模型</h2><p>预测属性词在句子中的情感, 标签:积极，消极，中性</p><h2 id="整体情感模型"><a href="#整体情感模型" class="headerlink" title="整体情感模型"></a>整体情感模型</h2><p>表达对这个产品的整体情感， 标签:整体积极，整体消极，整体中性，无整体情感<br>   eg: 东西还不错，就是洗了脸有点干干的，也洗的很干净</p><h2 id="贡献度模型"><a href="#贡献度模型" class="headerlink" title="贡献度模型"></a>贡献度模型</h2><p>预测每个aspect对整体情感的贡献度,使用普通线性回归模型，决策树和集成学习模型，深度学习模型分别进行实验<br>线性回归模型<br>    普通线性回归模型<br>    LASSO回归<br>    Ridge回归<br>    ElasticNet<br>    多项式回归<br>    Bayesian回归<br>    Bayesian ARD回归<br>    主成分回归<br>    偏最小二乘回归</p><p>决策树和集成学习模型： 使用特征重要性作为系数, feature_importance_<br>        Decision Tree<br>        Random Forest<br>        GradientBoosting<br>        AdaBoost<br>        XGBRegressor<br>        LightGBM<br>深度学习</p><h2 id="模型的可解释性"><a href="#模型的可解释性" class="headerlink" title="模型的可解释性"></a>模型的可解释性</h2><p>基于shapley值的可解释性，探讨属性的重要程度<br>特征重要性<br>    SHAP的特征重要性是shapley值的大小，或这说绝对值的大小，0表示这个特征可有可无，因为是加性归因，shapley值的特征重要性是累加思想，即每个特征的重要性是可以累加的。<br>        Shapley值是从整体考虑的特征重要性<br>    而原始的XGBoost树模型的特征重要性，是来自该特征在所有树的节点分割中使用的平均增益, 平均增益越大，那么就越重要<br>        表明每个特征在模型内构建提升决策树时的有用性或价值。一个属性特征越是用于决策树的关键决策，其相对重要性就越高<br>        重要性是通过每个属性分割点提高性能指标的量来计算的，性能指标衡量分割点“纯度”，例如信息增益<br>        集成树模型是从局部考虑特征重要性，然后做的加权平均</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>PCA和xlstat</title>
    <link href="/2022/06/24/PCA%E5%92%8Cxlstat/"/>
    <url>/2022/06/24/PCA%E5%92%8Cxlstat/</url>
    
    <content type="html"><![CDATA[<h1 id="PCA和xlsxstat分析"><a href="#PCA和xlsxstat分析" class="headerlink" title="PCA和xlsxstat分析"></a>PCA和xlsxstat分析</h1><img src="/2022/06/24/PCA%E5%92%8Cxlstat/PCA%E5%92%8Cxlstat.png" class="">]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>torch版本和随机数</title>
    <link href="/2022/04/14/torch%E7%89%88%E6%9C%AC%E5%92%8C%E9%9A%8F%E6%9C%BA%E6%95%B0/"/>
    <url>/2022/04/14/torch%E7%89%88%E6%9C%AC%E5%92%8C%E9%9A%8F%E6%9C%BA%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="在不同的PyTorch版本或不同的平台上，不保证完全可重复的结果。此外，即使使用相同的种子，在CPU和GPU的执行中，结果也可能无法重现。"><a href="#在不同的PyTorch版本或不同的平台上，不保证完全可重复的结果。此外，即使使用相同的种子，在CPU和GPU的执行中，结果也可能无法重现。" class="headerlink" title="在不同的PyTorch版本或不同的平台上，不保证完全可重复的结果。此外，即使使用相同的种子，在CPU和GPU的执行中，结果也可能无法重现。"></a>在不同的PyTorch版本或不同的平台上，不保证完全可重复的结果。此外，即使使用相同的种子，在CPU和GPU的执行中，结果也可能无法重现。</h1><p>以下在6台机器上实验，不设置随机数种子, 有的机器是torch相同的版本，有的不是,对比预测的logits分数和最终的预测结果。测试的是情感模型的预测结果.<br>不同的torch版本，也会导致预测有一些差异，但是差异很小，预测的分数有14%的差异，但是数千条数据，预测的结果只有一条有差异</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">w69</span> | CHANGED | rc=<span class="hljs-number">0</span> &gt;&gt;<br><span class="hljs-attribute">torch</span>==<span class="hljs-number">1</span>.<span class="hljs-number">8</span>.<span class="hljs-number">1</span><br><br><span class="hljs-attribute">w79</span> | CHANGED | rc=<span class="hljs-number">0</span> &gt;&gt;<br><span class="hljs-attribute">torch</span>==<span class="hljs-number">1</span>.<span class="hljs-number">8</span>.<span class="hljs-number">1</span><br><br><span class="hljs-attribute">w19</span> | CHANGED | rc=<span class="hljs-number">0</span> &gt;&gt;<br><span class="hljs-attribute">torch</span>==<span class="hljs-number">1</span>.<span class="hljs-number">8</span>.<span class="hljs-number">1</span><br><br><span class="hljs-attribute">w39</span> | CHANGED | rc=<span class="hljs-number">0</span> &gt;&gt;<br><span class="hljs-attribute">torch</span>==<span class="hljs-number">1</span>.<span class="hljs-number">7</span>.<span class="hljs-number">0</span>+cu110<br><br><span class="hljs-attribute">w09</span> | CHANGED | rc=<span class="hljs-number">0</span> &gt;&gt;<br><span class="hljs-attribute">torch</span>==<span class="hljs-number">1</span>.<span class="hljs-number">9</span>.<span class="hljs-number">0</span>+cu111<br><br><span class="hljs-attribute">w89</span> | CHANGED | rc=<span class="hljs-number">0</span> &gt;&gt;<br><span class="hljs-attribute">torch</span>==<span class="hljs-number">1</span>.<span class="hljs-number">9</span>.<span class="hljs-number">0</span>+cu111<br><br><span class="hljs-attribute">w99</span> | CHANGED | rc=<span class="hljs-number">0</span> &gt;&gt;<br><span class="hljs-attribute">torch</span>==<span class="hljs-number">1</span>.<span class="hljs-number">9</span>.<span class="hljs-number">0</span><br></code></pre></td></tr></table></figure><p>预测结果如下：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs stylus">主机<span class="hljs-number">19</span>的结果保存到: <span class="hljs-number">19</span>_result<span class="hljs-selector-class">.xlsx</span>, 标签占比是<span class="hljs-built_in">Counter</span>(&#123;<span class="hljs-string">&#x27;积极&#x27;</span>: <span class="hljs-number">351</span>, <span class="hljs-string">&#x27;中性&#x27;</span>: <span class="hljs-number">109</span>, <span class="hljs-string">&#x27;消极&#x27;</span>: <span class="hljs-number">40</span>&#125;)<br>主机<span class="hljs-number">39</span>的结果保存到: <span class="hljs-number">39</span>_result<span class="hljs-selector-class">.xlsx</span>, 标签占比是<span class="hljs-built_in">Counter</span>(&#123;<span class="hljs-string">&#x27;积极&#x27;</span>: <span class="hljs-number">351</span>, <span class="hljs-string">&#x27;中性&#x27;</span>: <span class="hljs-number">109</span>, <span class="hljs-string">&#x27;消极&#x27;</span>: <span class="hljs-number">40</span>&#125;)<br>主机<span class="hljs-number">69</span>的结果保存到: <span class="hljs-number">69</span>_result<span class="hljs-selector-class">.xlsx</span>, 标签占比是<span class="hljs-built_in">Counter</span>(&#123;<span class="hljs-string">&#x27;积极&#x27;</span>: <span class="hljs-number">351</span>, <span class="hljs-string">&#x27;中性&#x27;</span>: <span class="hljs-number">109</span>, <span class="hljs-string">&#x27;消极&#x27;</span>: <span class="hljs-number">40</span>&#125;)<br>主机<span class="hljs-number">79</span>的结果保存到: <span class="hljs-number">79</span>_result<span class="hljs-selector-class">.xlsx</span>, 标签占比是<span class="hljs-built_in">Counter</span>(&#123;<span class="hljs-string">&#x27;积极&#x27;</span>: <span class="hljs-number">351</span>, <span class="hljs-string">&#x27;中性&#x27;</span>: <span class="hljs-number">109</span>, <span class="hljs-string">&#x27;消极&#x27;</span>: <span class="hljs-number">40</span>&#125;)<br>主机<span class="hljs-number">89</span>的结果保存到: <span class="hljs-number">89</span>_result<span class="hljs-selector-class">.xlsx</span>, 标签占比是<span class="hljs-built_in">Counter</span>(&#123;<span class="hljs-string">&#x27;积极&#x27;</span>: <span class="hljs-number">352</span>, <span class="hljs-string">&#x27;中性&#x27;</span>: <span class="hljs-number">109</span>, <span class="hljs-string">&#x27;消极&#x27;</span>: <span class="hljs-number">39</span>&#125;)<br>主机<span class="hljs-number">09</span>的结果保存到: <span class="hljs-number">09</span>_result<span class="hljs-selector-class">.xlsx</span>, 标签占比是<span class="hljs-built_in">Counter</span>(&#123;<span class="hljs-string">&#x27;积极&#x27;</span>: <span class="hljs-number">352</span>, <span class="hljs-string">&#x27;中性&#x27;</span>: <span class="hljs-number">109</span>, <span class="hljs-string">&#x27;消极&#x27;</span>: <span class="hljs-number">39</span>&#125;)<br></code></pre></td></tr></table></figure><h1 id="对比预测结果和logits"><a href="#对比预测结果和logits" class="headerlink" title="对比预测结果和logits"></a>对比预测结果和logits</h1><p>相同的torch版本，预测结果相同</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">diff <span class="hljs-number">09</span>_result<span class="hljs-selector-class">.xlsx</span><span class="hljs-selector-class">.json</span> <span class="hljs-number">89</span>_result<span class="hljs-selector-class">.xlsx</span>.json<br></code></pre></td></tr></table></figure><p>不同的torch版本，预测结果不同</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">diff -<span class="hljs-selector-tag">q</span> <span class="hljs-number">09</span>_result<span class="hljs-selector-class">.xlsx</span><span class="hljs-selector-class">.json</span> <span class="hljs-number">19</span>_result<span class="hljs-selector-class">.xlsx</span><span class="hljs-selector-class">.json</span><br>Files <span class="hljs-number">09</span>_result<span class="hljs-selector-class">.xlsx</span><span class="hljs-selector-class">.json</span> and <span class="hljs-number">19</span>_result<span class="hljs-selector-class">.xlsx</span><span class="hljs-selector-class">.json</span> differ<br></code></pre></td></tr></table></figure><h1 id="所以我们在复现实验的时候，最好设定随机数种子-例如"><a href="#所以我们在复现实验的时候，最好设定随机数种子-例如" class="headerlink" title="所以我们在复现实验的时候，最好设定随机数种子, 例如"></a>所以我们在复现实验的时候，最好设定随机数种子, 例如</h1><p>设置random_seed</p><figure class="highlight monkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs monkey"><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> numpy as np<br><span class="hljs-built_in">seed</span>=<span class="hljs-number">100</span><span class="hljs-meta"></span><br><span class="hljs-meta"># torch的随机数种子固定，torch.manual_seed已经是支持CPU和GPU了，不需要设置这个torch.cuda.manual_seed_all了</span><br>torch.manual_seed(<span class="hljs-built_in">seed</span>)<span class="hljs-meta"></span><br><span class="hljs-meta"># numpy的随机数种子</span><br>np.random.<span class="hljs-built_in">seed</span>(<span class="hljs-built_in">seed</span>)<span class="hljs-meta"></span><br><span class="hljs-meta"># python的随机数种子</span><br>random.<span class="hljs-built_in">seed</span>(<span class="hljs-built_in">seed</span>)<span class="hljs-meta"></span><br><span class="hljs-meta"># cuDNN的保证每次实验使用相同的算法</span><br>torch.backends.cudnn.benchmark = <span class="hljs-literal">False</span><span class="hljs-meta">   # 如果改为True，表示速度提升，但是不是同一算法</span><span class="hljs-meta"></span><br><span class="hljs-meta"># 保证每个算法的确定性</span><br>torch.backends.cudnn.deterministic = <span class="hljs-literal">True</span> 或torch.use_deterministic_algorithms(<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>torch</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>apex报错</title>
    <link href="/2022/04/12/apex%E6%8A%A5%E9%94%99/"/>
    <url>/2022/04/12/apex%E6%8A%A5%E9%94%99/</url>
    
    <content type="html"><![CDATA[<h1 id="apex-报错"><a href="#apex-报错" class="headerlink" title="apex 报错"></a>apex 报错</h1><p>当使用pytorch_transformers时，遇到报错如下<br>ModuleNotFoundError: No module named ‘fused_layer_norm_cuda’</p><h1 id="解决方式"><a href="#解决方式" class="headerlink" title="解决方式"></a>解决方式</h1><p>手动编译安装apex</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli">git clone https:<span class="hljs-string">//github.com/NVIDIA/apex</span><br><span class="hljs-keyword">cd</span> apex<br>CUDA_HOME=<span class="hljs-string">/usr/local/cuda-11.2</span> pip install -v <span class="hljs-params">--no-cache-dir</span> <span class="hljs-params">--global-option=</span><span class="hljs-string">&quot;--cpp_ext&quot;</span> <span class="hljs-params">--global-option=</span><span class="hljs-string">&quot;--cuda_ext&quot;</span> <span class="hljs-string">./</span><br></code></pre></td></tr></table></figure><h1 id="安装时对不同的cuda版本的需求会导致apex报错"><a href="#安装时对不同的cuda版本的需求会导致apex报错" class="headerlink" title="安装时对不同的cuda版本的需求会导致apex报错"></a>安装时对不同的cuda版本的需求会导致apex报错</h1><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs awk">    Traceback (most recent call last):<br>      File <span class="hljs-string">&quot;&lt;string&gt;&quot;</span>, line <span class="hljs-number">1</span>, <span class="hljs-keyword">in</span> &lt;module&gt;<br>      File <span class="hljs-string">&quot;/media/backup/john/project/apex/setup.py&quot;</span>, line <span class="hljs-number">177</span>, <span class="hljs-keyword">in</span> &lt;module&gt;<br>        check_cuda_torch_binary_vs_bare_metal(CUDA_HOME)<br>      File <span class="hljs-string">&quot;/media/backup/john/project/apex/setup.py&quot;</span>, line <span class="hljs-number">34</span>, <span class="hljs-keyword">in</span> check_cuda_torch_binary_vs_bare_metal<br>        raise RuntimeError(<br>    RuntimeError: Cuda extensions are being compiled with a version of Cuda that does not match the version used to compile Pytorch binaries.  Pytorch binaries were compiled with Cuda <span class="hljs-number">11.3</span>.<br>    In some cases, a minor-version mismatch will not cause later errors:  https:<span class="hljs-regexp">//gi</span>thub.com<span class="hljs-regexp">/NVIDIA/</span>apex<span class="hljs-regexp">/pull/</span><span class="hljs-number">323</span><span class="hljs-comment">#discussion_r287021798.  You can try commenting out this check (at your own risk).</span><br>ERROR: Command errored out with <span class="hljs-keyword">exit</span> status <span class="hljs-number">1</span>: <span class="hljs-regexp">/home/</span>anaconda3<span class="hljs-regexp">/envs/</span>py38<span class="hljs-regexp">/bin/</span>python -u -c <span class="hljs-string">&#x27;import io, os, sys, setuptools, tokenize; sys.argv[0] = &#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;/media//john/project/apex/setup.py&#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;; __file__=&#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;/media//john/project/apex/setup.py&#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;;f = getattr(tokenize, &#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;open&#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;, open)(__file__) if os.path.exists(__file__) else io.StringIO(&#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;from setuptools import setup; setup()&#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;);code = f.read().replace(&#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;\r\n&#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;, &#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;\n&#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;);f.close();exec(compile(code, __file__, &#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;exec&#x27;</span><span class="hljs-string">&quot;&#x27;&quot;</span><span class="hljs-string">&#x27;))&#x27;</span> --cpp_ext --cuda_ext install --record <span class="hljs-regexp">/tmp/</span>pip-record-rw1s_hs_<span class="hljs-regexp">/install-record.txt --single-version-externally-managed --compile --install-headers /</span>home<span class="hljs-regexp">//</span>anaconda3<span class="hljs-regexp">/envs/</span>py38<span class="hljs-regexp">/include/</span>python3.<span class="hljs-number">8</span>/apex Check the logs <span class="hljs-keyword">for</span> full command output.<br></code></pre></td></tr></table></figure><p>解决方式，注销掉检查cuda版本的语句即可，例如根据提示，注销掉setup.py的177行，检查cuda版本的句子, 重新编译安装即可</p>]]></content>
    
    
    <categories>
      
      <category>apex</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>neo4j的构建的知识图谱的语法示例</title>
    <link href="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/"/>
    <url>/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="查询包含甘油的产品"><a href="#查询包含甘油的产品" class="headerlink" title="查询包含甘油的产品"></a>查询包含甘油的产品</h1><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">MATCH p=()-[r:PRODUCT_COMPONENT_IS] -&gt;(n:Component &#123;<span class="hljs-type">name</span>:&quot;甘油&quot;&#125;) <span class="hljs-keyword">return</span> p <span class="hljs-keyword">limit</span> <span class="hljs-number">50</span><br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/gan.png" class=""><p>#查看2个品牌之间有什么共同点</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs stylus">MATCH<br>(n:Brand &#123;name:<span class="hljs-string">&quot;希思黎&quot;</span>&#125;), (<span class="hljs-selector-tag">b</span>:Brand &#123;name:<span class="hljs-string">&#x27;欧莱雅&#x27;</span>&#125;), <span class="hljs-selector-tag">p</span> = <span class="hljs-built_in">allShortestPaths</span>((n)-<span class="hljs-selector-attr">[*]</span><span class="hljs-built_in">-</span>(b))<br>RETURN <span class="hljs-selector-tag">p</span> <br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/pin.png" class=""><h1 id="法国品牌"><a href="#法国品牌" class="headerlink" title="法国品牌"></a>法国品牌</h1><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">MATCH p=()-[r:BRAND_COUNTRY_IS]-&gt;(c:Country &#123;<span class="hljs-type">name</span>:&quot;法国&quot;&#125;) <span class="hljs-keyword">RETURN</span> p <span class="hljs-keyword">LIMIT</span> <span class="hljs-number">25</span><br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/fa.png" class=""><h1 id="collect-统计-各个品牌关于手部护理的产品的价格统计"><a href="#collect-统计-各个品牌关于手部护理的产品的价格统计" class="headerlink" title="collect 统计, 各个品牌关于手部护理的产品的价格统计"></a>collect 统计, 各个品牌关于手部护理的产品的价格统计</h1><figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs livescript">MATCH <span class="hljs-function"><span class="hljs-params">(:ProductCategory &#123;name:<span class="hljs-string">&quot;手部护理&quot;</span>&#125;)</span>--&gt;</span><span class="hljs-function"><span class="hljs-params">(:ProductCategory)</span>&lt;--<span class="hljs-params">(p:Product)</span>--&gt;</span>(b:Brand)<br>RETURN b.name <span class="hljs-keyword">as</span> Brand, collect(distinct p.price) <span class="hljs-keyword">as</span> Price<br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/price.png" class=""><h1 id="价格在200-300之间"><a href="#价格在200-300之间" class="headerlink" title="价格在200-300之间"></a>价格在200-300之间</h1><figure class="highlight fortran"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs fortran">MATCH (n:<span class="hljs-built_in">Product</span>) <span class="hljs-keyword">WHERE</span> n.price &gt;= <span class="hljs-number">200</span> AND n.price &lt; <span class="hljs-number">300</span> <span class="hljs-keyword">RETURN</span> n<br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/pris.png" class=""><h1 id="欧莱雅商品"><a href="#欧莱雅商品" class="headerlink" title="欧莱雅商品"></a>欧莱雅商品</h1><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs css">MATCH (n:Brand &#123;name:<span class="hljs-string">&quot;欧莱雅&quot;</span>&#125;) &lt;-<span class="hljs-selector-attr">[:PRODUCT_BRAND_IS]</span>-(<span class="hljs-selector-tag">p</span>) RETURN n,<span class="hljs-selector-tag">p</span> LIMIT <span class="hljs-number">25</span><br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/ou.png" class=""><h1 id="同样功效的产品"><a href="#同样功效的产品" class="headerlink" title="同样功效的产品"></a>同样功效的产品</h1><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs css">MATCH (n:Product &#123;name:<span class="hljs-string">&quot;欧莱雅强韧柔顺洗发露&quot;</span>&#125;)-<span class="hljs-selector-attr">[:PRODUCT_EFFECT_IS]</span>-&gt;(m)&lt;-<span class="hljs-selector-attr">[:PRODUCT_EFFECT_IS]</span>-(<span class="hljs-selector-tag">p</span>) RETURN n,<span class="hljs-selector-tag">p</span><br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/same.png" class=""><h1 id="同样功效，价格便宜"><a href="#同样功效，价格便宜" class="headerlink" title="同样功效，价格便宜"></a>同样功效，价格便宜</h1><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs css">MATCH (n:Product &#123;name:<span class="hljs-string">&quot;倩碧水嫩保湿水精萃&quot;</span>&#125;)-<span class="hljs-selector-attr">[:PRODUCT_EFFECT_IS]</span>-&gt;(m)&lt;-<span class="hljs-selector-attr">[:PRODUCT_EFFECT_IS]</span>-(<span class="hljs-selector-tag">p</span>) WHERE <span class="hljs-selector-tag">p</span><span class="hljs-selector-class">.price</span> &lt;n<span class="hljs-selector-class">.price</span> RETURN n,<span class="hljs-selector-tag">p</span> Limit <span class="hljs-number">10</span><br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/smae.png" class=""><h1 id="希思黎生产过哪些类型产品"><a href="#希思黎生产过哪些类型产品" class="headerlink" title="希思黎生产过哪些类型产品"></a>希思黎生产过哪些类型产品</h1><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs lisp">MATCH (<span class="hljs-name">c</span><span class="hljs-symbol">:Brand</span> &#123;name:<span class="hljs-string">&quot;希思黎&quot;</span>&#125;)&lt;--(<span class="hljs-symbol">:Product</span>)--&gt;(<span class="hljs-name">s</span><span class="hljs-symbol">:ProductCategory</span>)<br>RETURN DISTINCT s<br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/xisi.png" class=""><h1 id="小众品牌"><a href="#小众品牌" class="headerlink" title="小众品牌"></a>小众品牌</h1><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">MATCH p=()-[r:BRAND_POPULARITY_IS]-&gt;(b:BrandPopularity &#123;<span class="hljs-type">name</span>:&quot;小众&quot;&#125;) <span class="hljs-keyword">RETURN</span> p <span class="hljs-keyword">LIMIT</span> <span class="hljs-number">25</span><br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/xiaozhong.png" class=""><h1 id="找2个产品2跳以内的共同点"><a href="#找2个产品2跳以内的共同点" class="headerlink" title="找2个产品2跳以内的共同点"></a>找2个产品2跳以内的共同点</h1><figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs excel"><span class="hljs-built_in">MATCH</span> p=(<br>(<span class="hljs-symbol">n:Pr</span>oduct &#123;<span class="hljs-built_in">na</span><span class="hljs-symbol">me:</span><span class="hljs-string">&quot;倩碧水嫩保湿水精萃&quot;</span>&#125;)-[*<span class="hljs-number">1</span>..<span class="hljs-number">2</span>]-(<span class="hljs-symbol">m:Pr</span>oduct &#123;<span class="hljs-built_in">na</span><span class="hljs-symbol">me:</span><span class="hljs-string">&quot;蒂迩肌男士水油平衡洁面泡沫&quot;</span>&#125;)<br>)<br>RETURN p<br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/liangtiao.png" class=""><h1 id="找2个产品的一个共同点"><a href="#找2个产品的一个共同点" class="headerlink" title="找2个产品的一个共同点"></a>找2个产品的一个共同点</h1><figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs excel"><span class="hljs-built_in">MATCH</span> p=shortestPath(<br>(<span class="hljs-symbol">n:Pr</span>oduct &#123;<span class="hljs-built_in">na</span><span class="hljs-symbol">me:</span><span class="hljs-string">&quot;倩碧水嫩保湿水精萃&quot;</span>&#125;)-[*]-(<span class="hljs-symbol">m:Pr</span>oduct &#123;<span class="hljs-built_in">na</span><span class="hljs-symbol">me:</span><span class="hljs-string">&quot;蒂迩肌男士水油平衡洁面泡沫&quot;</span>&#125;)<br>)<br>RETURN p<br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/yige.png" class=""><h1 id="总产品数"><a href="#总产品数" class="headerlink" title="总产品数"></a>总产品数</h1><figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs excel"><span class="hljs-built_in">MATCH</span> (<span class="hljs-symbol">n:Pr</span>oduct)<br>RETURN <span class="hljs-built_in">count</span>(<span class="hljs-built_in">n</span>)<br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/az.png" class=""><h1 id="总成分数"><a href="#总成分数" class="headerlink" title="总成分数"></a>总成分数</h1><figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs excel"><span class="hljs-built_in">MATCH</span> (<span class="hljs-symbol">n:Co</span>mponent)<br>RETURN <span class="hljs-built_in">count</span>(<span class="hljs-built_in">n</span>)<br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/chf.png" class=""><h1 id="meta-graph，元图"><a href="#meta-graph，元图" class="headerlink" title="meta-graph，元图"></a>meta-graph，元图</h1><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">CALL</span> db.<span class="hljs-keyword">schema</span>.visualization()<br></code></pre></td></tr></table></figure><img src="/2022/03/15/neo4j%E7%9A%84%E6%9E%84%E5%BB%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B/zitu.png" class="">]]></content>
    
    
    <categories>
      
      <category>知识图谱</category>
      
    </categories>
    
    
    <tags>
      
      <tag>cql语法</tag>
      
      <tag>neo4j</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ubuntu20.04的Realtek网卡驱动安装</title>
    <link href="/2022/03/14/ubuntu20-04%E7%9A%84Realtek%E7%BD%91%E5%8D%A1%E9%A9%B1%E5%8A%A8%E5%AE%89%E8%A3%85/"/>
    <url>/2022/03/14/ubuntu20-04%E7%9A%84Realtek%E7%BD%91%E5%8D%A1%E9%A9%B1%E5%8A%A8%E5%AE%89%E8%A3%85/</url>
    
    <content type="html"><![CDATA[<h1 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h1><p>ubuntu的20.04版本对部分网卡的驱动没有默认集成，需要手动安装, 记录下安装流程</p><h2 id="查看网卡型号"><a href="#查看网卡型号" class="headerlink" title="查看网卡型号"></a>查看网卡型号</h2><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs dts">sudo lshw -C network<br>  *-network                 <br><span class="hljs-symbol">       description:</span> Ethernet interface<br><span class="hljs-symbol">       product:</span> RTL8125 <span class="hljs-number">2.5</span>GbE Controller<br><span class="hljs-symbol">       vendor:</span> Realtek Semiconductor Co., Ltd.<br></code></pre></td></tr></table></figure><h2 id="得知型号是RTL8125-2-5G，然后去官方网站下载对应的驱动"><a href="#得知型号是RTL8125-2-5G，然后去官方网站下载对应的驱动" class="headerlink" title="得知型号是RTL8125 2.5G，然后去官方网站下载对应的驱动"></a>得知型号是RTL8125 2.5G，然后去官方网站下载对应的驱动</h2><p><a href="https://www.realtek.com/en/component/zoo/category/network-interface-controllers-10-100-1000m-gigabit-ethernet-pci-express-software">https://www.realtek.com/en/component/zoo/category/network-interface-controllers-10-100-1000m-gigabit-ethernet-pci-express-software</a></p><h2 id="在你的机器上首先确保有make相关组件-新安装系统时需要安装好一些编译的包，也可以按下列方式重新安装"><a href="#在你的机器上首先确保有make相关组件-新安装系统时需要安装好一些编译的包，也可以按下列方式重新安装" class="headerlink" title="在你的机器上首先确保有make相关组件,新安装系统时需要安装好一些编译的包，也可以按下列方式重新安装"></a>在你的机器上首先确保有make相关组件,新安装系统时需要安装好一些编译的包，也可以按下列方式重新安装</h2><h3 id="首先，你网卡没法联网，只能使用本地镜像，本地镜像的构建方式如下"><a href="#首先，你网卡没法联网，只能使用本地镜像，本地镜像的构建方式如下" class="headerlink" title="首先，你网卡没法联网，只能使用本地镜像，本地镜像的构建方式如下:"></a>首先，你网卡没法联网，只能使用本地镜像，本地镜像的构建方式如下:</h3><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment">#挂载镜像</span><br>mkdir <span class="hljs-regexp">/media/i</span>so<br>sudo mount  ~<span class="hljs-regexp">/Desktop/u</span>buntu-<span class="hljs-number">20.04</span>.<span class="hljs-number">2.0</span>-desktop-amd64.iso <span class="hljs-regexp">/media/i</span>so<br></code></pre></td></tr></table></figure><p>#focal是ubtunu20.04的版本的名称<br>sudo vim &#x2F;etc&#x2F;apt&#x2F;sources.list<br>deb file:&#x2F;media&#x2F;iso&#x2F; focal main contrib</p><p>#更新下包的缓存<br>sudo apt update</p><p>#安装make命令, build-essential是编译代码所需的包，iso镜像中自带了，其实可以在安装系统时安装上<br>sudo apt install build-essential 或者make</p><h2 id="然把你下载的驱动拷贝到服务器，我的对应驱动是r8125-9-005-06-tar-bz2"><a href="#然把你下载的驱动拷贝到服务器，我的对应驱动是r8125-9-005-06-tar-bz2" class="headerlink" title="然把你下载的驱动拷贝到服务器，我的对应驱动是r8125-9.005.06.tar.bz2"></a>然把你下载的驱动拷贝到服务器，我的对应驱动是r8125-9.005.06.tar.bz2</h2><p>解压<br>tar jxvf r8125-9.005.06.tar.bz2</p><h2 id="编译和安装"><a href="#编译和安装" class="headerlink" title="编译和安装"></a>编译和安装</h2><p>cd r8125-9.005.06<br>sudo make<br>sudo .&#x2F;autorun.sh</p><h2 id="正常查看网络，或者手动配置ip"><a href="#正常查看网络，或者手动配置ip" class="headerlink" title="正常查看网络，或者手动配置ip"></a>正常查看网络，或者手动配置ip</h2><p>ip a</p>]]></content>
    
    
    <categories>
      
      <category>linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ubuntu</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ubuntu远程桌面的三种实现方式</title>
    <link href="/2022/03/14/ubuntu%E8%BF%9C%E7%A8%8B%E6%A1%8C%E9%9D%A2/"/>
    <url>/2022/03/14/ubuntu%E8%BF%9C%E7%A8%8B%E6%A1%8C%E9%9D%A2/</url>
    
    <content type="html"><![CDATA[<h1 id="方式1：-ubuntu-自带的vino的版本的vnc"><a href="#方式1：-ubuntu-自带的vino的版本的vnc" class="headerlink" title="方式1： ubuntu 自带的vino的版本的vnc"></a>方式1： ubuntu 自带的vino的版本的vnc</h1><h2 id="步骤1，需要登录到ubuntu的桌面环境，找到设置-然后找到Sharing选项"><a href="#步骤1，需要登录到ubuntu的桌面环境，找到设置-然后找到Sharing选项" class="headerlink" title="步骤1，需要登录到ubuntu的桌面环境，找到设置, 然后找到Sharing选项"></a>步骤1，需要登录到ubuntu的桌面环境，找到设置, 然后找到Sharing选项</h2><p>点击Screen Sharing，设置一个密码，注意Network选项是开启的</p><h2 id="步骤2-取消加密协议"><a href="#步骤2-取消加密协议" class="headerlink" title="步骤2,取消加密协议"></a>步骤2,取消加密协议</h2><p>不用root用户运行，取消加密</p><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs lasso">gsettings <span class="hljs-built_in">set</span> org.gnome.Vino <span class="hljs-keyword">require</span><span class="hljs-params">-encryption</span> <span class="hljs-literal">false</span><br></code></pre></td></tr></table></figure><h2 id="步骤3，使用苹果的屏幕共享货vnc-viewer连接即可-端口5900"><a href="#步骤3，使用苹果的屏幕共享货vnc-viewer连接即可-端口5900" class="headerlink" title="步骤3，使用苹果的屏幕共享货vnc viewer连接即可, 端口5900"></a>步骤3，使用苹果的屏幕共享货vnc viewer连接即可, 端口5900</h2><h1 id="方式2：-使用tigervnc"><a href="#方式2：-使用tigervnc" class="headerlink" title="方式2： 使用tigervnc"></a>方式2： 使用tigervnc</h1><h2 id="安装tigervnc-vncserver和vncconfig命令安装成功"><a href="#安装tigervnc-vncserver和vncconfig命令安装成功" class="headerlink" title="安装tigervnc, vncserver和vncconfig命令安装成功"></a>安装tigervnc, vncserver和vncconfig命令安装成功</h2><figure class="highlight axapta"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs axapta">apt install tigervnc-standalone-<span class="hljs-keyword">server</span><br></code></pre></td></tr></table></figure><p>其它机器可以安装 客户端，如果需要连接vncserver</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake">apt <span class="hljs-keyword">install</span> tigervnc-viewer<br></code></pre></td></tr></table></figure><p>默认使用当前用户连接VNC，如果需要使用其它用户连接VNC server，那么需要建立新的用户<br>设置VNC的连接密码</p><figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs vbnet">vncpasswd<br><span class="hljs-symbol">Password:</span><br><span class="hljs-symbol">Verify:</span><br>Would you <span class="hljs-built_in">like</span> <span class="hljs-keyword">to</span> enter a view-only password (y/n)? n  #不设置只能查看的vnc密码<br></code></pre></td></tr></table></figure><h2 id="编辑用户下的配置文件"><a href="#编辑用户下的配置文件" class="headerlink" title="编辑用户下的配置文件"></a>编辑用户下的配置文件</h2><p>.vnc&#x2F;xstartup<br>内容如下，这是专为Gnome准备的</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment">#!/bin/sh</span><br><span class="hljs-comment"># Start Gnome 3 Desktop </span><br>[ -x <span class="hljs-regexp">/etc/</span>vnc<span class="hljs-regexp">/xstartup ] &amp;&amp; exec /</span>etc<span class="hljs-regexp">/vnc/</span>xstartup<br>[ -r <span class="hljs-variable">$HOME</span><span class="hljs-regexp">/.Xresources ] &amp;&amp; xrdb $HOME/</span>.Xresources<br>vncconfig -iconic &amp;<br>dbus-launch --<span class="hljs-keyword">exit</span>-with-session gnome-session &amp;<br></code></pre></td></tr></table></figure><p>可执行权限<br>chmod a+x .vnc&#x2F;xstartup</p><h2 id="启动vncserver"><a href="#启动vncserver" class="headerlink" title="启动vncserver"></a>启动vncserver</h2><p>vncserver -localhost no  #不是只监听localhost的端口</p><p>#查看启动的VNCserver<br>vncserver -list</p><p>#如果不使用VNC，可以选择kill掉, :1代表kill 5901端口<br>vncserver -kill :1</p><p>#vncserver的自启动服务<br>mkdir -p .local&#x2F;share&#x2F;systemd&#x2F;user&#x2F;</p><h2 id="步骤4-作为服务启动"><a href="#步骤4-作为服务启动" class="headerlink" title="步骤4: 作为服务启动"></a>步骤4: 作为服务启动</h2><p>#编辑用户的service<br>#cat .local&#x2F;share&#x2F;systemd&#x2F;user&#x2F;vncserver@.service</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-section">[Unit]</span><br><span class="hljs-attr">Description</span>=TigerVNC Service<br><br><span class="hljs-section">[Service]</span><br><span class="hljs-attr">Type</span>=forking<br><span class="hljs-attr">ExecStartPre</span>=-/usr/bin/vncserver -kill :%i &gt; /dev/null <span class="hljs-number">2</span>&gt;&amp;<span class="hljs-number">1</span><br><span class="hljs-attr">ExecStart</span>=/usr/bin/vncserver :%i -localhost <span class="hljs-literal">no</span><br><span class="hljs-attr">ExecStop</span>=/usr/bin/vncserver -kill :%i<br><br><span class="hljs-section">[Install]</span><br><span class="hljs-attr">WantedBy</span>=default.target<br></code></pre></td></tr></table></figure><p>#vim ~&#x2F;.xinitrc   #启动VNC的时候使用x11的session<br>export XDG_SESSION_TYPE&#x3D;x11</p><p>#创建服务的xtartup脚本, 这个是用于服务的<br>sudo mkdir &#x2F;etc&#x2F;vnc<br>sudo cat &#x2F;etc&#x2F;vnc&#x2F;xstartup</p><figure class="highlight d"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs d"><span class="hljs-meta">#!/bin/sh</span><br>test x<span class="hljs-string">&quot;$SHELL&quot;</span> = <span class="hljs-string">x&quot;&quot;</span> &amp;&amp; SHELL=/bin/bash<br>test x<span class="hljs-string">&quot;$1&quot;</span>     = <span class="hljs-string">x&quot;&quot;</span> &amp;&amp; set -- <span class="hljs-keyword">default</span><br><br>vncconfig -iconic &amp;<br><span class="hljs-string">&quot;$SHELL&quot;</span> -l &lt;&lt; EOF<br><span class="hljs-keyword">export</span> XDG_SESSION_TYPE=x11<br><span class="hljs-keyword">export</span> GNOME_SHELL_SESSION_MODE=ubuntu<br>dbus-launch --exit-<span class="hljs-keyword">with</span>-session gnome-session --session=ubuntu<br>EOF<br>vncserver -kill $DISPLAY<br></code></pre></td></tr></table></figure><p>#设置可执行<br>sudo chmod a+x  &#x2F;etc&#x2F;vnc&#x2F;xstartup</p><p>#用户的服务reload, 只能这个用户启动<br>systemctl daemon-reload –user<br>systemctl restart <a href="mailto:&#x76;&#110;&#99;&#x73;&#x65;&#114;&#118;&#101;&#114;&#x40;&#49;&#46;&#115;&#101;&#x72;&#x76;&#x69;&#x63;&#101;">&#x76;&#110;&#99;&#x73;&#x65;&#114;&#118;&#101;&#114;&#x40;&#49;&#46;&#115;&#101;&#x72;&#x76;&#x69;&#x63;&#101;</a> –user<br>systemctl status <a href="mailto:&#x76;&#x6e;&#99;&#115;&#101;&#114;&#118;&#x65;&#114;&#x40;&#x31;&#x2e;&#x73;&#x65;&#x72;&#118;&#105;&#99;&#101;">&#x76;&#x6e;&#99;&#115;&#101;&#114;&#118;&#x65;&#114;&#x40;&#x31;&#x2e;&#x73;&#x65;&#x72;&#118;&#105;&#99;&#101;</a> –user<br>#加到开机启动<br>systemctl enable <a href="mailto:&#118;&#x6e;&#x63;&#115;&#x65;&#x72;&#x76;&#101;&#x72;&#64;&#49;&#x2e;&#115;&#x65;&#114;&#x76;&#105;&#x63;&#101;">&#118;&#x6e;&#x63;&#115;&#x65;&#x72;&#x76;&#101;&#x72;&#64;&#49;&#x2e;&#115;&#x65;&#114;&#x76;&#105;&#x63;&#101;</a> –user</p><h1 id="方法3：Ubuntu-xrdp的安装方法-xrdp等同于vnc-server，只是需要用微软的remote-desktop工具连接"><a href="#方法3：Ubuntu-xrdp的安装方法-xrdp等同于vnc-server，只是需要用微软的remote-desktop工具连接" class="headerlink" title="方法3：Ubuntu xrdp的安装方法, xrdp等同于vnc server，只是需要用微软的remote desktop工具连接"></a>方法3：Ubuntu xrdp的安装方法, xrdp等同于vnc server，只是需要用微软的remote desktop工具连接</h1><h2 id="如果没安装Desktop环境，需要安装"><a href="#如果没安装Desktop环境，需要安装" class="headerlink" title="如果没安装Desktop环境，需要安装"></a>如果没安装Desktop环境，需要安装</h2><p>sudo apt install tasksel -y<br>tasksel   #选中Ubuntu desktop，然后开始安装<br>systemctl set-default graphical.target #  启动图像界面作为默认</p><h2 id="安装xrdp"><a href="#安装xrdp" class="headerlink" title="安装xrdp"></a>安装xrdp</h2><p>sudo apt install xrdp -y<br>sudo systemctl status xrdp<br>sudo systemctl enable xrdp<br>sudo usermod -a -G ssl-cert xxx   #把你的当前用户xxx用户加入到ssl用户组，例如johnson<br>sudo vim &#x2F;etc&#x2F;xrdp&#x2F;startwm.sh<br>#在前2行加入如下配置<br>Unset DBUS_SESSION_ADDRESS<br>Unset XDG_RUNTIME_DIR</p><p>sudo systemctl restart xrdp</p><h2 id="如果启用了防火墙，需要配置3389可以访问"><a href="#如果启用了防火墙，需要配置3389可以访问" class="headerlink" title="如果启用了防火墙，需要配置3389可以访问"></a>如果启用了防火墙，需要配置3389可以访问</h2><p>sudo ufw allow from 192.168.1.0&#x2F;24 to any port 3389<br>sudo ufw reload</p><h2 id="完成，可以用微软的远程桌面客户端工具开始连接-也可以通过NAT映射出去一个端口，那么连接的时候直接用IP-PORT的"><a href="#完成，可以用微软的远程桌面客户端工具开始连接-也可以通过NAT映射出去一个端口，那么连接的时候直接用IP-PORT的" class="headerlink" title="完成，可以用微软的远程桌面客户端工具开始连接, 也可以通过NAT映射出去一个端口，那么连接的时候直接用IP:PORT的"></a>完成，可以用微软的远程桌面客户端工具开始连接, 也可以通过NAT映射出去一个端口，那么连接的时候直接用IP:PORT的</h2><p>方式连接就可以</p><p>#日志位置<br>sudo tail -f &#x2F;var&#x2F;log&#x2F;xrdp.log</p><p>#如果连接进行是黑屏，处理方法<br>echo “gnome-session -–session&#x3D;gnome-fallback” &gt; ~&#x2F;.xsession<br>sudo &#x2F;etc&#x2F;init.d&#x2F;xrdp restart</p><h1 id="然后再删掉-xsession-重启后就恢复了"><a href="#然后再删掉-xsession-重启后就恢复了" class="headerlink" title="然后再删掉.xsession, 重启后就恢复了"></a>然后再删掉.xsession, 重启后就恢复了</h1>]]></content>
    
    
    <categories>
      
      <category>linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ubuntu</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>知乎博客检索</title>
    <link href="/2022/03/11/%E7%9F%A5%E4%B9%8E%E5%8D%9A%E5%AE%A2%E6%A3%80%E7%B4%A2/"/>
    <url>/2022/03/11/%E7%9F%A5%E4%B9%8E%E5%8D%9A%E5%AE%A2%E6%A3%80%E7%B4%A2/</url>
    
    <content type="html"><![CDATA[<p>VisualSem: 用于视觉和语言的高质量知识图谱<br><a href="https://zhuanlan.zhihu.com/p/478679587">https://zhuanlan.zhihu.com/p/478679587</a><br>VisualSem： A High-quality Knowledge Graph for Vision &amp; Language</p><p>MET:用多模态知识库进行多模态实体标注<br><a href="https://zhuanlan.zhihu.com/p/478627581">https://zhuanlan.zhihu.com/p/478627581</a><br>Multimodal Entity Tagging with Multimodal Knowledge Base</p><p>M4C多模态transformer对TextVQA进行迭代式答案预测<br><a href="https://zhuanlan.zhihu.com/p/477062474">https://zhuanlan.zhihu.com/p/477062474</a><br>Iterative Answer Prediction with Pointer-Augmented Multimodal Transformers for TextVQA</p><p>TPLinker: 通过token对链接的单阶段联合提取实体和关系<br><a href="https://zhuanlan.zhihu.com/p/471975897">https://zhuanlan.zhihu.com/p/471975897</a><br>TPLinker：Single-stage Joint Extraction of Entities and Relations Through Token Pair Linking</p><p>UNIRE：实体关系抽取的统一标签空间<br><a href="https://zhuanlan.zhihu.com/p/454398188">https://zhuanlan.zhihu.com/p/454398188</a><br>UNIRE： A Uniﬁed Label Space for Entity Relation Extraction</p><p>SCIERC实体识别和关系抽取的英文数据集<br><a href="https://zhuanlan.zhihu.com/p/462638191">https://zhuanlan.zhihu.com/p/462638191</a><br>Multi-Task Identiﬁcation of Entities, Relations, and Coreference for Scientiﬁc Knowledge Graph Construction</p><p>SHAP解释树模型<br><a href="https://zhuanlan.zhihu.com/p/459470781">https://zhuanlan.zhihu.com/p/459470781</a><br>A Uniﬁed Approach to Interpreting Model Predictions</p><p>HySPA：用于可扩展的文本到图提取的混合跨度生成<br><a href="https://zhuanlan.zhihu.com/p/454339907">https://zhuanlan.zhihu.com/p/454339907</a><br>HySPA： Hybrid Span Generation for Scalable Text-to-Graph Extraction</p><p>对树模型进行局部解释<br><a href="https://zhuanlan.zhihu.com/p/458958125">https://zhuanlan.zhihu.com/p/458958125</a><br>From local explanations to global understanding with explainable AI for trees</p><p>XGBoost 一个可扩展的tree boosting系统<br><a href="https://zhuanlan.zhihu.com/p/459470547">https://zhuanlan.zhihu.com/p/459470547</a><br>XGBoost： A Scalable Tree Boosting System</p><p>用图卷积网络进行联合信息提取<br><a href="https://zhuanlan.zhihu.com/p/454304430">https://zhuanlan.zhihu.com/p/454304430</a><br>Cross-Task Instance Representation Interactions and Label Dependencies for Joint Information Extraction with Graph Convolutional Networks</p><p>用全局特征进行信息提取的联合神经模型<br><a href="https://zhuanlan.zhihu.com/p/454108143">https://zhuanlan.zhihu.com/p/454108143</a><br>A Joint Neural Model for Information Extraction with Global Features</p><p>利用打包浮动标记进行实体和关系抽取<br><a href="https://zhuanlan.zhihu.com/p/454398356">https://zhuanlan.zhihu.com/p/454398356</a><br>Pack Together： Entity and Relation Extraction with Levitated Marker</p><p>社媒的热点主题预测<br><a href="https://zhuanlan.zhihu.com/p/453417760">https://zhuanlan.zhihu.com/p/453417760</a><br>Hot topic prediction considering influence and expertise in social media</p><p>社交媒体大数据分析<br><a href="https://zhuanlan.zhihu.com/p/453838204">https://zhuanlan.zhihu.com/p/453838204</a><br>Big Social Media Data Analytics</p><p>PRCA和IGA联合建模分析顾客满意度<br><a href="https://zhuanlan.zhihu.com/p/449441801">https://zhuanlan.zhihu.com/p/449441801</a><br>Integrating methods for the prioritization of innovations and improvements in services</p><p>基于实体相对位置表示的多头选择的联合实体和关系抽取<br><a href="https://zhuanlan.zhihu.com/p/448112834">https://zhuanlan.zhihu.com/p/448112834</a><br>Entity Relative Position Representation based Multi-head Selection for Joint Entity and Relation Extraction</p><p>Kano加诺模型与数据挖掘的整合来预测客户满意度<br><a href="https://zhuanlan.zhihu.com/p/448486378">https://zhuanlan.zhihu.com/p/448486378</a><br>Concept Paper Kano Model Integration with Data Mining to Predict Customer Satisfaction</p><p>PRCA惩罚-奖励-对比分析：在顾客满意度研究中的应用<br><a href="https://zhuanlan.zhihu.com/p/449242532">https://zhuanlan.zhihu.com/p/449242532</a><br>Penalty–Reward-Contrast Analysis： a review of its application in customer satisfaction research</p><p>极端多标签文本分类的快速多分辨率transformer微调技术<br><a href="https://zhuanlan.zhihu.com/p/445661903">https://zhuanlan.zhihu.com/p/445661903</a><br>Fast Multi-Resolution Transformer Fine-tuning for Extreme Multi-label Text Classiﬁcation</p><p>多任务学习加强多标签文本分类<br><a href="https://zhuanlan.zhihu.com/p/445661700">https://zhuanlan.zhihu.com/p/445661700</a><br>Enhancing Label Correlation Feedback in Multi-Label Text Classiﬁcation via Multi-Task Learning</p><p>基于TFIDF和GloVe的多标签文本分类<br><a href="https://zhuanlan.zhihu.com/p/445587449">https://zhuanlan.zhihu.com/p/445587449</a><br>Deep Learning Based Multi-Label Text Classification of UNGA Resolutions</p><p>动态语义表示和深度神经网络结合的多标签文本分类方法<br><a href="https://zhuanlan.zhihu.com/p/445517482">https://zhuanlan.zhihu.com/p/445517482</a><br>A multi-label text classification method via dynamic semantic representation model and deep neural network</p><p>表-序列编码器联合提取实体和关系<br><a href="https://zhuanlan.zhihu.com/p/440722315">https://zhuanlan.zhihu.com/p/440722315</a><br>Two are Better than One：Joint Entity and Relation Extraction with Table-Sequence Encoders</p><p>用上下文跨度表示的实体、关系和事件提取<br><a href="https://zhuanlan.zhihu.com/p/443573825">https://zhuanlan.zhihu.com/p/443573825</a><br>Entity, Relation, and Event Extraction with Contextualized Span Representations</p><p>多头选择框架的BERT联合实体关系抽取<br><a href="https://zhuanlan.zhihu.com/p/443577609">https://zhuanlan.zhihu.com/p/443577609</a><br>BERT-Based Multi-Head Selection for Joint Entity-Relation Extraction</p><p>实体和关系抽取的简单方法<br><a href="https://zhuanlan.zhihu.com/p/440704543">https://zhuanlan.zhihu.com/p/440704543</a><br>A Frustratingly Easy Approach for Entity and Relation Extraction</p><p>BenchIE：基于事实而非token的开放式信息提取评估<br><a href="https://zhuanlan.zhihu.com/p/438437407">https://zhuanlan.zhihu.com/p/438437407</a><br>BenchIE： Open Information Extraction Evaluation Based on Facts, Not Tokens</p><p>OpenIE6：用于开放信息提取的迭代网格标签和协调分析<br><a href="https://zhuanlan.zhihu.com/p/438007291">https://zhuanlan.zhihu.com/p/438007291</a><br>OpenIE6: Iterative Grid Labeling and Coordination Analysis for Open Information Extraction</p><p>医学放射科报告生成与知识图谱<br><a href="https://zhuanlan.zhihu.com/p/436319124">https://zhuanlan.zhihu.com/p/436319124</a><br>When Radiology Report Generation Meets Knowledge Graph</p><p>BUTD：自下而上和自上而下的注意力多模态模型<br><a href="https://zhuanlan.zhihu.com/p/435174845">https://zhuanlan.zhihu.com/p/435174845</a><br>Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering</p><p>UniT：多模态多任务模型<br><a href="https://zhuanlan.zhihu.com/p/434243735">https://zhuanlan.zhihu.com/p/434243735</a><br>UniT: Multimodal Multitask Learning with a Uniﬁed Transformer</p><p>ACT: 自适应聚类transformer端到端目标检测<br><a href="https://zhuanlan.zhihu.com/p/435175009">https://zhuanlan.zhihu.com/p/435175009</a><br>End-to-End Object Detection with Adaptive Clustering Transformer</p><p>VisualBert: 经过预训练的多模态模型<br><a href="https://zhuanlan.zhihu.com/p/434272329">https://zhuanlan.zhihu.com/p/434272329</a><br>VISUALBERT: A SIMPLE AND PERFORMANT BASELINE FOR VISION AND LANGUAGE</p><p>双线性注意力网络（多模态）<br><a href="https://zhuanlan.zhihu.com/p/432970660">https://zhuanlan.zhihu.com/p/432970660</a><br>Bilinear Attention Networks</p><p>OpenUE：从文本中提取通用信息的开放工具箱<br><a href="https://zhuanlan.zhihu.com/p/431805279">https://zhuanlan.zhihu.com/p/431805279</a><br>OpenUE: An Open Toolkit of Universal Extraction from Text</p><p>多模态分类的跨模态检索增强功能<br><a href="https://zhuanlan.zhihu.com/p/432389016">https://zhuanlan.zhihu.com/p/432389016</a><br>Cross-Modal Retrieval Augmentation for Multi-Modal Classiﬁcation</p><p>艺术品类图像的双流多模态模型情感分析<br><a href="https://zhuanlan.zhihu.com/p/432373663">https://zhuanlan.zhihu.com/p/432373663</a><br>Understanding of Emotion Perception from Art</p><p>基于远端监督的开放领域数据的命名实体识别<br><a href="https://zhuanlan.zhihu.com/p/428925959">https://zhuanlan.zhihu.com/p/428925959</a><br>Named Entity Recognition for Open Domain Data Based on Distant Supervision</p><p>MISA: 多模态情感分析的模态不变和模态特定表示<br><a href="https://zhuanlan.zhihu.com/p/430407430">https://zhuanlan.zhihu.com/p/430407430</a><br>MISA: Modality-Invariant and -Specific Representations for Multimodal Sentiment Analysis</p><p>利用网络资源发现新的实体<br><a href="https://zhuanlan.zhihu.com/p/428861588">https://zhuanlan.zhihu.com/p/428861588</a><br>Emerging Entity Discovery Using Web Sources</p><p>知识图谱完成方法的重新评估<br><a href="https://zhuanlan.zhihu.com/p/428088532">https://zhuanlan.zhihu.com/p/428088532</a><br>A Re-evaluation of Knowledge Graph Completion Methods</p><p>Info-HCVAE问答对生成<br><a href="https://zhuanlan.zhihu.com/p/421265798">https://zhuanlan.zhihu.com/p/421265798</a><br>Generating Diverse and Consistent QA pairs from Contexts with Information-Maximizing Hierarchical Conditional VAEs</p><p>多任务学习框架下的观点三元组提取<br><a href="https://zhuanlan.zhihu.com/p/426376153">https://zhuanlan.zhihu.com/p/426376153</a><br>A Multi-task Learning Framework for Opinion Triplet Extraction</p><p>ASAP: 中文评论数据集：aspect的情感分析<br><a href="https://zhuanlan.zhihu.com/p/425981216">https://zhuanlan.zhihu.com/p/425981216</a><br>ASAP: A Chinese Review Dataset Towards Aspect Category Sentiment Analysis and Rating Prediction</p><p>DiaKG：用于构建医学知识图谱的糖尿病标注数据集<br><a href="https://zhuanlan.zhihu.com/p/424733768">https://zhuanlan.zhihu.com/p/424733768</a><br>DiaKG: an Annotated Diabetes Dataset for Medical Knowledge Graph Construction</p><p>P-Tuning v2: 与微调性能相等的提示性优化<br><a href="https://zhuanlan.zhihu.com/p/423902902">https://zhuanlan.zhihu.com/p/423902902</a><br>P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks</p><p>TechKG：一个大规模的中文技术导向的知识图谱<br><a href="https://zhuanlan.zhihu.com/p/420557472">https://zhuanlan.zhihu.com/p/420557472</a><br>TechKG: A Large-Scale Chinese Technology-Oriented Knowledge Graph</p><p>知识图谱增强的aspect情感分析<br><a href="https://zhuanlan.zhihu.com/p/414252384">https://zhuanlan.zhihu.com/p/414252384</a><br>Scalable End-to-End Training of Knowledge Graph-Enhanced Aspect Embedding for Aspect Level Sentiment Analysis</p><p>Pre-train, Prompt, and Predict: 自然语言处理中prompting方法总结<br><a href="https://zhuanlan.zhihu.com/p/411341801">https://zhuanlan.zhihu.com/p/411341801</a><br>Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing</p><p>用常识性知识图谱进行zero-shot学习<br><a href="https://zhuanlan.zhihu.com/p/410561852">https://zhuanlan.zhihu.com/p/410561852</a><br>Zero-Shot Learning with Common Sense Knowledge Graphs</p><p>用于自然语言推理的随机答案网络<br><a href="https://zhuanlan.zhihu.com/p/409085184">https://zhuanlan.zhihu.com/p/409085184</a><br>Stochastic Answer Networks for Natural Language Inference</p><p>用于自然语言理解的微软多任务深度神经网络工具包<br><a href="https://zhuanlan.zhihu.com/p/408851910">https://zhuanlan.zhihu.com/p/408851910</a><br>The Microsoft Toolkit of Multi-Task Deep Neural Networks for Natural Language Understanding</p><p>大型神经语言模型的对抗性训练<br><a href="https://zhuanlan.zhihu.com/p/408582923">https://zhuanlan.zhihu.com/p/408582923</a><br>Adversarial Training for Large Neural Language Models</p><p>行为克隆强化学习玩CS反恐精英<br><a href="https://zhuanlan.zhihu.com/p/403123868">https://zhuanlan.zhihu.com/p/403123868</a><br>Counter-Strike Deathmatch with Large-Scale Behavioural Cloning</p><p>HyperTools: 可视化和操作高维度据的Python工具箱<br><a href="https://zhuanlan.zhihu.com/p/407691325">https://zhuanlan.zhihu.com/p/407691325</a><br>HyperTools: A Python toolbox for visualizing and manipulating high-dimensional data</p><p>显存优化<br><a href="https://zhuanlan.zhihu.com/p/407429742">https://zhuanlan.zhihu.com/p/407429742</a><br>Training Deep Nets with Sublinear Memory Cost</p><p>自然语言查询问答模型<br><a href="https://zhuanlan.zhihu.com/p/406453009">https://zhuanlan.zhihu.com/p/406453009</a><br>Database Reasoning Over Text</p><p>Transformer Survey<br><a href="https://zhuanlan.zhihu.com/p/405623198">https://zhuanlan.zhihu.com/p/405623198</a><br>A Survey of Transformers</p><p>X-modaler: 用于跨模态分析的多功能和高性能的代码库<br><a href="https://zhuanlan.zhihu.com/p/402620759">https://zhuanlan.zhihu.com/p/402620759</a><br>X-modaler: A Versatile and High-performance Codebase for Cross-modal Analytics</p><p>PonderNet：适应性模型，提高模型计算效率<br><a href="https://zhuanlan.zhihu.com/p/401874414">https://zhuanlan.zhihu.com/p/401874414</a><br>PonderNet: Learning to Ponder</p><p>模式引导下的多领域对话数据集<br><a href="https://zhuanlan.zhihu.com/p/401779764">https://zhuanlan.zhihu.com/p/401779764</a><br>Towards Scalable Multi-Domain Conversational Agents: The Schema-Guided Dialogue Dataset</p><p>新冠COVID-19文献知识图谱构建<br><a href="https://zhuanlan.zhihu.com/p/400944819">https://zhuanlan.zhihu.com/p/400944819</a><br>COVID-19 Literature Knowledge Graph Construction and Drug Repurposing Report Generation</p><p>AutoKnow: 上千种产品的自动知识收集<br><a href="https://zhuanlan.zhihu.com/p/399419662">https://zhuanlan.zhihu.com/p/399419662</a><br>AutoKnow: Self-Driving Knowledge Collection for Products of Thousands of Types</p><p>用于联合意向分类和槽位填充的BERT<br><a href="https://zhuanlan.zhihu.com/p/399103189">https://zhuanlan.zhihu.com/p/399103189</a><br>BERT for Joint Intent Classiﬁcation and Slot Filling</p><p>数据标注的质量控制案例:TDT语料<br><a href="https://zhuanlan.zhihu.com/p/398515851">https://zhuanlan.zhihu.com/p/398515851</a><br>Quality Control in Large Annotation Projects Involving Multiple Judges: The Case of the TDT Corpora</p><p>DeiT: 蒸馏的图像transformer模型<br><a href="https://zhuanlan.zhihu.com/p/394627382">https://zhuanlan.zhihu.com/p/394627382</a><br>Training data-efﬁcient image transformers &amp; distillation through attention</p><p>ViT: transformer用于图像识别<br><a href="https://zhuanlan.zhihu.com/p/394288661">https://zhuanlan.zhihu.com/p/394288661</a><br>AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE</p><p>YOLOX<br><a href="https://zhuanlan.zhihu.com/p/393955749">https://zhuanlan.zhihu.com/p/393955749</a><br>YOLOX: Exceeding YOLO Series in 2021</p><p>完善知识图谱总结<br><a href="https://zhuanlan.zhihu.com/p/393885109">https://zhuanlan.zhihu.com/p/393885109</a><br>Knowledge Graph Refinement: A Survey of Approaches and Evaluation Methods</p><p>AdaShare: 高效的深度多任务学习<br><a href="https://zhuanlan.zhihu.com/p/393243186">https://zhuanlan.zhihu.com/p/393243186</a><br>AdaShare: Learning What To Share For Efﬁcient Deep Multi-Task Learning</p><p>知识图谱总结： 表示、获取和应用<br><a href="https://zhuanlan.zhihu.com/p/392429070">https://zhuanlan.zhihu.com/p/392429070</a><br>A Survey on Knowledge Graphs: Representation, Acquisition and Applications</p><p>REPAINT：深度强化学习中的知识迁移<br><a href="https://zhuanlan.zhihu.com/p/391824772">https://zhuanlan.zhihu.com/p/391824772</a><br>REPAINT: Knowledge Transfer in Deep Reinforcement Learning</p><p>重新审视Rainbow<br><a href="https://zhuanlan.zhihu.com/p/391126427">https://zhuanlan.zhihu.com/p/391126427</a><br>Revisiting Rainbow: Promoting more Insightful and Inclusive Deep Reinforcement Learning Research</p><p>遗传进化强化学习算法<br><a href="https://zhuanlan.zhihu.com/p/389895408">https://zhuanlan.zhihu.com/p/389895408</a><br>EVOLVING REINFORCEMENT LEARNING ALGORITHMS</p><p>强化学习环境：Google足球游戏<br><a href="https://zhuanlan.zhihu.com/p/389567798">https://zhuanlan.zhihu.com/p/389567798</a><br>Google Research Football: A Novel Reinforcement Learning Environment</p><p>无监督文本摘要<br><a href="https://zhuanlan.zhihu.com/p/388911963">https://zhuanlan.zhihu.com/p/388911963</a><br>Learning to Encode Text as Human-Readable Summaries using Generative Adversarial Networks</p><p>ERNIE 3.0: 用于语言理解和生成的大规模知识强化预训练<br><a href="https://zhuanlan.zhihu.com/p/388172601">https://zhuanlan.zhihu.com/p/388172601</a><br>ERNIE 3.0: LARGE-SCALE KNOWLEDGE ENHANCED PRE-TRAINING FOR LANGUAGE UNDERSTANDING AND GENERATION</p><p>COMET：自动构建知识图谱的常识transformer<br><a href="https://zhuanlan.zhihu.com/p/388106049">https://zhuanlan.zhihu.com/p/388106049</a><br>COMET : Commonsense Transformers for Automatic Knowledge Graph Construction</p><p>D2S: 通过基于查询的文本总结进行文档到幻灯片的生成<br><a href="https://zhuanlan.zhihu.com/p/387544973">https://zhuanlan.zhihu.com/p/387544973</a><br>D2S: Document-to-Slide Generation Via Query-Based Text Summarization</p><p>斗地主强化学习<br><a href="https://zhuanlan.zhihu.com/p/385496621">https://zhuanlan.zhihu.com/p/385496621</a><br>DouZero: Mastering DouDizhu with Self-Play Deep Reinforcement Learning</p><p>通过知识蒸馏改进多任务深度神经网络以促进自然语言理解<br><a href="https://zhuanlan.zhihu.com/p/384120253">https://zhuanlan.zhihu.com/p/384120253</a><br>Improving Multi-Task Deep Neural Networks via Knowledge Distillation for Natural Language Understanding</p><p>使用深度强化学习玩MOBA游戏<br><a href="https://zhuanlan.zhihu.com/p/378789632">https://zhuanlan.zhihu.com/p/378789632</a><br>Towards Playing Full MOBA Games with Deep Reinforcement Learning</p><p>MOBA游戏的复杂控制与深度强化学习<br><a href="https://zhuanlan.zhihu.com/p/379091485">https://zhuanlan.zhihu.com/p/379091485</a><br>Mastering Complex Control in MOBA Games with Deep Reinforcement Learning</p><p>用强化学习玩英雄联盟<br><a href="https://zhuanlan.zhihu.com/p/363495437">https://zhuanlan.zhihu.com/p/363495437</a><br>Deep Learning Bot for League of Legends</p><p>ATARI游戏的Model based的强化学习<br><a href="https://zhuanlan.zhihu.com/p/363279136">https://zhuanlan.zhihu.com/p/363279136</a><br>MODEL BASED REINFORCEMENT LEARNING FOR ATARI</p><p>关于视频游戏的深度强化学习算法<br><a href="https://zhuanlan.zhihu.com/p/363115461">https://zhuanlan.zhihu.com/p/363115461</a><br>A Survey of Deep Reinforcement Learning in Video Games</p><p>用于自然语言理解的多任务深度神经网络<br><a href="https://zhuanlan.zhihu.com/p/383137481">https://zhuanlan.zhihu.com/p/383137481</a><br>Multi-Task Deep Neural Networks for Natural Language Understanding</p><p>模仿学习: 自动排序的演示学习<br><a href="https://zhuanlan.zhihu.com/p/382272429">https://zhuanlan.zhihu.com/p/382272429</a><br>Better-than-Demonstrator Imitation Learning via Automatically-Ranked Demonstrations</p><p>预训练编码器文本摘要<br><a href="https://zhuanlan.zhihu.com/p/381490918">https://zhuanlan.zhihu.com/p/381490918</a><br>Text Summarization with Pretrained Encoders</p><p>Survey: 多任务学习<br><a href="https://zhuanlan.zhihu.com/p/381229374">https://zhuanlan.zhihu.com/p/381229374</a><br>A Survey on Multi-Task Learning</p><p>DDPG论文: 深强化学习连续控制<br><a href="https://zhuanlan.zhihu.com/p/371451813">https://zhuanlan.zhihu.com/p/371451813</a><br>CONTINUOUS CONTROL WITH DEEP REINFORCEMENT LEARNING</p><p>使用图像做无地图导航的强化学习<br><a href="https://zhuanlan.zhihu.com/p/379270657">https://zhuanlan.zhihu.com/p/379270657</a><br>Using RGB Image as Visual Input for Mapless Robot Navigation</p><p>Pettingzoo：类似gym的多Agent强化学习的环境<br><a href="https://zhuanlan.zhihu.com/p/375049925">https://zhuanlan.zhihu.com/p/375049925</a><br>PettingZoo: Gym for Multi-Agent Reinforcement Learning</p><p>RIIT: 最新的多Agent合作控制强化学习算法<br><a href="https://zhuanlan.zhihu.com/p/368284926">https://zhuanlan.zhihu.com/p/368284926</a><br>RIIT: Rethinking the Importance of Implementation Tricks in Multi-Agent Reinforcement Learning</p><p>复现深度强化学习算法效果的因素<br><a href="https://zhuanlan.zhihu.com/p/377369590">https://zhuanlan.zhihu.com/p/377369590</a><br>Deep_Reinforcement_Learning_that_Matters</p><p>PPO算法<br><a href="https://zhuanlan.zhihu.com/p/376978985">https://zhuanlan.zhihu.com/p/376978985</a><br>Proximal Policy Optimization Algorithms</p><p>交互式的强化学习<br><a href="https://zhuanlan.zhihu.com/p/379871647">https://zhuanlan.zhihu.com/p/379871647</a><br>REINFORCEMENT LEARNING WITH HUMAN ADVICE: A SURVEY</p><p>半监控机器翻译的简单基准<br><a href="https://zhuanlan.zhihu.com/p/378838885">https://zhuanlan.zhihu.com/p/378838885</a><br>A Simple Baseline to Semi-Supervised Domain Adaptation for Machine Translation</p><p>Survey: 深度神经网络翻译<br><a href="https://zhuanlan.zhihu.com/p/378524968">https://zhuanlan.zhihu.com/p/378524968</a><br>A Survey of Deep Learning Techniques for Neural Machine Translation</p><p>MMBT: 用于图像和文本分类的有监督多模态双向Transformer<br><a href="https://zhuanlan.zhihu.com/p/373581881">https://zhuanlan.zhihu.com/p/373581881</a><br>Supervised Multimodal Bitransformers for Classifying Images and Text</p><p>XLM-R: 大规模无监督跨语言表示模型<br><a href="https://zhuanlan.zhihu.com/p/372978148">https://zhuanlan.zhihu.com/p/372978148</a><br>Unsupervised Cross-lingual Representation Learning at Scale</p><p>跨语言的语言模型预训练<br><a href="https://zhuanlan.zhihu.com/p/372001934">https://zhuanlan.zhihu.com/p/372001934</a><br>Cross-lingual Language Model Pretraining</p><p>神经机器翻译的无监督领域适应<br><a href="https://zhuanlan.zhihu.com/p/371626610">https://zhuanlan.zhihu.com/p/371626610</a><br>Unsupervised Domain Adaptation for Neural Machine Translation with Domain-Aware Feature Embeddings</p><p>域适应翻译中的单词表适应方法<br><a href="https://zhuanlan.zhihu.com/p/371392857">https://zhuanlan.zhihu.com/p/371392857</a><br>Vocabulary Adaptation for Domain Adaptation in Neural Machine Translation</p><p>使用术语限制的神经网络翻译<br><a href="https://zhuanlan.zhihu.com/p/370661928">https://zhuanlan.zhihu.com/p/370661928</a><br>Training Neural Machine Translation To Apply Terminology Constraints</p><p>Survey: 机器翻译的领域适应和多领域适应<br><a href="https://zhuanlan.zhihu.com/p/370390321">https://zhuanlan.zhihu.com/p/370390321</a><br>Domain Adaptation and Multi-Domain Adaptation for Neural Machine Translation: A Survey</p><p>M2M-100: 多语言翻译模型<br><a href="https://zhuanlan.zhihu.com/p/368226087">https://zhuanlan.zhihu.com/p/368226087</a><br>Beyond English-Centric Multilingual Machine Translation</p><p>FAIRSEQ 语音到文本模型<br><a href="https://zhuanlan.zhihu.com/p/361585021">https://zhuanlan.zhihu.com/p/361585021</a><br>FAIRSEQ S2T: Fast Speech-to-Text Modeling with FAIRSEQ</p><p>自然语言中的强化学习<br><a href="https://zhuanlan.zhihu.com/p/364138298">https://zhuanlan.zhihu.com/p/364138298</a><br>A Survey of Reinforcement Learning Informed by Natural Language</p><p>MAAC注意力的演员评论家: Multi-Agent强化学习<br><a href="https://zhuanlan.zhihu.com/p/366413456">https://zhuanlan.zhihu.com/p/366413456</a><br>Actor-Attention-Critic for Multi-Agent Reinforcement Learning</p><p>mBART：多语言翻译预训练模型<br><a href="https://zhuanlan.zhihu.com/p/366525006">https://zhuanlan.zhihu.com/p/366525006</a><br>Multilingual Denoising Pre-training for Neural Machine Translation</p><p>MobileBERT:用于资源限制设备的紧凑型任务型BERT<br><a href="https://zhuanlan.zhihu.com/p/365329984">https://zhuanlan.zhihu.com/p/365329984</a><br>MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices</p><p>更快的深度自适应transformers<br><a href="https://zhuanlan.zhihu.com/p/364807276">https://zhuanlan.zhihu.com/p/364807276</a><br>Faster Depth-Adaptive Transformers</p><p>利用远端监督的强化学习关系抽取<br><a href="https://zhuanlan.zhihu.com/p/364444877">https://zhuanlan.zhihu.com/p/364444877</a><br>Large Scaled Relation Extraction with Reinforcement Learning</p><p>GLRE模型文档级关系抽取<br><a href="https://zhuanlan.zhihu.com/p/360980109">https://zhuanlan.zhihu.com/p/360980109</a><br>Global-to-Local Neural Networks for Document-Level Relation Extraction</p><p>关系抽取的注意力引导图卷积网络<br><a href="https://zhuanlan.zhihu.com/p/357518473">https://zhuanlan.zhihu.com/p/357518473</a><br>Attention Guided Graph Convolutional Networks for Relation Extraction</p><p>关系抽取Review（附上中文关系抽取的数据及代码)<br><a href="https://zhuanlan.zhihu.com/p/356551233">https://zhuanlan.zhihu.com/p/356551233</a><br>More Data, More Relations, More Context and More Openness: A Review and Outlook for Relation Extraction</p><p>DocRED: 大型文档级关系抽取数据集<br><a href="https://zhuanlan.zhihu.com/p/356077381">https://zhuanlan.zhihu.com/p/356077381</a><br>DocRED: A Large-Scale Document-Level Relation Extraction Dataset</p><p>文档级关系抽取：图增强双重注意力网络<br><a href="https://zhuanlan.zhihu.com/p/355473773">https://zhuanlan.zhihu.com/p/355473773</a><br>Graph Enhanced Dual Attention Network for Document-Level Relation Extraction</p><p>SENTIX:跨领域情感分析预训练模型<br><a href="https://zhuanlan.zhihu.com/p/350924103">https://zhuanlan.zhihu.com/p/350924103</a><br>SENTIX: A Sentiment-Aware Pre-Trained Model for Cross-Domain Sentiment Analysis</p><p>DEBERTA：解耦注意力的解码增强型BERT<br><a href="https://zhuanlan.zhihu.com/p/348704980">https://zhuanlan.zhihu.com/p/348704980</a><br>DEBERTA: DECODING-ENHANCED BERT WITH DISENTANGLED ATTENTION</p><p>SentiBERT： 基于可迁移的transformer的组合的情感语义预训练模型<br><a href="https://zhuanlan.zhihu.com/p/347854488">https://zhuanlan.zhihu.com/p/347854488</a><br>SentiBERT: A Transferable Transformer-Based Architecture for Compositional Sentiment Semantics</p><p>SentiLARE：带有语言知识的情感感知预训练模型<br><a href="https://zhuanlan.zhihu.com/p/346202158">https://zhuanlan.zhihu.com/p/346202158</a><br>SentiLARE: Sentiment-Aware Language Representation Learning with Linguistic Knowledge</p><p>SpanBERT：通过表示和预测跨度来改善预训练的模型(2020年1月修订)<br><a href="https://zhuanlan.zhihu.com/p/345401994">https://zhuanlan.zhihu.com/p/345401994</a><br>SpanBERT: Improving Pre-training by Representing and Predicting Spans</p><p>抱抱脸🤗Transformers论文(2020年)<br><a href="https://zhuanlan.zhihu.com/p/344553832">https://zhuanlan.zhihu.com/p/344553832</a><br>Transformers: State-of-the-Art Natural Language Processing</p><p>SentencePiece:子词tokenizer和detokenizer(2019年12月更新)<br><a href="https://zhuanlan.zhihu.com/p/343634730">https://zhuanlan.zhihu.com/p/343634730</a><br>SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing</p><p>ALBERT: 精简的BERT自监督的语言表示模型(2020年2月更新)<br><a href="https://zhuanlan.zhihu.com/p/343426088">https://zhuanlan.zhihu.com/p/343426088</a><br>ALBERT: A LITE BERT FOR SELF-SUPERVISED LEARNING OF LANGUAGE REPRESENTATIONS</p><p>上下文和实体名称哪个对关系抽取更重要(2020年12月论文)<br><a href="https://zhuanlan.zhihu.com/p/342360873">https://zhuanlan.zhihu.com/p/342360873</a><br>Learning from Context or Names? An Empirical Study on Neural Relation Extraction</p><p>Google Big Bird：长序列的transformers(2020年论文)<br><a href="https://zhuanlan.zhihu.com/p/342005602">https://zhuanlan.zhihu.com/p/342005602</a><br>Big Bird: Transformers for Longer Sequences</p><p>mT5: 多国语言版T5(中文T5)(2020年10月论文)<br><a href="https://zhuanlan.zhihu.com/p/340288423">https://zhuanlan.zhihu.com/p/340288423</a><br>mT5: A massively multilingual pre-trained text-to-text transformer</p><p>Google T5: 统一文本到文本迁移学习研究 (2020年7月论文)-Part3<br><a href="https://zhuanlan.zhihu.com/p/339502041">https://zhuanlan.zhihu.com/p/339502041</a><br>Exploring the Limits of Transfer Learning with a Uniﬁed Text-to-Text Transformer</p><p>CharBERT：字符感知的预训练语言模型(2020年11月论文)<br><a href="https://zhuanlan.zhihu.com/p/337587788">https://zhuanlan.zhihu.com/p/337587788</a><br>CharBERT: Character-aware Pre-trained Language Model</p><p>AdaBERT：可导神经结构搜索的任务自适应BERT压缩(2020年1月论文)<br><a href="https://zhuanlan.zhihu.com/p/337305614">https://zhuanlan.zhihu.com/p/337305614</a><br>AdaBERT: Task-Adaptive BERT Compression with Differentiable Neural Architecture Search</p><p>EasyTransfer–阿里NLP深度迁移学习平台(2020年11月论文)<br><a href="https://zhuanlan.zhihu.com/p/336730123">https://zhuanlan.zhihu.com/p/336730123</a><br>EasyTransfer – A Simple and Scalable Deep Transfer Learning Platform for NLP Applications</p><p>ConvBERT: 基于跨度的动态卷积BERT(2020年11月论文)<br><a href="https://zhuanlan.zhihu.com/p/336409975">https://zhuanlan.zhihu.com/p/336409975</a><br>ConvBERT: Improving BERT with Span-based Dynamic Convolution</p><p>MacBERT: 中文自然语言预训练模型(2020年11月论文)<br><a href="https://zhuanlan.zhihu.com/p/333202482">https://zhuanlan.zhihu.com/p/333202482</a><br>Revisiting Pre-trained Models for Chinese Natural Language Processing</p><p>FLAT: 使用Flat-Lattice Transformer结构中文NER(2020年5月论文)<br><a href="https://zhuanlan.zhihu.com/p/326135985">https://zhuanlan.zhihu.com/p/326135985</a><br>FLAT: Chinese NER Using Flat-Lattice Transformer</p><p>ELECTRA: 区别于BERT，使用判别器构建预训练模型（2020年3月论文)<br><a href="https://zhuanlan.zhihu.com/p/323931207">https://zhuanlan.zhihu.com/p/323931207</a><br>ELECTRA: PRE-TRAINING TEXT ENCODERS AS DISCRIMINATORS RATHER THAN GENERATORS</p><p>无监督的深度嵌入式聚类(2016年论文)<br><a href="https://zhuanlan.zhihu.com/p/313662693">https://zhuanlan.zhihu.com/p/313662693</a><br>Unsupervised Deep Embedding for Clustering Analysis</p><p>BOND：半监督的BERT开放域命名实体识别(2020年6月论文)<br><a href="https://zhuanlan.zhihu.com/p/307454757">https://zhuanlan.zhihu.com/p/307454757</a><br>BOND: BERT-Assisted Open-Domain Named Entity Recognition with Distant Supervision</p><p>使用半监督和监督学习检测虚假的在线评论(2019年2月)<br><a href="https://zhuanlan.zhihu.com/p/301268523">https://zhuanlan.zhihu.com/p/301268523</a><br>Detection of fake online reviews using semi-supervised and supervised learning </p><p>垃圾观点检测：使用基于多次迭代的图模型(2020年论文)<br><a href="https://zhuanlan.zhihu.com/p/300841251">https://zhuanlan.zhihu.com/p/300841251</a><br>Opinion spam detection: Using multi-iterative graph-based model</p><p>基于预训练和序列迁移的语法纠错系统(2019年7月)<br><a href="https://zhuanlan.zhihu.com/p/288219713">https://zhuanlan.zhihu.com/p/288219713</a><br>A Neural Grammatical Error Correction System Built On Better Pre-training and Sequential Transfer Learning</p><p>序列到序列的中文语法纠错(2018年)<br><a href="https://zhuanlan.zhihu.com/p/285211193">https://zhuanlan.zhihu.com/p/285211193</a><br>A Sequence to Sequence Learning for Chinese Grammatical Error Correction</p><p>BERT-of-Theseus: 通过逐步更换模块压缩BERT模型(2020年10月)<br><a href="https://zhuanlan.zhihu.com/p/283118184">https://zhuanlan.zhihu.com/p/283118184</a><br>BERT-of-Theseus: Compressing BERT by Progressive Module Replacing</p><p>TextBrewer：用于自然语言处理的开源知识蒸馏工具包(2020.04)<br><a href="https://zhuanlan.zhihu.com/p/275722016">https://zhuanlan.zhihu.com/p/275722016</a><br>TextBrewer: An Open-Source Knowledge Distillation Toolkit for Natural Language Processing</p><p>TinyBERT(华为)：自然语言理解之BERT蒸馏(2020.10)<br><a href="https://zhuanlan.zhihu.com/p/273467698">https://zhuanlan.zhihu.com/p/273467698</a><br>TinyBERT: Distilling BERT for Natural Language Understanding</p><p>BERT-PKD: BERT模型压缩之耐心知识蒸馏（2019.08）<br><a href="https://zhuanlan.zhihu.com/p/274329168">https://zhuanlan.zhihu.com/p/274329168</a><br>Patient Knowledge Distillation for BERT Model Compression</p><p>distilBert: Bert 蒸馏到简单的BiLSTM(2019.03)<br><a href="https://zhuanlan.zhihu.com/p/273543240">https://zhuanlan.zhihu.com/p/273543240</a><br>Distilling Task-Speciﬁc Knowledge from BERT into Simple Neural Networks</p><p>可转移域的端到端选择性对抗学习的Aspect-based情感分析(2019年10)<br><a href="https://zhuanlan.zhihu.com/p/268320982">https://zhuanlan.zhihu.com/p/268320982</a><br>Transferable End-to-End Aspect-based Sentiment Analysis with Selective Adversarial Learning</p><p>联合Aspect-Sentiment主题嵌入的弱监督的情感分析(2020年10)<br><a href="https://zhuanlan.zhihu.com/p/267744626">https://zhuanlan.zhihu.com/p/267744626</a><br>Weakly-Supervised Aspect-Based Sentiment Analysis via Joint Aspect-Sentiment Topic Embedding</p><p>观点目标提取和情感预测的统一模型(2019年)<br><a href="https://zhuanlan.zhihu.com/p/268580604">https://zhuanlan.zhihu.com/p/268580604</a><br>A Uniﬁed Model for Opinion Target Extraction and Target Sentiment Prediction</p><p>用于目标情感分类的注意力编码器网络(2019年04）<br><a href="https://zhuanlan.zhihu.com/p/270374318">https://zhuanlan.zhihu.com/p/270374318</a><br>Attentional Encoder Network for Targeted Sentiment Classiﬁcation</p><p>评测BERT类细粒度情感分类的语言表示模型(2020.05)<br><a href="https://zhuanlan.zhihu.com/p/268012476">https://zhuanlan.zhihu.com/p/268012476</a><br>Language Representation Models for Fine-Grained Sentiment Classiﬁcation</p><p>利用BERT进行端到端aspect-based的情感分析(2019年10）<br><a href="https://zhuanlan.zhihu.com/p/268801608">https://zhuanlan.zhihu.com/p/268801608</a><br>Exploiting BERT for End-to-End Aspect-based Sentiment Analysis</p><p>Aspect-level基于注意力的LSTM 情感分类(2016年)<br><a href="https://zhuanlan.zhihu.com/p/267254311">https://zhuanlan.zhihu.com/p/267254311</a><br>Attention-based LSTM for Aspect-level Sentiment Classification</p><p>BERT-EMD：多层对多层映射的BERT蒸馏（2020年10月）<br><a href="https://zhuanlan.zhihu.com/p/266602585">https://zhuanlan.zhihu.com/p/266602585</a><br>BERT-EMD: Many-to-Many Layer Mapping for BERT Compression with Earth Mover’s Distance</p><p>媲美GPT-3的变种PET模型(2020年9月论文)<br><a href="https://zhuanlan.zhihu.com/p/265646470">https://zhuanlan.zhihu.com/p/265646470</a><br>It’s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners</p><p>PRADO: 移动设备上的投影注意力文本分类网络(2019年论文)<br><a href="https://zhuanlan.zhihu.com/p/265042724">https://zhuanlan.zhihu.com/p/265042724</a><br>PRADO: Projection Attention Networks for Document Classiﬁcation On-Device</p><p>图神经网络的图归一化(2020.09论文)<br><a href="https://zhuanlan.zhihu.com/p/260811611">https://zhuanlan.zhihu.com/p/260811611</a><br>Learning Graph Normalization for Graph Neural Network</p><p>基于无标签数据Copy-Augmented预训练结构改善语法纠错(2019.06)<br><a href="https://zhuanlan.zhihu.com/p/258091623">https://zhuanlan.zhihu.com/p/258091623</a><br>Improving Grammatical Error Correction via Pre-Training a Copy-Augmented Architecture with Unlabeled Data</p><p>多层卷积编解码器神经网络语法纠错(2018.01论文)<br><a href="https://zhuanlan.zhihu.com/p/248000441">https://zhuanlan.zhihu.com/p/248000441</a><br>A Multilayer Convolutional Encoder-Decoder Neural Network for Grammatical Error Correction</p><p>近域微调的图片表格检测模型<br><a href="https://zhuanlan.zhihu.com/p/248393029">https://zhuanlan.zhihu.com/p/248393029</a><br>The Beneﬁts of Close-Domain Fine-Tuning for Table Detection in Document Images</p><p>IBM基于图片格式的表格识别(2020年03月论文)<br><a href="https://zhuanlan.zhihu.com/p/245032050">https://zhuanlan.zhihu.com/p/245032050</a><br>Image-based table recognition: data, model, and evaluation</p><p>FASPell基于DAE解码器的Spell Checker（2019.09）<br><a href="https://zhuanlan.zhihu.com/p/231626818">https://zhuanlan.zhihu.com/p/231626818</a><br>FASPell: A Fast, Adaptable, Simple, Powerful Chinese Spell Checker Based On DAE-Decoder Paradigm</p><p>个性化语法错误​​纠正（2020.06论文）<br><a href="https://zhuanlan.zhihu.com/p/231190671">https://zhuanlan.zhihu.com/p/231190671</a><br>Personalizing Grammatical Error Correction: Adaptation to Proficiency Level and L1</p><p>Reformer: 搞笑（高效）的transformer结构(2020年2月Google)<br><a href="https://zhuanlan.zhihu.com/p/208134502">https://zhuanlan.zhihu.com/p/208134502</a><br>REFORMER: THE EFFICIENT TRANSFORMER</p><p>2阶段中文纠错模型(2019论文)<br><a href="https://zhuanlan.zhihu.com/p/199551915">https://zhuanlan.zhihu.com/p/199551915</a><br>A Two-Stage Model for Chinese Grammatical Error Correction</p><p>CLUENER2020 2020年汉语NER和Benchmark<br><a href="https://zhuanlan.zhihu.com/p/197488236">https://zhuanlan.zhihu.com/p/197488236</a><br>CLUENER2020: FINE-GRAINED NAMED ENTITY RECOGNITION DATASET AND BENCHMARK FOR CHINESE</p><p>Google 最新 NLP语言模型可解释性可视化分析工具（2020-8月论文）<br><a href="https://zhuanlan.zhihu.com/p/188617204">https://zhuanlan.zhihu.com/p/188617204</a><br>The Language Interpretability Tool: Extensible, Interactive Visualizations and Analysis for NLP Models</p><p>聊天机器人架构设计和开发2-架构和设计（论文By Jack Cahn )<br><a href="https://zhuanlan.zhihu.com/p/181491658">https://zhuanlan.zhihu.com/p/181491658</a><br>CHATBOT: Architecture, Design, &amp; Development By Jack Cahn</p><p>DocBert Bert用作文档分类(2019年8月论文)<br><a href="https://zhuanlan.zhihu.com/p/180475198">https://zhuanlan.zhihu.com/p/180475198</a><br>DocBERT: BERT for Document Classification</p><p>TableBank：用于表检测和识别的基准数据集<br><a href="https://zhuanlan.zhihu.com/p/170365926">https://zhuanlan.zhihu.com/p/170365926</a><br>TableBank: A Benchmark Dataset for Table Detection and Recognition</p><p>LayoutLM 微软预训练模型图片类文档分类和实体识别(2020年6月论文)<br><a href="https://zhuanlan.zhihu.com/p/166128964">https://zhuanlan.zhihu.com/p/166128964</a><br>LayoutLM: Pre-training of Text and Layout for Document Image Understanding</p><p>UNILM 微软预训练的NLU和NLG结合模型(2019-10论文)<br><a href="https://zhuanlan.zhihu.com/p/164736442">https://zhuanlan.zhihu.com/p/164736442</a><br>Unified Language Model Pre-training for Natural Language Understanding and Generation</p><p>DIET模型 rasa 聊天机器人核心模型论文（2020年5月论文)<br><a href="https://zhuanlan.zhihu.com/p/162995854">https://zhuanlan.zhihu.com/p/162995854</a><br>Dual Intent and Entity Transformer</p><p>NLP之MixText 半监督文本分类(2020年4月论文解读)<br><a href="https://zhuanlan.zhihu.com/p/156091468">https://zhuanlan.zhihu.com/p/156091468</a><br>MixText: Linguistically-Informed Interpolation of Hidden Space for Semi-Supervised Text Classification</p><p>NLP 之数据增强算法(论文解读-2019年论文)<br><a href="https://zhuanlan.zhihu.com/p/152633064">https://zhuanlan.zhihu.com/p/152633064</a><br>EDA: Easy Data Augmentation Techniques for Boosting Performance onText Classification Tasks</p><p>TFIDF+Wordembedding无监督多标签文本分类算法（论文解读)<br><a href="https://zhuanlan.zhihu.com/p/152526817">https://zhuanlan.zhihu.com/p/152526817</a><br>Improving Recall and Precision in Unsupervised Multi-Label Document Classifification Tasks by Combining Word Embeddings with TF-IDF</p><p>评估对于少量样本使用Bert进行fine-tunning的优化方法（论文解读)<br><a href="https://zhuanlan.zhihu.com/p/152523646">https://zhuanlan.zhihu.com/p/152523646</a><br>Revisiting Few-sample BERT Fine-tuning</p><p>SYNTHESIZER代替self-attention机制（Google论文解读)<br><a href="https://zhuanlan.zhihu.com/p/152518921">https://zhuanlan.zhihu.com/p/152518921</a><br>Rethinking Self-Attention in Transformer Models</p>]]></content>
    
    
    <categories>
      
      <category>知乎</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>apex兼容torch1.10时的一个bug</title>
    <link href="/2022/03/08/apex%E7%9A%84%E4%B8%80%E4%B8%AAbug/"/>
    <url>/2022/03/08/apex%E7%9A%84%E4%B8%80%E4%B8%AAbug/</url>
    
    <content type="html"><![CDATA[<h1 id="关于apex的一个bug"><a href="#关于apex的一个bug" class="headerlink" title="关于apex的一个bug"></a>关于apex的一个bug</h1><p>具体报错内容如下:</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">    <span class="hljs-keyword">if</span> cached_x<span class="hljs-selector-class">.grad_fn</span><span class="hljs-selector-class">.next_functions</span><span class="hljs-selector-attr">[1]</span><span class="hljs-selector-attr">[0]</span><span class="hljs-selector-class">.variable</span> is not x:<br>IndexError: tuple index out of range<br></code></pre></td></tr></table></figure><p>先说具体的官方的issue和解决方法<br><a href="https://github.com/NVIDIA/apex/issues/1227">https://github.com/NVIDIA/apex/issues/1227</a><br><a href="https://github.com/NVIDIA/apex/issues/694#issuecomment-918833904">https://github.com/NVIDIA/apex/issues/694#issuecomment-918833904</a></p><p>zwithz用户已经指出应该修改这个文件，但是后面的用户classicsong说这个方法是有问题的</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs csharp">apex/amp/utils.py<br><span class="hljs-meta"># change this <span class="hljs-keyword">line</span> (<span class="hljs-keyword">line</span> 113)</span><br>- <span class="hljs-keyword">if</span> cached_x.grad_fn.next_functions[<span class="hljs-number">1</span>][<span class="hljs-number">0</span>].variable <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> x:<br><span class="hljs-meta"># 改成如下:</span><br>+ <span class="hljs-keyword">if</span> cached_x.grad_fn.next_functions[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>].variable <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> x:<br></code></pre></td></tr></table></figure><p>其实zwithz说的是对的，这是apex的一个bug<br>不同版本的torch的grad_fn数量</p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs nix"><span class="hljs-built_in">import</span> torch<br>print(torch.__version__)<br><span class="hljs-attr">x</span> = torch.ones(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-attr">requires_grad=True)</span><br><span class="hljs-attr">y</span> = x + <span class="hljs-number">2</span><br><span class="hljs-attr">z</span> = y * y * <span class="hljs-number">3</span><br><span class="hljs-attr">out</span> = z.mean()<br><span class="hljs-attr">half</span> = out.half()<br>print(len(half.grad_fn.next_functions))<br></code></pre></td></tr></table></figure><ul><li>1.7 版本</li></ul><p>1.7.0+cu110<br>2</p><ul><li>1.8版本</li></ul><p>1.8.0.post3<br>2</p><ul><li>1.9版本</li></ul><p>1.9.0+cu111<br>2</p><ul><li>1.10版本</li></ul><p>1.10.2<br>1</p><h2 id="关于grad-fn"><a href="#关于grad-fn" class="headerlink" title="关于grad_fn"></a>关于grad_fn</h2><p>grad_fn保存了链式计算的图<br>创建一个张量并设置requires_grad&#x3D;True, 那么这个tensor经过计算后的值都会写携带grad_fn属性，，用来追踪计算历史<br>Autograd是反向自动微分系统。从概念上讲，autograd记录了一个图，记录了你执行运算时产生数据的所有运算，给你一个有向无<br>环图，其叶子是输入张量，根是输出张量。通过追踪这个图从根到叶，你可以使用链式规则自动计算梯度。<br>在内部，autograd将这个图表示为Function对象的图（真正的表达式），autograd建立一个代表计算梯度的函数的图（每个torch.Tensor的.grad_fn属性是这个图的入口）。当前向传播完成后，我们在反向传播中评估这个图以计算梯度。</p><h2 id="官方示例"><a href="#官方示例" class="headerlink" title="官方示例"></a>官方示例</h2><p>如果你有一个模型，你按照损失的方向，使用它的.grad_fn属性，你会看到一个计算的图，看起来像这样。</p><figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs xl"><span class="hljs-function"><span class="hljs-title">input</span> -&gt;</span> <span class="hljs-function"><span class="hljs-title">conv2d</span> -&gt;</span> <span class="hljs-function"><span class="hljs-title">relu</span> -&gt;</span> <span class="hljs-function"><span class="hljs-title">maxpool2d</span> -&gt;</span> <span class="hljs-function"><span class="hljs-title">conv2d</span> -&gt;</span> <span class="hljs-function"><span class="hljs-title">relu</span> -&gt;</span> maxpool2d<br>      -&gt; <span class="hljs-function"><span class="hljs-title">flatten</span> -&gt;</span> <span class="hljs-function"><span class="hljs-title">linear</span> -&gt;</span> <span class="hljs-function"><span class="hljs-title">relu</span> -&gt;</span> <span class="hljs-function"><span class="hljs-title">linear</span> -&gt;</span> <span class="hljs-function"><span class="hljs-title">relu</span> -&gt;</span> linear<br>      -&gt; MSELoss<br>      -&gt; loss<br>因此，当我们调用loss.backward()时，整个图被微分，并且图中所有require_grad=True的张量都会有其.grad张量的梯度积累。<br>print(loss.grad_fn)  # MSELoss<br>print(loss.grad_fn.next_functions[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>])  # Linear<br>print(loss.grad_fn.next_functions[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>].next_functions[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>])  # ReLU<br>------&gt;<br>&lt;MseLossBackward0 object <span class="hljs-built_in">at</span> <span class="hljs-number">0</span>x7f09e8c788d0&gt;<br>&lt;AddmmBackward0 object <span class="hljs-built_in">at</span> <span class="hljs-number">0</span>x7f09e8c78978&gt;<br>&lt;AccumulateGrad object <span class="hljs-built_in">at</span> <span class="hljs-number">0</span>x7f09e8c78978&gt;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>torch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>apex</tag>
      
      <tag>fp16</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>信息提取的方式总结</title>
    <link href="/2022/03/08/%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96/"/>
    <url>/2022/03/08/%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96/</url>
    
    <content type="html"><![CDATA[<h1 id="信息抽取"><a href="#信息抽取" class="headerlink" title="信息抽取"></a>信息抽取</h1><p>信息抽取是构建知识图谱的关键一环，目前已实现了3种抽取的方式测试，发现了一些注意事项，总结如下:</p><img src="/2022/03/08/%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96/%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E6%80%BB%E7%BB%93.png" class="">]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>信息抽取</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>显存优化技术盘点</title>
    <link href="/2022/03/04/gpu-optimizer/"/>
    <url>/2022/03/04/gpu-optimizer/</url>
    
    <content type="html"><![CDATA[<h1 id="显存优化技术"><a href="#显存优化技术" class="headerlink" title="显存优化技术"></a>显存优化技术</h1><p>本思维导图总结了显存的占用的分为哪些部分，训练时的流程，和多GPU训练的分类。</p><img src="/2022/03/04/gpu-optimizer/%E6%98%BE%E5%AD%98%E4%BC%98%E5%8C%96%E6%8A%80%E6%9C%AF.png" class="">]]></content>
    
    
    <categories>
      
      <category>cuda</category>
      
    </categories>
    
    
    <tags>
      
      <tag>显存</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>一次pycharm在使用torch Dataloader进行debug时卡住</title>
    <link href="/2022/03/01/pycharm-debug/"/>
    <url>/2022/03/01/pycharm-debug/</url>
    
    <content type="html"><![CDATA[<h1 id="pycharm-debug可能卡住的原因有很多，其中之一是多进程导致的-尤其是我们在使用torch的DataLoader时，如果发生卡住，那么只需检查num-workers是否是0，即可"><a href="#pycharm-debug可能卡住的原因有很多，其中之一是多进程导致的-尤其是我们在使用torch的DataLoader时，如果发生卡住，那么只需检查num-workers是否是0，即可" class="headerlink" title="pycharm debug可能卡住的原因有很多，其中之一是多进程导致的, 尤其是我们在使用torch的DataLoader时，如果发生卡住，那么只需检查num_workers是否是0，即可"></a>pycharm debug可能卡住的原因有很多，其中之一是多进程导致的, 尤其是我们在使用torch的DataLoader时，如果发生卡住，那么只需检查num_workers是否是0，即可</h1><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs routeros">DataLoader(<br>    dataset,<br>    <span class="hljs-attribute">batch_size</span>=1,<br>    <span class="hljs-attribute">shuffle</span>=<span class="hljs-literal">False</span>,<br>    <span class="hljs-attribute">sampler</span>=None,<br>    <span class="hljs-attribute">batch_sampler</span>=None,<br>    <span class="hljs-attribute">num_workers</span>=0,<br>    <span class="hljs-attribute">collate_fn</span>=None,<br>    <span class="hljs-attribute">pin_memory</span>=<span class="hljs-literal">False</span>,<br>    <span class="hljs-attribute">drop_last</span>=<span class="hljs-literal">False</span>,<br>    <span class="hljs-attribute">timeout</span>=0,<br>    <span class="hljs-attribute">worker_init_fn</span>=None,<br>    <span class="hljs-attribute">multiprocessing_context</span>=None,<br>)<br>参数:<br>- dataset : 数据集<br>- batch_size: 批次大小<br>- shuffle: 是否乱序<br>- sampler: 样本采样函数，一般无需设置。<br>- batch_sampler: 批次采样函数，一般无需设置。<br>- num_workers: 使用多进程读取数据，设置的进程数。<br>- collate_fn: 整理一个批次数据的函数。<br>- pin_memory: 是否设置为锁业内存。默认为<span class="hljs-literal">False</span>，锁业内存不会使用虚拟内存(硬盘)，从锁业内存拷贝<br>到GPU上速度会更快。<br>- drop_last: 是否丢弃最后一个样本数量不足batch_size批次数据。<br>- timeout: 加载一个数据批次的最长等待时间，一般无需设置。<br>- worker_init_fn: 每个worker中dataset的初始化函数，常用于 IterableDataset。一般不使用<br></code></pre></td></tr></table></figure><p>根据API可知，num_workers是设置读取数据的并发进程数量，而根据pycharm的官方的issue，<a href="https://youtrack.jetbrains.com/issue/PY-39489%EF%BC%8C%E6%88%91%E4%BB%AC%E5%8F%91%E7%8E%B0pycharm%E5%A4%9A%E8%BF%9B%E7%A8%8B%E7%9A%84debug%E6%9C%89%E6%97%B6%E5%B9%B6%E4%B8%8D%E5%A4%AA%E6%96%B9%E4%BE%BF%EF%BC%8C%E6%89%80%E4%BB%A5%E5%8F%AA%E9%9C%80%E5%9C%A8debug%E6%97%B6%EF%BC%8C%E4%BF%AE%E6%94%B9num_workers%E5%8D%B3%E5%8F%AF%EF%BC%8C%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E5%9C%A8%E6%94%B9%E5%9B%9E%E6%9D%A5%E5%B0%B1%E8%A1%8C%E3%80%82">https://youtrack.jetbrains.com/issue/PY-39489，我们发现pycharm多进程的debug有时并不太方便，所以只需在debug时，修改num_workers即可，生产环境在改回来就行。</a></p>]]></content>
    
    
    <categories>
      
      <category>ide</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>多标签分类的2种简单实现</title>
    <link href="/2022/02/28/multilabel/"/>
    <url>/2022/02/28/multilabel/</url>
    
    <content type="html"><![CDATA[<h1 id="模型的损失函数"><a href="#模型的损失函数" class="headerlink" title="模型的损失函数"></a>模型的损失函数</h1><p>torch.nn.BCEWithLogitsLoss<br>先进行了sigmoid，然后进行了二分类交叉熵损失函数</p><h1 id="评估metric"><a href="#评估metric" class="headerlink" title="评估metric"></a>评估metric</h1><p>hamming score<br>sklearn.metrics.multilabel_confusion_matrix   #多标签混淆矩阵</p><p>#hamming score<br>示例</p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs nix"><span class="hljs-built_in">import</span> numpy as np<br><span class="hljs-attr">truth</span> = [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>] <span class="hljs-comment"># 真实值</span><br><span class="hljs-attr">prediction</span> = [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]  <span class="hljs-comment">#预测值</span><br><span class="hljs-attr">truth</span> = np.array(truth)<br><span class="hljs-attr">prediction</span> = np.array(prediction)<br><span class="hljs-attr">num_classes</span> = len(truth)<br><span class="hljs-attr">num_samples</span> = <span class="hljs-number">1</span><br><span class="hljs-attr">numerator</span> = float(sum(truth &amp; prediction))<br><span class="hljs-attr">denominator</span> = float(sum(truth | prediction))<br><span class="hljs-attr">hamming_score</span> = numerator / denominator<br>------&gt;<br><span class="hljs-number">0.667</span><br>如果是按照准确率计算accuracy_score(truth, prediction)，那么是<span class="hljs-number">0.8</span><br></code></pre></td></tr></table></figure><p>我们的输出是一个批次的，所以是二维的，计算的方法是: score&#x3D;((predicts &amp; labels).sum(axis&#x3D;1) &#x2F; (predicts | labels).sum(axis&#x3D;1)).mean()</p><h1 id="实现方式1：-使用CLS进行分类"><a href="#实现方式1：-使用CLS进行分类" class="headerlink" title="实现方式1： 使用CLS进行分类"></a>实现方式1： 使用CLS进行分类</h1><p>假设我们的示例是商品的购买意向，模型的基本输入是：CLS+句子1+SEP+商品+SEP<br>对CLS进行求sigmoid和二分类交叉熵<br>模型实现逻辑：</p><ol><li>Bert模型编码, last_hidden_state, all_hidden_states &#x3D; self.encode(input_ids, token_type_ids, attention_mask)</li><li>取最后一个隐藏层的CLS向量, first_token_tensor &#x3D; hidden_states[:, 0]  </li><li>进行dropout, self.dropout(first_token_tensor)</li><li>加个全连接层和激活</li><li>线性层映射到标签个数，得到logits, nn.Linear(hidden_size, num_labels)</li><li>计算损失, 反向传播,更新参数</li></ol><h1 id="实现方式2：-每个标签类别向量进行分类"><a href="#实现方式2：-每个标签类别向量进行分类" class="headerlink" title="实现方式2： 每个标签类别向量进行分类"></a>实现方式2： 每个标签类别向量进行分类</h1><p>假设我们的示例是商品的购买意向, 模型的基本输入是: CLS+句子1+SEP+商品+每个标签的id+SEP<br>取出每个标签的向量<br>对每个标签向量进行二分类交叉熵损失<br>模型实现逻辑：</p><ol><li>注意我们在输入的末尾添加了每个标签的id, 所以需要用特殊的token表示这些id, 所以需要增加词表，tokenizer.add_special_tokens({‘additional_special_tokens’:’opinion1’}) 我们用opinion1代表第一个标签，opinion2代表第二个标签，分别都加入到vocab中</li><li>注意在处理数据时，我们还有生成label_mask参数，告知我们关注的label的位置在哪里</li><li>Bert模型编码, last_hidden_state, all_hidden_states &#x3D; self.encode(input_ids, token_type_ids, attention_mask)</li><li>hidden_states 形状 [batch_size, seq_len, last_hidden_size] –&gt; [batch_size, labels_num, last_hidden_size]  加一个维度，然后扩充到hidden_states形状，方便后面取出label_mask需要的维度数据 label_mask_expand &#x3D; label_mask.unsqueeze(-1).expand(hidden_states.size())<br> labels_token_tensor_1d &#x3D; torch.masked_select(hidden_states, (label_mask_expand &#x3D;&#x3D; 1))<br>labels_token_tensor &#x3D; labels_token_tensor_1d.view(batch_size, -1, last_hidden_size)</li><li>加个droput, 全连接层和激活 </li><li>分类层, 最后变成1维度，nn.Linear(hidden_size, 1)</li><li>logits &#x3D; logits.squeeze(-1), 去掉最后一次，得到[batch_size, num_labels] 形状</li><li>计算损失, 反向传播,更新参数</li></ol>]]></content>
    
    
    <categories>
      
      <category>模型</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分类</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>一些论文中的专有名词</title>
    <link href="/2022/02/24/paper-word/"/>
    <url>/2022/02/24/paper-word/</url>
    
    <content type="html"><![CDATA[<h1 id="一些论文中的专有名词的解释或缩写"><a href="#一些论文中的专有名词的解释或缩写" class="headerlink" title="一些论文中的专有名词的解释或缩写"></a>一些论文中的专有名词的解释或缩写</h1><ul><li>low-resource:低资源:有标签或者无标签的训练的数据资源不足</li><li>Distant supervision:远端监督:大多数机器学习技术都需要一组训练数据。收集训练数据的传统方法是让人们标签一组文档。例如，对于婚姻关系，人类标注者可以将“比尔·克林顿”和“希拉里·克林顿”对标签为正的训练样本。这种方法在时间和金钱上都是昂贵的，并且如果我们的语料库很大，将无法产生足够的数据供我们的算法使用。而且由于人为错误，因此产生的训练数据极有可能是噪音的。生成训练数据的另一种方法是远距离监督(远程监督)。在远距离监督中，我们利用一个已经存在的数据库来收集要提取的关系的样本。然后，我们使用这些样本自动生成我们的训练数据。例如，包含巴拉克·奥巴马和米歇尔·奥巴马已婚的事实。我们考虑到这一事实，然后将出现在同一句子中的每对“巴拉克·奥巴马”和“米歇尔·奥巴马”都标签为我们婚姻关系的一个正例子。这样，我们可以轻松生成大量(可能是噪音的)训练数据。运用远距离监督来获得特定关系的正样本很容易，但是产生负样本比较难.即用知识库KG来获取2个实体之间的关系。</li><li>tokenization:分词器:原始raw text叫语料，字典中的单独词叫token，可能是单词，也可能是词语，取决于字典，tokenization是把raw text变成token的过程，假如英语就是把句子用空格切分，每个单词就叫token</li><li>detokenization:分词还原: 就是还原，把分词还原成句子，或者把分词后得到的id还原成原来的句子。</li><li>soft label:软标签:是一个teacher模型预测出来的，类似logits的概率值，是浮点数</li><li>hard label:硬标签:硬标签直接就是整数，就是对应概率最大的位置的索引，例如soft是0.82, hard就是1, <a href="https://arxiv.org/abs/1511.06335">https://arxiv.org/abs/1511.06335</a></li><li>SOTA:state-of-the-art:业界最新的性能，达到最新的模型性能</li><li>FLOPS:floating point operations per second:每秒浮动计算数, 是衡量计算机计算性能的一个指标</li><li>MLM:Masked language modeling, 掩盖语言建模, 也被叫做完形填空测试,cloze test,MLM的任务是根据占位符预测序列中的丢失token</li><li>T5: Text-to-Text Transfer Transformer</li><li>warm-up: 调整学习率的方式，在warm-up步数之前的学习率是恒定或者按照一定规则变大，warm-up之后的步数指数方式衰减和线性衰减</li><li>corruption损坏: 破坏一个原有的句子，例如BERT的MLM的无监督目标，可以对一个句子进行丢弃，替换，交换，添加操作，改变原有语句，然后让模型预测原有句子或改变的部分</li><li>域内数据: 就是一个领域的数据，例如新闻领域的文章和论文领域里的文章是不一样的,他们就是不同的域</li><li>pre-train-then-ﬁne-tune: 首先预训练模型，然后微调模型，预训练模型一般用大量数据做无监督训练，微调模型是用少量数据有监督训练</li><li>零样本学习(zero-shot learning): 即使训练时没有看到目标训练集，也能进行进行模型预测,零次训练或推理,无须训练，直接进行预测或推理。是一种训练策略，它允许机器学习模型预测新的类别，而不需要为新的类别提供任何标注的样本。</li><li>Few-Shot: 少量训练样本进行学习，然后预测，类似于low-resource</li><li>图灵完备性（Turing Completeness）:是针对一套数据操作规则而言的概念。数据操作规则可以是一门编程语言，也可以是计算机里具体实现了的指令集。当这套规则可以实现图灵机模型里的全部功能时，就称它具有图灵完备性。直白一点说，图灵完备性就是我给你一工具箱的东西，包括无限内存、if&#x2F;else 控制流、while 循环; 简单来讲，一切可计算的问题都能计算，这样的虚拟机或者编程语言就叫图灵完备的;举个例子，如果有人说，我的东西是图灵完备的，也就意味着理论上它能够用来解决任何计算性的问题。</li><li>有限状态机（英语：finite-state machine，缩写：FSM）又称有限状态自动机（英语：finite-state automation，缩写：FSA），简称状态机，是表示有限个状态以及在这些状态之间的转移和动作等行为的数学计算模型。</li><li>RE:relation extraction,neural relation extraction (NRE),  从一个句子中判断两个entity是否有关系，一般是一个二分类问题，指定某种关系。</li><li>Entity Mentions: 实体提及,就是句子中的实体, “New York City is good”  New York City就是实体，或者实体提及, 就是实体的名字</li><li>KGs: Knowledge Graph, 知识图谱</li><li>Autograd: 自动微分是训练神经网络的一种机制,自动求导，计算梯度</li><li>Segment: 片段，或者称为句子a，句子b等，例如训练BERT时结构如,“[CLS] x1 [SEP] x2 [SEP]”，x1表示片段1，或句子a，x2表示片段2或句子b。</li><li>Intrinsic tasks vs Downstream Tasks: 固有任务和下游任务，固有任务意思是预训练语言模型时的任务，下游任务是微调模型时的任务。</li><li>WordPiece: 是在自然语言处理中使用的子词分割算法。BERT用的此方法。子词分词的一种方法。 用该语言中的各个字符初始化单词表，然后将单词表中最常见的符号组合迭代添加到单词表中。 该过程是：1.用文本中的所有字符初始化单词清单。2.使用来自上一步的清单在训练数据上构建语言模型。 3. 通过组合当前单词清单中的两个单元, 将单词组装一个单词单元。 在添加到模型中时，从所有可能增加训练数据可能性中选择一个新的词单元。 4. 转到2，直到达到预定义的词单元限制或可能性增加低于某个特定阈值。</li><li>NMT:  Neural machine translation,神经机器翻译, 利用深度神经网络执行的端到端的翻译，例如seq2seq的神经网络翻译。</li><li>SMT: statistical machine translation,传统机器翻译的方法。</li><li>non-segmented语言: 分段语言，即用空格分隔的语言，例如英语，非分段语言，例如中文，日语，韩语。</li><li>NFD:Normalization Form Canonical Decomposition标准化形式规范分解,Unicode字符串标准化的一种算法,字符通过规范等价分解，并且多个组合字符按特定顺序排列</li><li>NFC:Normalization Form Canonical Composition 标准化形式规范组合,Unicode字符串标准化的一种算法, 字符被分解，然后通过规范对等重新组合。 </li><li>NFKD: Normalization Form Compatibility Decomposition: 标准化形式兼容性分解,字符通过兼容性分解，并且多个组合字符按特定顺序排列。 </li><li>NFKC: Normalization Form Compatibility Composition: 标准化形式兼容性组成,字符通过兼容性分解，然后通过规范对等重组。所有这些算法都是幂等转换，这意味着如果以相同算法再次处理，已经处于这些标准化形式之一的字符串将不会被修改。 </li><li>RBT3：由RoBERTa-wwm-ext 3层进行初始化，继续训练了1M步,RBT的名字是RoBERTa三个音节首字母组成，L代表large模型</li><li>RBTL3: 3层RoBERTa-wwm-ext-base&#x2F;large,由RoBERTa-wwm-ext-large 3层进行初始化，继续训练了1M步</li><li>ONNX: Open Neural Network Exchange format,开放式神经网络交换格式,提高模型推理速度的中间模型格式，最高实现4倍的推理加速。</li><li>ABSA: Aspect-based Sentiment Analysis, 给定句子中关心的情感的术语(aspect),即某个词在句子中表达的情感。等同于ALSC, Aspect level sentiment classification</li><li>Sentiment Analysis (SA): 也称为Opinion Mining (OM)</li><li>self-supervised: 类似于BERT的预训练模型的方式，也可以成为无监督,无监督表明我们确实没给BERT提供人工打标签，自监督表明它是用自己随机MASK部分token，然后预测被Mask的方式，所以叫做自监督。</li><li>context-gloss: 上下文的连贯性</li><li>LA-MLM: label-aware masked language model, 标签感知masked语言模型,分2个阶段Early Fusion早期融合和Late Supervision后期监督，它们的主要区别是早期融合阶段是把句子情感也作为输入，后期监督是把句子情感作为预测标签，监督训练句子情感。早期融合和后期监督的目的是让模型能够理解句子级情感和单词级情感和词性之间的内在联系。</li><li>parse tree: 分析树, 具体语法树（concrete syntax tree）,是一个反映某种形式语言字符串的语法关系的有根有序树。分析树一般按照两种相反的法则生成，一种是依存语法,一种是短语结构语法。二分类选举树,binary constituency tree</li><li>PLM: Pre-trained Language Models 预训练语言模型； 排列语言模型(Permutation Language Model) PLM, XLNet使用排列语言模型(PLM)</li><li>DRL: deep reinforcement learning</li><li>市场摩擦（英文：Market Friction）:是指金融资产在交易中存在的难度。它可由交易一定数量某金融资产的最佳占用时间来测定，也可由即时交易所需要的价格让步(Price concession)来测定。</li><li>inductive: 归纳式学习,transductive和inductive的区别在于我们想要预测的样本，是不是我们在训练的时候已经见（用）过的。inductive learning就是只根据现有的ABC，用比如kNN距离算法来预测，在来一个新的数据的时候，还是只根据5个ABC来预测。</li><li>transductive: 直推式学习,transductive learning直接以某种算法观察出数据的分布，这里呈现三个cluster，就根据cluster判定，不会建立一个预测的模型，如果一个新的数据加进来 就必须重新算一遍整个算法，新加的数据也会导致旧的已预测问号的结果改变</li><li>NRE: Neural Relation Extraction Models 神经网络的关系抽取模型</li><li>PCNN: PCNN（Piece-Wise-CNN）</li><li>OMR: 光学音乐识别(OPTICAL MUSIC Recognition，OMR)是将乐谱的扫描图像转换为像MusicXML[9]或MIDI这样的符号代表的问题。这种解决方案有很多明显的实际应用。</li><li>on-policy: 强化学习可以分为off-policy和on-policy的方法。off-policy RL算法意味着用于选择动作的行为策略与学习策略不同。相反，在on-policy RL算法中，行为策略与学习策略是相同的。此外，强化学习还可以分为基于价值的方法和基于策略的方法。在基于价值的RL中，agent更新价值函数来学习合适的策略，而基于策略的RL agent直接学习策略。</li><li>Hierarchical reinforcement learning (HRL): 分层强化学习</li><li>ALE: Atari Learning Environment</li><li>rollout:（就相当于在一个棋局时尝试多次不同路径的走子）类似右图产生多条路径</li><li>Imitation Learning: IL 模仿学习，模仿学习的思想很直观(intuitive)。我们在前面所介绍的Model-free, Model-based强化学习方法都是从零开始(from scratch)探索并学习一个使累计回报最大的策略(policy) [公式] 。 Imitation Learning的想法是，借助人类给出的示范(demonstration)，可以快速地达到这个目的。</li><li>• Forward model: (st, at) → st+1. 前向模型。(st, at) → st+1. 这是在给定当前状态和所选动作的情况下预测下一个状态。这是目前最常见的模型类型，可用于前向规划。</li><li>• Backward&#x2F;reverse model: st+1 → (st, at).  反向模型：st+1 →（st，at）。这个模型预测了哪些状态是某一特定状态的可能前兆。因此，我们可以在反向的方向上进行规划，例如，在prioritized sweeping中就使用了这种方法（Moore和Atkeson，1993）。</li><li>• Inverse model: (st, st+1) → at.  逆向模型。(st, st+1) → at. 逆向模型预测从一个状态到另一个状态需要哪种行动。例如，它被用于RRT规划中（LaValle，1998）。正如我们稍后将看到的那样，这个函数也可以作为表示学习的一部分。</li><li>NP-hard: NP是指非确定性多项式（non-deterministic polynomial，缩写NP）。所谓的非确定性是指，可用一定数量的运算去解决多项式时间内可解决的问题。例如，著名的推销员旅行问题（Travel Saleman Problem or TSP）：假设一个推销员需要从香港出发，经过广州，北京，上海，…，等 n 个城市， 最后返回香港。 任意两个城市之间都有飞机直达，但票价不等。假设公司只给报销 C 元钱，问是否存在一个行程安排，使得他能遍历所有城市，而且总的路费小于 C？ 推销员旅行问题显然是 NP 的。因为如果你任意给出一个行程安排，可以很容易算出旅行总开销。但是，要想知道一条总路费小于 C 的行程是否存在，在最坏情况下，必须检查所有可能的旅行安排！ 这将是个天文数字。</li><li>P类问题：可以找到一个多项式时间复杂度的算法去解决的问题；</li><li>NEXPTIME-complete:如果一个决策问题在NEXPTIME中，那么它就是NEXPTIME完整的，而且NEXPTIME中的每个问题都有一个多项式时间的多对一还原。换句话说，有一种多项式时间的算法可以将一个问题的实例转化为另一个问题的实例，而且答案相同。NEXPTIME-complete的问题可以被认为是NEXPTIME中最难的问题。我们知道NEXPTIME-complete问题不在NP中；根据时间层次定理，已经证明这些问题不能在多项式时间内被验证。 一组重要的NEXPTIME-complete问题与简洁电路有关。简明电路是一种简单的机器，用于在指数级的空间内描述图形。它们接受两个顶点数字作为输入，并输出它们之间是否有一条边。如果在自然表示法（如邻接矩阵）中解决一个图的问题是NP-完全的，那么在简洁电路表示法中解决同样的问题是NEXPTIME-完全的，因为输入是指数级的小（在一些温和的条件下，NP-完全性的减少是通过 “投影 “实现的）。[2][3] 作为一个简单的例子，为一个如此编码的图寻找一个汉密尔顿路径是NEXPTIME-完全的。</li><li>MARL: Multi-Agent Reinforcement Learning 多agent强化学习</li><li>annealed: 退火，意思是超参数随着时间的逐渐变小，参数越来越小。例如强化学习中的Qleanring的Greedy系数。</li><li>优势函数:advantage function , 强化学习 优势函数(Advantage Function),优势函数表达在状态s下，某动作a相对于平均而言的优势。 从数量关系来看，就是随机变量相对均值的偏差。 使用优势函数是深度强化学习极其重要的一种策略，尤其对于基于policy的学习。优势函数其实就是将Q-Value“归一化”到Value baseline上，如上讨论的，这样有助于提高学习效率，同时使学习更加稳定；同时经验表明，优势函数也有助于减小方差，而方差过大导致过拟合的重要因素。Aπ(s,a)&#x3D;Qπ(s,a) - Vπ(s)</li><li>bitext: bidirectional text, 双向语料，即翻译的平行语料，例如中英文翻译语料库</li><li>Dec-POMDP: 一个完全合作的多agent任务可以被描述为一个分散的部分可观察马尔可夫决策过程（Dec-POMDP）</li><li>CTDE: 集中训练和分散执行（CTDE）Kraemer和Banerjee[2016]的范式允许学习过程利用额外的状态信息。CTDE允许学习算法访问所有局部行动观察直方图和全局状态，并共享梯度和参数。然后，在执行阶段，每个单独的agent只能访问其局部行动观察历史τi。</li><li>tile-coding: 强化学习理论扩展到了连续空间（连续空间的泛化）。tile-coding是连续空间强化学习问题中最实用和计算效率最高的工具。本质上，tile-coding是连续状态空间中的特征表示,tile-coding的主要优势之一是其计算效率。一个tiling的意思是一张大网，里面有划分成不同的小网，观察的像素会落到这个tiling中的小网内，就可以用这个小网内的坐标表示这个特征，多个tiling就是用多个小网内的坐标表示这个特征，就像self-attention的多头和卷积中的多个卷积核一样。<a href="https://towardsdatascience.com/reinforcement-learning-tile-coding-implementation-7974b600762b">https://towardsdatascience.com/reinforcement-learning-tile-coding-implementation-7974b600762b</a></li><li>domain adaptation for machine translation (DAMT): 半监督领域适应翻译</li><li>ROUGE-N:系统和参考摘要之间N-grams的重叠。</li><li>ROUGE-1:指的是系统和参考摘要之间的unigram（每个字）的重叠情况。</li><li>ROUGE-2:指的是系统和参考摘要之间的bigram重叠。</li><li>ROUGE-L:基于最长共同子序列（LCS）的统计。最长共同子序列问题自然考虑到了句子层面的结构相似性，并自动识别序列中最长的共同出现的n-grams。</li><li>ROUGE-W:基于加权的LCS统计，倾向于连续的LCSs。</li><li>ROUGE-S:基于 Skip-bigram 的共现统计。Skip-bigram是指任何一对词在其句子中的序列。</li><li>ROUGE-SU:基于 Skip-bigram 和 unigram 的共现统计。</li><li>MTL: Multi-task learning </li><li>SAN: 随机答案网络,用于问答系统，stochastic answer network, Stochastic answer networks for natural language inference</li><li>MTPE:  machine translation post-editing</li><li>MBRL: model-based的强化学习</li><li>CPM:Chinese Pretrained language Model 中文预训练模型</li><li>prompt-tuning:（p-tuning）</li><li>TrGCN: transformer图卷积网络</li><li>NED:命名实体消歧named entity disambiguation</li><li>ERD: Entity Relationship Diagram 实体关系图</li><li>ELBO:  Evidence Lower Bound，即证据下界,这里的证据指数据或可观测变量的概率密度。使用变分推断时，首先需要计算的便是ELBO。<a href="https://blog.csdn.net/qy20115549/article/details/93074519">https://blog.csdn.net/qy20115549/article/details/93074519</a></li><li>New Words Discovery: 新词发现</li><li>ACSA: Aspect category sentiment analysis, 基于属性类别的情感分析</li><li>ABSA: Aspect Based Sentiment Analysis, 基于属性的情感分析</li><li>ATSA: 等同于ABSA，aspect术语情感分析</li><li>capsule Network: 胶囊神经网络,是相对于CNN的改进，综合了CNN的优点的同时，考虑了CNN缺失的相对位置、角度等其他信息，从而使得识别效果有所提升。<a href="https://easyai.tech/ai-definition/capsule/">https://easyai.tech/ai-definition/capsule/</a></li><li>MRR: Mean Reciprocal Rank, 是一个国际上通用的对 搜索算法 进行评价的机制，即第一个结果匹配，分数为1，第二个匹配分数为0.5，第n个匹配分数为1&#x2F;n，如果没有匹配的句子分数为0,最终的分数为所有得分之和</li><li>ER: entity recognition 实体识别</li><li>EL: entity linking 实体链接</li><li>ED: entity disambiguation 实体消歧</li><li>EEs: emerging entities 新出现的实体</li><li>EED: emerging entity discovery 新实体发现,通过对知识库中现有的候选实体进行鉴别,KB外的实体称为新出现的实体。</li><li>BPR: Best Possible Recall</li><li>CMD: Central Moment Discrepancy, 最先进的分布相似度指标,过匹配两个表示的顺序矩差来衡量它们之间的差异,类似KL散度,可以执行高阶矩的明确匹配，而不需要昂贵的距离和核矩阵计算。CMD距离随着两个分布的相似性而变小。</li><li>平凡解: trivial solution, 编码器函数近似于一个不相关的但不具代表性的模态向量，就会出现平凡解的情况，防止平凡解, 经常用于结构非常简单的对象（比如群或拓扑空间），有时亦会用明显或乏趣这两个词代替，但对非数学工作者来说，它们有时可能比其他更复杂的对象更难想象或理解。例如： 明显因数：对于每个正整数 n 来说，1、-1、n 和 -n 都是它的明显因数。 空集：不包含任何元素的集合； 平凡群：只含单位元的群；</li><li>DETR: 端到端目标检测,End-to-end Object Detection with Transformer, 达到与Faster-RCNN等两阶段目标检测相当的性能。</li><li>FGM: Factor Graph Model, 因子图模型,是概率图模型的一种</li><li>IGL: Iterative Grid Labeling 迭代式网关标注方式</li><li>TSA: Text Similarity Approach 文本相似性技术</li><li>MLTC:multi-label text classification 多标签文本分类</li><li>XMC: Extreme multi-label text classification 极端多标签文本分类, 寻求从一个极端大的标签集合中为给定的文本输入找到相关的标签。许多现实世界的应用可以被表述为XMC问题，如推荐系统、文档tagging和语义搜索。</li><li>exposure bias: 暴露偏差:模型训练与预测过程之间的不匹配。在训练时每一个词输入都来自真实样本，但是在推断时当前输入用的却是上一个词的输入</li></ul>]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>知识图谱的构建思路</title>
    <link href="/2022/02/24/knowledge-graph/"/>
    <url>/2022/02/24/knowledge-graph/</url>
    
    <content type="html"><![CDATA[<h1 id="知识图谱"><a href="#知识图谱" class="headerlink" title="知识图谱"></a>知识图谱</h1><ol><li>众所周知，计算机的计算能力比人类强，但是推理能力远不如人类，所以构建知识图谱是为了解决计算机的推理能力。。</li><li>计算机的常识的使用能力也远不如人类，所以经常可以看到构建常识的知识图谱。</li><li>知识图谱在专业领域一般应用较多，例如医疗行业等。</li><li>知识图谱分为构建和应用，其中构建又包括设计本体，知识获取（结构化，非结构化，半结构化）知识存储，知识表示和知识融合等。如今构建知识图谱的技术已经很成熟，部分应用知识图谱的技术也已经成熟，例如利用知识图谱的问题等。</li></ol><img src="/2022/02/24/knowledge-graph/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png" class="">]]></content>
    
    
    <categories>
      
      <category>知识图谱</category>
      
    </categories>
    
    
    <tags>
      
      <tag>构建</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>torch和paddlepaddle的部分API对比</title>
    <link href="/2022/02/23/torch-paddle/"/>
    <url>/2022/02/23/torch-paddle/</url>
    
    <content type="html"><![CDATA[<h1 id="paddlepaddle代码和torch的模型代码相互转换-其实只需要关注这些api的不同，进行相应替换即可"><a href="#paddlepaddle代码和torch的模型代码相互转换-其实只需要关注这些api的不同，进行相应替换即可" class="headerlink" title="paddlepaddle代码和torch的模型代码相互转换, 其实只需要关注这些api的不同，进行相应替换即可"></a>paddlepaddle代码和torch的模型代码相互转换, 其实只需要关注这些api的不同，进行相应替换即可</h1><p>paddlepaddle 封装了类似torch， huggingface transformers 和datasets的接口形式</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-title">torch</span>包和paddle包的对比, 只列出不同的地方<br><span class="hljs-type">PyTorch</span> <span class="hljs-type">PaddlePaddle</span>    说明<br><span class="hljs-title">torch</span>.nn    paddle.nn   包括了神经网络相关的大部分函数<br><span class="hljs-title">nn</span>.<span class="hljs-type">Module</span>   nn.<span class="hljs-type">Layer</span>    搭建网络时集成的父类，包含了初始化等基本功能<br><span class="hljs-title">torch</span>.optim paddle.optimizer    训练优化器<br><span class="hljs-title">torch</span>.optim.<span class="hljs-type">AdamW</span>   paddle.optimizer.<span class="hljs-type">AdamW</span>  参数也不一样<br><span class="hljs-title">torchvision</span>.transforms  paddle.vision.transforms    数据预处理、图片处理<br><span class="hljs-title">torchvision</span>.datasets    paddle.vision.datasets  数据集的加载与处理<br><span class="hljs-title">nn</span>.<span class="hljs-type">Conv2d</span>   nn.<span class="hljs-type">Conv2D</span>   <span class="hljs-number">2</span>维卷积层<br><span class="hljs-title">nn</span>.<span class="hljs-type">BatchNorm2d</span>  nn.<span class="hljs-type">BatchNorm2D</span>  <span class="hljs-type">Batch</span> <span class="hljs-type">Normalization</span> 归一化<br><span class="hljs-title">nn</span>.<span class="hljs-type">MaxPool2d</span>    nn.<span class="hljs-type">MaxPool2D</span>    二维最大池化层<br><span class="hljs-title">nn</span>.<span class="hljs-type">AdaptiveAvgPool2d</span>    nn.<span class="hljs-type">AdaptiveAvgPool2D</span>    自适应二维平均池化（只用给定输出形状即可）<br><span class="hljs-title">torch</span>.flatten   paddle.flatten  展平处理<br><span class="hljs-title">torch</span>.softmax   paddle.softmax  softmax层<br><span class="hljs-title">datasets</span>.<span class="hljs-type">ImageFolder</span>    datasets.<span class="hljs-type">DatasetFolder</span>  指定数据集文件夹<br><span class="hljs-title">torch</span>.utils.<span class="hljs-class"><span class="hljs-keyword">data</span>.<span class="hljs-type">DataLoader</span> paddle.io.<span class="hljs-type">DataLoader</span>    加载数据集, 参数也不一样</span><br>(optimizer).no_grad (optimizer).zero_grad   梯度清零<br><span class="hljs-title">torch</span>.save  paddle.jit.save 说实话，这两个还是有点区别的，使用请看官方文档<br><span class="hljs-title">torch</span>.device    paddle.set_device   指定设备<br><span class="hljs-title">torch</span>.utils.<span class="hljs-class"><span class="hljs-keyword">data</span>.<span class="hljs-type">Dataset</span>    paddle.io.<span class="hljs-type">Dataset</span>   数据集</span><br><span class="hljs-title">torch</span>.utils.<span class="hljs-class"><span class="hljs-keyword">data</span>.<span class="hljs-type">RandomSampler</span>  paddle.io.<span class="hljs-type">RandomSampler</span></span><br><span class="hljs-title">torch</span>.utils.<span class="hljs-class"><span class="hljs-keyword">data</span>.<span class="hljs-type">BatchSampler</span>   paddle.io.<span class="hljs-type">BatchSampler</span>   参数也不一样</span><br><span class="hljs-title">torch</span>.utils.<span class="hljs-class"><span class="hljs-keyword">data</span>.<span class="hljs-type">DataLoader</span> paddle.io.<span class="hljs-type">DataLoader</span>  数据集加载</span><br><span class="hljs-title">tensor</span>.<span class="hljs-class"><span class="hljs-keyword">type</span>(<span class="hljs-title">torch</span>.<span class="hljs-title">float32</span>)  paddle.cast(<span class="hljs-title">mask</span>, &#x27;<span class="hljs-title">float32&#x27;</span>)  数据类型变更</span><br><span class="hljs-title">tensor</span>.cpu().item() tensor.numpy().item()  # 取出数据<br><span class="hljs-title">transformers</span>.get_linear_schedule_with_warmup    paddlenlp.transformers.<span class="hljs-type">LinearDecayWithWarmup</span>   # warmup 函数<br>也不一样<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>torch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>api</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NLP项目和论文搜索</title>
    <link href="/2022/02/22/NLP%E9%A1%B9%E7%9B%AE%E5%92%8C%E8%AE%BA%E6%96%87%E6%90%9C%E7%B4%A2/"/>
    <url>/2022/02/22/NLP%E9%A1%B9%E7%9B%AE%E5%92%8C%E8%AE%BA%E6%96%87%E6%90%9C%E7%B4%A2/</url>
    
    <content type="html"><![CDATA[<h1 id="NLP项目的一般解决思路"><a href="#NLP项目的一般解决思路" class="headerlink" title="NLP项目的一般解决思路"></a>NLP项目的一般解决思路</h1><img src="/2022/02/22/NLP%E9%A1%B9%E7%9B%AE%E5%92%8C%E8%AE%BA%E6%96%87%E6%90%9C%E7%B4%A2/%E5%A6%82%E4%BD%95%E5%81%9A%E4%B8%80%E4%B8%AAAI%E9%A1%B9%E7%9B%AE.png" class="">]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>一个小的子列表位置查找函数</title>
    <link href="/2022/02/22/python-list/"/>
    <url>/2022/02/22/python-list/</url>
    
    <content type="html"><![CDATA[<h1 id="sublist是original列表中的一部分，即子列表，如果存在sublist，那么就返回起始和结束位置，否则返回None"><a href="#sublist是original列表中的一部分，即子列表，如果存在sublist，那么就返回起始和结束位置，否则返回None" class="headerlink" title="sublist是original列表中的一部分，即子列表，如果存在sublist，那么就返回起始和结束位置，否则返回None"></a>sublist是original列表中的一部分，即子列表，如果存在sublist，那么就返回起始和结束位置，否则返回None</h1><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs vim">def index_partof_list(original, sublist):<br>    <span class="hljs-string">&quot;&quot;</span><span class="hljs-comment">&quot;</span><br>    子列表查找, 也可以用于字符串的查找<br>    :param original: 一个列表<br>    :<span class="hljs-built_in">type</span> original:<br>    :param sublist: sublist是original列表中的一部分，即子列表，如果存在sublist，那么就返回起始和结束位置，否<br>则返回None<br>    :<span class="hljs-built_in">type</span> sublist:<br>    :<span class="hljs-keyword">return</span>: 返回<span class="hljs-number">2</span>个值，bool值和查找到的索引值，如果没查找到返回[] 如果找到一个或找到多个，返回 [(x1,y1),(x2,y2)]<br>    :rtype:<br>    <span class="hljs-string">&quot;&quot;</span><span class="hljs-comment">&quot;</span><br>    ori_len = <span class="hljs-built_in">len</span>(original)<br>    sub_len = <span class="hljs-built_in">len</span>(sublist)<br>    find_indexes = []<br>    <span class="hljs-keyword">if</span> ori_len &lt; sub_len:<br>        <span class="hljs-keyword">return</span> find_indexes<br>    <span class="hljs-keyword">for</span> <span class="hljs-built_in">index</span> in <span class="hljs-built_in">range</span>(ori_len-sub_len+<span class="hljs-number">1</span>):<br>        <span class="hljs-keyword">if</span> original[<span class="hljs-built_in">index</span>:<span class="hljs-built_in">index</span> + sub_len] == sublist:<br>            find_indexes.<span class="hljs-keyword">append</span>((<span class="hljs-built_in">index</span>, <span class="hljs-built_in">index</span>+ sub_len))<br>    <span class="hljs-keyword">return</span> find_indexes<br><br>ori = [<span class="hljs-string">&#x27;《&#x27;</span>, <span class="hljs-string">&#x27;邪&#x27;</span>, <span class="hljs-string">&#x27;少&#x27;</span>, <span class="hljs-string">&#x27;兵&#x27;</span>, <span class="hljs-string">&#x27;王&#x27;</span>, <span class="hljs-string">&#x27;》&#x27;</span>, <span class="hljs-string">&#x27;是&#x27;</span>, <span class="hljs-string">&#x27;冰&#x27;</span>, <span class="hljs-string">&#x27;火&#x27;</span>, <span class="hljs-string">&#x27;未&#x27;</span>, <span class="hljs-string">&#x27;央&#x27;</span>, <span class="hljs-string">&#x27;写&#x27;</span>, <span class="hljs-string">&#x27;的&#x27;</span>, <span class="hljs-string">&#x27;网&#x27;</span>, <span class="hljs-string">&#x27;络&#x27;</span>, <span class="hljs-string">&#x27;小&#x27;</span>, <span class="hljs-string">&#x27;说&#x27;</span>, <span class="hljs-string">&#x27;连&#x27;</span>, <span class="hljs-string">&#x27;载&#x27;</span>, <span class="hljs-string">&#x27;于&#x27;</span>, <span class="hljs-string">&#x27;旗&#x27;</span>, <span class="hljs-string">&#x27;峰&#x27;</span>, <span class="hljs-string">&#x27;天&#x27;</span>, <span class="hljs-string">&#x27;下&#x27;</span>]<br>sub = [<span class="hljs-string">&#x27;网&#x27;</span>, <span class="hljs-string">&#x27;络&#x27;</span>, <span class="hljs-string">&#x27;小&#x27;</span>, <span class="hljs-string">&#x27;说&#x27;</span>]<br><span class="hljs-keyword">res</span> = index_partof_list(ori,sub)<br><span class="hljs-keyword">print</span>(<span class="hljs-keyword">res</span>)<br>------&gt;<br>[(<span class="hljs-number">13</span>, <span class="hljs-number">17</span>)]<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>python</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>对存在过合并的excel的单元格进行处理</title>
    <link href="/2022/02/22/pandas-na/"/>
    <url>/2022/02/22/pandas-na/</url>
    
    <content type="html"><![CDATA[<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p>日常我们经常遇到表头是合并的单元格，如左侧表头，或者上测表头都是合并过的，而我们想读取使用pandas读取的excel后，每列都进行对应回原来的数据的结构，那么这时就需要进行填充了，因为读取后，只有合并的单元格的第一行或第一列是有值的，其它都是nan，我们需要用前向填充的方法，ffill()<br>示例如图:</p><img src="/2022/02/22/pandas-na/shili1.png" class=""><h1 id="填充代码，可以给定超参数，填充表头，按行和按列填充"><a href="#填充代码，可以给定超参数，填充表头，按行和按列填充" class="headerlink" title="填充代码，可以给定超参数，填充表头，按行和按列填充"></a>填充代码，可以给定超参数，填充表头，按行和按列填充</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">fill_pdna</span>(<span class="hljs-params">df, row=[], col=[]</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    当excel的表头的行或列有合并单元格的情况时，只有第一个单元格是正确的，值，这时候需要使用前向填充ffill，即使用上一个单元格的内容填充当前为nan的单元格</span><br><span class="hljs-string">    但是填充的时候一般进行限制，只填充表头的前几行，或前几列</span><br><span class="hljs-string">    :param df:</span><br><span class="hljs-string">    :type df:</span><br><span class="hljs-string">    :param row: [] 表示所有行都使用前面的值进行填充，1表示第一行, eg: [1,2] 表示第1，2行用前面的值填充,-1表示不填充</span><br><span class="hljs-string">    :param col: []表示，所有列都使用前面的值填充， 0表示第一列, 注意行和列的其实索引位置不一样, -1表示不填充</span><br><span class="hljs-string">    :return:</span><br><span class="hljs-string">    :rtype:</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 首先对行进行填充，填充哪些行</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> row:<br>        <span class="hljs-comment"># 如果为空，先按行进行填充，行空的时候使用前一个单元格填充</span><br>        df = df.ffill(axis=<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> col:<br>        <span class="hljs-comment"># 然后对列进行填充</span><br>        df = df.ffill(axis=<span class="hljs-number">0</span>)<br>    <span class="hljs-keyword">if</span> col <span class="hljs-keyword">and</span> col != [-<span class="hljs-number">1</span>]:<br>        <span class="hljs-keyword">for</span> col_num <span class="hljs-keyword">in</span> col:<br>            df[col_num] = df[col_num].ffill(axis=<span class="hljs-number">0</span>)<br>    <span class="hljs-keyword">if</span> row <span class="hljs-keyword">and</span> row != [-<span class="hljs-number">1</span>]:<br>        <span class="hljs-keyword">for</span> row_num <span class="hljs-keyword">in</span> row:<br>            df[:row_num] = df[:row_num].ffill(axis=<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> df<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">read_excel</span>(<span class="hljs-params">excel_file</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    读取excel内容</span><br><span class="hljs-string">    :param excel_file:</span><br><span class="hljs-string">    :type excel_file:</span><br><span class="hljs-string">    :return:</span><br><span class="hljs-string">    :rtype:</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;开始读取<span class="hljs-subst">&#123;excel_file&#125;</span>&quot;</span>)<br>    df = pd.read_excel(excel_file, header=<span class="hljs-literal">None</span>)<br>    newdf = fill_pdna(df, row=[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>], col=[<span class="hljs-number">0</span>])<br>    <span class="hljs-built_in">print</span>(newdf)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>python</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>shap值的探索，判断shap值是否符合基本单调递增</title>
    <link href="/2022/02/18/shap-explore2/"/>
    <url>/2022/02/18/shap-explore2/</url>
    
    <content type="html"><![CDATA[<h1 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h1><ol><li>构建一个模型，本示例用的XGBoost，然后构建shap解释模型，使用shap值对模型特征进行解释</li><li>按特征重要性，这里对应的是shap值的绝对值的均值，shap_values.abs.mean，进行排序</li><li>如果特征符合基本单调递增, 不一定是线性的，因为特征之间可能有相关性,打印对应shap值为0附近的原始特征数值，用原始特征的均值代替</li></ol><h1 id="意义"><a href="#意义" class="headerlink" title="意义"></a>意义</h1><p>我们构建的是一个客户满意度模型，使用的是用户对一个商品的整体满意度与商品的各个属性满意度之间的关系，我们想找出当每个属性的满意度达到多少时，才能对整体满意度产生影响，即各个属性满意度的理想值。</p><p>示例代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> xgboost<br><span class="hljs-keyword">import</span> shap<br><span class="hljs-keyword">import</span> pickle<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> matplotlib <span class="hljs-keyword">as</span> mpl<br>mpl.rcParams[<span class="hljs-string">&#x27;font.family&#x27;</span>] = [<span class="hljs-string">&#x27;SimHei&#x27;</span>]<br>mpl.rcParams[<span class="hljs-string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="hljs-literal">False</span><br><br>saved_file = <span class="hljs-string">&#x27;/tmp/adult.pkl&#x27;</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">dump_info</span>(<span class="hljs-params">data</span>):<br>    pickle.dump(data, <span class="hljs-built_in">open</span>(saved_file, <span class="hljs-string">&quot;wb&quot;</span>))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;保存成功&quot;</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_info</span>():<br>    data = pickle.load(<span class="hljs-built_in">open</span>(saved_file, <span class="hljs-string">&quot;rb&quot;</span>))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;加载成功&quot;</span>)<br>    <span class="hljs-keyword">return</span> data<br><br><span class="hljs-keyword">if</span> os.path.exists(saved_file):<br>    X,y = load_info()<br><span class="hljs-keyword">else</span>:<br>    X,y = shap.datasets.adult()<br>    dump_info(data=(X,y))<br>model = xgboost.XGBClassifier().fit(X, y)<br><br><span class="hljs-comment"># compute SHAP values</span><br>explainer = shap.Explainer(model, X)<br>shap_values = explainer(X)<br><span class="hljs-comment"># shap_values [num_samples, num_features]</span><br><span class="hljs-comment"># shap.plots.beeswarm(shap_values)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">find_closely_sublist</span>(<span class="hljs-params">src_list, percent=<span class="hljs-number">0.05</span>, des_num=<span class="hljs-number">0.3</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    找出src_list 中与des_num最接近的数字，找到总数量的为百分之percent</span><br><span class="hljs-string">    :param src_list:</span><br><span class="hljs-string">    :type src_list: list</span><br><span class="hljs-string">    :param percent:</span><br><span class="hljs-string">    :type percent:</span><br><span class="hljs-string">    :param des_num:</span><br><span class="hljs-string">    :type des_num:</span><br><span class="hljs-string">    :return: 返回百分之percent的数据的个数的列表，列表是src_list的子列表</span><br><span class="hljs-string">    :rtype:</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 取值为0范围的%5的数</span><br>    total_num = <span class="hljs-built_in">len</span>(src_list)<br>    got_num = <span class="hljs-built_in">int</span>(total_num * percent)<br>    left_num = right_num = <span class="hljs-built_in">int</span>(got_num/<span class="hljs-number">2</span>)<br>    sorted_l = <span class="hljs-built_in">sorted</span>(src_list)<br>    <span class="hljs-comment">#定位与0最接近的位置的索引</span><br>    min_closest_idx = <span class="hljs-number">0</span><br>    min_closed_distance = <span class="hljs-number">100000</span><br>    <span class="hljs-keyword">for</span> idx, i <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(sorted_l):<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">abs</span>(i - des_num) &lt; min_closed_distance:<br>            min_closed_distance = <span class="hljs-built_in">abs</span>(i - des_num)<br>            min_closest_idx = idx<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;最接近于<span class="hljs-subst">&#123;des_num&#125;</span>的数字是<span class="hljs-subst">&#123;sorted_l[min_closest_idx]&#125;</span>&quot;</span>)<br>    start_idx = min_closest_idx - left_num<br>    <span class="hljs-keyword">if</span> start_idx &lt; <span class="hljs-number">0</span>:<br>        start_idx = <span class="hljs-number">0</span><br>    end_idx = min_closest_idx + right_num<br>    sublist = sorted_l[start_idx:end_idx]<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;收集接近于目标值<span class="hljs-subst">&#123;des_num&#125;</span>, 总数据条数:<span class="hljs-subst">&#123;total_num&#125;</span>, 收集占比为<span class="hljs-subst">&#123;percent&#125;</span>,共收集到数据条数: <span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(sublist)&#125;</span>条，分别是: <span class="hljs-subst">&#123;sublist&#125;</span>&quot;</span>)<br>    <span class="hljs-keyword">return</span> sublist<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_middle_data</span>(<span class="hljs-params">mean_shape</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    根据给定的shap，获取shap值为0时，原始data的值，因为有的值不是单递增的，还要判断是否是单调递增的， 统计的方法判断</span><br><span class="hljs-string">    根据均值和中位数，判断是否是单调递增的，大部分不是线性递增的</span><br><span class="hljs-string">    :param mean_shape:</span><br><span class="hljs-string">    :type mean_shape:</span><br><span class="hljs-string">    :return:</span><br><span class="hljs-string">    :rtype:</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    feature_name = mean_shape.feature_names<br>    shape_value = mean_shape.values<br>    feature_data = mean_shape.data<br>    <span class="hljs-comment"># 按大小排序</span><br>    sort_shap = np.sort(shape_value)<br>    sort_shap = sort_shap.tolist()<br>    <span class="hljs-comment"># 最接近0的shap值，大概5%</span><br>    sublist = find_closely_sublist(src_list=sort_shap,percent=<span class="hljs-number">0.05</span>, des_num=<span class="hljs-number">0</span>)<br>    <span class="hljs-comment"># 取0轴为的5%的数</span><br>    start_threhold, end_threhold = <span class="hljs-built_in">min</span>(sublist), <span class="hljs-built_in">max</span>(sublist)<br>    zero_range_shap_idx = np.where((shape_value &gt;= start_threhold) &amp; (shape_value &lt;= end_threhold))<br>    <span class="hljs-comment">#判断是否单调的问题，大部分shap值小于zero附近shap的，它对应的原始特征数也小于，shap值大于zero附近的，它的原始特征对应的数据也大于zero的原始特征，咱们都用平均值和中位数2个结合判断</span><br>    zero_range_data = feature_data[zero_range_shap_idx]<br>    zero_data_mean = np.mean(zero_range_data)<br>    zero_data_median = np.median(zero_range_data)<br>    less_zero_shap_idx = np.where(shape_value &lt; start_threhold)<br>    biger_zero_shap_idx = np.where(shape_value &gt; end_threhold)<br>    less_zero_data = feature_data[less_zero_shap_idx]<br>    biger_zero_data = feature_data[biger_zero_shap_idx]<br>    less_zero_mean = np.mean(less_zero_data)<br>    less_zero_median = np.median(less_zero_data)<br>    biger_zero_mean = np.mean(biger_zero_data)<br>    biger_zero_median = np.median(biger_zero_data)<br>    <span class="hljs-keyword">if</span> less_zero_mean &lt; zero_data_mean &lt; biger_zero_mean <span class="hljs-keyword">and</span> less_zero_median &lt; zero_data_median &lt; biger_zero_median:<br>        <span class="hljs-comment">#基本上是单调递增的，那么返回0的附近的对应的原始数据的均值, 即zero_data_mean</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span>, zero_data_mean, feature_name<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span>, <span class="hljs-number">0</span>, feature_name<br><br><span class="hljs-comment"># 打印前10个特征，按照shap值的重要性排序</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">10</span>, <span class="hljs-number">1</span>):<br>    mean_shape = shap_values[:, shap_values.<span class="hljs-built_in">abs</span>.mean(<span class="hljs-number">0</span>).argsort[-i]]<br>    is_monotone, middle_data, feature_name = get_middle_data(mean_shape)<br>    fig = plt.gcf()<br>    fig.set_size_inches(<span class="hljs-number">18.5</span>, <span class="hljs-number">10.5</span>, forward=<span class="hljs-literal">True</span>)<br>    ax = fig.gca()<br>    <span class="hljs-keyword">if</span> is_monotone:<br>        title = <span class="hljs-string">f&quot;特征<span class="hljs-subst">&#123;i&#125;</span>_<span class="hljs-subst">&#123;feature_name&#125;</span>是基本上是单调递增的，对应的shap值0附近的原始特征数据均值值是:<span class="hljs-subst">&#123;middle_data&#125;</span>&quot;</span><br>    <span class="hljs-keyword">else</span>:<br>        title = <span class="hljs-string">f&quot;特征<span class="hljs-subst">&#123;i&#125;</span>_<span class="hljs-subst">&#123;feature_name&#125;</span>不是单调递增的&quot;</span><br>    ax.set_title(title)<br>    shap.plots.scatter(shap_values = mean_shape, ax=ax)<br></code></pre></td></tr></table></figure><h1 id="绘图结果，按照特征重要性进行的排序"><a href="#绘图结果，按照特征重要性进行的排序" class="headerlink" title="绘图结果，按照特征重要性进行的排序"></a>绘图结果，按照特征重要性进行的排序</h1><img src="/2022/02/18/shap-explore2/shap1.png" class=""><img src="/2022/02/18/shap-explore2/shap2.png" class=""><img src="/2022/02/18/shap-explore2/shap3.png" class=""><img src="/2022/02/18/shap-explore2/shap4.png" class=""><img src="/2022/02/18/shap-explore2/shap5.png" class=""><img src="/2022/02/18/shap-explore2/shap6.png" class=""><img src="/2022/02/18/shap-explore2/shap7.png" class=""><img src="/2022/02/18/shap-explore2/shap8.png" class=""><img src="/2022/02/18/shap-explore2/shap9.png" class="">]]></content>
    
    
    <categories>
      
      <category>模型</category>
      
    </categories>
    
    
    <tags>
      
      <tag>可解释性</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
